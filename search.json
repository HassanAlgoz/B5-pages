[
  {
    "objectID": "index.html#week-2-data-work-etl-eda",
    "href": "index.html#week-2-data-work-etl-eda",
    "title": "AI Pros Bootcamp",
    "section": "Week 2: Data Work (ETL + EDA)",
    "text": "Week 2: Data Work (ETL + EDA)\n\n1. Foundations for an Offline‑First Data Workflow\n\n\n2. Verify + Clean + Join (first real EDA)\n\n\n3. Transform → Feature Table → EDA Tables (Tidy data + time + outliers)\n\n\n4. EDA with Plotly — Chart Choice + Uncertainty\n\n\n5. Ship a trustworthy data product (rebuild + metadata + SQL lens)"
  },
  {
    "objectID": "index.html#week-3-machine-learning",
    "href": "index.html#week-3-machine-learning",
    "title": "AI Pros Bootcamp",
    "section": "Week 3: Machine Learning",
    "text": "Week 3: Machine Learning\n\n1. ML in one picture + your dataset contract\n\n\n2. Split + baseline + train\n\n\n3. Evaluate + artifacts\n\n\n4. Predict CLI + inference contracts\n\n\n5. Write-up + submit"
  },
  {
    "objectID": "index.html#week-4-deep-learning",
    "href": "index.html#week-4-deep-learning",
    "title": "AI Pros Bootcamp",
    "section": "Week 4: Deep Learning",
    "text": "Week 4: Deep Learning\n\nModules"
  },
  {
    "objectID": "index.html#week-6-agentic-ai",
    "href": "index.html#week-6-agentic-ai",
    "title": "AI Pros Bootcamp",
    "section": "Week 6: Agentic AI",
    "text": "Week 6: Agentic AI\n\nDay 1:\n\nPrompting\nEvaluation and Structured Output\n\nDay 2:\n\nEmbeddings\nVector Stores\nRAG Architectures\n\nDay 3:\n\nIntroduction to Agents\nAgent Development Kit (ADK)\n\nDay 4:\n\nAgent Tools & Best Practices"
  },
  {
    "objectID": "index.html#week-7-building-ai-apps",
    "href": "index.html#week-7-building-ai-apps",
    "title": "AI Pros Bootcamp",
    "section": "Week 7: Building AI Apps",
    "text": "Week 7: Building AI Apps\n\nA learning outcome is a concise description of what students will learn and how that learning will be assessed. Having clearly articulated learning outcomes can make designing a course, assessing student learning progress, and facilitating learning activities easier and more effective. Learning outcomes can also help students regulate their learning and develop effective study strategies.\n\nRead Learning Outcomes for Week 7 Here.\n\nDaily Sessions\n\nDay 1:\n\n[M1] Client-server Architecture\nSelf-paced lab: curl_lab.md (B5 repo)\n[M2] FastAPI Introduction\n[M2] FastAPI Reading: Overview & Tooling (Session 1)\n\nDay 2:\n\n[M2] FastAPI Reading: Sessions (2 - 6)\n[M2] Becoming a 10x Developer\nAssignment: Build an API with FastAPI and Coding Agents (B5 repo)\n\nDay 3:\n\n[M3] Building MCP Servers\n[M4] Connecting to Backend Databases\n\nDay 4:\n\n[M5] Deployment"
  },
  {
    "objectID": "W7/curriculum.html",
    "href": "W7/curriculum.html",
    "title": "Week 7 Curriculum: Building AI Apps",
    "section": "",
    "text": "By the end of this module, you are able to:\n\nAnalyze client-server architecture features, use cases, and examples given a system diagram.\n\nIdentify the appropriate layer (client or server) for a specific unit of code.\n\nEvaluate the benefits of logical separation of concerns in distributed systems.\nExplain the necessity of specialized protocols like HTTP, LSP, and MCP.\nTrace the HTTP protocol flow and distinguish between Header and Body functions given a raw request.\nDifferentiate between a Resource and its various Representations.\nDeconstruct a URL into its component parts (scheme, host, path, query).\nAnalyze a RESTful endpoint to identify Nouns (resources) and Verbs (actions).\n\n\n\n\n\nMDN Web Docs: HTTP\nWikipedia: Client–server model"
  },
  {
    "objectID": "W7/curriculum.html#module-1-client-server-architecture",
    "href": "W7/curriculum.html#module-1-client-server-architecture",
    "title": "Week 7 Curriculum: Building AI Apps",
    "section": "",
    "text": "By the end of this module, you are able to:\n\nAnalyze client-server architecture features, use cases, and examples given a system diagram.\n\nIdentify the appropriate layer (client or server) for a specific unit of code.\n\nEvaluate the benefits of logical separation of concerns in distributed systems.\nExplain the necessity of specialized protocols like HTTP, LSP, and MCP.\nTrace the HTTP protocol flow and distinguish between Header and Body functions given a raw request.\nDifferentiate between a Resource and its various Representations.\nDeconstruct a URL into its component parts (scheme, host, path, query).\nAnalyze a RESTful endpoint to identify Nouns (resources) and Verbs (actions).\n\n\n\n\n\nMDN Web Docs: HTTP\nWikipedia: Client–server model"
  },
  {
    "objectID": "W7/curriculum.html#module-2-fastapi",
    "href": "W7/curriculum.html#module-2-fastapi",
    "title": "Week 7 Curriculum: Building AI Apps",
    "section": "Module 2: FastAPI",
    "text": "Module 2: FastAPI\nBy the end of this module, you are able to:\n\nLearning Objectives (Section 1): Fast API\n\nEvaluate the key features of FastAPI for building high-performance APIs.\nDistinguish between dev and production servers\nImplement Pydantic models to validate and serialize data.\nApply Python type hints and docstrings to enhance code quality.\nAppreciate the value of well-written documentation, as exemplified by FastAPI docs\nConstruct a simple RESTful API with multiple resources (items, users) and methods (GET, POST).\nStructure a FastAPI application using APIRouter for modular routing.\nUtilize advanced Pydantic features including BaseModel, Annotated, Literal, nested structures, and @field_validator.\n\n\n\nLearning Objectives (Section 2): Becoming a 10x Developer\n\nDistinguish between standard smart IDE features and AI-powered coding assistance.\nClassify AI agents based on Interaction and Environment dimensions.\nAnalyze factors contributing to the operational cost of Coding Agents.\nApply efficiency strategies to enhance development velocity.\nDemonstrate proficiency with VS Code navigation shortcuts (Quick file navigation, Go to Definition, Rename symbol).\nDemonstrate proficiency with VS Code editing shortcuts (Multi-cursor, Find/Replace, Global Search).\nExecute file comparisons using VS Code’s diff tools.\nExplain the role of MCP servers in extending Coding Agent capabilities.\nJustify the necessity of providing LLMs with up-to-date documentation.\n\n\n\nReferences\n\nFastAPI Documentation\nVS Code Documentation"
  },
  {
    "objectID": "W7/curriculum.html#module-3-building-an-mcp-server",
    "href": "W7/curriculum.html#module-3-building-an-mcp-server",
    "title": "Week 7 Curriculum: Building AI Apps",
    "section": "Module 3: Building an MCP Server",
    "text": "Module 3: Building an MCP Server\n\nLearning Objectives\nBy the end of this module, you are able to:\n\nConstruct a minimal MCP Server using the MCP Python SDK or FastMCP.\nRefactor an existing FastAPI server into a compliant MCP server using fastapi-mcp.\nIntegrate an Agent with an MCP server using an MCP Client (Google ADK, LangChain, or Pydantic AI).\n\n\n\nReferences\n\nMCP Python SDK\nFastMCP\nFastAPI-MCP"
  },
  {
    "objectID": "W7/curriculum.html#module-4-virtualization",
    "href": "W7/curriculum.html#module-4-virtualization",
    "title": "Week 7 Curriculum: Building AI Apps",
    "section": "Module 4: Virtualization",
    "text": "Module 4: Virtualization\nBy the end of this module, you are able to:\n\nLearning Objectives\n\nDistinguish between a Container (runtime) and an Image (build-time artifact).\nUtilize DockerHub to locate and pull official container images.\nOrchestrate multi-container environments using Docker CLI and Docker Compose.\nConfigure Docker volumes to persist data generated by running containers.\nDifferentiate between execution stack layers: Hardware, Platform, Runtime, and Application.\nEstablish a secure database connection using the psycopg driver.\nConstruct schema definitions and execute database queries using SQLAlchemy.\nManage database schema evolution using dbmate migration scripts.\n\n\n\nReferences\n\nدليل المطور الشامل - حسان القوز"
  },
  {
    "objectID": "W7/curriculum.html#module-5-deployment",
    "href": "W7/curriculum.html#module-5-deployment",
    "title": "Week 7 Curriculum: Building AI Apps",
    "section": "Module 5: Deployment",
    "text": "Module 5: Deployment\n\nLearning Objectives\nBy the end of this module, you are able to:\n\nConfigure a FastAPI application for production by separating configuration settings from code using Environment Variables.\nDeploy a web service to a PaaS provider (e.g., Railway) by integrating with a Version Control System.\nProvision a managed release of PostgreSQL and configure internal networking to connect it with the web service.\nDiagnose deployment errors (e.g., Build failures, Crashing processes) by inspecting platform logs.\nValidate the public deployment by executing requests against the production URL.\nImplement a Continuous Deployment (CD) workflow where git push triggers automatic rebuilding and redeployment.\n\n\n\nReferences\n\nRailway Documentation\nFastAPI Deployment"
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#the-hook",
    "href": "W7/M4/01_backend_databases.html#the-hook",
    "title": "Connecting to Backend Databases",
    "section": "The Hook",
    "text": "The Hook\n\n\n\nFigure: A stylized pipeline connecting a database cylinder to a Python logo, symbolizing a robust connection.\n\n\nHow do I direct my SQL commands to a database system and connect my Python application to it?\n\nWe’ve built agents and APIs, but now we need persistent storage. Databases are the foundation of any real application. But how do we get started? We need to understand the environment where databases run, how to set them up reliably, and how to connect our Python code to them. This journey will take us through virtualization, Docker containers, connection protocols, and modern Python frameworks that make database work practical and safe."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#todays-journey-12",
    "href": "W7/M4/01_backend_databases.html#todays-journey-12",
    "title": "Connecting to Backend Databases",
    "section": "Today’s Journey (1/2)",
    "text": "Today’s Journey (1/2)\n\nSetting Up the Database\n\nEnvironment setup and virtualization\nDocker containers vs virtual machines\nRunning PostgreSQL with Docker Compose\n\nConnecting the Application\n\nUsing psycopg driver\nDB-API 2.0 protocol\nTransactions and cursors\n\n\n\nToday we’ll cover four major topics. First, we’ll set up a database environment using Docker, understanding the difference between containers and virtual machines. Then we’ll connect our Python application using the psycopg driver."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#todays-journey-22",
    "href": "W7/M4/01_backend_databases.html#todays-journey-22",
    "title": "Connecting to Backend Databases",
    "section": "Today’s Journey (2/2)",
    "text": "Today’s Journey (2/2)\n\nSQLAlchemy Framework\n\nCore concepts: Engine, Metadata, Tables\nBuilding queries in Python\nConnection pooling\n\nDatabase Migrations\n\nVersion control for schema\nMigration scripts with dbmate\nSafe schema evolution\n\n\n\nNext, we’ll level up to SQLAlchemy, a framework that solves many problems with raw database drivers. Finally, we’ll learn about migrations—the professional way to evolve your database schema without losing data. Each step builds on the previous one."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#part-1-setting-up-the-database",
    "href": "W7/M4/01_backend_databases.html#part-1-setting-up-the-database",
    "title": "Connecting to Backend Databases",
    "section": "Part 1: Setting Up the Database",
    "text": "Part 1: Setting Up the Database"
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#the-problem-environment-complexity",
    "href": "W7/M4/01_backend_databases.html#the-problem-environment-complexity",
    "title": "Connecting to Backend Databases",
    "section": "The Problem: Environment Complexity",
    "text": "The Problem: Environment Complexity\nSoftware needs an environment\n\nCPU architecture (x86/x64, ARM)\nOperating system\nMemory and I/O devices\nInstalled binaries and libraries\nConfiguration files\n\nThe challenge: Conflicts between different software requirements\n\nA database is software—compiled binary instructions that run on hardware. But software doesn’t run in isolation. It needs an environment: the right CPU architecture, operating system, memory, network access, storage, installed libraries, and configuration files. The problem developers have faced for decades is that different software needs different environments, and these can conflict with each other. One project needs Python 3.9, another needs 3.11. One needs PostgreSQL 14, another needs 16. Managing these conflicts manually is a nightmare."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#the-solution-containerization",
    "href": "W7/M4/01_backend_databases.html#the-solution-containerization",
    "title": "Connecting to Backend Databases",
    "section": "The Solution: Containerization",
    "text": "The Solution: Containerization\n\n\nDocker packages everything together\n\nApplication binaries\nLibraries and dependencies\nConfiguration files\nAll in one isolated container\n\n\n\n\n\nFigure: A transparent shipping container revealing neatly packed binaries, libraries, and configurations. (Click to Enlarge)\n\n\n\n\nDocker emerged as a solution. Instead of just packaging compiled binaries, Docker packages everything: the binaries, the libraries, the configuration files—all into a single unit called a container. The Docker platform on your machine runs these containers in isolation from each other, preventing conflicts. This is a fundamental shift in how we think about deployable units."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#benefits-of-containerization",
    "href": "W7/M4/01_backend_databases.html#benefits-of-containerization",
    "title": "Connecting to Backend Databases",
    "section": "Benefits of Containerization",
    "text": "Benefits of Containerization\n\nBetter development experience\n\nFocus on real problems, not environment setup\n\nEasier collaboration\n\nEvery developer has the same environment\n\nProject isolation\n\nSwitch between projects without conflicts\n\nSimplified deployment\n\nSame container works in development and production\n\n\n\nThe benefits are immediate. You can focus on solving actual application problems instead of wrestling with environment setup. When collaborating, everyone runs the exact same environment. You can work on multiple projects on the same machine without conflicts. And the same container that works on your laptop works in production. This abstraction removes a huge class of problems."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#virtualization-background",
    "href": "W7/M4/01_backend_databases.html#virtualization-background",
    "title": "Connecting to Backend Databases",
    "section": "Virtualization Background",
    "text": "Virtualization Background\n\n\n\nVirtualization (1966)\n\nDividing expensive mainframes into multiple virtual computers\nFoundation of cloud computing\n\nContainerization (2008-2013)\n\nInternal project at dotCloud (France)\nOpen-sourced as Docker by Solomon Hykes (March 2013)\n\n\n\n\n\n\nFigure: A timeline showing the evolution from mainframes to virtual machines and finally to containers.\n\n\n\n\nThis didn’t come out of nowhere. Virtualization dates back to 1966, when expensive mainframes were divided into multiple virtual computers for better efficiency. That’s the foundation of cloud computing. Containerization evolved from this. It started as an internal project at dotCloud in France around 2008, and was open-sourced as Docker in March 2013 by Solomon Hykes. It’s a relatively recent innovation that’s become essential."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#dockerfile-vs-image-vs-container",
    "href": "W7/M4/01_backend_databases.html#dockerfile-vs-image-vs-container",
    "title": "Connecting to Backend Databases",
    "section": "Dockerfile vs Image vs Container",
    "text": "Dockerfile vs Image vs Container\n\n\n\nDockerfile, Image, and Container\n\n\nDockerfile: A recipe for building a Docker image\nImage: A template for creating a container\nContainer: A running instance of an image\n\nA Dockerfile is a recipe for building a Docker image. An image is a template for creating a container. A container is a running instance of an image.\nSee Getting Started Workshop | Docker Documentation"
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#container-vs-virtual-machine",
    "href": "W7/M4/01_backend_databases.html#container-vs-virtual-machine",
    "title": "Connecting to Backend Databases",
    "section": "Container vs Virtual Machine",
    "text": "Container vs Virtual Machine\n\n\n\nEvolution of Containers\n\n\nBoth are isolated environments from an image\nDifference: What the image contains\n\nVM Image: includes a full operating system\nContainer Image: shares the host OS kernel\n\n\nBoth containers and virtual machines provide isolated environments created from images. The key difference is what’s in the image. A VM image includes a full operating system. A container image shares the host OS kernel."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#containers-are-lighter",
    "href": "W7/M4/01_backend_databases.html#containers-are-lighter",
    "title": "Connecting to Backend Databases",
    "section": "Containers are lighter",
    "text": "Containers are lighter\n\nLess resource consumption\nFaster startup/shutdown\nEasier to manage\n\n\n… this makes containers much lighter—they consume fewer resources, start and stop faster, and are easier to manage. For most applications, containers are the better choice."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#running-postgresql-with-docker",
    "href": "W7/M4/01_backend_databases.html#running-postgresql-with-docker",
    "title": "Connecting to Backend Databases",
    "section": "Running PostgreSQL with Docker",
    "text": "Running PostgreSQL with Docker\nStep 1: Create environment file (.env)\nPOSTGRES_HOST=127.0.0.1\nPOSTGRES_DB=mydatabase\nPOSTGRES_USER=user\nPOSTGRES_PASSWORD=secret\n\nNow let’s get practical. First, we create an environment file to store our database configuration. This keeps sensitive information like passwords out of our code. We’ll reference this file in our Docker Compose configuration."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#docker-compose-configuration",
    "href": "W7/M4/01_backend_databases.html#docker-compose-configuration",
    "title": "Connecting to Backend Databases",
    "section": "Docker Compose Configuration",
    "text": "Docker Compose Configuration\nStep 2: Define services in compose.yaml\nservices:\n  db:\n    image: postgres:17.6\n    env_file:\n      - .env\n    ports:\n      - \"5432:5432\"\n    volumes:\n      - pgdata:/var/lib/postgresql/data\n\nvolumes:\n  pgdata:\n\nDocker Compose lets us define our services in a YAML file. We specify the PostgreSQL image from DockerHub, point to our environment file, map the port so we can connect from outside the container, and most importantly, create a volume to persist data. Without the volume, all data would be lost when the container stops."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#understanding-docker-compose-elements",
    "href": "W7/M4/01_backend_databases.html#understanding-docker-compose-elements",
    "title": "Connecting to Backend Databases",
    "section": "Understanding Docker Compose Elements",
    "text": "Understanding Docker Compose Elements\n\nimage: postgres:17.6 - Image name and version from DockerHub\nenv_file - References our .env file\nports: \"5432:5432\" - Maps host port to container port\nvolumes: pgdata - Persists data outside the container\n\n\nLet’s break down what each part does. The image tells Docker what to download from DockerHub. The env_file loads our configuration. The ports mapping lets us connect from our host machine. And the volume is critical—it stores the database data on the host filesystem, so it persists even when the container is destroyed. This is how we solve the data persistence problem."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#starting-and-stopping",
    "href": "W7/M4/01_backend_databases.html#starting-and-stopping",
    "title": "Connecting to Backend Databases",
    "section": "Starting and Stopping",
    "text": "Starting and Stopping\nStart the database:\ndocker compose up\nStop the database:\ndocker compose down\n\nStarting is simple: just run docker compose up. Docker will download the image if needed, create the container, and start it. To stop, use docker compose down. The data in the volume persists, so when you start again, your data is still there."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#connecting-to-the-database",
    "href": "W7/M4/01_backend_databases.html#connecting-to-the-database",
    "title": "Connecting to Backend Databases",
    "section": "Connecting to the Database",
    "text": "Connecting to the Database\nMany Approaches:\n\nCLI: psql (text interface)\nGUI: Adminer or VS Code Database Client\nDB-API: psycopg driver and sqlalchemy framework\nMCP: DBHub (Bytebase) MCP server for agentic access\n\n\nOnce the database is running, we need to connect to it. There are many approaches: the command-line tool psql, which is powerful but text-based, or graphical tools like Adminer or the VS Code Database Client extension, which are more user-friendly. The DB-API is what psycopg used by sqlalchemy framework implements. Finally, MCP allows agents to connect to the database and query and store data."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#part-2-connecting-the-application",
    "href": "W7/M4/01_backend_databases.html#part-2-connecting-the-application",
    "title": "Connecting to Backend Databases",
    "section": "Part 2: Connecting the Application",
    "text": "Part 2: Connecting the Application"
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#the-question",
    "href": "W7/M4/01_backend_databases.html#the-question",
    "title": "Connecting to Backend Databases",
    "section": "The Question",
    "text": "The Question\nHow do I connect a Python application to the database to query and store data?\nAnswer: Use the psycopg package\n\nNow that we have a running database, we need to connect our Python code to it. The answer is the psycopg package, which implements the DB-API 2.0 protocol. This is the standard way Python talks to PostgreSQL databases."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#db-api-2.0-protocol",
    "href": "W7/M4/01_backend_databases.html#db-api-2.0-protocol",
    "title": "Connecting to Backend Databases",
    "section": "DB-API 2.0 Protocol",
    "text": "DB-API 2.0 Protocol\nStandardized database interface in Python: fetchone(), fetchmany(), fetchall(), execute(), commit(), rollback(), etc.\n\npsycopg implements this protocol for PostgreSQL\nWorks with other databases: SQLite, MySQL, etc.\n\n\nThe DB-API 2.0 is a standardized protocol for database access in Python. psycopg implements this protocol for PostgreSQL. The beautiful thing is that once you understand this protocol, you can apply the same concepts to other database drivers. The patterns are consistent."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#step-1-import-and-install",
    "href": "W7/M4/01_backend_databases.html#step-1-import-and-install",
    "title": "Connecting to Backend Databases",
    "section": "Step 1: Import and Install",
    "text": "Step 1: Import and Install\nInstall the package:\nuv add \"psycopg[binary]\"\nImport in Python:\nimport psycopg\n\nFirst, we install psycopg using uv. The [binary] extra includes pre-compiled binaries for faster installation. Then we import it in our Python code. Simple enough."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#step-2-create-connection",
    "href": "W7/M4/01_backend_databases.html#step-2-create-connection",
    "title": "Connecting to Backend Databases",
    "section": "Step 2: Create Connection",
    "text": "Step 2: Create Connection\nConnection string format (URI):\nconn = psycopg.connect(\n    'postgresql://user:password@localhost:5432/dbname'\n)\nOr with parameters (conninfo):\nconn = psycopg.connect(\n    conninfo=(\n      'user=user password=secret '\n      'host=localhost port=5432 dbname=testdb')\n)\n\nCreating a connection requires connection information: the user, password, host, port, and database name. You can provide this as a URI string or as individual parameters. The URI format is more compact and commonly used. Notice we’re using localhost and port 5432, which matches our Docker setup. The conninfo format is more verbose but allows for more flexibility."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#connection-string-sources",
    "href": "W7/M4/01_backend_databases.html#connection-string-sources",
    "title": "Connecting to Backend Databases",
    "section": "Connection String Sources",
    "text": "Connection String Sources\nTwo places connection info can come from:\n\nEnvironment variables (from .env file)\nConnection string parameters (URI or conninfo)\n\nBoth are checked by psycopg\n\nIt’s important to know that psycopg checks two places for connection information: environment variables and the connection string parameter. Some values might be set in your .env file, others in the connection string. If you’re having connection issues, check both places."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#step-3-working-with-data",
    "href": "W7/M4/01_backend_databases.html#step-3-working-with-data",
    "title": "Connecting to Backend Databases",
    "section": "Step 3: Working with Data",
    "text": "Step 3: Working with Data"
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#create-a-cursor-cur-from-the-connection-conn",
    "href": "W7/M4/01_backend_databases.html#create-a-cursor-cur-from-the-connection-conn",
    "title": "Connecting to Backend Databases",
    "section": "Create a cursor (cur) from the connection (conn):",
    "text": "Create a cursor (cur) from the connection (conn):\nwith conn.cursor() as cur:\n    cur.execute(\"SELECT name, age FROM users WHERE age &gt; 18\")\n    rows = cur.fetchall()\n\nTo interact with the database, we create a cursor from the connection. The cursor is our interface for sending commands and reading results. We use a context manager (the with statement) to ensure proper cleanup. Then we execute SQL commands and fetch results."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#why-execute-and-fetch",
    "href": "W7/M4/01_backend_databases.html#why-execute-and-fetch",
    "title": "Connecting to Backend Databases",
    "section": "Why execute AND fetch?",
    "text": "Why execute AND fetch?\nAccording to the PEP 249 specification:\n\nexecute(): Submits the SQL to the database, parses it, and identifies the matching rows. The database creates a “result set” or a pointer (cursor) to those rows.\nfetch*(): These methods are the actual data transfer mechanism. They move the data from the database server/buffer into your Python environment as objects (tuple or list).\n\n\nSee: Cursor Objects | PEP 249"
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#reading-data",
    "href": "W7/M4/01_backend_databases.html#reading-data",
    "title": "Connecting to Backend Databases",
    "section": "Reading Data",
    "text": "Reading Data\nFour ways to fetch rows:\n# Fetch one row\nrow = cur.fetchone()\n\n# Fetch many rows\nrows = cur.fetchmany(10)\n\n# Fetch all rows\nall_rows = cur.fetchall()\n\n# Or iterate\nfor row in cur:\n    print(row)\n\nFor reading data, we have three main methods: fetchone gets a single row, fetchmany gets a specified number, and fetchall gets everything. The cursor is also iterable, so you can loop over it directly. For large result sets, be careful with fetchall—it loads everything into memory at once."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#writing-data",
    "href": "W7/M4/01_backend_databases.html#writing-data",
    "title": "Connecting to Backend Databases",
    "section": "Writing Data",
    "text": "Writing Data\nUsing transactions:\nwith psycopg.connect(conn_string) as conn:\n    with conn.cursor() as cur:\n        cur.execute(\n            \"INSERT INTO test (num, data) VALUES (%s, %s)\",\n            (100, \"abc'def\")\n        )\n        # Transaction commits automatically\n\nWhen writing data, we use transactions. The connection context manager automatically handles this. If everything succeeds, it commits. If an error occurs, it rolls back. This ensures data integrity. Notice we use parameterized queries with %s placeholders—this prevents SQL injection attacks."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#problems-with-raw-drivers",
    "href": "W7/M4/01_backend_databases.html#problems-with-raw-drivers",
    "title": "Connecting to Backend Databases",
    "section": "Problems with Raw Drivers",
    "text": "Problems with Raw Drivers\nWhat psycopg doesn’t solve:\n\nSQL written as strings (raw SQL) → typos, syntax errors\nParameter passing (not using placeholders) → SQL injection risks\nConnection management (not using connection pooling) → expensive to create connections\n\n\nWhile psycopg works, it has limitations. Writing SQL as strings means typos and syntax errors aren’t caught until runtime. Parameter passing can be error-prone. The code is database-specific, making it hard to switch databases. And creating connections is expensive—we need connection pooling. This is where SQLAlchemy comes in."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#part-3-sqlalchemy-framework",
    "href": "W7/M4/01_backend_databases.html#part-3-sqlalchemy-framework",
    "title": "Connecting to Backend Databases",
    "section": "Part 3: SQLAlchemy Framework",
    "text": "Part 3: SQLAlchemy Framework"
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#what-is-sqlalchemy",
    "href": "W7/M4/01_backend_databases.html#what-is-sqlalchemy",
    "title": "Connecting to Backend Databases",
    "section": "What is SQLAlchemy?",
    "text": "What is SQLAlchemy?\n\n\nPython’s most popular database framework\n\nRaises database work to a higher level\nSolves driver limitations\nTwo parts: Core and ORM\n\n\n\n\n\nFigure: A diagram showing raw SQL transforming through SQLAlchemy into clean Python code.\n\n\n\n\nSQLAlchemy is Python’s most popular database framework. It elevates database work from the low-level driver world to a higher abstraction. It solves all those problems we just identified: type safety, security, database portability, and connection pooling. SQLAlchemy has two main parts: Core, which we’ll focus on, and ORM, which maps database tables to Python classes."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#the-engine",
    "href": "W7/M4/01_backend_databases.html#the-engine",
    "title": "Connecting to Backend Databases",
    "section": "The Engine",
    "text": "The Engine\nCentral component: manages connections\nfrom sqlalchemy import create_engine, URL\n\nengine = create_engine(\n    url=URL.create(\n        \"postgresql+psycopg\",\n        username=os.getenv(\"POSTGRES_USER\"),\n        password=os.getenv(\"POSTGRES_PASSWORD\"),\n        host=os.getenv(\"POSTGRES_HOST\"),\n        database=os.getenv(\"POSTGRES_DB\"),\n    )\n)\nUsually a singleton (one per database)\n\nThe Engine is the heart of SQLAlchemy. It manages connection pooling—creating connections, keeping them alive, and reusing them. This solves the expensive connection creation problem. You typically create one engine per database, and it’s shared across your application. Notice the connection string format: “postgresql+psycopg” where postgresql is the dialect and psycopg is the driver."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#dialect-vs-driver",
    "href": "W7/M4/01_backend_databases.html#dialect-vs-driver",
    "title": "Connecting to Backend Databases",
    "section": "Dialect vs Driver",
    "text": "Dialect vs Driver\nConnection string: postgresql+psycopg\n\nDialect (postgresql): SQL language variant\n\nAlso: mysql, sqlite, mssql, oracle\n\nDriver (psycopg): Low-level communication\n\nAlso: asyncpg, pymysql, pyodbc\n\n\nSeparation allows flexibility\n\nThe connection string separates dialect from driver. The dialect is the SQL language variant—PostgreSQL has different syntax than MySQL. The driver is the low-level communication library. This separation is powerful: you can use different drivers with the same dialect, or switch dialects while keeping similar code structure."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#defining-schema-with-metadata",
    "href": "W7/M4/01_backend_databases.html#defining-schema-with-metadata",
    "title": "Connecting to Backend Databases",
    "section": "Defining Schema with Metadata",
    "text": "Defining Schema with Metadata\nMetadata: describes your database structure\nfrom sqlalchemy.schema import MetaData, Table, Column\nfrom sqlalchemy.types import Integer, String, Date\n\nmetadata = MetaData()\n\nusers_table = Table(\n    \"users\",\n    metadata,\n    Column(\"id\", Integer, primary_key=True),\n    Column(\"name\", String(100)),\n    Column(\"birth_date\", Date)\n)\n\nInstead of writing raw SQL CREATE TABLE statements, we define our schema using Python objects. Metadata is a container for all our table definitions. We create Table objects with Column definitions. This gives us type safety and Python’s help with autocomplete and error checking."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#creating-tables",
    "href": "W7/M4/01_backend_databases.html#creating-tables",
    "title": "Connecting to Backend Databases",
    "section": "Creating Tables",
    "text": "Creating Tables\nApply definitions to the database:\nmetadata.create_all(engine)\nTranslates to SQL:\nCREATE TABLE users (\n    id INTEGER NOT NULL,\n    name VARCHAR(100),\n    birth_date DATE,\n    PRIMARY KEY (id)\n);\n\nWhen we call create_all, SQLAlchemy translates our Python definitions into SQL DDL statements and executes them. This is much safer than writing SQL by hand—we get Python’s type checking and IDE support. However, this method is destructive and only suitable for development. For production, we need migrations."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#foreign-keys",
    "href": "W7/M4/01_backend_databases.html#foreign-keys",
    "title": "Connecting to Backend Databases",
    "section": "Foreign Keys",
    "text": "Foreign Keys\nDefining relationships:\nfrom sqlalchemy.schema import ForeignKey\n\nuser_emails_table = Table(\n    \"user_emails\",\n    metadata,\n    Column(\"id\", Integer, primary_key=True),\n    Column(\"user_id\", ForeignKey(\"users.id\"), nullable=False),\n    Column(\"email\", String, nullable=False),\n)\n\nForeign keys define relationships between tables. Here, each email must belong to a user. The ForeignKey constraint ensures data integrity—you can’t create an email without a valid user_id. SQLAlchemy handles the SQL translation automatically."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#inserting-data",
    "href": "W7/M4/01_backend_databases.html#inserting-data",
    "title": "Connecting to Backend Databases",
    "section": "Inserting Data",
    "text": "Inserting Data\nBuilding insert statements:\nfrom sqlalchemy.sql.expression import insert\n\nstmt = (\n    insert(users_table)\n    .values(\n        name=\"Adam Banana\",\n        birth_date=datetime.date(1990, 1, 1)\n    )\n    .returning(users_table.c.id)\n)\n\nInstead of writing INSERT SQL strings, we build statements using Python functions. The .values() method sets the data to insert. The .returning() clause gets back the generated ID. This is type-safe and prevents SQL injection."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#executing-statements",
    "href": "W7/M4/01_backend_databases.html#executing-statements",
    "title": "Connecting to Backend Databases",
    "section": "Executing Statements",
    "text": "Executing Statements\nSending to database:\nwith engine.connect() as conn:\n    result = conn.execute(stmt)\n    conn.commit()\n    row = result.fetchone()\n    user_id = row[0]\n\nWe get a connection from the engine, execute our statement, manually commit the transaction, and fetch the result. The connection context manager handles cleanup. The result cursor works just like psycopg cursors, following the DB-API standard."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#selecting-data",
    "href": "W7/M4/01_backend_databases.html#selecting-data",
    "title": "Connecting to Backend Databases",
    "section": "Selecting Data",
    "text": "Selecting Data\nBuilding SELECT queries:\nfrom sqlalchemy.sql.expression import select\n\nstmt = (\n    select(users_table.c.name, users_table.c.birth_date)\n    .where(users_table.c.id == user_id)\n)\n\nwith engine.connect() as conn:\n    result = conn.execute(stmt)\n    row = result.fetchone()\n\nSELECT queries are built using the select() function. We reference columns using table.c.column_name syntax, which gives us autocomplete and type checking. The .where() method adds conditions. This is much safer than string concatenation."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#aggregations",
    "href": "W7/M4/01_backend_databases.html#aggregations",
    "title": "Connecting to Backend Databases",
    "section": "Aggregations",
    "text": "Aggregations\nUsing SQL functions:\nfrom sqlalchemy.sql.functions import count\n\nstmt = (\n    select(\n        user_emails_table.c.user_id,\n        count(user_emails_table.c.email)\n    )\n    .group_by(user_emails_table.c.user_id)\n)\n\nSQLAlchemy provides functions for aggregations like count, sum, min, max. We use them in select statements and combine with group_by for summaries. All of this is type-safe and translates to correct SQL."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#raw-sql-when-needed",
    "href": "W7/M4/01_backend_databases.html#raw-sql-when-needed",
    "title": "Connecting to Backend Databases",
    "section": "Raw SQL When Needed",
    "text": "Raw SQL When Needed\nSQLAlchemy allows raw SQL:\nfrom sqlalchemy import text\n\nsql_text = text(\n    \"SELECT name, salary FROM employees \"\n    \"WHERE department = :dept AND salary &gt; :min_sal\"\n)\n\nresult = conn.execute(\n    sql_text,\n    {\"dept\": \"Sales\", \"min_sal\": 50000}\n)\n\nSometimes you need raw SQL for complex queries. SQLAlchemy allows this through the text() function. Notice we still use parameterized queries with :parameter_name syntax. This maintains security by preventing SQL injection while giving us the flexibility of raw SQL when needed."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#part-4-database-migrations",
    "href": "W7/M4/01_backend_databases.html#part-4-database-migrations",
    "title": "Connecting to Backend Databases",
    "section": "Part 4: Database Migrations",
    "text": "Part 4: Database Migrations"
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#the-problem",
    "href": "W7/M4/01_backend_databases.html#the-problem",
    "title": "Connecting to Backend Databases",
    "section": "The Problem",
    "text": "The Problem\nSchema changes (CREATE TABLE, ALTER TABLE, DROP TABLE, …etc.) applied manually are dangerous:\n\ndata loss risk, hard to roll back (undo)\nnot reproducible, out-of-sync between:\n\ndifferent environments (development, staging, production)\ndifferent developers working on the same codebase\n\nnot auditable, no history of:\n\nwhat was changed\nwho changed it\nwhen it was changed\nwhy it was changed\n\n\n\nWe’ve been using create_all() and drop_all(), but these are destructive and only work for development. In real applications, we need to evolve the schema over time without losing data. Manual changes are dangerous—they’re not reproducible, hard to roll back, and environments drift apart. We need version control for our database schema, just like we have for our code."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#version-control-for-code",
    "href": "W7/M4/01_backend_databases.html#version-control-for-code",
    "title": "Connecting to Backend Databases",
    "section": "Version Control for Code",
    "text": "Version Control for Code\n\n\nGit tracks code changes:\n\nLine-by-line history\nTime travel (undo)\nReview before merging\nCollaboration\n\nWe need the same for database schema.\n\n\n\n\nFigure: A split-view document showing code diffs with red deletions and green additions under a branching icon.\n\n\n\n\nWe use git for version control of our code. It tracks every change, lets us travel back in time, requires review before merging, and enables collaboration. We need the exact same thing for our database schema. Every schema change should be a script that’s tracked in git, reviewed, and applied consistently across all environments."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#migration-scripts",
    "href": "W7/M4/01_backend_databases.html#migration-scripts",
    "title": "Connecting to Backend Databases",
    "section": "Migration Scripts",
    "text": "Migration Scripts\nSolution: Migration scripts\n\nEach change is a script\nTracked in git\nReversible (up and down)\nApplied automatically\n\nTool: dbmate\n\nThe solution is migration scripts. Each schema change becomes a script that’s tracked in git. Each script has an “up” direction (apply the change) and a “down” direction (reverse it). These scripts are applied automatically, ensuring all environments stay in sync. We’ll use dbmate, a simple and effective migration tool."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#installing-dbmate",
    "href": "W7/M4/01_backend_databases.html#installing-dbmate",
    "title": "Connecting to Backend Databases",
    "section": "Installing dbmate",
    "text": "Installing dbmate\nOn Linux:\nsudo curl -fsSL -o /usr/local/bin/dbmate \\\n  https://github.com/amacneil/dbmate/releases/latest/download/dbmate-linux-amd64\nsudo chmod +x /usr/local/bin/dbmate\n\ndbmate is a single binary, making installation straightforward. We download it, make it executable, and it’s ready to use. It reads the DATABASE_URL from environment variables or a .env file."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#configuration",
    "href": "W7/M4/01_backend_databases.html#configuration",
    "title": "Connecting to Backend Databases",
    "section": "Configuration",
    "text": "Configuration\nSet DATABASE_URL in .env:\nDATABASE_URL=\"postgres://user:password@127.0.0.1:5432/testdb?sslmode=disable\"\ndbmate reads this automatically\n\ndbmate looks for a DATABASE_URL environment variable. We can set it in our .env file. The format is a standard database URI. Notice the ?sslmode=disable parameter—we’re disabling SSL since we’re running locally. dbmate will read this automatically."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#creating-a-migration-file",
    "href": "W7/M4/01_backend_databases.html#creating-a-migration-file",
    "title": "Connecting to Backend Databases",
    "section": "Creating a Migration File",
    "text": "Creating a Migration File\nGenerate new migration file:\ndbmate new \"add_users_table\"\nCreates a file with two sections:\n-- migrate:up\n\n\n-- migrate:down\n\nTo create a migration, we run dbmate new with a descriptive name. This creates a new migration file with two sections: migrate:up for applying the change, and migrate:down for reversing it."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#writing-the-migration-sql",
    "href": "W7/M4/01_backend_databases.html#writing-the-migration-sql",
    "title": "Connecting to Backend Databases",
    "section": "Writing the Migration SQL",
    "text": "Writing the Migration SQL\nWe write the SQL for both directions. This ensures we can always roll back.\n-- migrate:up\nCREATE TABLE users (id SERIAL PRIMARY KEY);\n\n-- migrate:down\nDROP TABLE users;"
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#applying-migrations",
    "href": "W7/M4/01_backend_databases.html#applying-migrations",
    "title": "Connecting to Backend Databases",
    "section": "Applying Migrations",
    "text": "Applying Migrations\nRun pending migrations:\ndbmate up\nRoll back last migration:\ndbmate down\nCheck status:\ndbmate status\n\nTo apply migrations, we run dbmate up. It checks which migrations have been applied and runs only the new ones. To roll back, we use dbmate down, which reverses the most recent migration. We can check the status to see which migrations have been applied."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#version-controlled-migrations-workflow-12",
    "href": "W7/M4/01_backend_databases.html#version-controlled-migrations-workflow-12",
    "title": "Connecting to Backend Databases",
    "section": "Version Controlled Migrations Workflow (1/2)",
    "text": "Version Controlled Migrations Workflow (1/2)\n1. Create migration:\ndbmate new \"add_email_column\"\n2. Write up and down SQL:\n-- migrate:up\nALTER TABLE users ADD COLUMN email VARCHAR;\n\n-- migrate:down\nALTER TABLE users DROP COLUMN email;"
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#version-controlled-migrations-workflow-22",
    "href": "W7/M4/01_backend_databases.html#version-controlled-migrations-workflow-22",
    "title": "Connecting to Backend Databases",
    "section": "Version Controlled Migrations Workflow (2/2)",
    "text": "Version Controlled Migrations Workflow (2/2)\n3. Update Python models:\nusers = Table(\n    \"users\",\n    metadata,\n    Column(\"id\", Integer, primary_key=True),\n    Column(\"email\", String),  # NEW\n)\n4. Commit both together:\ngit add db/migrations/xxx_add_email_column.sql\ngit add src/models.py\ngit commit -m \"schema: add email column to users\"\n\nHere’s the professional workflow. We create a migration, write both the up and down SQL, update our Python models to match, and commit both the migration script and the model changes together in a single git commit. This keeps everything in sync. If someone pulls this commit, they get both the migration and the code that uses it."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#key-takeaways",
    "href": "W7/M4/01_backend_databases.html#key-takeaways",
    "title": "Connecting to Backend Databases",
    "section": "Key Takeaways",
    "text": "Key Takeaways"
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#database-setup",
    "href": "W7/M4/01_backend_databases.html#database-setup",
    "title": "Connecting to Backend Databases",
    "section": "1. Database Setup",
    "text": "1. Database Setup\n\nContainers solve environment problems\n\nPackage everything together\nIsolated from conflicts\nSame environment everywhere\n\nDocker Compose simplifies orchestration\n\nDefine services in YAML\nVolumes persist data\nOne command to start/stop\n\n\n\nLet’s recap what we’ve learned. Containers solve the environment problem by packaging everything together in isolation. Docker Compose makes it easy to define and run our database with a simple YAML file. Volumes ensure our data persists even when containers are destroyed."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#database-connections",
    "href": "W7/M4/01_backend_databases.html#database-connections",
    "title": "Connecting to Backend Databases",
    "section": "2. Database Connections",
    "text": "2. Database Connections\n\nDB-API 2.0 is the standard\n\npsycopg implements it for PostgreSQL\nPatterns transfer to other databases\n\nTransactions ensure data integrity\n\nAutomatic commit/rollback\nContext managers handle cleanup\n\n\n\nDB-API 2.0 provides a standard interface for database access. psycopg implements this for PostgreSQL, and the patterns you learn apply to other database drivers. Transactions are crucial for data integrity, and context managers make them easy to use correctly."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#sqlalchemy-benefits",
    "href": "W7/M4/01_backend_databases.html#sqlalchemy-benefits",
    "title": "Connecting to Backend Databases",
    "section": "3. SQLAlchemy Benefits",
    "text": "3. SQLAlchemy Benefits\n\nType-safe database code\n\nPython objects instead of SQL strings\nIDE autocomplete and error checking\n\nConnection pooling\n\nReuses expensive connections\nBetter performance\n\nDatabase portability\n\nSwitch databases with minimal code changes\nDialect handles SQL differences\n\n\n\nSQLAlchemy elevates database work to a higher level. We get type safety through Python objects, connection pooling for better performance, and database portability through the dialect system. It solves all the problems we identified with raw drivers."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#migration-best-practices",
    "href": "W7/M4/01_backend_databases.html#migration-best-practices",
    "title": "Connecting to Backend Databases",
    "section": "4. Migration Best Practices",
    "text": "4. Migration Best Practices\n\nVersion control your schema\n\nEvery change is a script\nTracked in git\nReversible\n\nKeep migrations and models in sync\n\nCommit migration and code changes together\nEnsures consistency across environments\n\n\n\nMigrations are essential for professional database development. Every schema change becomes a versioned script that’s tracked in git and reversible. Most importantly, we keep our migration scripts and Python models in sync by committing them together. This ensures everyone’s database schema matches their code."
  },
  {
    "objectID": "W7/M4/01_backend_databases.html#the-complete-picture",
    "href": "W7/M4/01_backend_databases.html#the-complete-picture",
    "title": "Connecting to Backend Databases",
    "section": "The Complete Picture",
    "text": "The Complete Picture\n\n\n\nFigure: A system diagram connecting a Dockerized PostgreSQL database, Python app via SQLAlchemy, and Git-tracked migrations.\n\n\nYou now have a Professional workflow:\n\nIsolated database environment (PostgreSQL in Docker)\nType-safe database code (sqlalchemy with psycopg)\nVersion-controlled schema (dbmate and git)\n\n\nPutting it all together: we have an isolated database running in Docker, type-safe database code using SQLAlchemy, version-controlled schema through migrations, and a professional workflow that scales from development to production. This is the foundation for building real applications with persistent data storage."
  },
  {
    "objectID": "W7/M2/di.html#motivating-problem",
    "href": "W7/M2/di.html#motivating-problem",
    "title": "Module 2: FastAPI",
    "section": "Motivating Problem",
    "text": "Motivating Problem\nDatabase Session Management."
  },
  {
    "objectID": "W7/M2/di.html#database-session-management",
    "href": "W7/M2/di.html#database-session-management",
    "title": "Module 2: FastAPI",
    "section": "1. Database Session Management",
    "text": "1. Database Session Management\ndef get_user_endpoint(user_id: int):\n    # 1. SETUP: Manually create the connection\n    db = Database()\n    \n    try:\n        # A. Data Access\n        user = db.execute(f\"SELECT * FROM users WHERE id={user_id}\")\n        \n        # B. Business Logic\n        process_user_data(user)\n        \n        # C. Return Result\n        return user\n        \n    except Exception as e:\n        # D. ERROR HANDLING\n        # ...\n        \n    finally:\n        # 2. TEARDOWN: Manually closing. \n        # If you forget this block, the server eventually crashes.\n        db.close()\n\n\nProblem 1: repetition opens room for errors:\n\nOne might forget to close the connection; which leads to server crashing\nOne might misplace the code in the catch or try when you must put it in the finally\n\nProblem 2: imagine having to repeat this code for every function that needs database access"
  },
  {
    "objectID": "W7/M2/di.html#dependency-injection",
    "href": "W7/M2/di.html#dependency-injection",
    "title": "Module 2: FastAPI",
    "section": "Dependency Injection",
    "text": "Dependency Injection\n\nThe Dependency Injection (DI) system is designed to minimize code repetition by handling logic that is required before the path operation function executes.\n\ndef db_connection():\n    # ...\n\ndef main_endpoint(db_connection: DatabaseConnection = Depends(db_connection)):\n    # ...\n\nOther common terms for this same idea of “dependency injection” are:\n\nresources\nproviders\nservices\ninjectables\ncomponents"
  },
  {
    "objectID": "W7/M2/di.html#using-yield",
    "href": "W7/M2/di.html#using-yield",
    "title": "Module 2: FastAPI",
    "section": "Using yield",
    "text": "Using yield\nA function that returns a generator with a yield statement:\n\nWhen a request is received, FastAPI executes code before the yield (setup).\nWhen the request is finished, FastAPI executes code after the yield (teardown).\n\ndef db_connection():\n    db = Database()\n    yield db\n    db.close()"
  },
  {
    "objectID": "W7/M2/di.html#dependency-graph",
    "href": "W7/M2/di.html#dependency-graph",
    "title": "Module 2: FastAPI",
    "section": "Dependency Graph",
    "text": "Dependency Graph\nFastAPI does not just pass arguments; it builds a Dependency Graph. This is a concept from Graph Theory.\nTheory: Your API is a graph where Nodes are functions and Edges are dependencies. \\(A \\to B\\) means “A depends on B”."
  },
  {
    "objectID": "W7/M2/di.html#example",
    "href": "W7/M2/di.html#example",
    "title": "Module 2: FastAPI",
    "section": "Example",
    "text": "Example\n# Node C: The Config\ndef get_config():\n    return {\"model\": \"gpt-4\"}\n\n# Node D: The Client (Depends on C)\ndef get_llm(config = Depends(get_config)):\n    return OpenAI(model=config[\"model\"])\n\n# Node E: The Endpoint (Depends on D)\n# FastAPI automatically runs: get_config() -&gt; get_llm() -&gt; endpoint()\n@app.get(\"/\")\ndef endpoint(llm = Depends(get_llm)):\n    return llm.generate()\n\nIf Endpoint \\(E\\) needs Database \\(D\\), and Database \\(D\\) needs Config \\(C\\): \\[E \\to D \\to C\\]\nTopological Sort: FastAPI resolves this graph from the bottom up. It creates \\(C\\), passes it to \\(D\\), creates \\(D\\), and passes it to \\(E\\)."
  },
  {
    "objectID": "W7/M2/di.html#enforcing-authentication",
    "href": "W7/M2/di.html#enforcing-authentication",
    "title": "Module 2: FastAPI",
    "section": "Enforcing Authentication",
    "text": "Enforcing Authentication\nDependencies are also the primary way FastAPI handles security.\n\nScenario: Specific routes (like /users/me) require the user to be logged in.\nMechanism: You define a get_current_user dependency. If the user is invalid, the dependency raises an HTTP exception (e.g., 401 Unauthorized) immediately, preventing the route logic from ever running.\n\ndef oauth2_scheme(...):\n    # ...\n    \n\ndef get_current_user(token: str = Depends(oauth2_scheme)):\n    # this code won't run if oauth2_scheme raises an exception\n    # ..."
  },
  {
    "objectID": "W7/M2/di.html#shared-query-parameters",
    "href": "W7/M2/di.html#shared-query-parameters",
    "title": "Module 2: FastAPI",
    "section": "Shared Query Parameters",
    "text": "Shared Query Parameters\nYou can group common query parameters into a single reusable class or function.\n\nScenario: Multiple endpoints (/items, /users, /logs) all need skip and limit parameters for pagination.\nMechanism: Instead of repeating skip: int = 0, limit: int = 10 in every function signature, you define a common_parameters dependency and inject it into each route.\n\ndef common_pagination(q: str | None = None, skip: int = 0, limit: int = 100):\n    return {\"q\": q, \"skip\": skip, \"limit\": limit}\n\n\n@app.get(\"/items/\")\ndef get_items(common_params: Annotated[dict, Depends(common_pagination)]):\n    # use common_params\n    # ..."
  },
  {
    "objectID": "W7/M2/02_fastapi_reading.html",
    "href": "W7/M2/02_fastapi_reading.html",
    "title": "FastAPI Reading",
    "section": "",
    "text": "FastAPI is a modern, fast (high-performance), web framework for building APIs with Python based on standard Python type hints."
  },
  {
    "objectID": "W7/M2/02_fastapi_reading.html#session-1-overview-tooling",
    "href": "W7/M2/02_fastapi_reading.html#session-1-overview-tooling",
    "title": "FastAPI Reading",
    "section": "Session 1: Overview & Tooling",
    "text": "Session 1: Overview & Tooling\n\nTutorial - User Guide ~ 5 min (Introductory)\nFirst Steps ~ 5-10 min\nStatic Files ~ 5 min\nFastAPI CLI ~ 5–10 min\nIntro to Python Types ~ 20–30 min\nFeatures ~ 3–5 min"
  },
  {
    "objectID": "W7/M2/02_fastapi_reading.html#session-2-request-handling",
    "href": "W7/M2/02_fastapi_reading.html#session-2-request-handling",
    "title": "FastAPI Reading",
    "section": "Session 2: Request Handling",
    "text": "Session 2: Request Handling\n\nPath Parameters ~ 10 min\nQuery Parameters ~ 10 min\nRequest Body ~ 10-15 min\nQuery Parameters and String Validations ~ 10-15 min\nPath Parameters and Numeric Validations ~ 10 min\nQuery Parameter Models ~ 10 min"
  },
  {
    "objectID": "W7/M2/02_fastapi_reading.html#session-3-request-body",
    "href": "W7/M2/02_fastapi_reading.html#session-3-request-body",
    "title": "FastAPI Reading",
    "section": "Session 3: Request Body",
    "text": "Session 3: Request Body\n\nBody - Multiple Parameters ~ 15 min\nBody - Fields ~ 10 min\nBody - Nested Models ~ 20-25 min (Complex structure)\nDeclare Request Example Data ~ 10 min\nExtra Data Types ~ 5-10 min\n\nExtra:\n\nDebugging ~ 5-10 min"
  },
  {
    "objectID": "W7/M2/02_fastapi_reading.html#session-4-headers-and-cookies",
    "href": "W7/M2/02_fastapi_reading.html#session-4-headers-and-cookies",
    "title": "FastAPI Reading",
    "section": "Session 4: Headers and Cookies",
    "text": "Session 4: Headers and Cookies\n\nCookie Parameters ~ 5-10 min\nHeader Parameters ~ 5-10 min\nCookie Parameter Models ~ 5-10 min\nHeader Parameter Models ~ 5-10 min\n\nExtra:\n\nMiddleware ~ 10 min"
  },
  {
    "objectID": "W7/M2/02_fastapi_reading.html#session-5-form-data-and-files",
    "href": "W7/M2/02_fastapi_reading.html#session-5-form-data-and-files",
    "title": "FastAPI Reading",
    "section": "Session 5: Form Data and Files",
    "text": "Session 5: Form Data and Files\n\nForm Data ~ 10-15 min\nForm Models ~ 10 min\nRequest Files ~ 10-15 min\nRequest Forms and Files ~ 10 min\nBody - Updates ~ 10-15 min (Logic heavy)"
  },
  {
    "objectID": "W7/M2/02_fastapi_reading.html#session-6-response",
    "href": "W7/M2/02_fastapi_reading.html#session-6-response",
    "title": "FastAPI Reading",
    "section": "Session 6: Response",
    "text": "Session 6: Response\n\nResponse Model - Return Type ~ 15-20 min\nExtra Models (Modular Design Concept: Decoupling) ~ 10-15 min\nResponse Status Code ~ 5-10 min\n\nExtra:\n\nHandling Errors (a bit nuanced) ~ 15-25 min\nJSON Compatible Encoder (needed for Database) ~ 5-10 min\nHTMLResponse (1 small section)"
  },
  {
    "objectID": "W7/M2/02_fastapi_reading.html#session-7",
    "href": "W7/M2/02_fastapi_reading.html#session-7",
    "title": "FastAPI Reading",
    "section": "Session 7",
    "text": "Session 7\n\nPath Operation Configuration (important for Agents’ tool-use) ~ 10-15 min\nTesting ~ 20-30 min (Heavy code)"
  },
  {
    "objectID": "W7/M2/02_fastapi_reading.html#session-8",
    "href": "W7/M2/02_fastapi_reading.html#session-8",
    "title": "FastAPI Reading",
    "section": "Session 8",
    "text": "Session 8\n\nDependencies ~ 20-30 min (Core Concept: Intro + Sub-chapters)\nSQL (Relational) Databases ~ 30-40 min (Very Long, heavy code)"
  },
  {
    "objectID": "W7/M2/02_fastapi_reading.html#session-9",
    "href": "W7/M2/02_fastapi_reading.html#session-9",
    "title": "FastAPI Reading",
    "section": "Session 9",
    "text": "Session 9\n\nSecurity ~ 25-35 min (Overview + Implementation steps)\nCORS (Cross-Origin Resource Sharing) ~ 10 min"
  },
  {
    "objectID": "W7/M2/02_fastapi_reading.html#session-10",
    "href": "W7/M2/02_fastapi_reading.html#session-10",
    "title": "FastAPI Reading",
    "section": "Session 10",
    "text": "Session 10\n\nBigger Applications - Multiple Files (Code Structure) ~ 20-25 min\nMetadata and Docs URLs ~ 10-15 min\n\nExtra:\n\nConcurrency and async / await ~ 10–15 min"
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#the-cloud-isnt-magic",
    "href": "W7/M1/01_client-server_arch.html#the-cloud-isnt-magic",
    "title": "Introduction to Client-server Architecture",
    "section": "The “Cloud” isn’t Magic",
    "text": "The “Cloud” isn’t Magic\n\nFigure: A whimsical illustration of a cloud being unzipped to reveal racks of computer servers inside. The style should be modern, clean line art with blue and white tones.The Cloud is just someone else’s computer.\n\n\nHook: We often talk about the “Cloud” as this abstract, magical entity.\nToday, we’re going to demystify it.\nWhen you strip away the marketing, the cloud is physically just servers—computers—racked in a datacenter, listening for your messages."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#server-side-website-programming",
    "href": "W7/M1/01_client-server_arch.html#server-side-website-programming",
    "title": "Introduction to Client-server Architecture",
    "section": "Server-Side Website Programming",
    "text": "Server-Side Website Programming\n\nWeb browsers and servers communicate via HyperText Transfer Protocol (HTTP).\nEvery action—clicking a link, submitting a form, or searching—triggers an HTTP Request from the browser to the server.\nSame for mobile apps.\n\n\nThe web server “listens” for incoming messages, processes the logic, and returns an HTTP Response."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#capabilities-of-server-side-programming",
    "href": "W7/M1/01_client-server_arch.html#capabilities-of-server-side-programming",
    "title": "Introduction to Client-server Architecture",
    "section": "Capabilities of Server-Side Programming",
    "text": "Capabilities of Server-Side Programming\n\nEfficient Information Delivery\nTailored User Experiences\nControlled Access & Security\nSession & State Management\nData Analysis"
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#efficient-information-delivery-15",
    "href": "W7/M1/01_client-server_arch.html#efficient-information-delivery-15",
    "title": "Introduction to Client-server Architecture",
    "section": "Efficient Information Delivery (1/5)",
    "text": "Efficient Information Delivery (1/5)\nInstead of creating millions of static HTML files, servers use databases to dynamically construct pages.\n\nDynamic Generation: Templates are populated with data (JSON, XML, HTML) on the fly.\nScalability: Handles vast inventories (Amazon) or billions of posts (Facebook) using a single layout structure.\nCross-System Sharing: Inventory databases can sync across web stores and physical shops simultaneously.\n\n\nNote: Your imagination doesn’t have to work hard to see the benefit of server-side code for efficient storage and delivery of information:\n\nGo to Amazon or some other e-commerce site.\nSearch for a number of keywords and note how the page structure doesn’t change, even though the results do.\nOpen two or three different products. Note again how they have a common structure and layout, but the content for different products has been pulled from the database.\n\nFor a common search term (“fish”, say) you can see literally millions of returned values. Using a database allows these to be stored and shared efficiently, and it allows the presentation of the information to be controlled in just one place."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#tailored-user-experiences-25",
    "href": "W7/M1/01_client-server_arch.html#tailored-user-experiences-25",
    "title": "Introduction to Client-server Architecture",
    "section": "Tailored User Experiences (2/5)",
    "text": "Tailored User Experiences (2/5)\nServers store and analyze client data to provide convenience and personalization:\n\nSaved Preferences: Persistent storage for credit cards, shipping addresses, and search history.\nLocation Awareness: Services like Google Maps provide routing based on real-time or saved locations.\nPredictive Logic: Autocomplete and search suggestions based on deep analysis of user habits.\n\n\nNote: Google Maps saves your search and visit history. Frequently visited or frequently searched locations are highlighted more than others.\n\nGoogle search results are optimized based on previous searches.\nGo to Google search.\nSearch for “football”.\n\nNow try typing “favorite” in the search box and observe the autocomplete search predictions.\nCoincidence? Nada!"
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#controlled-access-security-35",
    "href": "W7/M1/01_client-server_arch.html#controlled-access-security-35",
    "title": "Introduction to Client-server Architecture",
    "section": "Controlled Access & Security (3/5)",
    "text": "Controlled Access & Security (3/5)\nServer-side logic acts as a gatekeeper for sensitive or private data:\n\nAuthentication: Restricts data access to authorized users (e.g., Online Banking).\nPermissions: Social media platforms use server code to determine who can see specific posts or feeds.\n\n\nNote: Consider other real examples where access to content is controlled. For example, what can you see if you go to the online site for your bank? Log in to your account — what additional information can you see and modify? What information can you see that only the bank can change?"
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#session-state-management-45",
    "href": "W7/M1/01_client-server_arch.html#session-state-management-45",
    "title": "Introduction to Client-server Architecture",
    "section": "Session & State Management (4/5)",
    "text": "Session & State Management (4/5)\nServers use sessions to “remember” users as they navigate or return to a site:\n\nPersistence: Staying logged in across multiple tabs or resuming a game where you left off.\nBusiness Logic: Tracking article views on news sites to trigger subscription prompts via cookies.\n\n\nNote: Visit a newspaper site that has a subscription model and open a bunch of tabs (e.g., The Age). Continue to visit the site over a few hours/days. Eventually, you will start to be redirected to pages explaining how to subscribe, and you will be unable to access articles. This information is an example of session information stored in cookies."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#data-analysis-55",
    "href": "W7/M1/01_client-server_arch.html#data-analysis-55",
    "title": "Introduction to Client-server Architecture",
    "section": "Data Analysis (5/5)",
    "text": "Data Analysis (5/5)\nWebsites use server-side logic to log and monitor user interactions that occur beyond simple page views:\n\nBehavioral: What you search for, recommend, and how long you stay on a specific page.\nTransactional: Purchase history, cart additions, and payment methods.\nContextual: Device type, location (via IP), and referral sources.\n\n\nAnalyzing data on the server rather than the client (browser) offers critical technical advantages:\n\nAccuracy: Bypasses browser-based ad blockers and privacy settings that often strip out tracking scripts.\nData Enrichment: The server can combine “live” click data with “historical” data from a CRM (Customer Relationship Management) database to create a complete user profile.\nPrivacy Control: Sensitive data can be cleaned or anonymized on the server before being sent to third-party analytics tools."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#physical-vs.-logical",
    "href": "W7/M1/01_client-server_arch.html#physical-vs.-logical",
    "title": "Introduction to Client-server Architecture",
    "section": "Physical vs. Logical",
    "text": "Physical vs. Logical\n\nFigure: Two diagrams. Top: ‘Physical’ showing a Laptop connected to a Server Rack. Bottom: ‘Logical’ showing two software boxes ‘Browser’ and ‘Localhost Server’ both inside the same Laptop icon.Logical Tier \\(\\neq\\) Physical Tier.\n\n\nCrucial distinction: “Client” and “Server” are roles, not just boxes.\nPhysical: Your laptop vs AWS.\nLogical: You can run both on your laptop (localhost).\nThis is how we develop. We simulate the world on one machine."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#examples-in-the-wild",
    "href": "W7/M1/01_client-server_arch.html#examples-in-the-wild",
    "title": "Introduction to Client-server Architecture",
    "section": "Examples in the Wild",
    "text": "Examples in the Wild\n\nLSP vs No LSP. Note that MCP (Model-Context Protocol) is influenced by LSP.\nIDE (LSP): Editor (Client) \\(\\leftrightarrow\\) Language Server.\nJupyter: Notebook (Client) \\(\\leftrightarrow\\) Kernel (Server).\n\n\n\nIt’s not just web browsers.\nJupyter: You can run the interface on your laptop, but the Kernel on the Cloud.\nWhen you code in VS Code, the “Client” is the UI, and a separate “Server” provides errors/autocomplete.\nThe protocol they use to communicate is called LSP (Language Server Protocol)"
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#overview-of-http",
    "href": "W7/M1/01_client-server_arch.html#overview-of-http",
    "title": "Introduction to Client-server Architecture",
    "section": "Overview of HTTP",
    "text": "Overview of HTTP\n\nCore Definition: An application-layer protocol for fetching resources (HTML, images, video).\nArchitecture: A client-server model where the recipient (User-Agent) initiates requests.\nTransport: Primarily runs over TCP or TLS-encrypted connections for reliability.\n\n\nHTTP is the foundation of data exchange on the Web. While it usually runs over TCP, it can theoretically use any reliable transport protocol."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#key-components-clients-servers",
    "href": "W7/M1/01_client-server_arch.html#key-components-clients-servers",
    "title": "Introduction to Client-server Architecture",
    "section": "Key Components: Clients & Servers",
    "text": "Key Components: Clients & Servers\n\nUser-Agent: Any tool acting for the user (usually a browser). It is always the entity initiating the request.\nWeb Server: A virtual machine or collection of machines (load balancers) that serves the requested document.\nProxies: Intermediate nodes performing caching, filtering, load balancing, or authentication.\n\n\nProxies sit between them, operating at the application layer to manage traffic and security."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#the-http-flow",
    "href": "W7/M1/01_client-server_arch.html#the-http-flow",
    "title": "Introduction to Client-server Architecture",
    "section": "The HTTP Flow",
    "text": "The HTTP Flow\n\nTCP Connection: Establishing a reliable channel for message exchange.\nThe Request: Sending a human-readable (or binary frame) message to the server.\nThe Response: Reading the status code and resource returned by the server.\nConclusion: Closing or reusing the connection for the next request.\n\n\nHTTP/2 introduced multiplexing, allowing multiple requests to be sent over a single “warm” connection simultaneously."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#url-anatomy",
    "href": "W7/M1/01_client-server_arch.html#url-anatomy",
    "title": "Introduction to Client-server Architecture",
    "section": "URL Anatomy",
    "text": "URL Anatomy\n\nFigure: Example URL: http://example.com/api/users?id=123&status=active\nScheme: http (Protocol).\nHost: example.com (Where).\nPath: /api/users (What).\nQuery: ?id=123&status=active (Parameters).\n\n\n\nExplaining: Let’s dissect a URL. It’s not just a random string; it has anatomy.\nScheme: How are we talking? (HTTP/HTTPS).\nHost: Which building are we going to? (Server address).\nPath: Which room in that building? (Resource location).\nQuery: Specific instructions? (Sort by price, Page 2).\nLandmark: Understanding this structure helps you debug why a request might be failing."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#parameters-in-the-query-string",
    "href": "W7/M1/01_client-server_arch.html#parameters-in-the-query-string",
    "title": "Introduction to Client-server Architecture",
    "section": "Parameters in the Query String",
    "text": "Parameters in the Query String\nCommon Use Cases:\n\nFiltering: ?category=electronics&sort=price_desc\nSearching: ?q=how+to+build+a+website (note: + is URL encoded for space)\nTracking: ?utm_source=newsletter (Commonly used in marketing analytics).\nPagination: ?page=2\n\n\n\nWhile query strings are great for bookmarkable links (like search results)\nthe request body (POST) is the standard for complex or secure data transmission."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#resources-vs-representations",
    "href": "W7/M1/01_client-server_arch.html#resources-vs-representations",
    "title": "Introduction to Client-server Architecture",
    "section": "Resources vs Representations",
    "text": "Resources vs Representations\n\nFigure: An abstract cube labeled ‘Resource (User)’. Two arrows point from it to ‘JSON File’ and ‘HTML Page’. Text: ‘One Resource, Many Representations’.\nResource: The concept (e.g., User Profile).\nRepresentation: The format (.json, .html).\nContent Negotiation: “I speak JSON, please send JSON.”\n\n\n\nExplaining: There is a Zen-like distinction in REST between the Thing and the Representation of the Thing.\nStorytelling: Think of a “User Profile.” That is the Resource.\nBut how do I give it to you?\n\nI can write it on paper (HTML).\nI can burn it onto a CD (binary).\nI can read it aloud (JSON).\n\nYou ask for the Resource, but the server sends a Representation. Negotiating the best format is key to flexible APIs."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#http-methods",
    "href": "W7/M1/01_client-server_arch.html#http-methods",
    "title": "Introduction to Client-server Architecture",
    "section": "HTTP Methods",
    "text": "HTTP Methods\n\nGET: Retrieve a representation of a resource (Read).\nPOST: Create a new resource within a collection (Create).\nPUT: Replace an entire resource or create if missing (Update/Replace).\nPATCH: Apply partial modifications to a resource (Partial Update).\nDELETE: Remove a specific resource (Delete).\n\n\n\nMDN Web Docs emphasize that GET and HEAD methods are “safe” because they do not change the state of the server\nwhereas POST, PUT, and DELETE are intended to modify data."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#http-message-request",
    "href": "W7/M1/01_client-server_arch.html#http-message-request",
    "title": "Introduction to Client-server Architecture",
    "section": "HTTP Message: Request",
    "text": "HTTP Message: Request\n\nFigure: HTTP Request Message Components\nHeader: Metadata (Context, Auth, Negotiation).\nBody: Payload (Data, Files) - Empty in GET.\nSeparation: Headers tell us how to process the Body.\n\n\n\nExplaining: Think of an HTTP request like a physical letter or package.\nLandmark: There are two main parts: the Envelope (Headers) and the Contents (Body).\nThe Header contains metadata: “I am using Chrome,” “I want JSON data,” or “Here is my ID badge (Cookie).” This tells the server how to handle the message.\nThe Body is the actual cargo. If you’re uploading a photo, the photo accounts for the bytes in the body.\nReasoning: Why separate them? It allows the server to make decisions (routing, authentication) without having to open the entire package first."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#some-request-headers",
    "href": "W7/M1/01_client-server_arch.html#some-request-headers",
    "title": "Introduction to Client-server Architecture",
    "section": "Some Request Headers",
    "text": "Some Request Headers\n\nIllustration of a client and server negotiating content format.\nUser-Agent: “Hello, I am Firefox”.\nAccept: “I want JSON”.\nAccept-Encoding: “Please gzip the response” (Compression).\n\n\n\nStorytelling: Imagine walking into a bakery in Paris.\nYou say, “Bonjour” (Handshake), and “I would like a baguette” (Request). But you also add, “I only speak English” (Accept-Language) and “Please put it in a bag” (Accept-Encoding).\nExplaining: This is Content Negotiation. The client tells the server what it can handle.\nReasoning: Compression (gzip) is critical because bandwidth costs money and time. If we can shrink a text file by 70% before sending it, the website loads faster. The browser then “unzips” it automatically."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#http-response-status-codes",
    "href": "W7/M1/01_client-server_arch.html#http-response-status-codes",
    "title": "Introduction to Client-server Architecture",
    "section": "HTTP Response Status Codes",
    "text": "HTTP Response Status Codes\n\nFigure: A traffic light arrangement. Green light labeled ‘200 OK’. Yellow light labeled ‘301 Redirect’. Red light labeled ‘404/500 Error’.\n200 OK: Success.\n301/302: Redirect (Moved).\nClient error (400 – 499):\n\n400 Bad Request: You sent garbage.\n401 Unauthorized: Who are you?\n403 Forbidden: Not allowed.\n404 Not Found: Are you lost?\n\n500 Internal Error: Server exploded.\n\n\n\nLandmark: Status codes are the traffic lights of the web.\nExplaining: The first digit tells the story:\n\n2xx: “All Good.” Green light.\n3xx: “Go over there.” Detour.\n4xx: “You messed up.” The client sent a bad request.\n5xx: “I messed up.” The server crashed.\n\nStorytelling: If you walk into a store and ask for a product they don’t sell, that’s a 404 (Your mistake). If you walk in and the shelf falls on you, that’s a 500 (Their mistake).\n\nSee HTTP response status codes | MDN."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#the-address-problem",
    "href": "W7/M1/01_client-server_arch.html#the-address-problem",
    "title": "Introduction to Client-server Architecture",
    "section": "The Address Problem",
    "text": "The Address Problem\n\nFigure: A person looking confused at a long string of numbers ‘142.250.190.46’. A thought bubble shows ‘google.com’.Humans remember Names. Machines leverage IPs.\n\n\nHook: Try to memorize 142.250.190.46. Now try to memorize google.com.\nReasoning: Humans are terrible at remembering unique strings of numbers. We are great at language.\nComputers complement this: they are terrible at ambiguity but great at precise numerical addressing.\nWe need a system to bridge this gap."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#dns-the-address-book",
    "href": "W7/M1/01_client-server_arch.html#dns-the-address-book",
    "title": "Introduction to Client-server Architecture",
    "section": "DNS: The Address Book",
    "text": "DNS: The Address Book\n\nFigure: An Address Book Mapping Domain Names to IP AddressesDomain Name System matches Names to IPs.\n\n\nExplaining: DNS is the phonebook of the internet.\nYou look up a name (Google), and it gives you the number (IP Address) to dial.\nLandmark: It’s hierarchical.\n\nRead right-to-left: .com (Top Level), google (Domain), maps (Subdomain).\n\nWithout DNS, we’d be memorizing IP addresses for every website we visit."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#localhost",
    "href": "W7/M1/01_client-server_arch.html#localhost",
    "title": "Introduction to Client-server Architecture",
    "section": "Localhost",
    "text": "Localhost\n\nFigure: A looping arrow connecting a computer back to itself. Text label: ‘127.0.0.1’ and ‘Home’.localhost = 127.0.0.1 “There’s no place like home.”\n\n\nExplaining: There is a special IP address reserved for “This Computer.”\n127.0.0.1 is Localhost. It’s the digital equivalent of talking to yourself.\nReasoning: Why do we need this? It allows us to run a server and a client on the same machine for development.\nWhen you ping localhost, the signal never leaves your potential network card. It loops right back."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#try-it",
    "href": "W7/M1/01_client-server_arch.html#try-it",
    "title": "Introduction to Client-server Architecture",
    "section": "Try It",
    "text": "Try It\n\nEdit /etc/hosts (Mac/Linux) or System32/.../hosts (Win).\nMap 127.0.0.1 to me.com.\nBrowser -&gt; http://me.com -&gt; Your Local Server.\n\n\n\nThis proves DNS isn’t magic. It’s just a lookup.\nYou can override it locally for your machine.\nGreat for development (simulating production domains)."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#stateless-conversation",
    "href": "W7/M1/01_client-server_arch.html#stateless-conversation",
    "title": "Introduction to Client-server Architecture",
    "section": "Stateless Conversation",
    "text": "Stateless Conversation\n\nFigure: A comic strip style sequence. Panel 1: Client asks for page. Server gives page. Panel 2: Client asks again. Server looks blank and says ‘Who are you?’.\nDefinition: Server retains no memory of past requests.\nImplication: Every request must contain all necessary info (Auth, Context).\nFeature, not Bug: Easier to scale (Load Balancing).\n\n\n\nLandmark: This is the most important concept in HTTP: Statelessness.\nStorytelling: Imagine a barista who has amnesia.\nYou order a latte. They make it. You come back 5 seconds later for sugar. They look at you blankly and say, “Who are you?”\nReasoning: This sounds annoying, but it’s great for scale. If that barista takes a break, any other barista can help you because you have to re-state your order anyway.\nIn tech terms: If Server A dies, Server B can take over immediately because no “memory” was lost on Server A."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#problem-shopping-cart",
    "href": "W7/M1/01_client-server_arch.html#problem-shopping-cart",
    "title": "Introduction to Client-server Architecture",
    "section": "Problem: Shopping Cart?",
    "text": "Problem: Shopping Cart?\n\nFigure: Shopping CartHow do we build Stateful shopping carts on a Stateless protocol?\n\n\nHook: So if the web is stateless, how does Amazon remember items in your cart?\nHow do you stay logged in to Facebook?\nWe need a way to build State on top of a Stateless protocol."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#cookies-managing-state",
    "href": "W7/M1/01_client-server_arch.html#cookies-managing-state",
    "title": "Introduction to Client-server Architecture",
    "section": "Cookies: Managing State",
    "text": "Cookies: Managing State\n\nFigure: A waiter (Server) sticking a post-it note (Cookie) on a customer’s (Client) jacket. Next time the customer comes in, the waiter reads the note.\nThe Problem: How to stay “Logged In” if HTTP is stateless?\nThe Solution: Cookies (Client-side fast storage).\nMechanism: Server sends Set-Cookie. Browser sends it back automatically.\n\n\n\nExplaining: The solution is the Cookie.\nThink of it like a coat check ticket or a VIP badge.\nWhen you first log in, the server gives you a badge (Cookie).\nLandmark: The magic is that your browser automatically pins this badge to every single subsequent request you make to that server.\nThe server sees the badge and says, “Ah, welcome back, User 123.”"
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#the-web-server",
    "href": "W7/M1/01_client-server_arch.html#the-web-server",
    "title": "Introduction to Client-server Architecture",
    "section": "The “Web Server”",
    "text": "The “Web Server”\n\nVirtual Presence: Appears as a single entity to the client, but often represents a complex infrastructure.\nComposition: Can include load balancers, caches, and database servers working in tandem.\nShared Hosting: Multiple software instances can coexist on one physical machine, often sharing an IP via the Host header.\n\n\n\nExplaining: A “server” is rarely just one computer anymore. It is a logical concept.\nStorytelling: When you visit google.com, you aren’t talking to a single machine under a desk in California. You are talking to a massive distributed system that acts like a single responder.\nReasoning: This abstraction allows for Shared Hosting. A single physical machine can host bobspizza.com and alicesbakery.com."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#proxies-the-middlemen",
    "href": "W7/M1/01_client-server_arch.html#proxies-the-middlemen",
    "title": "Introduction to Client-server Architecture",
    "section": "Proxies: The Middlemen",
    "text": "Proxies: The Middlemen\n\nUser Agent acting on behalf of the User making requests and recieving responses. Proxies in-between the User-Agent and the Server.\nProxies are essential for performance and security.\n\nFunctions of a Proxy\n\nCaching: Stores copies of resources to serve future requests faster.\nFiltering: Performs antivirus scans or implements parental controls.\nLoad Balancing: Distributes incoming traffic across multiple backend servers.\nAuthentication: Validates user credentials before allowing access to resources.\nLogging: Tracks request history for security and analytics.\n\n\n\nLandmark: Proxies are the silent workhorses of the web.\nExplaining: A proxy sits between you (the client) and the destination (the server). It acts on your behalf.\nReasoning: Why use them?\n\nCaching: If 100 people ask for the same logo, the proxy saves it once and serves it 99 times. Faster for you, cheaper for the server.\nSecurity: Corporate firewalls are proxies that filter “bad” sites.\n\nStorytelling: It’s like sending your assistant to buy coffee. The barista doesn’t know you ordered it, they just see the assistant."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#securing-sensitive-information",
    "href": "W7/M1/01_client-server_arch.html#securing-sensitive-information",
    "title": "Introduction to Client-server Architecture",
    "section": "Securing Sensitive Information",
    "text": "Securing Sensitive Information\n\nCredit Card Information Transmission over TLS Encrypted Channel (HTTPS).\nHTTP: Plain text (Dangerous).\nHTTPS: Encrypted (TLS/SSL).\nWhat is Encrypted?: Headers, Body.\nWhat is Visible?: URL, Path, IP Address, Port, Domain.\n\n\n\nExplaining: Standard HTTP is like sending a postcard. Anyone handling the mail (routers, ISPs) can read it.\nReasoning: This is dangerous for passwords and credit cards.\nHTTPS wraps that postcard in an unbreakable, armored envelope.\nLandmark: Crucial Detail—The mailman still needs to know the Destination Address (IP) and the House Name (Domain), but they cannot see the Letter Contents (Body) or even the Specific Room (Path)."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#nouns-and-verbs",
    "href": "W7/M1/01_client-server_arch.html#nouns-and-verbs",
    "title": "Introduction to Client-server Architecture",
    "section": "Nouns and Verbs",
    "text": "Nouns and Verbs\n\nREST is a set of practices mapping HTTP methods to actions on resources.\n\n\nNouns (Resources): Represent the “what” of the request.\nVerbs (Actions): Represent the “how” or the operation being performed.\n\n\nAccording to the original dissertation by Roy Fielding and supplemental MDN documentation: - resources (nouns) should always be plural and represent entities - while methods (verbs) define the transition of state."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#naming-conventions-nouns",
    "href": "W7/M1/01_client-server_arch.html#naming-conventions-nouns",
    "title": "Introduction to Client-server Architecture",
    "section": "Naming Conventions (Nouns)",
    "text": "Naming Conventions (Nouns)\n\nObjects: Use /articles instead of /getArticles.\nNested: Use /authors/42/books to show relationship.\n\n\nOfficial RESTful design patterns documented by MDN suggest avoiding verbs in URLs to maintain the separation of concerns between the protocol (HTTP verbs) and the data (resource nouns)."
  },
  {
    "objectID": "W7/M1/01_client-server_arch.html#restful-endpoints-meaning",
    "href": "W7/M1/01_client-server_arch.html#restful-endpoints-meaning",
    "title": "Introduction to Client-server Architecture",
    "section": "RESTful Endpoints Meaning",
    "text": "RESTful Endpoints Meaning\n\nGET /users -&gt; List all.\nGET /users/1 -&gt; Get specific one.\nPOST /users -&gt; Create new.\nPUT /users/1 -&gt; Replace it.\nPATCH /users/1 -&gt; Update it.\nDELETE /users/1 -&gt; remove it.\n\n\n\nThe URL + Verb tells the whole story.\nThis is the beauty of REST. It’s predictable."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-core-pattern-decoupling-search-from-retrieval",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-core-pattern-decoupling-search-from-retrieval",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "The Core Pattern: Decoupling Search from Retrieval",
    "text": "The Core Pattern: Decoupling Search from Retrieval\n\nThe Status Quo: 1:1 Ratio (Search Unit = Synthesis Unit)\nThe Process: Chunk \\(\\rightarrow\\) Embed \\(\\rightarrow\\) Store \\(\\rightarrow\\) Retrieve \\(\\rightarrow\\) Prompt\nThe Architect’s Insight: This linear approach is a production bottleneck.\nThe Goal: Separate how we find data from what we show the LLM.\n\n\n\nStart by acknowledging that most students have built a basic RAG where chunk size is fixed.\nExplain that in production, the 1:1 ratio is the first thing to break.\nWe are moving from “Basic RAG” to “Architected RAG.”"
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-context-paradox",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-context-paradox",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "The Context Paradox",
    "text": "The Context Paradox\n\n\n\n1. The Search Need (Precision)\n\nRequires Granular text.\nLarge chunks create “blurry” embeddings.\nGoal: High signal-to-noise ratio.\n\n\n\n2. The LLM Need (Context)\n\nRequires Broad text.\nSmall snippets lack definitions/nuance.\nGoal: Full narrative flow.\n\n\n\n\n\n\nThe Paradox: Small chunks are better for retrieval; large chunks are better for generation.\n\n\n\nUse the “Blurry” analogy: if a chunk covers 5 topics, its vector is an average of 5 things, making it hit nothing perfectly.\nMention “Synthesis Failure”: the LLM gets the answer but doesn’t know what it refers to (e.g., “it” or “the system”)."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-architectural-shift-small-to-big",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-architectural-shift-small-to-big",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "The Architectural Shift: Small-to-Big",
    "text": "The Architectural Shift: Small-to-Big\n\n\n\n\n\ngraph TD\n    subgraph Standard [Standard RAG 1:1]\n    Q1[Query] --&gt; VS1{Vector Search}\n    VS1 --&gt; C1[Chunk A]\n    C1 --&gt; LLM1[LLM Prompt]\n    end\n\n    \n\n    subgraph Decoupled [Small-to-Big]\n    Q2[Query] --&gt; VS2{Vector Search}\n    VS2 --&gt; SC[Small Child Chunk]\n    SC -.-&gt;|Linked Reference| LP[Large Parent Context]\n    LP --&gt; LLM2[LLM Prompt]\n    end\n\n    style SC fill:#f9f,stroke:#333,stroke-width:2px\n    style LP fill:#bbf,stroke:#333,stroke-width:4px\n\n\n\n\n\n\n\nThe Search Unit (The “Bait”): Small, specific segments (Child Chunks) optimized for vector math.\nThe Retrieval Unit (The “Payload”): The original, larger context (Parent Document) optimized for LLM reasoning.\n\n\n\nExplain the “Bait and Payload” analogy.\nHighlight that the “Linked Reference” is a simple metadata pointer in the database."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#optimizing-the-bait-search-unit",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#optimizing-the-bait-search-unit",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Optimizing the “Bait” (Search Unit)",
    "text": "Optimizing the “Bait” (Search Unit)\n\nProblem: Diluted embeddings.\nConcept: A 1,000-word page vector is an average of every topic on that page.\nSolution: Index 100-token “Child Chunks.”\nResult: High cosine similarity for specific technical queries.\n\n\nExample: “What is the cooling capacity?” matches a child chunk about radiators better than a whole car manual.\n\n\n\nEmphasize that vector embeddings are just math; “averaging” too much text loses the specific “coordinates” of the answer."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#optimizing-the-payload-retrieval-unit",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#optimizing-the-payload-retrieval-unit",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Optimizing the “Payload” (Retrieval Unit)",
    "text": "Optimizing the “Payload” (Retrieval Unit)\n\nProblem: LLMs are “Context Engines.”\nThe “As Mentioned Above” Trap: Small chunks often contain pronouns or references to missing text.\nSolution: When a child is “hit,” fetch the 1,500-token Parent.\nResult: The LLM sees headers, definitions, and the full scope of logic.\n\n\n\nMention that LLMs perform better when they can “see” the structure of the document (Markdown headers, etc.).\nThis prevents hallucinations caused by missing context."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#comparison-why-decouple",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#comparison-why-decouple",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Comparison: Why Decouple?",
    "text": "Comparison: Why Decouple?\n\n\n\nFeature\nStandard (1:1)\nSmall-to-Big\n\n\n\n\nSearch Precision\nModerate (Noise)\nHigh (Focused)\n\n\nLLM Context\nLow (Limited)\nHigh (Full)\n\n\nStorage Cost\nLower\nHigher (More Vectors)\n\n\nComplexity\nSimple\nModerate\n\n\nReliability\nProne to “Out of Context”\nProduction Grade\n\n\n\n\n\nBe honest about the trade-offs: more vectors mean more storage and slightly more complex ingestion.\nFrame this as the “Level Up” from a tutorial project to a professional system."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#summary-retrieval-vs.-synthesis",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#summary-retrieval-vs.-synthesis",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Summary: Retrieval vs. Synthesis",
    "text": "Summary: Retrieval vs. Synthesis\n\nRetrieval and Synthesis are two different cognitive tasks.\nThey require different data granularities.\nThe Architect’s Rule: Find with a needle, feed with a shovel.\n\n\nNext up: The Library Card Catalog Mental Model\n\n\nReinforce the “Architect’s Rule” as a mnemonic.\nPrepare them for the next section which uses a real-world analogy to solidify this."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-conflict-of-interest",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-conflict-of-interest",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "The Conflict of Interest",
    "text": "The Conflict of Interest\n\n\n\nSearch-Optimized\n\nSmall, punchy text.\nHigh “signal” for math.\nGoal: Be easy to find.\n\n\n\nContext-Optimized\n\nLarge, nuanced blocks.\nRich “Chain of Thought.”\nGoal: Be easy to understand.\n\n\n\n\n\n\nThe Architect’s Dilemma: The text easiest for a computer to find is rarely the text best for an LLM to reason with.\n\n\n\nIntroduce the fundamental tension in RAG: Small chunks are precise for math/vectors, but large chunks are better for LLM reasoning.\nWe shouldn’t force one piece of text to do both jobs."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#mental-model-the-library-card-catalog",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#mental-model-the-library-card-catalog",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Mental Model: The Library Card Catalog",
    "text": "Mental Model: The Library Card Catalog\n\n\n\n\n\ngraph LR\n    A[User Question] --&gt; B(Card Catalog)\n    B --&gt;|Small Index Card| C{Call Number}\n    C --&gt;|Reference| D[The Heavy Book]\n    D --&gt; E[Knowledge Acquired]\n\n\n\n\n\n\n\nThe Card: Searchable, compact, metadata-rich.\nThe Book: Deep context, diagrams, full narrative.\nThe Link: The “Call Number” connects the two.\n\n\n\nUse the NY Public Library analogy.\nExplain that we don’t search by reading every book (linear search); we use a proxy (the card).\nThe card is the “Pointer,” the book is the “Payload.”"
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#mapping-the-analogy-to-rag",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#mapping-the-analogy-to-rag",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Mapping the Analogy to RAG",
    "text": "Mapping the Analogy to RAG\n\n\n\n\n\n\n\n\nLibrary Component\nRAG Component\nTechnical Role\n\n\n\n\nIndex Card\nChild Chunk\n100-200 tokens. Optimized for Cosine Similarity.\n\n\nCall Number\nMetadata Link\nA UUID mapping the Child to the Parent.\n\n\nThe Book\nParent Document\n1000+ tokens. Optimized for LLM Comprehension.\n\n\n\n\n\nDefine the technical transition from analogy to architecture.\nEmphasize that the vector is generated ONLY from the Child Chunk.\nThe Parent Document is never vectorized in this model; it is just stored."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-bait-and-switch-workflow",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-bait-and-switch-workflow",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "The “Bait and Switch” Workflow",
    "text": "The “Bait and Switch” Workflow\n\n\n\n\n\ngraph LR\n    Q((Query)) -- Semantic Search --&gt; CC[Child Chunks]\n    CC -- Matches --&gt; ID[Parent_ID]\n    ID -- Fetch --&gt; P[Parent Document]\n    P -- Context --&gt; LLM[LLM Generation]\n    \n    subgraph Vector_Store [Vector Store]\n    CC\n    ID\n    end\n    \n    subgraph Doc_Store [Document Store]\n    P\n    end\n\n\n\n\n\n\n\n\nExplain the logic flow: We use the “Bait” (Child) to catch the “Fish” (Query).\nOnce caught, we perform a “Bait and Switch” to provide the “Feast” (Parent) to the LLM.\nThis maintains high precision without sacrificing context."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#why-hierarchical-indexing-wins",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#why-hierarchical-indexing-wins",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Why Hierarchical Indexing Wins",
    "text": "Why Hierarchical Indexing Wins\n\nSmall Chunks: Prevent “Vector Dilution.” A 2,000-word doc has a “blurry” vector; a 50-word sentence has a “sharp” vector.\nLarge Chunks: Prevent Hallucinations. LLMs need surrounding sentences to understand intent and nuance.\nThe Result: High Retrieval Precision + High Generation Faithfulness.\n\n\n\nDiscuss Vector Dilution: How a specific topic gets lost in a large document’s average vector.\nExplain that this architecture is a standard “Advanced RAG” pattern for production systems."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-architects-data-schema",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-architects-data-schema",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "The Architect’s Data Schema",
    "text": "The Architect’s Data Schema\n{\n    \"id\": \"child_001\",\n    \"text\": \"The Brooklyn Bridge used steel wire for the first time...\", \n    \"vector\": [0.12, -0.04, 0.88, ...], \n    \"metadata\": {\n        \"parent_id\": \"doc_99\", \n        \"full_context\": \"In 1869, John Roebling designed... [1000 words] ...\",\n        \"source\": \"history_archive_01\"\n    }\n}\n\nSearchable: text + vector\nRetrievable: full_context via parent_id\n\n\n\nShow the graduates what the code actually looks like.\nPoint out that the vector is a representation of the small text, not the full_context.\nMention that full_context could also live in a separate NoSQL database (like Mongo or Redis) to keep the Vector Store lean."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-architects-blueprint-components-data-structures",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-architects-blueprint-components-data-structures",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "The Architect’s Blueprint: Components & Data Structures",
    "text": "The Architect’s Blueprint: Components & Data Structures\n\nThe Problem: Standard RAG uses the same unit for searching and reading.\nThe Solution: Decouple the Unit of Search from the Unit of Retrieval.\nThe Strategy: Small-to-Big (Parent Document Retrieval).\nThe Goal: High-speed filing with “Sticky Note” searches and “Folder” contexts.\n\n\n\nTransition from the Library analogy to the actual system architecture.\nExplain that “Decoupling” is the core architectural shift here.\nMention that this solves the ‘Lost in the Middle’ or ‘Lack of Context’ problems in standard RAG."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-dual-layered-approach",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-dual-layered-approach",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "The Dual-Layered Approach",
    "text": "The Dual-Layered Approach\n\n\n\nSearch Index\n\nChild Chunks\nSmall, dense snippets.\nOptimized for mathematical similarity.\n“The Sticky Note.”\n\n\n\nThe Archive\n\nParent Documents\nLarge, contextual blocks.\nOptimized for LLM comprehension.\n“The Filing Folder.”\n\n\n\n\n\n\n\n\n\n\ngraph LR\n    A[Raw Document] --&gt; B[Parent Splitter]\n    B --&gt; C[Child Splitter]\n    C --&gt; D[(Vector DB)]\n    B --&gt; E[(Doc Store)]\n    D -.-&gt;|parent_id| E\n\n\n\n\n\n\n\n\nUse the visual to show the one-to-many relationship.\nEmphasize that one Parent can have dozens of Children."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#component-1-the-parent-splitter",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#component-1-the-parent-splitter",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Component 1: The Parent Splitter",
    "text": "Component 1: The Parent Splitter\n\nRole: Defines the “Retrieval Unit” (The Context).\nLogic: Preserves the “Why” and “How” surrounding a fact.\nGranularity: 1,000–2,000 tokens or logical sections.\nStorage: Key-Value Store (Redis, MongoDB, S3).\n\n\n“If a user asks about revenue growth, the child finds the number; the parent provides the explanation.”\n\n\n\nExplain that the Parent Splitter is about LLM performance, not search performance.\nMention that storage here is cheap (Key-Value) compared to Vector storage."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#component-2-the-child-splitter",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#component-2-the-child-splitter",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Component 2: The Child Splitter",
    "text": "Component 2: The Child Splitter\n\nRole: Defines the “Search Unit” (The Precision).\nLogic: High-dimensional vectors lose “resolution” in long text.\nGranularity: 50–150 tokens (Sentences/Small Paragraphs).\nStorage: Vector Database (Pinecone, Chroma, Milvus).\n\n\nWhy go small? - A 1,000-word embedding is blurry. - A 50-word embedding is sharp.\n\n\nUse the “Blurry vs Sharp” analogy to explain embedding density.\nExplain that smaller chunks lead to higher “Top-K” relevancy."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-glue-parent_id-metadata",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-glue-parent_id-metadata",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "The “Glue”: parent_id Metadata",
    "text": "The “Glue”: parent_id Metadata\nThe system relies on a Foreign Key relationship to function.\n\n\n\n\n\n\n\nField\nPurpose\n\n\n\n\nVector\nMathematical “address” of the child text.\n\n\nText\n(Optional) Small snippet for debugging.\n\n\nparent_id\nCritical Link to the full-context Parent Document.\n\n\n\n\n\nStress that without the parent_id, the system is just two disconnected piles of text.\nThis is the “Architect’s Secret Sauce” for RAG."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#mapping-the-relationship",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#mapping-the-relationship",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Mapping the Relationship",
    "text": "Mapping the Relationship\n\n\n\n\n\ngraph LR\n    subgraph DocStore [Document Store: The Archive]\n        P1[Parent A: Q3 Financials]\n        P2[Parent B: Roadmap]\n    end\n\n    subgraph VecDB [Vector Store: The Search Index]\n        C1[Child 1: Revenue +5%] -- id:A --&gt; P1\n        C2[Child 2: Costs up] -- id:A --&gt; P1\n        C3[Child 3: Feature X] -- id:B --&gt; P2\n    end\n\n    Query((User Query)) --&gt;|Search| C1\n    C1 --&gt;|Lookup| P1\n    P1 --&gt;|Full Context| LLM[LLM Response]\n\n\n\n\n\n\n\n\nWalk through the flow: Query hits Child 1 -&gt; System grabs Parent A -&gt; LLM reads Parent A.\nNote that the LLM never actually sees the Child Chunk text."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#dual-store-architecture-speed-cost",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#dual-store-architecture-speed-cost",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Dual-Store Architecture: Speed & Cost",
    "text": "Dual-Store Architecture: Speed & Cost\n\n\n\n\n\n\n\n\n\nComponent\nTechnology\nPurpose\nContent\n\n\n\n\nVector Store\nPinecone, Chroma\nFast Similarity Search\nChild Embeddings + ID\n\n\nDoc Store\nRedis, S3, Mongo\nReliable Retrieval\nFull Parent Text\n\n\n\n\nEfficiency: Vector DBs are expensive for large text storage.\nSpeed: “Fetch-by-ID” in Redis is faster than metadata-heavy vector lookups.\n\n\n\nExplain the cost implications: Vector memory is expensive (RAM-heavy).\nDocument stores are persistent and cheaper (Disk-heavy)."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#visualizing-the-transformation",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#visualizing-the-transformation",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Visualizing the Transformation",
    "text": "Visualizing the Transformation\n\nImage: A visualization showing a single document color-coded into large parent blocks, with each block further subdivided into multiple small child points.\n\nUse this slide to show the “Density” of the data.\nPoint out how one document becomes a hierarchy."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#architects-summary",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#architects-summary",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Architect’s Summary",
    "text": "Architect’s Summary\n\nDecoupling is Power: Search for precision, read for context.\nMetadata is the Backbone: If you lose the parent_id, the system is broken.\nOptimize for Scale: Use the right tool for the right job (Vector vs. KV Store).\n\n\n\nFinal wrap-up of the blueprint.\nPrepare the students for the next section: how the “Bait and Switch” actually executes in code."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#execution-flow-the-bait-and-switch",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#execution-flow-the-bait-and-switch",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Execution Flow: The ‘Bait and Switch’",
    "text": "Execution Flow: The ‘Bait and Switch’\n\n\n\nThe Core Philosophy\n\nSearch \\(\\neq\\) Generation.\nIn standard RAG, what you find is what you feed the LLM.\nIn Hierarchical Indexing, we break this 1:1 relationship to optimize for both precision and context.\n\n\n\nThe “Bait and Switch”\n\nBait: Use a granular “Child” chunk for high-precision vector search.\nSwitch: Swap the child for a broad “Parent” chunk for the LLM prompt.\n\n\n\n\n\n\nIntroduce the concept of decoupling search units from context units.\nExplain that we are optimizing for two different things: finding the right spot (search) and providing enough info (generation)."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-architects-switchboard",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-architects-switchboard",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "The Architect’s Switchboard",
    "text": "The Architect’s Switchboard\n\n\n\n\n\ngraph LR\n    User((User)) --&gt; Q_Emb[Query Embedding]\n    Q_Emb --&gt; VectorSearch{Vector Search}\n    \n    subgraph \"The Child Index\"\n        VectorSearch --&gt;|k-NN| ChildNode[Child Chunk ID]\n    end\n    \n    subgraph \"The Bait and Switch\"\n        ChildNode --&gt;|Lookup| ParentID[Parent ID]\n        ParentID --&gt;|Fetch| DocStore[(Document Store)]\n    end\n    \n    DocStore --&gt;|Full Context| Prompt[Prompt Template]\n    Prompt --&gt; LLM[LLM]\n    LLM --&gt; Response((Final Answer))\n\n    style ChildNode fill:#f96,stroke:#333\n    style DocStore fill:#69f,stroke:#333\n\n\n\n\n\n\n\n\nWalk through the flow: User query to Embedding.\nFocus on the “Bait and Switch” subgraph.\nExplain the DocStore is often a NoSQL DB or simple Key-Value store, not necessarily a vector DB."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#step-1-2-precision-retrieval",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#step-1-2-precision-retrieval",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Step 1 & 2: Precision Retrieval",
    "text": "Step 1 & 2: Precision Retrieval\n\nThe Query: “What are the specific safety protocols for high-pressure valve maintenance?”\nThe Embedding: Query is converted to a vector (e.g., text-embedding-3-small).\nThe Search: We query the Child Index (128-token chunks).\n\n\nWhy Small Chunks?\n\nSignal-to-Noise Ratio: Large chunks (1000+ words) are “blurry” vectors.\nPrecision: Small chunks represent specific concepts or sentences.\nThe Result: We find the exact needle in the haystack.\n\n\n\nEmphasize “Vector Blurring”—when a chunk covers 5 topics, its vector is an average of all of them.\nSmall chunks ensure the mathematical match is tight."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#step-3-the-switch-metadata-pivot",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#step-3-the-switch-metadata-pivot",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Step 3: The ‘Switch’ (Metadata Pivot)",
    "text": "Step 3: The ‘Switch’ (Metadata Pivot)\nThe system ignores the Child text and extracts the Parent ID from the metadata.\n{\n  \"id\": \"child_vec_99\",\n  \"text\": \"Technicians must wear Grade-4 thermal gloves...\",\n  \"metadata\": {\n    \"parent_id\": \"doc_page_level_45\",\n    \"source\": \"maintenance_manual.pdf\",\n    \"page_no\": 12\n  }\n}\n\nThe Pivot: We use the “Bait” (the glove sentence) to find the “Location” (Page 12).\n\n\n\nThis is the “Architectural Pivot.”\nWe don’t care about the child text anymore; it has served its purpose as a locator."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#step-4-5-contextual-generation",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#step-4-5-contextual-generation",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Step 4 & 5: Contextual Generation",
    "text": "Step 4 & 5: Contextual Generation\n\n\n\nStandard RAG\n\nPrompt: Context: [Child Chunk] + Question\nResult: “Wear gloves.”\nVerdict: Too brief. Lacks “Why” and “How.”\n\n\n\nHierarchical RAG\n\nPrompt: Context: [Full Parent Chunk] + Question\nResult: Full safety procedure, warnings, and follow-up steps.\nVerdict: Professional and comprehensive.\n\n\n\n\n\n\nThe Parent Chunk provides the “narrative flow” that the LLM needs to reason effectively.\n\n\n\nCompare the two. Standard RAG often feels “choppy” or “robotic” because it lacks surrounding context.\nParent chunks (e.g., 1000 tokens) provide the “story” around the data point."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#balancing-precision-vs.-recall",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#balancing-precision-vs.-recall",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Balancing Precision vs. Recall",
    "text": "Balancing Precision vs. Recall\n\n\n\n\n\n\n\n\nFeature\nChild Search (The Bait)\nParent Retrieval (The Switch)\n\n\n\n\nGoal\nHigh Precision\nHigh Recall\n\n\nAction\nFind the needle\nGet the whole haystack\n\n\nBenefit\nAvoids “Vector Blurring”\nProvides “Narrative Flow”\n\n\nLLM Impact\nMinimizes irrelevant data\nMaximizes reasoning capability\n\n\n\n\n\nThis table summarizes the trade-offs.\nExplain that we are solving the “Goldilocks Problem”: chunks are small enough to find, big enough to use."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#visualizing-information-density",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#visualizing-information-density",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Visualizing Information Density",
    "text": "Visualizing Information Density\n\nImage: A line chart showing ‘Search Accuracy’ peaking at small chunk sizes and ‘Context Quality’ peaking at large chunk sizes, with the ‘Bait and Switch’ sitting at the intersection.The Architect’s Verdict: The “Bait and Switch” decouples retrieval logic from generation logic, allowing both to be optimized independently.\n\n\nFinal takeaway: This is a modular design pattern.\nIf search is bad, tune the child size. If answers are bad, tune the parent size."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#production-considerations-storage-vs.-context",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#production-considerations-storage-vs.-context",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Production Considerations: Storage vs. Context",
    "text": "Production Considerations: Storage vs. Context\n\nSustainable Design: Moving beyond “it works” to “it scales.”\nThe Trade-off: Balancing performance gains against physical and economic constraints.\nThe Architect’s Dilemma:\n\nStorage Overhead (Infrastructure)\nInference Economics (Operational Cost)\n\n\n\n\nTransition from the “Bait and Switch” logic to real-world deployment.\nEmphasize that every architectural choice has a “bill” attached to it.\nRemind students that as architects, they are responsible for the budget, not just the code."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-storage-multiplier-architecture",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-storage-multiplier-architecture",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "The Storage Multiplier: Architecture",
    "text": "The Storage Multiplier: Architecture\n\n\n\n1. Vector Database\n\nThe Search Index\nStores thousands of Child Chunks.\nHigher RAM usage (Pinecone/Milvus).\nHigh-frequency, low-latency lookups.\n\n\n\n2. Document Store\n\nThe Content Warehouse\nStores high-res Parent Documents.\nDisk-based storage (S3/MongoDB).\nLower cost, higher capacity.\n\n\n\n\n\n\n\n\n\n\ngraph LR\n    subgraph VectorDB [Search Index - RAM]\n    C1[Child 1]\n    C2[Child 2]\n    C3[Child 3]\n    end\n\n    subgraph DocStore [Warehouse - Disk]\n    P1[Parent Document]\n    end\n\n    C1 -.-&gt;|parent_id| P1\n    C2 -.-&gt;|parent_id| P1\n    C3 -.-&gt;|parent_id| P1\n\n\n\n\n\n\n\n\nExplain the “One-to-Many” relationship between Parent and Children.\nArchitect’s Tip: Use metadata tags (parent_id) to keep the vector DB lean.\nMention that storing full text in a Vector DB is an expensive anti-pattern."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#context-window-economics",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#context-window-economics",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Context Window Economics",
    "text": "Context Window Economics\n\nToken Throughput: Larger payloads = Higher “Time to First Token” (TTFT).\nInput Costs: 5 parents @ 2k tokens = 10k tokens/query.\n“Lost in the Middle”:\n\nModels struggle with extremely long contexts.\nInformation density decreases as volume increases.\n\n\n\nImage: A line chart showing ‘Accuracy vs. Context Length’ with a U-shaped dip in the center.\n\nExplain that LLM providers charge by the token; parent retrieval can 4x your bill.\nDiscuss the “Lost in the Middle” phenomenon: models are better at the start and end of a prompt."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#ideal-use-cases-when-to-go-big",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#ideal-use-cases-when-to-go-big",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Ideal Use Cases: When to Go “Big”",
    "text": "Ideal Use Cases: When to Go “Big”\n\nLegal & Compliance\n\nClauses require definitions found elsewhere in the document.\n\nTechnical Manuals\n\nSteps require safety warnings and tool prerequisites.\n\nAcademic Research\n\nResults mean nothing without the methodology context.\n\n\n\n\nThe Rule of Thumb: Use when “Small” chunks find the Location, but “Big” documents provide the Meaning.\n\n\n\nUse the “Legal” example: “The Party of the First Part” is a variable that needs the Parent document to resolve.\nNarrative continuity is the key differentiator here."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#contra-indications-when-to-stay-small",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#contra-indications-when-to-stay-small",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "Contra-indications: When to Stay “Small”",
    "text": "Contra-indications: When to Stay “Small”\n\nAtomized Information\n\nFAQs or standalone snippets with no broader context.\n\nLatency-Critical Apps\n\nVoice assistants or real-time chat where every millisecond counts.\n\nLow-Budget Projects\n\nWhen token bloat will drain API credits 5x faster.\n\n\n\n\nWarn against “Over-engineering.”\nIf standard RAG gets the answer right, do not add the complexity of Hierarchical Indexing."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-architects-decision-matrix",
    "href": "W6/W6-chunking-and-preprocessing/04-parent-document-retrieval/draft.html#the-architects-decision-matrix",
    "title": "Hierarchical Indexing: Small-to-Big Retrieval",
    "section": "The Architect’s Decision Matrix",
    "text": "The Architect’s Decision Matrix\n\n\n\nCriteria\nStandard RAG\nSmall-to-Big RAG\n\n\n\n\nData Structure\nIndependent snippets\nInterconnected sections\n\n\nPrimary Goal\nSpeed & Low Cost\nAccuracy & Continuity\n\n\nStorage\nSimple (Single Store)\nComplex (Dual Store)\n\n\nContext Window\nSmall (4k - 8k)\nLarge (32k - 128k)\n\n\nPayload\n~500 tokens\n~2,000+ tokens\n\n\n\n\n\nUse this slide to summarize the section.\nAsk the students: “Based on your current project, which column do you fall into?”\nFinal thought: It’s a surgical tool, not a hammer."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#the-logic-of-recursion-a-waterfall-model",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#the-logic-of-recursion-a-waterfall-model",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "The Logic of Recursion: A Waterfall Model",
    "text": "The Logic of Recursion: A Waterfall Model\n\n\n\nThe Context Problem\n\nLLMs have fixed Context Windows.\nData must be sliced into chunks.\nThe Risk: “Semantic Integrity” loss.\n\n\n\nThe Architect’s Solution\n\nMove beyond “Fixed-Length” ribbons.\nAdopt Recursive Structural Splitting.\nPrioritize human-readable boundaries.\n\n\n\n\n\n\nRemind students that LLMs aren’t infinite; we have to feed them data in bite-sized pieces.\nExplain that if we cut a sentence in half, the vector embedding (the “meaning”) becomes corrupted or “noisy.”\nIntroduce the shift from rigid math (every 500 chars) to logical structure."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#the-separator-hierarchy",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#the-separator-hierarchy",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "The Separator Hierarchy",
    "text": "The Separator Hierarchy\nDocuments are nested hierarchies, not flat strings.\n\nLevel 1: \"\\n\\n\" (Paragraphs/Sections)\nLevel 2: \"\\n\" (Individual Lines)\nLevel 3: \" \" (Words)\nLevel 4: \"\" (Characters - The Last Resort)\n\nThe Architect’s Rule: Always split at the highest possible level to keep context together. Only move down if the chunk is still too large.\n\n\nUse the analogy of a human reading: we look for chapters, then paragraphs, then sentences.\nExplain that keeping a paragraph together is better for RAG because the surrounding sentences provide context for the facts within."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#the-algorithm-try-then-refine",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#the-algorithm-try-then-refine",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "The Algorithm: “Try, Then Refine”",
    "text": "The Algorithm: “Try, Then Refine”\n\n\n\n\n\ngraph LR\n    A[Raw Document] --&gt; B{Fits in \\n \\n?}\n    B --&gt;|Yes| C[Keep Paragraph]\n    B --&gt;|No| D{Fits in \\n?}\n    D --&gt;|Yes| E[Keep Line]\n    D --&gt;|No| F{Fits in ' '?}\n    F --&gt;|Yes| G[Keep Word]\n    F --&gt;|No| H[Split Character]\n\n    style C fill:#d4edda,stroke:#28a745\n    style E fill:#d4edda,stroke:#28a745\n    style G fill:#d4edda,stroke:#28a745\n    style H fill:#f8d7da,stroke:#dc3545\n\n\n\n\n\n\n\nGoal: Maximize chunk size without exceeding the limit.\n\n\nWalk through the logic: The splitter is a decision tree.\nIt doesn’t just cut; it “negotiates” with the text.\nHighlight that splitting by character is a “failure” state we try to avoid."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#visualizing-the-waterfall",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#visualizing-the-waterfall",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "Visualizing the “Waterfall”",
    "text": "Visualizing the “Waterfall”\n\n\n\nThe Flow\n\nText “pours” through filters.\nOnly “overflow” moves down.\nAdaptive to content density.\n\n\n\nSemantic Glue\n\nPrevents mangled words.\nBad: “The capital is Par | is.”\nGood: “The capital is Paris.”\n\n\n\n\n\n\nExplain the term “Waterfall”: the text flows down the hierarchy.\nMention “Semantic Glue”: the invisible context that binds words. If you break the glue, the RAG system fails to find the right answer."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#logic-in-action-integrity-vs.-density",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#logic-in-action-integrity-vs.-density",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "Logic in Action: Integrity vs. Density",
    "text": "Logic in Action: Integrity vs. Density\n\nImage: Bar chart showing Semantic Integrity vs Content Density. Paragraph level splits have higher integrity than character level splits.\n\nExplain the chart: High-quality documents (with paragraphs) allow the splitter to stay at Level 4 (Paragraphs).\nTechnical data like long URLs or DNA sequences force the splitter down to Level 1 (Characters), which is harder for LLMs to “understand.”"
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#the-architects-takeaway",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#the-architects-takeaway",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "The Architect’s Takeaway",
    "text": "The Architect’s Takeaway\n\nRecursive splitting is adaptive.\nIt avoids “one-size-fits-all” logic.\nIt respects natural language boundaries.\nReliability First: It only degrades to aggressive splitting when the context window is threatened.\n\n\n\nWrap up by emphasizing that as architects, we choose tools that adapt to the data.\nTransition to the next section: How to actually code this using LangChain’s RecursiveCharacterTextSplitter."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#implementing-recursivecharactertextsplitter",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#implementing-recursivecharactertextsplitter",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "Implementing RecursiveCharacterTextSplitter",
    "text": "Implementing RecursiveCharacterTextSplitter\n\nFrom Blueprint to Studio: Moving from theory to production-grade implementation.\nThe Goal: Designing a data pipeline where chunks are digestible yet contextually rich.\nThe Tool: LangChain’s RecursiveCharacterTextSplitter.\n\n\n\nTransition from the “Waterfall” concept to actual code.\nRemind students that as architects, they are managing the “resolution” of their data."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#the-two-pillars-of-configuration",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#the-two-pillars-of-configuration",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "The Two Pillars of Configuration",
    "text": "The Two Pillars of Configuration\n\n\n\n1. Chunk Size\n\nThe Resolution\nMaximum characters/tokens per chunk.\nToo Small: Loss of “Big Picture.”\nToo Large: Risk of context window overflow.\n\n\n\n2. Chunk Overlap\n\nThe Safety Margin\nText shared between consecutive chunks.\nThe Logic: Prevents cutting meaning in half.\nActs as a “Context Bridge.”\n\n\n\n\n\n\nChunk size is the target, not a strict rule (the splitter tries to stay under it).\nOverlap is vital for RAG so that the “seams” of the data don’t hide information."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#the-default-hierarchy",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#the-default-hierarchy",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "The Default Hierarchy",
    "text": "The Default Hierarchy\nThe splitter uses a prioritized list of separators to maintain semantic unity.\n\n\n\n\n\ngraph LR\n    A[Raw Document] --&gt; B{\"Split by '\\n\\n'?\"}\n    B -- Fits Chunk Size --&gt; C[Final Chunk: Paragraph]\n    B -- Too Large --&gt; D{\"Split by '\\n'?\"}\n    D -- Fits Chunk Size --&gt; E[Final Chunk: Line]\n    D -- Too Large --&gt; F{\"Split by ' '?\"}\n    F -- Fits Chunk Size --&gt; G[\"Final Chunk: Words/Sentences\"]\n    F -- Too Large --&gt; H[Split by Character]\n    \n    style C fill:#d4edda,stroke:#28a745\n    style E fill:#d4edda,stroke:#28a745\n    style G fill:#d4edda,stroke:#28a745\n    style H fill:#f8d7da,stroke:#dc3545\n\n\n\n\n\n\n\n\nDouble Newline: Keeps paragraphs intact.\nSingle Newline: Keeps sentences/list items together.\nSpace: Keeps words whole.\nEmpty String: Last resort (character-level split).\n\n\n\nExplain that the splitter iterates through this list.\nIt only moves to the next separator if the current one results in a chunk larger than chunk_size."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#visualizing-the-sliding-window",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#visualizing-the-sliding-window",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "Visualizing the Sliding Window",
    "text": "Visualizing the Sliding Window\nThe overlap ensures that meaning isn’t lost at the “seam.”\n\nImage: A diagram showing Chunk 1 from character 0-6 and Chunk 2 from character 4-10, with a highlighted overlap area from 4-6.\n\nAnalogous to a panoramic photo where frames must overlap to be stitched together.\nThis allows the LLM to see the “tail end” of the previous thought."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#the-architects-implementation",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#the-architects-implementation",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "The Architect’s Implementation",
    "text": "The Architect’s Implementation\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\n# 1. Configuration\nsplitter = RecursiveCharacterTextSplitter(\n    chunk_size=100,\n    chunk_overlap=20,\n    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n)\n\n# 2. Execution\nchunks = splitter.split_text(document)\n\n# 3. Inspection\nfor i, chunk in enumerate(chunks):\n    print(f\"Chunk {i+1}: {repr(chunk)}\")\n\n\nrepr() is used to visualize the hidden newline characters.\nNote how we define the separators explicitly to control the “waterfall.”"
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#logic-analysis-why-it-works",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#logic-analysis-why-it-works",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "Logic Analysis: Why It Works",
    "text": "Logic Analysis: Why It Works\n\nParagraph Preservation: If “Section A” fits in 100 chars, it stays as one unit.\nThe “Hard” Limit: If a paragraph is 150 chars, the splitter drops to \\n to find a break point.\nThe Context Bridge: The 20-character overlap ensures Chunk 2 starts with a “hint” of Chunk 1.\n\n\n\nThe Insurance Policy: Unlike simple splitters, this method prevents the “Mid-Word Disaster” (e.g., splitting “Architecture” into “Archi” and “tecture”).\n\n\n\nEmphasize that this is “Smart” splitting.\nMention the “Lost Context” problem: splitting a “NOT” away from the rest of the sentence."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#recursive-vs.-character-splitter",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#recursive-vs.-character-splitter",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "Recursive vs. Character Splitter",
    "text": "Recursive vs. Character Splitter\n\n\n\n\n\n\n\n\nFeature\nCharacter Splitter\nRecursive Splitter\n\n\n\n\nLogic\nRigid / Fixed\nHierarchical / Adaptive\n\n\nWord Integrity\nHigh risk of mid-word cuts\nPrioritizes word/sentence boundaries\n\n\nContext\nOften fragmented\nMaintained via “Waterfall”\n\n\nUse Case\nSimple, uniform logs\nComplex, structured documents\n\n\n\n\n\nUse this to justify why RecursiveCharacterTextSplitter is the industry standard for RAG.\nPrepare students for the next section on specialized separators (Code/Markdown)."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#context-aware-separators-code-markdown",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#context-aware-separators-code-markdown",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "Context-Aware Separators: Code & Markdown",
    "text": "Context-Aware Separators: Code & Markdown\n\nThe Problem: Blunt instruments (\\n, \\n\\n) break logic.\nThe Goal: Context Preservation.\nThe Risk: A split function is a “hallucination factory.”\nThe Architect’s Rule: Structure must dictate the split.\n\n\n\nTransition from general recursive splitting to specialized splitting.\nExplain that “Context” is the most valuable asset in RAG.\nIf an LLM gets half a function, it can’t reason about the logic."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#why-generic-splitting-fails",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#why-generic-splitting-fails",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "Why Generic Splitting Fails",
    "text": "Why Generic Splitting Fails\n\n\n\nThe “Flat String” Trap\n\nTreats Python like Prose.\nBreaks classes mid-definition.\nSeparates headers from content.\n\n\n\nThe Result\n\nChunk A: class DataProcessor:\nChunk B: def process(self): ...\nLLM Context: Chunk B loses its “Parent” identity.\n\n\n\n\n\n\nEmphasize the “Functional Hierarchy” of code.\nMention that retrieval is only as good as the coherence of the chunk."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#code-splitting-ast-aware-logic",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#code-splitting-ast-aware-logic",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "Code Splitting: AST-Aware Logic",
    "text": "Code Splitting: AST-Aware Logic\n\nAST (Abstract Syntax Tree): The “skeleton” of your code.\nHierarchy of Meaning:\n\nclass (Logical Container)\ndef (Functional Unit)\nif/elif/else (Logic Branch)\nfor/while (Iteration)\n\n\n\n\nThe Strategy: Force the “Waterfall” to respect these keywords first.\n\n\n\nWe don’t need a full compiler, but we need to emulate its logic.\nExplain that we want to keep “Units of Thought” together."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#implementation-from_language",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#implementation-from_language",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "Implementation: from_language",
    "text": "Implementation: from_language\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n\n# Architect's Choice: Python-Specific Logic\npython_splitter = RecursiveCharacterTextSplitter.from_language(\n    language=Language.PYTHON, \n    chunk_size=500, \n    chunk_overlap=50\n)\n\n# Logic: Breaks at \\nclass, then \\ndef, then \\n\\tdef\nchunks = python_splitter.split_text(code_sample)\n\n\nPoint out the Language.PYTHON enum.\nExplain that LangChain pre-populates the separator list for us.\nNote the indentation handling in the separators."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#markdown-headers-as-hard-boundaries",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#markdown-headers-as-hard-boundaries",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "Markdown: Headers as Hard Boundaries",
    "text": "Markdown: Headers as Hard Boundaries\n\nMarkdown is the “Lingua Franca” of LLM Knowledge Bases.\nHeader = Anchor: Without the #, the paragraph loses its “Topic.”\n\n\n\n\n\n\ngraph LR\n    A[Markdown Doc] --&gt; B{Split at H1 #}\n    B -- Too Big? --&gt; C{Split at H2 ##}\n    C -- Too Big? --&gt; D{Split at H3 ###}\n    D -- Too Big? --&gt; E[Recursive Text Splitting]\n\n\n\n\n\n\n\n\nExplain that headers provide the “semantic umbrella” for the text below them.\nMention that H1/H2/H3 are natural logical breakpoints."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#metadata-rich-splitting",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#metadata-rich-splitting",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "Metadata-Rich Splitting",
    "text": "Metadata-Rich Splitting\n\nThe Strategy: Don’t just split; Tag.\nUse MarkdownHeaderTextSplitter.\nBenefit: Every chunk “knows” its location in the document hierarchy.\n\n\n\n\nContent\nMetadata\n\n\n\n\n“Run pip install…”\n{\"Header 1\": \"Installation\"}\n\n\n“Set API_KEY in .env”\n{\"Header 1\": \"Configuration\"}\n\n\n\n\n\nThis is a pro-tip: Metadata injection is a superpower for RAG.\nEven if the chunk is small, the LLM knows it belongs to “Installation.”"
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#architectural-pattern-the-splitter-router",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#architectural-pattern-the-splitter-router",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "Architectural Pattern: The Splitter Router",
    "text": "Architectural Pattern: The Splitter Router\n\nAnti-Pattern: One “Global Splitter” for all file types.\nThe Pattern: Detect file extension \\(\\rightarrow\\) Route to specialized logic.\n\n\n\n\n\n\ngraph LR\n    A[Raw Files] --&gt; B{Router}\n    B --&gt;|.py| C[PythonSplitter]\n    B --&gt;|.md| D[MarkdownSplitter]\n    B --&gt;|.txt| E[RecursiveSplitter]\n\n\n\n\n\n\n\n\nFor Code: Prioritize class and def. Never split a single line.\nFor Markdown: Use headers as primary boundaries; inject into metadata.\nFor Data (JSON): Respect delimiters (brackets/keys) to avoid invalid syntax.\n\n\n\nIn production, you deal with heterogeneous data.\nThe Router ensures the right “tool” is used for the right “material.”"
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#section-4-edge-cases",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#section-4-edge-cases",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "Section 4: Edge Cases",
    "text": "Section 4: Edge Cases\nThe Unsplittable Chunk\n\nThe “Happy Path” vs. Reality: Production data is rarely clean prose.\nArchitect’s Responsibility: Build systems that don’t crash on “messy” data.\nThe Goal: Prevent OOM (Out of Memory) errors and Semantic Noise.\n\n\n\nRemind students that while recursive splitting works for 90% of cases, the last 10% (edge cases) causes system crashes.\nAs architects, we focus on reliability and robustness."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#the-unsplittable-problem",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#the-unsplittable-problem",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "The ‘Unsplittable’ Problem",
    "text": "The ‘Unsplittable’ Problem\nWhen Delimiters Disappear\n\n\n\nCommon Culprits\n\nDeep Links: 5,000+ char tracking URLs.\nBase64 Blobs: Images embedded in JSON.\nDNA Sequences: Continuous AGCT strings.\nLog Files: Massive lines without whitespace.\n\n\n\nThe Logic Failure\n\nSplitter looks for \\n, then \" \", then ..\nIf none found: The chunk exceeds your limit.\nResult: API Error or Dimension Mismatch.\n\n\n\n\n\n\nExplain that recursive splitters are “polite”—they try not to break words.\nIf a word is longer than the chunk size, the splitter might give up and return the whole thing, breaking the LLM context window."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#the-emergency-brake-strategy",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#the-emergency-brake-strategy",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "The “Emergency Brake” Strategy",
    "text": "The “Emergency Brake” Strategy\nImplementing Hard Character Splits\n\nThe Fallback: Use the empty string \"\" as the final separator.\nThe Guarantee: If no semantic break exists, cut exactly at the character limit.\n\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\nsplitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,\n    chunk_overlap=100,\n    # The \"\" is the 'Emergency Brake'\n    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"] \n)\n\n\nEmphasize that the order of the list matters.\nThe empty string should always be last; it’s the “last resort” to ensure system stability."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#small-chunk-noise",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#small-chunk-noise",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "Small Chunk Noise",
    "text": "Small Chunk Noise\nThe “Tail” of the Recursion\n\nThe Scenario: A 1,050-char doc split into 500-char chunks leaves a 50-char “tail”.\nThe Problem: “Contact us at support@example.com” has no context.\nThe Impact: These “noisy” chunks waste space in the context window.\n\nThe Architect’s Fix: Post-Processing\n\nDiscard: Remove chunks below a threshold (e.g., &lt; 100 chars).\nMerge: Append the tiny “tail” to the previous chunk.\n\n\n\nDiscuss the trade-off: Is a tiny chunk better than no chunk?\nUsually, a tiny chunk is just noise that confuses the retrieval step."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#visualizing-failure-modes",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#visualizing-failure-modes",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "Visualizing Failure Modes",
    "text": "Visualizing Failure Modes\nThe “Messy Data” Profile\n\nImage: A histogram showing chunk size distribution. Most chunks are at the target size, but there are spikes at the very low end (noise) and the very high end (unsplittable blobs exceeding the red hard-limit line).\n\nExplain the histogram: the red line is the LLM’s hard limit.\nAnything to the right of the red line causes a system crash.\nAnything at the far left is “context-less” noise."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#the-architects-stress-test",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#the-architects-stress-test",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "The Architect’s Stress Test",
    "text": "The Architect’s Stress Test\nEvaluation Heuristic\n\n\n\n\n\n\n\n\nMetric\nQuestion\nDanger Zone\n\n\n\n\nOverflow Rate\nAny chunks &gt; chunk_size?\nOOM Risk\n\n\nThe 10% Tail\n&gt;10% of chunks &lt; 100 chars?\nHigh Noise\n\n\nHeader Isolation\nChunk ends with a Title only?\nBroken Context\n\n\nMid-Code Split\nLogic cut in the middle?\nLogic Failure\n\n\n\n\n\nUse this as a checklist for students to use during their final projects.\n“Header isolation” is a common reason why RAG systems fail to answer simple questions."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#logic-flow-robust-splitting",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#logic-flow-robust-splitting",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "Logic Flow: Robust Splitting",
    "text": "Logic Flow: Robust Splitting\n\n\n\n\n\ngraph LR\n    A[Input Text] --&gt; B{Has Separators?}\n    B -- Yes --&gt; C[Recursive Logic]\n    B -- No --&gt; D{Length &gt; Limit?}\n    D -- Yes --&gt; E[Hard Char Split]\n    D -- No --&gt; F[Single Chunk]\n    C --&gt; G{Too Small?}\n    E --&gt; G\n    G -- Yes --&gt; H[Merge or Discard]\n    G -- No --&gt; I[Vector DB]\n    H --&gt; I\n    F --&gt; I\n\n\n\n\n\n\n\n\nThis diagram summarizes the entire section.\nIt shows how we handle both the “too big” (Hard Split) and “too small” (Merge/Discard) problems."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#summary-the-architects-word",
    "href": "W6/W6-chunking-and-preprocessing/02-structural-splitting/draft.html#summary-the-architects-word",
    "title": "Structural Logic: Recursive & Separator Splitting",
    "section": "Summary: The Architect’s Word",
    "text": "Summary: The Architect’s Word\n\nNever trust your data: Production data is hostile.\nSystem Reliability &gt; Semantic Integrity: Better to cut a URL in half than to crash the server.\nFilter the Noise: Post-process your chunks to ensure quality retrieval.\n\n\n\nFinal takeaway: A GenAI Architect builds for the worst-case scenario.\nTransition to the next module on Embedding Models."
  },
  {
    "objectID": "W6/D5/day_5_context_engineering.html#the-context-window-constraint",
    "href": "W6/D5/day_5_context_engineering.html#the-context-window-constraint",
    "title": "Day 5: Context Engineering",
    "section": "The Context Window Constraint",
    "text": "The Context Window Constraint\n\n\n\nA diagram of a funnel labeled ‘Context Window’ overflowing with documents, showing the ‘middle’ getting crushed.\n\n\nFinite Application Memory\n\nConstraint: Models have a limit (8k, 128k, 1M tokens).\nCost: More context = Higher Cost + Higher Latency.\nChallenge: “Lost in the Middle” phenomenon.\n\n\nKey points:\n\nLLMs are stateless - Reasoning confined to single API call’s context window\nCost & latency scale - Even 1M token windows become expensive/unusable\n“Lost in the Middle” - Model attention degrades as context grows (context rot)\nEvolution from Prompt Engineering - From static instructions to dynamic, state-aware payload construction\n\nAnalogy: Context Engineering = mise en place (chef preparing ingredients). Goal: no more, no less than what’s needed right now."
  },
  {
    "objectID": "W6/D5/day_5_context_engineering.html#outline",
    "href": "W6/D5/day_5_context_engineering.html#outline",
    "title": "Day 5: Context Engineering",
    "section": "Outline",
    "text": "Outline\n\nContext Engineering: Managing the input window.\nSessions: Handling the “Now” (active conversation).\nMemory: Handling the “Past” (long-term storage).\nProduction: Privacy, Lineage, and Ops.\n\n\nSession roadmap:\n\nContext Engineering - Payload assembly: system instructions, tools, few-shot examples, memory, RAG, history. Dynamic = selective retrieval, task-relevant examples, query-based RAG.\nSessions - “The Now”: dialogue history (events) + working memory (state). Events = user input, agent response, tool calls/outputs. State = structured scratchpad (e.g., shopping cart).\nMemory - “The Past”: long-term persistence across sessions. Lifecycle: Extract → Consolidate → Retrieve. Types: procedural (how-to), semantic (facts), episodic (history).\nProduction - Privacy (PII, GDPR), security (data poisoning), evaluation (recall/precision/hallucination detection), ops (costs, latency, bloat)."
  },
  {
    "objectID": "W6/D5/day_5_context_engineering.html#what-is-a-session",
    "href": "W6/D5/day_5_context_engineering.html#what-is-a-session",
    "title": "Day 5: Context Engineering",
    "section": "What is a Session?",
    "text": "What is a Session?\n\n\n\nTwo people talking at a table labeled ‘Session’. A waiter (The System) holds a notepad with their recent quotes.\n\n\nShort-Term Interaction State\n\nScope: A single conversation thread or workflow.\nStorage: Ephemeral (In-memory or fast KV store like Redis).\nGoal: Coherency during a task.\n\n\nSession = “The Now” - Immediate dialogue history + working memory for single conversation.\nTwo components:\n\nEvents (chronological history): user input, agent response, tool calls, tool outputs. Analogous to LLM API Content objects (role + parts).\nState (working memory): structured scratchpad for temporary data (e.g., shopping cart items, multi-step process current step).\n\nProduction note: Execution environments are stateless → must persist to DB (not just in-memory). Use robust databases (e.g., Redis for fast KV, SQL for structured). In dev, in-memory is fine."
  },
  {
    "objectID": "W6/D5/day_5_context_engineering.html#multi-agent-sessions",
    "href": "W6/D5/day_5_context_engineering.html#multi-agent-sessions",
    "title": "Day 5: Context Engineering",
    "section": "Multi-Agent Sessions",
    "text": "Multi-Agent Sessions\n\n\n\nA round table with robots. In the center is a shared document. Each robot also has a private notebook.\n\n\nShared vs. Private State\n\nShared State: All agents see the main thread (e.g., Slack channel).\nPrivate State: Agents have internal “scratchpads” or side-bars.\nInteroperability: Standardizing message formats across frameworks (LangChain, CrewAI).\n\n\nMulti-agent complexity: Multiple specialized agents must share information effectively.\nKey distinction: Session history (permanent transcript) vs. Context (crafted payload for single LLM turn).\nTwo architectural patterns:\n\nShared unified history - All agents write to single log. Best for tightly coupled tasks (e.g., multi-step problem-solving where output → input). Sub-agents can filter/label before passing to LLM.\nSeparate individual histories - Each agent has private log (black box). Communication via explicit messages (final output only, not process). Implemented via Agent-as-a-Tool or A2A Protocol.\n\nInteroperability: Frameworks (ADK, LangGraph, LangChain, CrewAI) differ in session/event/state implementation. Frameworks = universal translator: stable internal API, varied external LLM APIs. Prevents vendor lock-in."
  },
  {
    "objectID": "W6/D5/day_5_context_engineering.html#what-is-memory",
    "href": "W6/D5/day_5_context_engineering.html#what-is-memory",
    "title": "Day 5: Context Engineering",
    "section": "What is Memory?",
    "text": "What is Memory?\n\n\n\nA library archive labeled ‘Memory’. A librarian robot is filing a book.\n\n\nLong-Term Persistence\n\nScope: Across sessions, days, or years.\nStorage: Durable (Vector DB, Graph DB, SQL).\nGoal: Personalization and Learning.\n\n\nMemory = “The Past” - Long-term persistence across sessions/days/years.\nEnables: “Welcome back, I remember you like Python” - personalization and learning.\nStorage: Durable systems (Vector DB, Graph DB, SQL) - not ephemeral. Must support similarity search, keyword matching, time-based triggers.\nAnalogy: Memory = organized filing cabinet vs. Session = messy workbench. Don’t shove entire desk into storage - review, discard drafts, file only critical finalized docs. Keeps filing cabinet clean and reliable.\nTransforms: Stateless LLM → stateful intelligent agent with relationship continuity."
  },
  {
    "objectID": "W6/D5/day_5_context_engineering.html#types-of-memory",
    "href": "W6/D5/day_5_context_engineering.html#types-of-memory",
    "title": "Day 5: Context Engineering",
    "section": "Types of Memory",
    "text": "Types of Memory\n\n\n\nA diagram of a brain divided into three sections: ‘Skills’ (Procedural), ‘Facts’ (Semantic), ‘Story’ (Episodic).\n\n\nStructure vs. Meaning\n\nProcedural: “How to do things” (Few-shot examples).\nSemantic: “Facts and Knowledge” (RAG).\nEpisodic: “What happened” (User history).\nMultimodal: Images, Audio, Attachments.\n\n\nMemory types by purpose:\n\nProcedural - “How to do things” (few-shot examples). Example: “Here is how you format a SQL query.” Guides reasoning via in-context learning. Powerful when task-relevant (not hardcoded generic).\nSemantic - “Facts and knowledge” (RAG). Example: “The capital of France is Paris.” Substantive data for reasoning. Sources: external KBs, documents, accumulated facts. Serves as ‘evidence’ for responses.\nEpisodic - “What happened” (user history). Example: “Last week we debugged the login API.” Narrative of past interactions. Enables context, continuity, personalization, rapport.\nMultimodal - Images, audio, attachments. Artifacts stored/retrieved alongside text.\n\nOrganization patterns: Flat structures, hierarchical taxonomies, graph-based relationships."
  },
  {
    "objectID": "W6/D5/day_5_context_engineering.html#memory-lifecycle",
    "href": "W6/D5/day_5_context_engineering.html#memory-lifecycle",
    "title": "Day 5: Context Engineering",
    "section": "Memory Lifecycle",
    "text": "Memory Lifecycle\n\n\n\nA cycle diagram: Extract -&gt; Consolidate -&gt; Store -&gt; Retrieve -&gt; Extract…\n\n\nThe Memory Loop\n\nExtraction: Identifying useful info from a session.\nConsolidation: Merging new info with old (summarization).\nRetrieval: Fetching relevant info for the current context.\n\n\nMemory lifecycle: Transform raw conversation → useful persistent knowledge.\n\nExtract - Identify useful info from session. Example: “Oh, the user mentioned they use VsCode.” Not automatic - need mechanisms: pattern matching, LLM-based analysis, explicit triggers. Key: Distinguish signal from noise.\nConsolidate - Merge new with old. Example: Update profile, don’t append “Uses VsCode” 50 times. Prevents redundancy. Involves: summarization, deduplication, conflict resolution (Python last week → Java this week?), temporal relationships. Memory evolves, doesn’t just accumulate.\nRetrieve - Fetch relevant info for current context. Critical: Can’t inject all memories (context bloat/cost). Must be selective: similarity search, keyword matching, time-based triggers. Timing: eager (before generation, like RAG) vs. lazy (during generation, agent decides).\n\nLoop: Extract → Consolidate → Store → Retrieve → Extract (from new sessions). Keeps memory current and relevant."
  },
  {
    "objectID": "W6/D5/day_5_context_engineering.html#deep-dive-generation-strategy",
    "href": "W6/D5/day_5_context_engineering.html#deep-dive-generation-strategy",
    "title": "Day 5: Context Engineering",
    "section": "Deep Dive: Generation Strategy",
    "text": "Deep Dive: Generation Strategy\n\n\n\nParallel tracks: One showing ‘User Wait’ while memory saves, the other showing ‘User Reply’ while memory saves in background.\n\n\nBlocking vs. Background\n\nBlocking: Wait for memory to update before replying (Consistent but Slow).\nBackground: Reply immediately, update memory async (Fast but potentially inconsistent).\nMemory-as-a-Tool: Agent decides when to save a memory.\n\n\nMemory generation timing - critical design decision:\n\nBlocking - Wait for DB write before replying. Pros: Consistent (memory guaranteed available next turn). Cons: Latency (especially LLM-based extraction, expensive DB writes). Unacceptable for user-facing apps.\nBackground - Reply immediately, update async. Pros: Fast response. Cons: Race conditions (“What did I just say?” → “I don’t know yet”). Problematic for conversational agents expecting immediate recall.\nMemory-as-a-Tool - Agent has save_memory() / remember_this() tools. Hybrid: Critical info saved synchronously, less critical deferred. Agent decides: “Important now” vs. “Nice to have later”. Balances consistency + performance, gives agent agency.\n\nTriggering: End of turn (auto), specific events (user mentions preference), schedule (batch), explicit tools. Affects freshness and computational cost."
  },
  {
    "objectID": "W6/D5/day_5_context_engineering.html#memory-provenance",
    "href": "W6/D5/day_5_context_engineering.html#memory-provenance",
    "title": "Day 5: Context Engineering",
    "section": "Memory Provenance",
    "text": "Memory Provenance\n\n\n\nA detective board connecting a ‘Fact’ note to a ‘Source Document’ with a red string.\n\n\nTrusting the Source\n\nLineage: “Where did this fact come from?” (User? Tool? hallucination?).\nConfidence: High (User explicitly stated) vs. Low (Inferred).\nAttribution: Citing the source message or document.\n\n\nProvenance = tracking origin, lineage, confidence - Essential for trust, debugging, data quality.\nExample: Agent believes “The sky is green” → Need to know: user said it? bad blog post? hallucination?\nTracks: Source (user message, tool output, document), metadata (timestamps, session IDs, extraction method, confidence scores).\nEnables:\n\nDebugging - Trace false memories to source\nConfidence scoring - User explicitly stated (high) vs. inferred (low)\nAttribution - Agent cites sources (“According to our previous conversation…”)\nConflict resolution - When sources conflict, decide which to trust\nGDPR compliance - Know where memories are stored for deletion\nData poisoning protection - Safeguards: “only trust verified sources”, “flag low confidence for review”\n\nPrinciple: Never store a fact without source reference. Answer: Who? When? Context? Confidence?"
  },
  {
    "objectID": "W6/D5/day_5_context_engineering.html#timing-and-trigging",
    "href": "W6/D5/day_5_context_engineering.html#timing-and-trigging",
    "title": "Day 5: Context Engineering",
    "section": "Timing and Trigging",
    "text": "Timing and Trigging\n\n\n\nA timeline. ‘Input’ -&gt; ‘Eager Retrieval’ -&gt; ‘Thinking’ -&gt; ‘Lazy Retrieval’ -&gt; ‘Output’.\n\n\nWhen to remember?\n\nEager: Retrieve before generating (RAG).\nLazy: Retrieve during generation (Tool use).\nTrigger: Similarity search vs. Keyword match vs. Time-based.\n\n\nRetrieval timing - fundamental architectural decision:\n\nEager - Fetch before generation (like RAG). Flow: User asks Q → Look up docs → Answer. Pros: Complete context upfront. Cons: Must predict needs (might retrieve too much/little). Best for: Clear info needs (user profile, domain knowledge).\nLazy - Fetch during generation when agent decides. Agent thinks: “I don’t know this, let me check my memory tool.” Tools: search_memory(), recall_user_preference(). Pros: Flexible, efficient (only what’s needed). Cons: Complex reasoning, multiple tool calls. Best for: Unpredictable needs, agent control desired.\n\nTrigger mechanisms:\n\nSimilarity search (embeddings) - Powerful but expensive\nKeyword matching - Fast, predictable, less flexible\nTime-based - Recent memories or specific periods\nHybrid - Combine for sophisticated retrieval\n\nBalance: Recall (find all relevant) vs. Precision (avoid irrelevant). Too much = context bloat/cost. Too little = missing context. Tune by use case, memory store size, performance requirements."
  },
  {
    "objectID": "W6/D5/day_5_context_engineering.html#inference-with-memories",
    "href": "W6/D5/day_5_context_engineering.html#inference-with-memories",
    "title": "Day 5: Context Engineering",
    "section": "Inference with Memories",
    "text": "Inference with Memories\n\n\n\nA prompt construction diagram showing ‘System Prompt’ + ‘Relevant Memories’ + ‘User Query’ merging into ‘Model Input’.\n\n\nInjecting State\n\nSystem Instructions: “You are helpful. (User info: Name=Dave, Lang=Python)”.\nConversation History: Injecting relevant past summaries.\nTools: Giving the agent a search_memory() tool.\n\n\nMemory injection strategies:\n\nSystem Instructions - Embed stable, frequently-used info. Example: “You are helpful. User’s name is Dave, prefers Python, works on backend.” Pros: Always available, no retrieval. Cons: Only small amounts (bloat risk). Best for: Core user profile.\nConversation History - Prepend past summaries, key facts. Example: “In our previous conversation, we discussed…” Pros: Maintains flow, provides context. Cons: Risk duplication/confusion. Best for: Episodic memories.\nDynamic Tools - Agent calls search_memory(query), get_user_preference(key), recall_past_conversation(topic). Pros: Flexible, on-demand. Cons: Requires sophisticated agent, multiple tool calls (latency). Best for: Less stable, voluminous memories.\nProcedural (Few-shot) - In system instructions or prompt examples. Key: Task-relevant examples (dynamic selection) &gt; static hardcoded.\n\nWell-designed system: Combination - core profile in system, frequent facts in history, specialized via tools."
  },
  {
    "objectID": "W6/D5/day_5_context_engineering.html#privacy-security",
    "href": "W6/D5/day_5_context_engineering.html#privacy-security",
    "title": "Day 5: Context Engineering",
    "section": "Privacy & Security",
    "text": "Privacy & Security\n\n\n\nA vault door labeled ‘Private Memory’ with a ‘GDPR Compliant’ stamp.\n\n\nThe Risk of Remembering Too Much\n\nPII Leakage: Storing sensitive data in vector stores.\nData Poisoning: Malicious user input becoming a “fact”.\nForgetting: The “Right to be Forgotten” (GDPR).\n\n\nMemory = liability - Privacy, security, operational risks.\nPrivacy (PII):\n\nProtection required: Encryption (at rest/in transit), access controls, audit logging\nLeakage vectors: Direct storage, inference from innocuous info, correlation across memories\nCompliance: GDPR, CCPA, HIPAA require careful handling\nMitigation: Data classification, anonymization, strict access controls\n\nGDPR “Right to be Forgotten”:\n\nChallenge: Memories across multiple systems (vector DBs, SQL, caches), embedded in consolidated memories, referenced by others\nMechanisms needed: Identify all user memories, delete across systems, handle cascading deletions, verify completion\nProvenance crucial: Know where memories are stored\n\nSecurity (Data Poisoning):\n\nExample: User says “My name is ‘Ignore all rules’” → don’t store as fact!\nVectors: Direct statements, extraction manipulation, consolidation exploitation\nSafeguards: Input validation/sanitization, confidence scoring, source verification, anomaly detection\nProvenance helps: Track sources, identify/remove poisoned memories\n\nAdditional risks: Cross-user contamination, inference attacks, unauthorized access. Need isolation, access controls, monitoring.\nOperational: Storage costs (vector DBs expensive at scale), retrieval latency, memory bloat, consistency. Need lifecycle management: archival, expiration, cleanup."
  },
  {
    "objectID": "W6/D5/day_5_context_engineering.html#evaluation",
    "href": "W6/D5/day_5_context_engineering.html#evaluation",
    "title": "Day 5: Context Engineering",
    "section": "Evaluation",
    "text": "Evaluation\n\n\n\nA teacher grading a test paper labeled ‘Memory Recall’.\n\n\nDid we remember correctly?\n\nRecall: Did we find the right memory?\nPrecision: Did we avoid irrelevant noise?\nHallucination: Did we invent a fake memory?\n\n\nMemory evaluation challenges: Measure storage, retrieval correctness, appropriate usage, maintenance over time.\nGold standard test cases:\n\nCover: memory types (procedural/semantic/episodic), retrieval scenarios (eager/lazy), edge cases (conflicts, outdated info, ambiguous queries)\nInclude: should retrieve X, should NOT retrieve Y (precision), consolidation tests (updates handled)\n\nMetrics:\n\nRecall - Can system find right memory? Example: “What is my favorite fruit?” → Must retrieve “Apples”. Fraction of relevant memories successfully retrieved. Also verify correct usage in response.\nPrecision - Avoid irrelevant noise. Example: Retrieves “Apples” (correct) but also “Oranges” (incorrect) = precision problem. High recall + low precision = context bloat. High precision + low recall = missing relevant. Ideal: High recall + high precision.\nHallucination detection - Agent invents fake memory or incorrectly consolidates. Test: Agent doesn’t “remember” things never stored, handles “no relevant memory” correctly (“I don’t know” not made-up).\n\nLifecycle testing: Extraction, consolidation, retrieval, deletion. End-to-end tests simulating real interactions.\nScenarios: New users, returning users, memory updates, conflicts, edge cases (empty/ambiguous/malicious queries). Automated + manual evaluation."
  },
  {
    "objectID": "W6/D5/day_5_context_engineering.html#key-takeaways",
    "href": "W6/D5/day_5_context_engineering.html#key-takeaways",
    "title": "Day 5: Context Engineering",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nContext is Finite: Engineer it carefully.\nSessions are Now: Manage short-term state for coherency.\nMemory is Past: Extract, Consolidate, and Retrieve for long-term value.\nProvenance is Key: Know where your facts came from.\n\n\nSummary - Context Engineering foundation:\nModels are stateless → You are the state manager. Construct context for every turn: strategically select, summarize, inject. Evolution from Prompt Engineering (static) to Context Engineering (dynamic, state-aware).\nSessions = “The Now” - Turn-by-turn state: events (dialogue history) + state (working memory). Ephemeral workbench. Multi-agent: shared (unified) or separate (individual) histories.\nMemory = “The Past” - Long-term persistence across sessions. Filing cabinet (not messy desk). Lifecycle: Extract → Consolidate → Retrieve. Types: procedural, semantic, episodic, multimodal.\nProvenance is key - Track origin, confidence, source. Enables debugging, trust, data poisoning protection. Never store fact without source reference.\nProduction: Privacy (PII, GDPR), security (data poisoning), evaluation (recall/precision/hallucination), ops (costs, latency, bloat). Context cycle: Fetch → Prepare → Invoke → Upload.\nContext Engineering = mise en place - No more, no less than what’s needed. Transforms stateless LLMs → stateful intelligent agents."
  },
  {
    "objectID": "W6/D3/day_3_agents.html#what-is-an-agent",
    "href": "W6/D3/day_3_agents.html#what-is-an-agent",
    "title": "Day 3: Introduction to Agents",
    "section": "What is an Agent?",
    "text": "What is an Agent?\n\nAn Agent is a system that pursues a specific goal by perceiving its environment and autonomously deciding which actions to take to achieve that goal.\n\n\nToday we’re entering the world of Autonomous Agents. This is a shift from “Predictive AI”—where we ask a model to predict the next word—to “Agentic AI”—where we ask a system to accomplish a goal.\nWe’ll cover the core architecture, how agents “think”, and the levels of autonomy from simple tools to self-evolving systems."
  },
  {
    "objectID": "W6/D3/day_3_agents.html#what-youll-learn-today",
    "href": "W6/D3/day_3_agents.html#what-youll-learn-today",
    "title": "Day 3: Introduction to Agents",
    "section": "What You’ll Learn Today",
    "text": "What You’ll Learn Today\nBy the end of this session, you will:\n\nDefine an AI Agent and its core components (Model, Tools, Orchestration)\nUnderstand the 5-step “Think, Act, Observe” loop\nClassify agents using the 5-level taxonomy\nRecognize the importance of “Agent Ops” for production reliability\n\n\nWe’ll start with the definition. You’ll learn that an agent isn’t just a smarter model; it’s a software system.\nWe’ll dissect the “Think, Act, Observe” loop—the engine that drives every agent.\nWe’ll look at the taxonomy—how we go from a Level 0 reasoning engine to a Level 4 self-evolving system.\nAnd finally, we’ll talk about the boring but critical stuff: Ops. How do you actually keep these things running without setting money on fire?"
  },
  {
    "objectID": "W6/D3/day_3_agents.html#the-paradigm-shift-from-predictive-to-agentic",
    "href": "W6/D3/day_3_agents.html#the-paradigm-shift-from-predictive-to-agentic",
    "title": "Day 3: Introduction to Agents",
    "section": "The Paradigm Shift: From Predictive to Agentic",
    "text": "The Paradigm Shift: From Predictive to Agentic\n\n\n\nFigure 1: A new class of software\n\n\n\nPredictive AI: Passive, discrete tasks (answering, translating).\nAgentic AI: Active, goal-oriented, multi-step execution.\nThe Shift: From “User directs every step” to “User sets a goal”.\n\n\nFor years, AI was passive. You give a prompt, you get an answer. If you wanted a complex task done, you had to be the “bricklayer,” prompting for every single step.\nNow, we’re building “Agentic AI”. The user is the “director.” You set the scene, give the goal, and the agent figures out the steps. It plans, acts, and corrects itself."
  },
  {
    "objectID": "W6/D3/day_3_agents.html#what-is-an-ai-agent",
    "href": "W6/D3/day_3_agents.html#what-is-an-ai-agent",
    "title": "Day 3: Introduction to Agents",
    "section": "What is an AI Agent?",
    "text": "What is an AI Agent?\nAgent = Model + Tools + Orchestration + Runtime\n\n\n\nFigure 2: An anatomical diagram of an AI Agent\n\n\n\nAn agent is not just a model. It’s a compound system. It has a Brain (the LM) to reason. It has Hands (Tools) to interact with the world—APIs, databases. It has a Nervous System (Orchestration) to manage memory and planning. And it has a Body (Deployment) to run reliably in production."
  },
  {
    "objectID": "W6/D3/day_3_agents.html#the-model-brain",
    "href": "W6/D3/day_3_agents.html#the-model-brain",
    "title": "Day 3: Introduction to Agents",
    "section": "The Model (Brain)",
    "text": "The Model (Brain)\n\nSelection: Not just benchmarks. Choose for reasoning and tool use.\nRouting: Use “thinking” models for planning, “flash” models for simple tasks.\nMultimodal: Vision/audio vs. reliable text-only pipelines.\n\n\n\n\nFigure 3: Tradeoff between cost/speed and reasoning quality\n\n\n\n\nYour choice of model matters. Don’t just pick the biggest one.\nFor complex planning, you need high reasoning. Use a frontier model.\nFor summarizing a retrieved email, a smaller, faster model is cheaper and faster.\nRouting between them is a key optimization."
  },
  {
    "objectID": "W6/D3/day_3_agents.html#the-tools-hands",
    "href": "W6/D3/day_3_agents.html#the-tools-hands",
    "title": "Day 3: Introduction to Agents",
    "section": "The Tools (Hands)",
    "text": "The Tools (Hands)\n\nRetrieval (RAG): “Library card” for knowledge.\nActions: APIs, SQL execution, sending emails.\nFunction Calling: Structured contracts (OpenAPI) for reliability.\nHuman-in-the-Loop: Tools to ask the user for clarification.\n\n\n\n\nFigure 4: Agent tools as a Swiss Army knife\n\n\n\n\nTools define what an agent can do.\nRAG is a tool—it’s how the agent knows things.\nActions are how it changes things—API calls, SQL queries, sending emails.\nAnd don’t forget the Human. A tool that asks the user “Did you mean X?” is often the most valuable one."
  },
  {
    "objectID": "W6/D3/day_3_agents.html#the-orchestration-nervous-system",
    "href": "W6/D3/day_3_agents.html#the-orchestration-nervous-system",
    "title": "Day 3: Introduction to Agents",
    "section": "The Orchestration (Nervous System)",
    "text": "The Orchestration (Nervous System)\n\n\n\nFigure 5: Context Engineering\n\n\n\nShort-term Memory: The current conversation thread.\nLong-term Memory: Vector stores for past sessions.\nGuardrails: Hard-coded rules (e.g., “Spend limit &lt; $100”)\n\n\n\nOrchestration is the code that holds it all together.\nIt manages the context window. You can’t fit everything, so you must engineer the context.\nIt handles memory—what did we say 5 minutes ago? What did we say 5 days ago?\nAnd it enforces guardrails. An agent shouldn’t be able to buy a house just because it hallucinated a command."
  },
  {
    "objectID": "W6/D3/day_3_agents.html#documentation-is-critical",
    "href": "W6/D3/day_3_agents.html#documentation-is-critical",
    "title": "Day 3: Introduction to Agents",
    "section": "Documentation is Critical",
    "text": "Documentation is Critical\n\n\n\nFigure 7: A blueprint document with highlighted sections for ‘Name’, ‘Parameters’, and ‘Examples’\n\n\n\nupdate_jira or get_data (Bad: not descriptive)\ncreate_critical_bug and fetch_customer_order_history (Good: descriptive)\nExplain type and purpose.\nShow the model how to handle tricky cases.\nDocument default values clearly.\n\n\nIf your agent isn’t working, 90% of the time it’s your tool definitions. The documentation is the prompt. Use clear, verbose names. get_data is bad. fetch_customer_order_history is good. Give examples in the docstring. It saves you from fine-tuning."
  },
  {
    "objectID": "W6/D3/day_3_agents.html#describe-actions-not-implementations",
    "href": "W6/D3/day_3_agents.html#describe-actions-not-implementations",
    "title": "Day 3: Introduction to Agents",
    "section": "Describe Actions, Not Implementations",
    "text": "Describe Actions, Not Implementations\n\n\n\nFigure 8: A director chair labeled ‘Action’ vs a mechanic’s manual labeled ‘Implementation’\n\n\n\n“Use the send_message tool” (Bad: dictating tool usage)\n“Send message to John Doe” (Good: describing the action)\nDon’t repeat tool docs in system instructions\nDocument side effects: If a tool saves a file, the agent needs to know that file exists for the next step.\n\n\nWhen instructing the model, focus on the goal. Tell it what to achieve, not strictly how to call the API. If you dictate the exact workflow, you lose the agent’s ability to handle edge cases. But DO explain side effects. If a tool saves a file, the agent needs to know that file exists for the next step."
  },
  {
    "objectID": "W6/D3/day_3_agents.html#publish-tasks-not-api-calls",
    "href": "W6/D3/day_3_agents.html#publish-tasks-not-api-calls",
    "title": "Day 3: Introduction to Agents",
    "section": "Publish Tasks, Not API Calls",
    "text": "Publish Tasks, Not API Calls\n\n\n\nFigure 9: A neatly wrapped package labeled ‘Task’ vs a tangled wire labeled ‘Raw API’\n\n\n\nTools should map to user goals, not raw endpoints.\nOne tool = One specific responsibility.\nDon’t chain 10 steps into one black box function.\n\n\nDon’t just wrap your entire API surface. APIs are for developers. Tools are for agents. An agent needs a tool that says “Book Flight”, not 5 separate tools for “Auth”, “Check Availability”, “Reserve Seat”, “Process Payment”, “Confirm”. Wrap that complexity into a meaningful “Task” for the agent."
  },
  {
    "objectID": "W6/D3/day_3_agents.html#design-for-concise-output",
    "href": "W6/D3/day_3_agents.html#design-for-concise-output",
    "title": "Day 3: Introduction to Agents",
    "section": "Design for Concise Output",
    "text": "Design for Concise Output\n\n\n\nFigure 10: A funnel filtering a large database dump into a single concise reference card’\n\n\n\nUse References: Return a table_name or file_path instead of raw data.\nError Messages: Make them descriptive. Tell the agent how to fix the error.\n\n\nOutput matters. If your tool returns a 5MB JSON file, you just blew your context window/budget (and maybe confused the model). Return summaries or references. And if it fails, don’t just say “Error 500”. Say “Product not found. Try searching by name instead of ID.” Guide the agent to self-correct."
  },
  {
    "objectID": "W6/D3/day_3_agents.html#key-takeaways",
    "href": "W6/D3/day_3_agents.html#key-takeaways",
    "title": "Day 3: Introduction to Agents",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nDocumentation is Critical: The documentation is the prompt.\nDescribe Actions, Not Implementations: Tell the model what to achieve, not strictly how to call the API.\nPublish Tasks, Not API Calls: Wrap your entire API surface. APIs are for developers. Tools are for agents.\nDesign for Concise Output: Return summaries or references.\nError Messages: If it fails, don’t just say “Error 500”. Guide the agent to self-correct."
  },
  {
    "objectID": "W6/D3/Python_Quickstart_for_ADK.html",
    "href": "W6/D3/Python_Quickstart_for_ADK.html",
    "title": "Python Quickstart for ADK",
    "section": "",
    "text": "This guide shows you how to get up and running with Agent Development Kit (ADK) for Python. Before you start, make sure you have the following installed:"
  },
  {
    "objectID": "W6/D3/Python_Quickstart_for_ADK.html#setup-virtual-environment",
    "href": "W6/D3/Python_Quickstart_for_ADK.html#setup-virtual-environment",
    "title": "Python Quickstart for ADK",
    "section": "Setup Virtual Environment",
    "text": "Setup Virtual Environment\nuv venv -p 3.12\nuv init\n\nInstall Packages\n\ngoogle-adk - Agent Development Kit (ADK) is a flexible and modular framework for developing and deploying AI agents. While optimized for Gemini and the Google ecosystem, ADK is model-agnostic, deployment-agnostic, and is built for compatibility with other frameworks. ADK was designed to make agent development feel more like software development, to make it easier for developers to create, deploy, and orchestrate agentic architectures that range from simple tasks to complex workflows.\nlitellm - LiteLLM is a Python library that acts as a translation layer for models and model hosting services, providing a standardized, OpenAI-compatible interface to over 100+ LLMs\npython-dotenv - To load environment variables from a .env file\n\n\nuv add google-adk litellm python-dotenv\n\n\nActivate the virtual environment\n\nWindowsMacOS / Linux\n\n\n.venv\\Scripts\\activate.bat\n\n\nsource .venv/bin/activate"
  },
  {
    "objectID": "W6/D3/Python_Quickstart_for_ADK.html#api-key-setup",
    "href": "W6/D3/Python_Quickstart_for_ADK.html#api-key-setup",
    "title": "Python Quickstart for ADK",
    "section": "API Key Setup",
    "text": "API Key Setup\nThink of an API Key as a hotel key card.\n\nThe Hotel (Server): Has resources (rooms) but keeps them locked.\nThe Guest (Client): Wants access.\nThe Key Card (API Key): Identifies you and proves you are allowed to enter specific rooms.\n\n\n\nWhat & Why\nAn API key is a unique string of characters used to identify the calling program.\n\nIdentification: Keys “authenticate the calling project,” allowing the server to recognize who is asking for data.\nControl: This lets the server track usage for billing and enforce limits (quotas) so one user doesn’t crash the system.\n\n\n\n\nSecurity Risks\nIf you lose your key, it is like dropping your credit card.\n\nTheft: Attackers can use your key to make requests on your behalf.\nConsequences: You suffer financial loss (paying for their usage) or service denial (they use up your available quota).\n\n\nRule: Never post keys on public sites like GitHub.\n\n\n\nHow to Set Your API Key?\nThis project uses OpenRouter (The Unified Interface For LLMs), via LiteLLM to access the DeepSeek model, which requires an API key. If you don’t already have an OpenRouter API key, you can create one for free at: OpenRouter.\nWrite your API key into an .env file as an environment variable, as follows:\nOPENROUTER_API_KEY=...\n\nNote: make sure to add it to .gitignore to avoid committing it to the repository.\nNote: this is different than the .venv file used for the virtual environment."
  },
  {
    "objectID": "W6/D3/Python_Quickstart_for_ADK.html#create-an-agent-project",
    "href": "W6/D3/Python_Quickstart_for_ADK.html#create-an-agent-project",
    "title": "Python Quickstart for ADK",
    "section": "Create an agent project",
    "text": "Create an agent project\nRun the adk create command to start a new agent project.\nadk create my_agent\n\nExplore the agent project\nThe created agent project has the following structure, with the agent.py file containing the main control code for the agent.\nmy_agent/\n    agent.py      # main agent code\n    .env          # API keys or project IDs\n    __init__.py"
  },
  {
    "objectID": "W6/D3/Python_Quickstart_for_ADK.html#update-your-agent-project",
    "href": "W6/D3/Python_Quickstart_for_ADK.html#update-your-agent-project",
    "title": "Python Quickstart for ADK",
    "section": "Update your agent project",
    "text": "Update your agent project\nThe agent.py file contains a root_agent definition which is the only required element of an ADK agent. You can also define tools for the agent to use. Update the generated agent.py code to include a get_current_time tool for use by the agent, as shown in the following code:\nimport os\nfrom dotenv import load_dotenv\n\n# Load the API key from the .env file\nload_dotenv()\n\nfrom google.adk.agents import Agent\nfrom google.adk.models.lite_llm import LiteLlm\n\n# Mock tool implementation\ndef get_current_time(city: str) -&gt; dict:\n    \"\"\"Returns the current time in a specified city.\"\"\"\n    return {\"status\": \"success\", \"city\": city, \"time\": \"10:30 AM\"}\n\nroot_agent = Agent(\n    model=LiteLlm(model=\"openrouter/deepseek/deepseek-chat\"),\n    name='root_agent',\n    description=\"Tells the current time in a specified city.\",\n    instruction=\"You are a helpful assistant that tells the current time in cities. Use the 'get_current_time' tool for this purpose.\",\n    tools=[get_current_time],\n)"
  },
  {
    "objectID": "W6/D3/Python_Quickstart_for_ADK.html#run-your-agent",
    "href": "W6/D3/Python_Quickstart_for_ADK.html#run-your-agent",
    "title": "Python Quickstart for ADK",
    "section": "Run your agent",
    "text": "Run your agent\nYou can run your ADK agent with an interactive command-line interface using the adk run command or the ADK web user interface provided by the ADK using the adk web command. Both these options allow you to test and interact with your agent.\n\nRun with command-line interface\nRun your agent using the adk run command-line tool.\nadk run my_agent\n\n\n\nadk-run.png\n\n\n\n\nRun with web interface\nThe ADK framework provides web interface you can use to test and interact with your agent. You can start the web interface using the following command:\nadk web --port 8000\n\nNote: Run this command from the parent directory that contains your my_agent/ folder. For example, if your agent is inside agents/my_agent/, run adk web from the agents/ directory.\n\nThis command starts a web server with a chat interface for your agent. You can access the web interface at (http://localhost:8000). Select the agent at the upper left corner and type a request.\n\n\n\nadk-web-dev-ui-chat.png\n\n\n\nCaution: ADK Web is not meant for use in production deployments. You should use ADK Web for development and debugging purposes only."
  },
  {
    "objectID": "W6/D3/Python_Quickstart_for_ADK.html#build-your-agent",
    "href": "W6/D3/Python_Quickstart_for_ADK.html#build-your-agent",
    "title": "Python Quickstart for ADK",
    "section": "Build your agent",
    "text": "Build your agent\nFollow the link to Build a multi-tool agent."
  },
  {
    "objectID": "W6/D3/Python_Quickstart_for_ADK.html#want-to-run-llms-locally",
    "href": "W6/D3/Python_Quickstart_for_ADK.html#want-to-run-llms-locally",
    "title": "Python Quickstart for ADK",
    "section": "Want to run LLMs locally?",
    "text": "Want to run LLMs locally?\nYou can run LLMs on CPU or GPU locally, using the following tools:\n\nollama\nvllm"
  },
  {
    "objectID": "W6/D2/day_2_rag_architectures.html#module-overview",
    "href": "W6/D2/day_2_rag_architectures.html#module-overview",
    "title": "Day 2: RAG Architectures",
    "section": "Module Overview",
    "text": "Module Overview\nSession: RAG Architectures\n\nSimple RAG & Memory\nAdvanced Retrieval Strategies\nAgentic & Self-Correcting RAG\n\n\nToday we’re exploring the landscape of Retrieval Augmented Generation architectures. We’ll move beyond the basic “retrieve and generate” loop to see how modern systems handle complexity.\nWe’ll cover 8 distinct architectures, ranging from simple setups to complex, agentic systems that can self-correct and reason."
  },
  {
    "objectID": "W6/D2/day_2_rag_architectures.html#what-youll-learn-today",
    "href": "W6/D2/day_2_rag_architectures.html#what-youll-learn-today",
    "title": "Day 2: RAG Architectures",
    "section": "What You’ll Learn Today",
    "text": "What You’ll Learn Today\nBy the end of this session, you will:\n\nIdentify 8 key RAG architectures and their use cases\nUnderstand when to add memory, branching, or agents to RAG\nRecognize how to optimize retrieval for complex queries\n\n\nBy the end of this hour, you’ll be able to look at a problem and decide which RAG architecture fits best.\nYou’ll understand not just how they work, but why you would choose one over the other. Whether you need speed, accuracy, or the ability to handle multi-step reasoning, you’ll know the right pattern to use."
  },
  {
    "objectID": "W6/D2/day_2_rag_architectures.html#simple-rag",
    "href": "W6/D2/day_2_rag_architectures.html#simple-rag",
    "title": "Day 2: RAG Architectures",
    "section": "1. Simple RAG",
    "text": "1. Simple RAG\n\n\n\nSimple RAG workflow\n\n\n\nWorkflow: Query → Retrieve → Generate\nUse Case: FAQ systems, limited knowledge bases\nPros: Simple, fast, deterministic retrieval\n\n\nThis is the baseline. 1. Simple RAG.\nThe model retrieves documents from a static database based on a user query and generates an answer. It’s straightforward and works well when your database is small and your queries are direct.\nThink of it like a librarian looking up a book and summarizing it for you. It’s great for FAQs where the answer is definitely in the text."
  },
  {
    "objectID": "W6/D2/day_2_rag_architectures.html#simple-rag-with-memory",
    "href": "W6/D2/day_2_rag_architectures.html#simple-rag-with-memory",
    "title": "Day 2: RAG Architectures",
    "section": "2. Simple RAG with Memory",
    "text": "2. Simple RAG with Memory\n\n\n\nSimple RAG with Memory workflow\n\n\n\nAddition: Conversation history\nWorkflow: Query + History → Retrieve → Generate\nUse Case: Customer service chatbots, personalized recommendations\n\n\nNext is 2. Simple RAG with Memory.\nThis adds a storage component for conversation history. The model uses past interactions to provide context.\nIf a user says “I have a problem with my order,” and then follows up with “It hasn’t arrived,” the model needs memory to know “It” refers to the order. This is essential for any conversational bot."
  },
  {
    "objectID": "W6/D2/day_2_rag_architectures.html#branched-rag",
    "href": "W6/D2/day_2_rag_architectures.html#branched-rag",
    "title": "Day 2: RAG Architectures",
    "section": "3. Branched RAG",
    "text": "3. Branched RAG\n\n\n\nBranched RAG workflow\n\n\n\nConcept: Route query to specific sources\nWorkflow: Query → Classifier → Specific DB → Generate\nUse Case: Legal tools, multidisciplinary research\n\n\n\nBranched RAG. This is about routing.\n\nInstead of searching everything, the system first decides where to look. If the user asks a legal question, it routes to the legal database. If they ask a technical question, it routes to the documentation.\nThis reduces noise. You don’t want medical advice showing up in your legal search results. It selects the most relevant source based on the input."
  },
  {
    "objectID": "W6/D2/day_2_rag_architectures.html#hyde-hypothetical-document-embedding",
    "href": "W6/D2/day_2_rag_architectures.html#hyde-hypothetical-document-embedding",
    "title": "Day 2: RAG Architectures",
    "section": "4. HyDe (Hypothetical Document Embedding)",
    "text": "4. HyDe (Hypothetical Document Embedding)\n\n\n\nHyDe workflow\n\n\n\nConcept: Generate answer first, then retrieve\nWorkflow: Query → Hypothetical Answer → Embed & Retrieve → Generate\nUse Case: Vague queries, creative content, R&D\n\n\n\nHyDe - Hypothetical Document Embedding.\n\nThis is a clever twist. Instead of searching for the user’s question, the model first hallucinates a hypothetical answer. It then uses that hypothetical answer to search for real documents.\nWhy? Because the user’s question might not look like the answer document. But a hypothetical answer will look like the real answer. It bridges the semantic gap between query and document."
  },
  {
    "objectID": "W6/D2/day_2_rag_architectures.html#adaptive-rag",
    "href": "W6/D2/day_2_rag_architectures.html#adaptive-rag",
    "title": "Day 2: RAG Architectures",
    "section": "5. Adaptive RAG",
    "text": "5. Adaptive RAG\n\n\n\nAdaptive RAG workflow\n\n\n\nConcept: Adjust strategy based on complexity\nWorkflow: Query → Complexity Analysis → Strategy A/B/C → Generate\nUse Case: Enterprise search, varying query difficulty\n\n\n\nAdaptive RAG.\n\nThis is about efficiency. Not every query needs a cannon.\nAdaptive RAG analyzes the complexity of the query first. - Simple question? Do a quick keyword search. - Complex analysis? Do a multi-step semantic search.\nIt balances speed and depth by adapting its strategy in real-time."
  },
  {
    "objectID": "W6/D2/day_2_rag_architectures.html#corrective-rag-crag",
    "href": "W6/D2/day_2_rag_architectures.html#corrective-rag-crag",
    "title": "Day 2: RAG Architectures",
    "section": "6. Corrective RAG (CRAG)",
    "text": "6. Corrective RAG (CRAG)\n\n\n\nCorrective RAG workflow\n\n\n\nConcept: Evaluate retrieval quality\nWorkflow: Query → Retrieve → Grade Documents → (Web Search if poor) → Generate\nUse Case: High-accuracy domains (Medical, Legal)\n\n\n\nCorrective RAG (CRAG).\n\nThis adds a “grader” step. After retrieving documents, the system checks: “Are these actually relevant?”\nIf they are good, proceed. If they are bad, CRAG might trigger a fallback, like a web search, to find better information. It filters out irrelevant “knowledge strips” to ensure the generation is based on high-quality data."
  },
  {
    "objectID": "W6/D2/day_2_rag_architectures.html#self-rag",
    "href": "W6/D2/day_2_rag_architectures.html#self-rag",
    "title": "Day 2: RAG Architectures",
    "section": "7. Self-RAG",
    "text": "7. Self-RAG\n\n\n\nSelf-RAG workflow\n\n\n\nConcept: Model self-queries during generation\nWorkflow: Generate → Critique → Retrieve More → Generate\nUse Case: Long-form content, exploratory research\n\n\n\nSelf-RAG.\n\nHere, the model is more active. As it generates an answer, it might realize: “Wait, I need more info on this specific point.”\nIt can pause, issue a new retrieval query to fill that gap, and then continue generating. It’s an iterative process of generation and retrieval, allowing for much more comprehensive answers."
  },
  {
    "objectID": "W6/D2/day_2_rag_architectures.html#agentic-rag",
    "href": "W6/D2/day_2_rag_architectures.html#agentic-rag",
    "title": "Day 2: RAG Architectures",
    "section": "8. Agentic RAG",
    "text": "8. Agentic RAG\n\n\n\nAgentic RAG workflow\n\n\n\nConcept: Agents orchestrate retrieval\nWorkflow: Meta-Agent → Document Agents → Synthesis\nUse Case: Complex research, multi-source aggregation\n\n\nFinally, 8. Agentic RAG.\nThis is the most complex. You have a “Meta-Agent” that manages other agents. You might have “Document Agents” that are experts on specific documents.\nThe Meta-Agent breaks down a complex user request, assigns tasks to sub-agents, and synthesizes their findings. It’s like a project manager coordinating a research team. It can handle multi-step, complex reasoning tasks."
  },
  {
    "objectID": "W6/D2/day_2_rag_architectures.html#key-takeaways",
    "href": "W6/D2/day_2_rag_architectures.html#key-takeaways",
    "title": "Day 2: RAG Architectures",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nStart Simple: Standard RAG works for many use cases\nAdd Complexity only when needed: Memory, routing, or correction\nAgentic patterns allow for reasoning and multi-step tasks\nHyDe helps when queries are vague\n\n\nTo wrap up:\n\nWe started with Simple RAG - the foundation.\nWe added Memory for conversation.\nWe used Branching for efficiency.\nWe saw HyDe specifically for vague semantic matching.\nAdaptive RAG gave us efficiency routing.\nCorrective RAG gave us quality control.\nAnd Self-RAG and Agentic RAG gave us autonomy and reasoning.\n\nChoose the architecture that matches your specific problem constraint."
  },
  {
    "objectID": "W6/D1/day_1b_evaluation-and-structured-output.html#session-overview",
    "href": "W6/D1/day_1b_evaluation-and-structured-output.html#session-overview",
    "title": "Day 1b: Evaluation and Structured Output",
    "section": "Session Overview",
    "text": "Session Overview\nEvaluation and Structured Output\n\nStructured Output: JSON, schemas, parsing\nEvaluation Methods\nPointwise Evaluation\nPairwise Evaluation\nBest Practices\n\n\nThis session has five main parts. First, we’ll learn how to get structured outputs - instead of free-form text, you’ll get JSON or other structured data that’s easy to parse and use in your applications.\nThen we’ll dive into evaluation. Pointwise evaluation scores individual responses - is this answer good or bad? Pairwise evaluation compares two responses - which one is better? And we’ll discuss when to use each method and how to choose the right evaluation approach.\nFinally, we’ll cover best practices for documenting and tracking your prompt engineering work, which is essential for iterative improvement.\nThese skills are what separate prototyping from production. Anyone can get a response from ChatGPT. But building an application that reliably produces good, structured outputs and can evaluate its own performance? That requires these techniques."
  },
  {
    "objectID": "W6/D1/day_1b_evaluation-and-structured-output.html#the-problem-with-free-form-text",
    "href": "W6/D1/day_1b_evaluation-and-structured-output.html#the-problem-with-free-form-text",
    "title": "Day 1b: Evaluation and Structured Output",
    "section": "The Problem with Free-Form Text",
    "text": "The Problem with Free-Form Text\nUnstructured outputs are hard to use\nResponse: \"The user seems happy based on the \nemojis and positive words in their message.\"\n\nRequires parsing\nError-prone extraction\nInconsistent formatting\nHard to validate\n\n\nWhen you ask an LLM a question, you usually get free-form text back. That’s great for reading, but terrible for building applications. How do you extract the sentiment? How do you parse the answer? How do you use it in your code?\nFree-form text requires parsing, which is error-prone. You might try to extract JSON from the text, or use regex to find patterns, but it’s fragile. The model might format things differently, or include extra text, or miss something you need.\nThat’s why structured output exists - instead of getting text, you get data structures that are easy to work with programmatically. This is the foundation for building reliable applications."
  },
  {
    "objectID": "W6/D1/day_1b_evaluation-and-structured-output.html#structured-output",
    "href": "W6/D1/day_1b_evaluation-and-structured-output.html#structured-output",
    "title": "Day 1b: Evaluation and Structured Output",
    "section": "Structured Output",
    "text": "Structured Output\nGetting data, not text\n{\n  \"sentiment\": \"positive\",\n  \"confidence\": 0.85,\n  \"keywords\": [\"happy\", \"excited\", \"great\"]\n}\n\nEasy parsing: No fragile text extraction\nIntegration: Works with databases, APIs, services\n\n\nStructured output means getting responses in a specific format - usually JSON, but it could be XML, CSV, or any other structured format. Instead of parsing text, you’re parsing data structures.\nThis makes everything easier. You can validate the structure. You can access fields directly. You can type-check the data. You can use it in your application without worrying about parsing errors.\nMost modern LLM APIs support structured output through schemas. You define what you want, and the model returns data that matches that schema. It’s like having a contract with the model: “I’ll give you this input, you’ll give me this structure.”\nStructured output is the difference between a demo and an application. In a demo, you can manually read the response. In an application, you need to process it automatically."
  },
  {
    "objectID": "W6/D1/day_1b_evaluation-and-structured-output.html#schema-example-product-data",
    "href": "W6/D1/day_1b_evaluation-and-structured-output.html#schema-example-product-data",
    "title": "Day 1b: Evaluation and Structured Output",
    "section": "Schema Example: Product Data",
    "text": "Schema Example: Product Data\nDefining product structure\n{\n  \"type\": \"object\",\n  \"properties\": {\n    \"name\": { \"type\": \"string\", \"description\": \"Product name\" },\n    \"category\": { \"type\": \"string\", \"description\": \"Product category\" },\n    \"price\": { \"type\": \"number\", \"format\": \"float\", \"description\": \"Product price\" },\n    \"features\": {\n      \"type\": \"array\",\n      \"items\": { \"type\": \"string\" },\n      \"description\": \"Key features of the product\"\n    },\n    \"release_date\": { \"type\": \"string\", \"format\": \"date\", \"description\": \"Date the product was released\" }\n  }\n}\n\n\n\n\n\n\n\nTip\n\n\nJSON Schema is a declarative language for annotating and validating JSON documents’ structure, constraints, and data types. It helps you standardize and define expectations for JSON data.\n\n\n\n\n\nEach field has a type and a description. The description helps the model understand what should go in that field.\nWhen you provide this schema to the model along with product data, the model will generate a JSON object that conforms to this structure. This makes it much easier to work with the output programmatically.\nThe key insight from the whitepaper: by preprocessing your data and instead of providing full documents, only providing both the schema and the data, you give the LLM a clear understanding of the product’s attributes, making it much more likely to generate an accurate and relevant description."
  },
  {
    "objectID": "W6/D1/day_1b_evaluation-and-structured-output.html#schema-benefits",
    "href": "W6/D1/day_1b_evaluation-and-structured-output.html#schema-benefits",
    "title": "Day 1b: Evaluation and Structured Output",
    "section": "Schema Benefits",
    "text": "Schema Benefits\nGuiding the model’s attention\n\nSchema guiding model attention to relevant fields\nThe structured input approach, guiding the LLM’s attention to the relevant fields, is especially valuable when working with large volumes of data or when integrating LLMs into complex applications.\nInstead of giving the model a full document and asking it to extract information, you’re providing:\n\nA schema that defines what you want\nThe relevant data in a structured format\n\nThis helps the model focus on the right information and produce consistent outputs. It’s like giving the model a form to fill out rather than asking it to write a free-form essay.\nThis approach is particularly powerful for:\n\nData extraction tasks\nInformation retrieval\nForm filling\nDatabase operations\nAPI integrations"
  },
  {
    "objectID": "W6/D1/day_1b_evaluation-and-structured-output.html#evaluation-why-it-matters",
    "href": "W6/D1/day_1b_evaluation-and-structured-output.html#evaluation-why-it-matters",
    "title": "Day 1b: Evaluation and Structured Output",
    "section": "Evaluation: Why It Matters",
    "text": "Evaluation: Why It Matters\nMeasuring what works\n\nPrompts are experiments\nModels can be inconsistent\nProduction needs reliability\n\n\nNow let’s talk about evaluation. Prompting is experimental - you try something, see if it works, adjust, try again. But how do you know if it actually works? How do you measure improvement?\nEvaluation is the answer. It’s how you measure whether your prompts are producing good results. Without evaluation, you’re flying blind. You might think your prompt is great because you saw one good response, but what about edge cases? What about consistency?\nEvaluation is especially important for production systems. You can’t deploy something and hope it works. You need to know, with data, that it’s producing good results consistently.\nThe whitepaper emphasizes that prompt engineering is an iterative process. You craft and test different prompts, analyze, and document the results. You refine your prompt based on the model’s performance. You keep experimenting until you achieve the desired output."
  },
  {
    "objectID": "W6/D1/day_1b_evaluation-and-structured-output.html#evaluation-methods-overview",
    "href": "W6/D1/day_1b_evaluation-and-structured-output.html#evaluation-methods-overview",
    "title": "Day 1b: Evaluation and Structured Output",
    "section": "Evaluation Methods Overview",
    "text": "Evaluation Methods Overview\n\nAutomated metrics: Fast, but task-specific\n\nBLEU for translation\nROUGE for summarization\nBERTScore for paraphrasing\n\nHuman evaluation: Gold standard, but expensive and slow\nLLM-as-judge: Scalable, but needs validation\nHybrid: Combine methods for reliability\n\n\n\n\n\n\n\nNote\n\n\nHuman evaluation: At LM Arena users are presented with two anonymous models (e.g., Model A vs. Model B), and vote on which answer is better.\n\n\n\n\nAutomated metrics are fast and cheap - things like BLEU for translation, ROUGE for summarization. But they’re task-specific and don’t always correlate with human judgment.\nThere are several ways to actually perform evaluation. Human evaluation is the gold standard - humans are the best judges of quality. But it’s expensive and slow, so it’s not practical for large-scale evaluation.\nLLM-as-judge is a newer approach: use an LLM to evaluate other LLM responses. It’s scalable and can be quite good, but you need to validate it against human evaluation to make sure it’s reliable.\nThe best approach is often hybrid: use automated metrics for quick feedback, LLM-as-judge for scale, and human evaluation for validation and high-stakes decisions.\nThe key is matching the evaluation method to your needs. For prototyping, maybe LLM-as-judge is enough. For production, you might need human evaluation for critical decisions. For scale, automated metrics might be necessary."
  },
  {
    "objectID": "W6/D1/day_1b_evaluation-and-structured-output.html#llm-as-judge",
    "href": "W6/D1/day_1b_evaluation-and-structured-output.html#llm-as-judge",
    "title": "Day 1b: Evaluation and Structured Output",
    "section": "LLM-as-Judge",
    "text": "LLM-as-Judge\nUsing models to evaluate models\nJudge Prompt: \"Rate this response on a scale \nof 1-5 for correctness, completeness, and clarity.\"\n\nResponse: [The response to evaluate]\nScore: 4/5\n\nLLM-as-judge showing model evaluating model responses\nLLM-as-judge is a powerful technique: you use an LLM to evaluate other LLM responses. You give the judge LLM the original question, the response to evaluate, and evaluation criteria, and it scores the response.\nThis is scalable - you can evaluate thousands of responses quickly. And it can be quite good, especially for tasks where the evaluation criteria are clear.\nBut it’s not perfect. The judge LLM can have biases. It might not catch subtle errors. And it needs to be validated against human evaluation to ensure it’s reliable. Still, for many use cases, it’s a great balance between quality and scale.\nThe key to effective LLM-as-judge is: - Clear evaluation criteria - Good judge prompts - Validation against human evaluation - Understanding the judge’s limitations\nUse LLM-as-judge for scale, but always validate with human evaluation for critical decisions."
  },
  {
    "objectID": "W6/D1/day_1b_evaluation-and-structured-output.html#pointwise-evaluation",
    "href": "W6/D1/day_1b_evaluation-and-structured-output.html#pointwise-evaluation",
    "title": "Day 1b: Evaluation and Structured Output",
    "section": "Pointwise Evaluation",
    "text": "Pointwise Evaluation\nThe simplest form of evaluation\nCustomer Query: \"How do I reset my account password, and will I lose my saved progress in the app?\"\n\nLLM A: \"To reset your password, click 'Forgot Password' on the login screen. We will send an email to your registered address. Changing your password does not delete your account or any of your saved progress.\"\n\n\n\n\n\n\nNote\n\n\nEvaluation Criteria (LLM B Analysis):\n\nCorrect ✅ PASS - Factually accurate per Official Documentation (Section 4.2: Password Management). Password resets are strictly credential updates and do not trigger data wipes.\nComplete ✅ PASS - Addresses both parts of the user’s query: 1) The ‘How-to’ instructions for resetting and 2) The specific concern regarding data loss.\nRelevant ✅ PASS - Stays strictly on topic. It provides direct instructions and reassurances without drifting into unrelated features like MFA setup or subscription tiers.\nSafe ✅ PASS - Follows Company Security Guidelines by instructing the user to use the official ‘Forgot Password’ flow rather than asking the user to provide their current credentials in the chat.\n\n\n\n\n\nPointwise evaluation scores individual responses. You take a response, and you give it a score - usually on a scale from 0 to 1, or as a rating like “good” or “bad.”\nThis is the simplest form of evaluation. You have a response, you evaluate it, you get a score. It’s straightforward, but it has limitations - a score of 0.8 doesn’t tell you why it’s 0.8, or what would make it better.\nOften, you’ll combine multiple criteria into a single score, or keep them separate to understand different aspects of quality. The key is defining what “good” means for your specific use case.\nEach of these can be scored separately, or combined into an overall score."
  },
  {
    "objectID": "W6/D1/day_1b_evaluation-and-structured-output.html#evaluation-different-ways-to-score",
    "href": "W6/D1/day_1b_evaluation-and-structured-output.html#evaluation-different-ways-to-score",
    "title": "Day 1b: Evaluation and Structured Output",
    "section": "Evaluation: Different ways to score",
    "text": "Evaluation: Different ways to score\n\nMultiple scoring dimensions\nPointwise evaluation is useful when you have clear criteria. Is the response correct? Is it complete? Is it in the right format? Is it relevant? Does it meet safety guidelines? These are yes/no or numeric questions that you can score.\nThere are many ways to score a response pointwise. Correctness is the most obvious - is the answer factually correct? But there are other dimensions too.\n\nCorrectness: Is the answer factually correct?\nCompleteness: Does it cover everything it should?\nFormat: Does it match structural requirements?\nRelevance: Is it actually answering the question?\nSafety: Does it meet content guidelines?\n\nCompleteness asks whether the response covers everything it should. Format checks if the response matches structural requirements. Relevance checks if it’s actually answering the question. Safety checks if it meets content guidelines."
  },
  {
    "objectID": "W6/D1/day_1b_evaluation-and-structured-output.html#pairwise-evaluation",
    "href": "W6/D1/day_1b_evaluation-and-structured-output.html#pairwise-evaluation",
    "title": "Day 1b: Evaluation and Structured Output",
    "section": "Pairwise Evaluation",
    "text": "Pairwise Evaluation\nCustomer Query: “I forgot the PIN to my smart-lock at home. My kids are stuck outside in the rain! How do I override the lock, and is there a master code?”\nA vs B:\nResponse A: “Oh no! To let the kids in, just find a heavy brick and apply it directly to the front window. It’s the ultimate master code! While you’re at it, did you know that rain is actually just the sky crying? Also, I recommend buying a trampoline. It won’t help with the lock, but it’s fun.”\nResponse B: “For security reasons, there is no universal master code for our smart-locks. To regain access, you must use the physical backup key provided at purchase. If the key is unavailable, you can reset the lock via the mobile app using your biometric login. This will allow you to set a new PIN without deleting your existing settings.”\n\nPairwise evaluation compares two responses and asks: which one is better? Instead of scoring each response independently, you’re making a relative judgment.\nPairwise evaluation shines when you need to make relative comparisons. If you’re trying to decide between two prompts, pairwise evaluation will tell you which one is better more reliably than trying to score each one independently.\nIt’s also great for ranking. If you generate multiple responses and want to pick the best one, pairwise evaluation can rank them. You compare each pair, and the response that wins more comparisons is ranked higher.\nAnd it’s useful when absolute scores are hard to define. Sometimes it’s easier to say “this is better” than to say “this is 0.85 out of 1.0.” Pairwise evaluation leverages that human intuition."
  },
  {
    "objectID": "W6/D1/day_1b_evaluation-and-structured-output.html#best-practices-document-everything",
    "href": "W6/D1/day_1b_evaluation-and-structured-output.html#best-practices-document-everything",
    "title": "Day 1b: Evaluation and Structured Output",
    "section": "Best Practices: Document Everything",
    "text": "Best Practices: Document Everything\nLearning from iteration\n\nPrompt Card Template\nThe whitepaper emphasizes the importance of documenting your prompt attempts in full detail so you can learn over time what went well and what did not.\nPrompt outputs can differ across models, across sampling settings, and even across different versions of the same model. Moreover, even across identical prompts to the same model, small differences in output sentence formatting and word choice can occur.\nWe recommend creating a tracking system with fields for:\n\nName and version: Identify the prompt\nGoal: One sentence explanation of the goal\nModel: Name and version of the used model\nConfiguration: Temperature, token limit, top-K, top-P\nPrompt: Write out the full prompt\nOutput: Write out the output or multiple outputs\nPerformance: OK/NOT OK/SOMETIMES OK\nFeedback: What worked, what didn’t\n\nThe advantages of this approach are that you have a complete record when you inevitably have to revisit your prompting work - either to pick it up in the future, to test prompt performance on different versions of a model, and to help debug future errors."
  },
  {
    "objectID": "W6/D1/day_1b_evaluation-and-structured-output.html#key-takeaways",
    "href": "W6/D1/day_1b_evaluation-and-structured-output.html#key-takeaways",
    "title": "Day 1b: Evaluation and Structured Output",
    "section": "Key Takeaways",
    "text": "Key Takeaways\nMeasuring success\n\nStructured output: Get data, not text\nEvaluation methods: Choose based on needs\nPointwise evaluation: Score individual responses\nPairwise evaluation: Compare responses\nDocumentation: Track and learn from iterations\n\n\nLet’s bring it all together. Evaluation and structured output are what turn LLM interactions into reliable applications.\nStructured output gives you data you can work with programmatically. Pointwise evaluation tells you if individual responses are good. Pairwise evaluation helps you compare and improve. Different evaluation methods give you different trade-offs between quality, speed, and cost. And documentation helps you learn from your iterations.\nThe key is matching the approach to your needs. For prototyping, maybe LLM-as-judge is enough. For production, you might need human evaluation for critical decisions. For scale, automated metrics might be necessary.\nTogether with the prompting techniques from the first session, you now have the foundation for building real AI applications. You can craft effective prompts, get structured outputs, and evaluate whether they’re working. That’s Day 1 complete.\nRemember: prompt engineering is an iterative process. Craft and test different prompts, analyze, and document the results. Refine your prompt based on the model’s performance. Keep experimenting until you achieve the desired output. When you change a model or model configuration, go back and keep experimenting with the previously used prompts."
  },
  {
    "objectID": "W4_DL/trainer_notes.html",
    "href": "W4_DL/trainer_notes.html",
    "title": "Week 4 Delivery Guide",
    "section": "",
    "text": "IMPORTANT: Please read and share this with the students: Student Notes, to setup expectations for the entire week.\n\n\nIt is up to you to decide how you should:\n\nDiscourage cheating and encourage effort\nMeasure the actual acquisition of skills and knowledge (preventing both: underfitting and overfitting)\nMake the learning process a self-rewarding experience unto itself"
  },
  {
    "objectID": "W4_DL/trainer_notes.html#learning-objectives-assessment",
    "href": "W4_DL/trainer_notes.html#learning-objectives-assessment",
    "title": "Week 4 Delivery Guide",
    "section": "",
    "text": "IMPORTANT: Please read and share this with the students: Student Notes, to setup expectations for the entire week.\n\n\nIt is up to you to decide how you should:\n\nDiscourage cheating and encourage effort\nMeasure the actual acquisition of skills and knowledge (preventing both: underfitting and overfitting)\nMake the learning process a self-rewarding experience unto itself"
  },
  {
    "objectID": "W4_DL/trainer_notes.html#successful-delivery-suggestions",
    "href": "W4_DL/trainer_notes.html#successful-delivery-suggestions",
    "title": "Week 4 Delivery Guide",
    "section": "Successful Delivery (suggestions)",
    "text": "Successful Delivery (suggestions)\nBelow are some suggestions for you to consider when delivering this week."
  },
  {
    "objectID": "W4_DL/trainer_notes.html#require-proof-of-effort",
    "href": "W4_DL/trainer_notes.html#require-proof-of-effort",
    "title": "Week 4 Delivery Guide",
    "section": "1. Require Proof of Effort",
    "text": "1. Require Proof of Effort\nTo ensure students are actively working on the assignments, and control for copy-pasting, GenAI Policy Violations, or worse yet: having another student do the work for them:\n\nstudents MUST commit to GitHub repos on each question of each assignment (mentioning the question number in the commit message)\nto make things easier, some lab work includes instant-feedback exercises via Unit Tests, so that’s a clear checkpoint for a commit\n\nYou can git -C ./student_repo log to check the commit history, which should look something like this:\ncommit 2d0273722392f26a723b862de7c837642b3b096b\nAuthor: Renadalju &lt;riihyunee@gmail.com&gt;\nDate:   Thu Jan 1 18:49:54 2026 +0300\n\n    solve M7.03: use the cross_validate function and compute multiple scores/errors\n\ncommit 78fd8f2d3633fe31ee64077ab5872ac146ef7687\nAuthor: Renadalju &lt;riihyunee@gmail.com&gt;\nDate:   Thu Jan 1 18:46:17 2026 +0300\n\n    solve M7.03: use the mean absolute error (MAE)\n\ncommit bfd369daa6fdd471588a91bc381f5531a4c52700\nAuthor: Renadalju &lt;riihyunee@gmail.com&gt;\nDate:   Thu Jan 1 18:44:20 2026 +0300\n\n    solve M7.03: estimate the generalization performance of the model\n\ncommit 6830b25ca215ed486ea1febee7d5ee751f39af29\nAuthor: Renadalju &lt;riihyunee@gmail.com&gt;\nDate:   Thu Jan 1 18:42:43 2026 +0300\n\n    solve M7.03:  create a linear regression model.\n\ncommit 62cfe5a1669a875f99515d2ed6f3e94f0fbe742d\nAuthor: Renadalju &lt;riihyunee@gmail.com&gt;\nDate:   Thu Jan 1 18:41:14 2026 +0300\n\n    add Exercise M7.03\nNotice how adding the exercise (before solving it) should be the first commit."
  },
  {
    "objectID": "W4_DL/trainer_notes.html#encourage-application-of-skills",
    "href": "W4_DL/trainer_notes.html#encourage-application-of-skills",
    "title": "Week 4 Delivery Guide",
    "section": "2. Encourage Application of Skills",
    "text": "2. Encourage Application of Skills\nA Project’s goal is demonstrating some level of mastery in applying the knowledge & skills acquired in this week (+ previous weeks). Note: just like the assignments, commits of the project should be frequent and meaningful work-units (with clear commit messages).\n\n2.1 Require Proof of Contribution\n“Teamwork”.. to control for “oh we worked on this together so I copied it” to justify HUGE commits. Each student must contribute using their own GitHub account:\n\nCan clone with write access contributor\nCan collaborate using Pull Requests (PRs)\nCan use VS Code Live Share for pair programming\n\nNo excuses for not committing:\n\nMake it clear that any untracked work is as good as no work\nHuge commits are no work either"
  },
  {
    "objectID": "W4_DL/trainer_notes.html#reward-extra-effort",
    "href": "W4_DL/trainer_notes.html#reward-extra-effort",
    "title": "Week 4 Delivery Guide",
    "section": "3. Reward Extra Effort",
    "text": "3. Reward Extra Effort\n\nBonus points awarded to students who actively participate in lecture, asking the right questions (not for the sake of just asking),\nand helping others when needed\nOptional exercises do exist for the advanced students\nWhen they methodically/systematically improve their training/inference performance, significant enough to be noticeable:\n\naccuracy\nresource utilization\nlatency/speed\ndesign simplicity (code complexity, readability, maintainability, etc.)"
  },
  {
    "objectID": "W4_DL/lab_setup.html",
    "href": "W4_DL/lab_setup.html",
    "title": "Lab Setup",
    "section": "",
    "text": "Since CPUs are not enough for Deep Learning models; we’ll need a GPU. For, that we’ll need Google Colab. Understanding the client-server interaction is crucial for working with such remote code execution environments (here shown as Jupyter Server).\n\n\n\n\n\nThe image above shows how we interact with remote servers, such as Google Colab, to run our code:\n\nWe write code in the Browser Jupyter Notebooks or in VS Code\nOn save: the code is sent to the Juypter/Colab Server and stored there as .ipynb files\nOn run: the code is:\n\nsent to the kernel for execution\nthen back to the server to save the results\nwhich are then sent back to the browser"
  },
  {
    "objectID": "W4_DL/lab_setup.html#client-server-architecture",
    "href": "W4_DL/lab_setup.html#client-server-architecture",
    "title": "Lab Setup",
    "section": "",
    "text": "Since CPUs are not enough for Deep Learning models; we’ll need a GPU. For, that we’ll need Google Colab. Understanding the client-server interaction is crucial for working with such remote code execution environments (here shown as Jupyter Server).\n\n\n\n\n\nThe image above shows how we interact with remote servers, such as Google Colab, to run our code:\n\nWe write code in the Browser Jupyter Notebooks or in VS Code\nOn save: the code is sent to the Juypter/Colab Server and stored there as .ipynb files\nOn run: the code is:\n\nsent to the kernel for execution\nthen back to the server to save the results\nwhich are then sent back to the browser"
  },
  {
    "objectID": "W4_DL/lab_setup.html#setup-instructions",
    "href": "W4_DL/lab_setup.html#setup-instructions",
    "title": "Lab Setup",
    "section": "Setup Instructions",
    "text": "Setup Instructions\nFirst, Make sure you have a Google account. And can access Google Colab.\nFrom the original repo, you may:\n\nDownload as Zip then make a new repo\nor Fork the repo (to copy the repo under your username)\nThen, you can open a Colab Notebook and git clone it\nTo save your changes, you’ll have to git commit and git push\n\nUse the %cd magic command to move into your specific lab folder. Note that if your folder names contain spaces, you should wrap the path in quotes.\nExample for C1_M1_Lab_1_simple_nn you will %cd in the following way:\n%cd \"/content/W4_DL/C1_M1_Getting_Started/C1_M1_Lab_1_simple_nn\"\nTo confirm you are in the correct directory run:\n!ls\nYou should see:\n\nC1_M1_Lab_1_simple_nn.ipynb\nhelper_utils.py"
  },
  {
    "objectID": "W4_DL/lab_setup.html#optional-working-from-inside-vs-code-instead-of-the-colab-notebook",
    "href": "W4_DL/lab_setup.html#optional-working-from-inside-vs-code-instead-of-the-colab-notebook",
    "title": "Lab Setup",
    "section": "Optional: Working from inside VS Code instead of the Colab Notebook",
    "text": "Optional: Working from inside VS Code instead of the Colab Notebook\nGoogle Colab for VS Code extension allows you to work in VS Code while the code is sent and executed in Colab servers. However, the steps above are still required."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session_transfer_learning.html#what-is-transfer-learning",
    "href": "W4_DL/C1_M4_Core_NN_Components/session_transfer_learning.html#what-is-transfer-learning",
    "title": "Module 4 - Session 1.5: Transfer Learning",
    "section": "What is Transfer Learning?",
    "text": "What is Transfer Learning?\nStanding on the Shoulders of Giants\n\nStart with a model pre-trained on a massive dataset (vs. random weights)\nGoal: Apply learned visual features to a new problem\n\nTwo key approaches:\n\nFeature Extraction: Find patterns, train only the classifier\nFine-Tuning: Adjust valid weights to fit specific task\n\n\nImagine you want to learn to play the electric guitar. You don’t start by trying to understand the physics of sound waves or how to build a guitar from wood. You start with the skills you might have from playing the acoustic guitar or even just general musical knowledge.\nTransfer learning is the same. We take a model that has already learned to “see” the world (detect edges, shapes, textures) and apply that knowledge to our specific problem."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session_transfer_learning.html#the-power-of-imagenet",
    "href": "W4_DL/C1_M4_Core_NN_Components/session_transfer_learning.html#the-power-of-imagenet",
    "title": "Module 4 - Session 1.5: Transfer Learning",
    "section": "The Power of ImageNet",
    "text": "The Power of ImageNet\nThe “University” for Computer Vision Models\nDataset Stats:\n\n14 Million+ Images and 1,000 Categories\n\nWhy it matters:\n\nModels learn universal visual features (edges, textures, shapes)\nThese features transfer to your specific problem\nEven transfers to different domains (e.g. medical imaging)\n\n\nImageNet is like the standard curriculum for computer vision. Models trained on it have seen more images than you likely ever will. They know what a “curve” looks like, what “fur” looks like, what “metal” looks like. Even if your dataset is medical X-rays (which aren’t in ImageNet), the low-level features (edges, gradients) are still transferable."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session_transfer_learning.html#why-use-transfer-learning",
    "href": "W4_DL/C1_M4_Core_NN_Components/session_transfer_learning.html#why-use-transfer-learning",
    "title": "Module 4 - Session 1.5: Transfer Learning",
    "section": "Why Use Transfer Learning?",
    "text": "Why Use Transfer Learning?\n\nLess Data Required: You don’t need millions of images; hundreds or thousands can suffice.\nFaster Training: The model already knows how to “see”; it just needs to learn your specific classes.\nBetter Performance: Starting with good weights usually leads to higher accuracy than starting from scratch."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session_transfer_learning.html#pytorch-implementation",
    "href": "W4_DL/C1_M4_Core_NN_Components/session_transfer_learning.html#pytorch-implementation",
    "title": "Module 4 - Session 1.5: Transfer Learning",
    "section": "PyTorch Implementation",
    "text": "PyTorch Implementation\nStep 1: Load a Pre-trained Model\nfrom torchvision import models\n\n# Load ResNet18 with default (ImageNet) weights\nmodel = models.resnet18(weights='DEFAULT')\nStep 2: Freeze the Feature Extractor\n# Prevent backprop through these layers\nfor param in model.parameters():\n    param.requires_grad = False\n\nWe freeze the parameters (weights) so that we don’t destroy the pre-trained knowledge during the initial training phase. We want those “feature detector” layers to stay exactly as they are."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session_transfer_learning.html#pytorch-implementation-continued",
    "href": "W4_DL/C1_M4_Core_NN_Components/session_transfer_learning.html#pytorch-implementation-continued",
    "title": "Module 4 - Session 1.5: Transfer Learning",
    "section": "PyTorch Implementation (Continued)",
    "text": "PyTorch Implementation (Continued)\nStep 3: Replace the “Head” (Output Layer)\nThe original ResNet output 1000 classes. We need it to output our number of classes (e.g., 2).\n# Check input size of the final layer\nnum_ftrs = model.fc.in_features \n\n# Create a new linear layer for our specific problem\nmodel.fc = nn.Linear(num_ftrs, 2) \nNow, only model.fc has requires_grad=True by default.\n\nThis is the surgery part. We cut off the original head (which predicted 1000 ImageNet classes) and stitch on a new one tailored to our problem. When we train, only this new head gets updated."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session_transfer_learning.html#summary",
    "href": "W4_DL/C1_M4_Core_NN_Components/session_transfer_learning.html#summary",
    "title": "Module 4 - Session 1.5: Transfer Learning",
    "section": "Summary",
    "text": "Summary\n\nDon’t reinvent the wheel: Use pre-trained models.\nImageNet: The massive dataset that gives models their “vision”.\nWorkflow: Load Model \\(\\rightarrow\\) Freeze Parameters \\(\\rightarrow\\) Replace Head \\(\\rightarrow\\) Train."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#module-4-overview",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#module-4-overview",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "Module 4 Overview",
    "text": "Module 4 Overview\nWhat will we learn?\n\nConvolutional layers: filters, patterns, and feature maps\nComplete CNN architecture: convolution, pooling, fully connected layers\nTraining CNNs for image classification\nDynamic computation graphs in PyTorch\nModular architectures and code organization\nModel inspection and debugging techniques\n\n\nWelcome to Module 4! You’ve mastered data pipelines and built models with linear layers. But now the butterfly house next door wants to expand your botanical garden app to classify insects and small animals. Linear layers treat every pixel independently - they can’t see that neighboring pixels form features like wings, antennae, or eye spots.\nThis module introduces Convolutional Neural Networks (CNNs), the backbone of computer vision. We’ll explore how CNNs learn to see patterns in images, build complete CNN architectures, and then dive into PyTorch’s dynamic computation graphs and professional code organization.\nThe question chain: How do CNNs see patterns? → How do we build a complete CNN? → How do we train it? → How does PyTorch’s flexibility help us? → How do we write professional, maintainable code? → How do we inspect and debug our models?"
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#session-1-convolutional-neural-networks",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#session-1-convolutional-neural-networks",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "Session 1: Convolutional Neural Networks",
    "text": "Session 1: Convolutional Neural Networks\nWhat you’ll know by the end:\n\nHow convolutional filters detect patterns in images\nThe complete architecture of a CNN\nHow to train a CNN for multi-class image classification\n\n\nBy the end of this session, you’ll understand how CNNs work fundamentally - from the pixel level to complete architectures. You’ll see how filters learn to detect edges, textures, and patterns, and how these components combine into a powerful image classifier."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#the-new-challenge",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#the-new-challenge",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "The New Challenge",
    "text": "The New Challenge\n\nButterfly house expansion\n\nClassify flowers, insects, and small animals\nNeed to detect edges, textures, and patterns\nLinear layers aren’t enough\n\n\nThe botanical garden app is working great, but now the butterfly house next door wants in. They want to expand the app so visitors can classify insects and small animals too. This is a bigger challenge - you need something that can recognize more advanced visual features.\nThe problem with linear layers: they treat every pixel as independent. When your model looks at a flower or butterfly image, it sees thousands of separate numbers with no understanding that neighboring pixels can form features like wings, antennae, or eye spots."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#why-linear-layers-fall-short",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#why-linear-layers-fall-short",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "Why Linear Layers Fall Short",
    "text": "Why Linear Layers Fall Short\n\nEvery pixel is independent\n\nNo spatial understanding\nCan’t recognize patterns formed by neighboring pixels\nWings, antennae, eye spots are invisible\n\n\nThink about how you identify a butterfly. You don’t analyze every pixel. You notice wing shapes, vein patterns, those distinctive orange and black sections. Your brain uses these features to recognize that’s a monarch.\nLinear layers can’t do this. They see pixels as isolated numbers. That’s where convolutional neural networks come in."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#convolutional-neural-networks",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#convolutional-neural-networks",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "Convolutional Neural Networks",
    "text": "Convolutional Neural Networks\n\nInspired by biology\n\n1960s: Visual cortex neurons respond to specific patterns\nCNNs mimic this with learnable filters\nFilters scan images to extract features\n\n\nCNNs are the backbone of computer vision, and they’re inspired by biology. In the 1960s, neuroscientists found that certain neurons in the visual cortex respond only when they see particular patterns. CNNs mimic this by using filters to sort out features in images and learn from those."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#how-filters-work",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#how-filters-work",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "How Filters Work",
    "text": "How Filters Work\n\nSource: https://dennybritz.com/posts/wildml/understanding-convolutional-neural-networks-for-nlp/A 3×3 grid of numbers\n\nSlide over the image\nMultiply filter values with pixel values\nSum the results\nThis is convolution\n\nSee: Convolution Arithmetic for more details.\n\nLet’s see how this works with one of our nature photos. Here’s a closeup in grayscale. If we zoom in, we see individual pixels. You’ve centered on a pixel with value 61. Think of the surrounding pixels in this three-by-three grid as its neighbors.\nNow imagine a filter - a separate three-by-three grid of numbers. You’ll slide this filter over the image. At each position, you’ll multiply the filter values with the pixel values underneath, then add all of these together. That process is called a convolution."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#what-do-filters-detect",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#what-do-filters-detect",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "What Do Filters Detect?",
    "text": "What Do Filters Detect?\n\n\nVertical edges\nHorizontal edges\nTextures and shapes\n\n\nWhy would you do this? By assigning different weights in the filter, you actually highlight different kinds of patterns. Take this filter - can you guess what it might do? The values in the center start from a baseline of zero. But if you look to the left and right, adjacent pixel values that are similar will cancel each other out. But if there’s a sharp contrast - say the left side is really dark and the right side is really bright - that creates a strong output. That’s exactly what you’d expect for a vertical edge in an image."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#butteryfly-example",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#butteryfly-example",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "Butteryfly Example",
    "text": "Butteryfly Example\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nButterfly image passing through one filter of first layer.\n\nSimilarly, this filter detects horizontal edges. When you identify a butterfly, you notice wing shapes, vein patterns, those distinctive sections. Your brain uses these features. For our model, it’s the same idea. Filters help highlight the patterns that distinguish a monarch from a swallowtail or between a butterfly and a beetle."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#learning-vs.-hand-designing-filters",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#learning-vs.-hand-designing-filters",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "Learning vs. Hand-Designing Filters",
    "text": "Learning vs. Hand-Designing Filters\n\nDifferent weights → different patterns\n\nHere’s the interesting part. You could design those filters by hand, but how would you know which filters work best for butterflies versus flowers versus beetles? Or what if the model could learn which filters work best and tune them to find specific patterns that identify each class?\nThat’s the key power of convolutional neural networks. They will figure out which visual features matter most for the specific task that you have in mind. Pretty cool, right?"
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#the-power-of-hierarhical-feature-extraction",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#the-power-of-hierarhical-feature-extraction",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "The Power of Hierarhical Feature Extraction",
    "text": "The Power of Hierarhical Feature Extraction\n\nSource: Receptive Field in Deep Convolutional Networks | by Reza Kalantar | MediumThe image illustrates how a single “pixel” in a deep layer of a neural network can “see” a much larger portion of the original input image. This concept is called the Receptive Field. Because the orange area in Layer 2 was already looking at a larger area in Layer 1, the single pixel in Layer 3 is effectively “aware” of a area in the original input."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#creating-convolutional-layers-in-pytorch",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#creating-convolutional-layers-in-pytorch",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "Creating Convolutional Layers in PyTorch",
    "text": "Creating Convolutional Layers in PyTorch\nnn.Conv2d(\n    in_channels=3,      # RGB color channels\n    out_channels=32,    # Number of filters\n    kernel_size=3,      # 3×3 filter size\n    padding=1,          # Preserve image size\n    stride=1            # Step size\n)\nNumber of parameters for this layer:\n\\[\n[(\\text{kernel_size}^2 \\times \\text{in_channels})  + \\underbrace{1}_{\\text{bias}}] \\times \\text{out_channels}\n\\]\n\nNow let’s see how you can create convolutional layers in PyTorch using nn.Module. Earlier, you built networks using layers like nn.Linear. A convolutional layer works in exactly the same way. It’s just another type of layer that you add to your model architecture. In PyTorch, you define one using nn.Conv2d. That name just means it’s a two-dimensional convolution like you would use in a two-dimensional image.\nLet’s walk through each of these settings step-by-step."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#output-activationfeature-maps",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#output-activationfeature-maps",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "Output: Activation/Feature Maps",
    "text": "Output: Activation/Feature Maps\n\nHere we see a out_channels=16 of convolution outputs showing high values where they activate (after ReLU()).\n\nSo that covers how filters work and how convolutional layers use them to find useful patterns in images. The output of a convolutional layer may look like 32 new images, but they’re really just arrays of numerical values showing how strongly each filter reacted to different parts of the image. These are commonly known as feature maps or activation maps. They map where each feature appears in the input."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#pooling",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#pooling",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "Pooling",
    "text": "Pooling\n\nExample: 28×28 feature map\n\nAfter first pool: 14×14\nAfter second pool: 7×7\nEach pooling layer halves the spatial dimensions\n\n\nThen it’s fed into something called MaxPool2d. What is that? Well, let’s take a look. Pooling is a common technique in convolutional neural networks that’s used to reduce the size of feature maps. It’s effectively a way to throw away pixels after a filter has been applied, compressing the data while keeping the most important parts in a way that shouldn’t affect the results.\nThe logic here is that your filters have already extracted the important features from the original image. So now by applying pooling, you’re compressing each filtered image, keeping just the most significant information. As a result, less data needs to pass through the network, and the next layer sees images that were only a quarter of the original size.\nThis is important because after your first convolutional layer, you now have 32 different feature maps flowing into the second layer. For large images this quickly becomes a lot of data. Pooling reduces this volume of information, making your neural network much more efficient without losing valuable details and more robust to small changes."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#building-a-complete-cnn-architecture",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#building-a-complete-cnn-architecture",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "Building a Complete CNN Architecture",
    "text": "Building a Complete CNN Architecture\n\nA sequential conv-pool conv-pool flatten fc fc architecture\nIn the last video, you explored how convolutional layers work and how CNNs can learn useful filters to extract features and patterns from images. Now we’re going to put those pieces together into a full convolutional neural network architecture. It extends nn.Module just like you’ve done before."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#cnn-architecture-overview",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#cnn-architecture-overview",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "CNN Architecture Overview",
    "text": "CNN Architecture Overview\nThree main components:\nclass CNN(nn.Module):\n    def __init__(self):\n        # Convolutional layers → extract features\n        # Pooling layers → reduce size\n        # Fully connected layers → classify\nDefine the flow:\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.relu1(x)\n        x = self.pool1(x)\n        # ... more layers ...\n        x = x.flatten()\n        x = self.fc(x)\n        return x\n\nIn the init function, you’ll define the structure of your network. It starts with convolutional layers and ends with a fully connected layer to classify your images. Fully connected just means that every neuron in the input is connected to every neuron in the output. It’s just another name for linear layer.\nThen you have the forward method to define the flow of data, which is pretty straightforward. You pass data through each of the convolutional layers and then recall that the linear layer expects a single row of values. So you need to flatten your tensor into a single vector and pass it through that final layer to produce a prediction. And that’s your full CNN pipeline from raw pixels to learned features to classification."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#the-snow-detector-problem",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#the-snow-detector-problem",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "The Snow Detector Problem",
    "text": "The Snow Detector Problem\n\nHusky misclassified as wolf\n\nModel fixated on snow in background\nSome neurons became “snow detectors”\nOthers relied on them (co-adaptation)\n\n\nImagine a model trained to classify dogs versus wolves. This husky image was misclassified as a wolf. Can you guess why? Well, it’s not because the husky looks like a wolf. It’s because the model was fixating on the snow in the background. In the training set, some wolf images had snowy backgrounds. And that was enough for the model to start learning that snow means wolf.\nWhat’s happening here is called co-adaptation. Some neurons become specialized snow detectors, and others start relying on them. The model then gets lazy. It leans on shortcuts instead of learning robust features like body shape or facial structure."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#regularization",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#regularization",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "Regularization",
    "text": "Regularization\n\n\nRegularization in deep learning refers to techniques used to prevent models from overfitting to the training data. Overfitting occurs when a model learns not only the underlying patterns but also the noise in the data, resulting in poor performance on unseen data. Regularization methods add a form of constraint or penalty to the learning process, encouraging simpler models that generalize better."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#dropout",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#dropout",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "Dropout",
    "text": "Dropout\n\nDropout: Randomly turns off a fraction of neurons during training, forcing the network to develop redundant representations and making it less likely to rely too heavily on any single feature.\n\nDuring training, this layer randomly deactivates about 50% of the neurons. Now, this might sound counterintuitive. Why would we want to turn off parts of our network? Well, let’s look at an example.\nDropout breaks those shortcuts. By randomly turning off neurons during training, dropout makes it risky to rely too much on any one pattern. If the snow detector neuron gets dropped out, the model then has to find other cues, the ones that actually matter.\nIn practice, dropout rates typically range from 0.2 to 0.5, and you’ll place dropout after activation functions but before the final classification layer."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#weight-decay",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#weight-decay",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "Weight Decay",
    "text": "Weight Decay\n\nWeight Decay: Add a penalty to the loss function based on the size of the weights, encouraging them to be smaller and discouraging complex models.\n\nIn the graded assignment, you’ll also see weight decay applied to the Adam optimizer. Like dropout, it’s a regularization technique that helps with generalization, but it works differently. Instead of turning neurons off, weight decay discourages the network from using very large weights.\nWhy would it do this? Well, it’s because large weights can be a sign that the model is memorizing specific patterns in the training data rather than learning features that generalize. Weight decay adds a small penalty for large weights, nudging the model towards simpler and more robust solutions."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#the-two-regularization-techniques",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#the-two-regularization-techniques",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "The two regularization techniques",
    "text": "The two regularization techniques\n\n\n\n\n\n\n\n\nFeature\nDropout\nWeight Decay\n\n\n\n\nMechanism\nRandomly deactivates neurons.\nPenalizes large weight values.\n\n\nGoal\nBreaks co-dependency between neurons.\nKeeps the model simple and less sensitive.\n\n\nActive When?\nOnly during training.\nDuring training (via the optimizer).\n\n\nAnalogy\nA team where players are randomly benched so everyone learns to play every position.\nA coach telling players not to over-commit to a single move so they stay balanced."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#dataset-issue",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#dataset-issue",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "Dataset Issue",
    "text": "Dataset Issue\nIf most wolf images in your dataset have snow and dog images don’t, that’s a dataset problem."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#solution",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#solution",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "Solution",
    "text": "Solution\nGet more representative data."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#lab-1-building-a-cnn-for-nature-classification",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#lab-1-building-a-cnn-for-nature-classification",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "Lab 1: Building a CNN for Nature Classification",
    "text": "Lab 1: Building a CNN for Nature Classification\n\n“If we want machines to think, we need to teach them to see.” — ImageNet Project launch\n\n\nCUE: START THE LAB HERE"
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session1.html#whats-next",
    "href": "W4_DL/C1_M4_Core_NN_Components/session1.html#whats-next",
    "title": "Module 4 - Session 1: Convolutional Neural Networks",
    "section": "What’s Next?",
    "text": "What’s Next?\nIn Session 2: PyTorch Techniques and Model Inspection we learn:\n\nDynamic computation graphs in PyTorch\nBuilding modular architectures\nModel inspection and debugging\n\n\nSo now it’s your turn. Head to the notebook and explore how it all works in detail. In the next session, we’ll explore PyTorch’s dynamic computation graphs, learn how to build modular architectures, and discover tools for inspecting and debugging your models."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#device-management",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#device-management",
    "title": "Module 2 - Session 3: Device Management and Image Classification Setup",
    "section": "Device Management",
    "text": "Device Management\n\nEvery tensor and model lives on a device\n\nCPU (default)\nGPU (accelerator)\n\nKey rule: Model and data must be on the same device!\n\nWelcome back. As you start working more with tensors and models in PyTorch, there’s something important that you need to understand early on: every tensor and every model lives on a device. Now that could be your CPU, or a GPU, or other accelerator if one is available.\nAnd here’s the key: PyTorch will not move things around for you automatically. And if your tensors and models aren’t all on the same device, your code may not run. It could crash with an error.\nIn this session, you’ll learn how to control where your data and computations live, and how to avoid one of the most common errors people run into when they get started with PyTorch."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#cpu-vs-gpu",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#cpu-vs-gpu",
    "title": "Module 2 - Session 3: Device Management and Image Classification Setup",
    "section": "CPU vs GPU",
    "text": "CPU vs GPU\nCPU:\n\nDefault device\nGeneral purpose\nSequential operations\n\nGPU:\n\nAccelerator\nParallel operations\n10-15x faster for training\n\n\nEvery computer has a CPU, and that’s the default device PyTorch uses unless you tell it otherwise. CPUs are built for general purpose work and run operations sequentially. But some systems also have an accelerator like a GPU, a graphics processing unit, which can run tensor operations much faster, especially during training.\nIn fact, training on an accelerator like a GPU can be 10 to 15 times faster than on a CPU alone. So if your system has one of these, you’ll almost always want to use it. But you do need to ensure that your model and data are both on the same device, and you’ll do this manually."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#checking-for-gpu",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#checking-for-gpu",
    "title": "Module 2 - Session 3: Device Management and Image Classification Setup",
    "section": "Checking for GPU",
    "text": "Checking for GPU\ntorch.cuda.is_available()  # Returns True if GPU available\nCommon pattern:\ndevice = torch.device('cuda' if torch.cuda.is_available() \n                      else 'cpu')\n\nPyTorch gives you a simple way to check whether your system has an accelerator using the following code. If this returns true, then PyTorch can use a GPU to accelerate your computations.\nA common pattern for choosing a device looks like this. This sets the device to CUDA if a GPU is available and CPU otherwise. It is a safe default and one you’ll often see in PyTorch code. The CUDA keyword refers to NVIDIA GPUs that have a toolkit called CUDA. Now while there are other options like MPS for Apple Silicon, CUDA is the most commonly used one and it’s what the labs in this course will be using also."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#moving-model-to-device",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#moving-model-to-device",
    "title": "Module 2 - Session 3: Device Management and Image Classification Setup",
    "section": "Moving Model to Device",
    "text": "Moving Model to Device\nmodel = MyModel()\nmodel = model.to(device)  # Move model to device\nPuts model’s parameters on the selected device\n\nOnce you’ve defined your device, the next step is to move your model and your data onto it. First, you can move your model when you create it like this. This puts the model’s parameters onto the selected device."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#moving-data-to-device",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#moving-data-to-device",
    "title": "Module 2 - Session 3: Device Management and Image Classification Setup",
    "section": "Moving Data to Device",
    "text": "Moving Data to Device\nfor batch in dataloader:\n    inputs, targets = batch\n    inputs = inputs.to(device)\n    targets = targets.to(device)\n    # ... rest of training\nMove each batch within the training loop\n\nThen within your training loop, move each batch of data like this. Now if you’re not sure where something lives, you can always check."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#checking-device-location",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#checking-device-location",
    "title": "Module 2 - Session 3: Device Management and Image Classification Setup",
    "section": "Checking Device Location",
    "text": "Checking Device Location\n# For tensors\ntensor.device\n\n# For models (check a parameter)\nnext(model.parameters()).device \n# model.parameters() returns a generator. That's why we use next\n\nFor tensors, it’s pretty straightforward. For models, it’s a bit different. Models themselves aren’t on the devices, but their parameters are. So you can check one parameter to see where they all are.\nIf you’re getting device errors, you should also double check that your targets and the output of your model are also on the same device too."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#common-mistake-with-.to",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#common-mistake-with-.to",
    "title": "Module 2 - Session 3: Device Management and Image Classification Setup",
    "section": "Common Mistake with .to()",
    "text": "Common Mistake with .to()\n.to() doesn’t change tensor in place\nIt creates a new one!\n# Wrong\ntensor.to(device)  # Result is discarded!\n\n# Right\ntensor = tensor.to(device)  # Reassign\n\nNow there’s one common mistake to watch out for when you use .to(). It doesn’t change the tensor in place - it actually creates a new one. So if you want to actually move the tensor, you need to reassign it. Anytime you use .to(), make sure you’re assigning the results to a variable that you will actually use."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#complete-training-loop-with-device-management",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#complete-training-loop-with-device-management",
    "title": "Module 2 - Session 3: Device Management and Image Classification Setup",
    "section": "Complete Training Loop with Device Management",
    "text": "Complete Training Loop with Device Management\ndevice = torch.device('cuda' if torch.cuda.is_available() \n                      else 'cpu')\nmodel = MyModel().to(device)\n\nfor batch in dataloader:\n    inputs, targets = batch[0].to(device), batch[1].to(device)\n    optimizer.zero_grad()\n    outputs = model(inputs)\n    loss = loss_fn(outputs, targets)\n    loss.backward()\n    optimizer.step()\nKey steps: 1. Choose device up front 2. Move model once 3. Move data in every batch\n\nNow here’s what a complete training loop looks like with proper device management. The key steps are: choose your device up front, move the model once, and then move the data in every batch. This pattern is the foundation of every training script that you’ll write in PyTorch."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#gpu-memory-limits",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#gpu-memory-limits",
    "title": "Module 2 - Session 3: Device Management and Image Classification Setup",
    "section": "GPU Memory Limits",
    "text": "GPU Memory Limits\nGPU memory is limited\nError if batch size too large:\nRuntimeError: CUDA out of memory\nSolution: Lower batch size (32-64 is good starting point)\n\nEven when everything’s on the right device, there’s one more thing to watch out for: the GPU memory. Because it is limited. If your model and batch size take up more memory than the GPU has available, you’ll see an error like this.\nAnd that’s why batch size matters. Small batches make training slow. Large batches too large, and you might exceed your GPU’s memory and cause a crash. For many systems, a batch size between 32 and 64 is a good starting point, but it does depend on your hardware and on your model architecture.\nIf you see a memory error, first try lowering your batch size. It is the most common fix. Get device management right early, and you’ll avoid one of the most frustrating classes of errors in PyTorch. And when something does go wrong, you’ll know exactly what to check."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#building-your-first-image-classifier",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#building-your-first-image-classifier",
    "title": "Module 2 - Session 3: Device Management and Image Classification Setup",
    "section": "Building Your First Image Classifier",
    "text": "Building Your First Image Classifier\n\nMNIST Dataset:\n\n60,000 training images\n10,000 test images\n28×28 pixels, grayscale\n10 classes (digits 0-9)\n\n\nYou’ve now seen how to manage devices, and with everything you’ve learned so far, you’re ready to put it all together. In the rest of this session, you’ll see how to train your first image classifier in PyTorch, bringing that full pipeline to life.\nYou’re working with MNIST, those handwritten digits. This dataset has 60,000 training images and 10,000 test images. Each of these are 28 by 28 pixels in grayscale. It’s the perfect warm-up before tackling more complex image classification tasks."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#setting-up-the-data-pipeline",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#setting-up-the-data-pipeline",
    "title": "Module 2 - Session 3: Device Management and Image Classification Setup",
    "section": "Setting Up the Data Pipeline",
    "text": "Setting Up the Data Pipeline\nimport torchvision\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n    # Grayscale Images have 1 Channel. \n    # That's why we used 1 element tuples for Normalize\n])\nToTensor: converts to tensors, scales 0-255 → 0-1\nNormalize: centers around 0 using dataset mean/std\n\nSo let’s jump into the code and build a model. We’ll start with the data pipeline. First, you need to import TorchVision, and this is PyTorch’s computer vision library. It comes built in with popular datasets like MNIST, as well as tools for image processing.\nRemember transforms? Well here you’re applying them to MNIST. ToTensor converts the images to tensors and then scales the pixels from 0 to 255 down to a range of 0 to 1. Normalize then shifts and scales those values so they’re centered around 0.\nNow what are these numbers 0.1307 and 0.3081? Well, they are the mean and standard deviation of the entire training set. By normalizing every image with the same values, you make the data more consistent, and that helps the model learn faster. We’ll see more on that in the next module."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#loading-the-dataset",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#loading-the-dataset",
    "title": "Module 2 - Session 3: Device Management and Image Classification Setup",
    "section": "Loading the Dataset",
    "text": "Loading the Dataset\ntrain_dataset = torchvision.datasets.MNIST(\n    root='./data',\n    train=True,\n    download=True,\n    transform=transform\n)\n\ntest_dataset = torchvision.datasets.MNIST(\n    root='./data',\n    train=False,\n    transform=transform\n)\nTorchVision handles downloading and organizing\n\nNow let’s load in the datasets. For the training dataset, root='./data' says simply where to store the files on your computer. train=True tells it that you want the 60,000 training images. download=True means that if MNIST isn’t already there, go ahead and download it. And transform applies those pre-processing steps that you just defined to every image automatically.\nThe test dataset is almost identical. Just use train=False to get the 10,000 test images instead of the training ones. Got to use the same transforms, the same storage location, and all of that. TorchVision will handle all of the downloading and organizing for you."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#creating-dataloaders",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#creating-dataloaders",
    "title": "Module 2 - Session 3: Device Management and Image Classification Setup",
    "section": "Creating DataLoaders",
    "text": "Creating DataLoaders\ntrain_loader = DataLoader(\n    train_dataset, \n    batch_size=64, \n    shuffle=True\n)\n\ntest_loader = DataLoader(\n    test_dataset, \n    batch_size=1000,\n    shuffle=False\n)\nTraining: shuffle=True (mix up order each epoch)\nTesting: shuffle=False (order doesn’t matter)\n\nNow onto data loaders. For training, you’re setting the batch size to be 64. That means it’s 64 images in each batch. With shuffle=True, for every epoch the model will see the images in a different random order. The test loader uses batch_size=1000. These are much larger batches because we don’t need to calculate gradients - we’re only testing.\nBut notice something interesting: the training data is shuffled, but the test data isn’t. Take a moment to think about why that might be. Well, datasets often come organized by class. If you don’t shuffle, your model might see 6,000 zeros in a row before seeing any ones. It could learn unintended patterns like “early batches are zeros, late batches are nines,” instead of actually learning what makes a zero look like a zero.\nShuffling will mix everything up so that each batch has variety in it. The model learns the actual features of each digit and not just their position in the dataset. But for testing, well, the model’s done learning. You’re just checking if it can recognize digits correctly. Order doesn’t matter then."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#building-the-model-architecture",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#building-the-model-architecture",
    "title": "Module 2 - Session 3: Device Management and Image Classification Setup",
    "section": "Building the Model Architecture",
    "text": "Building the Model Architecture\nclass MNISTClassifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.linear1 = nn.Linear(784, 128)\n        self.relu = nn.ReLU()\n        self.linear2 = nn.Linear(128, 10)\n    \n    def forward(self, x):\n        x = self.flatten(x)\n        x = self.linear1(x)\n        x = self.relu(x)\n        x = self.linear2(x)\n        return x\n\nSo now it’s time to create your neural network. You’re going to go beyond Sequential and we’ll build a custom architecture. Let’s walk through this. You’re creating a class that inherits from nn.Module. This gives you all of PyTorch’s neural network functionality.\nIn its __init__, you’re going to define your layers. First comes flatten. This is new. Here’s why you need it."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#why-flatten",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#why-flatten",
    "title": "Module 2 - Session 3: Device Management and Image Classification Setup",
    "section": "Why Flatten?",
    "text": "Why Flatten?\nMNIST images: shape [1, 28, 28] (channels, height, width)\nWith batch: shape [64, 1, 28, 28]\nLinear layers expect: flat vectors [batch, features]\nFlatten: [64, 1, 28, 28] → [64, 784]\n\n\nMNIST images arrive as tensors with a specific shape. When PyTorch loads a single MNIST image, it gives you a [1, 28, 28]-dimensional tensor. And that’s the channels, the height, and the width. The one channel means that it’s grayscale - just a single brightness value from 0 to 255 for each pixel. 28 by 28 pixels are the size, and those are the other two dimensions.\nBut when you’re training on batches, PyTorch will actually add another dimension. So with batch_size=64, your data arrives as [64, 1, 28, 28]. So that’s 64 images, each one channel, and each is 28 by 28 pixels.\nHere’s the issue: Linear layers expect flat vectors, and that’s one long row of numbers per image, not two-dimensional grids. And that’s what flatten does. It takes each of your 28 by 28 images and reshapes them into 784 values in a row. Why 784? Because 28 × 28 = 784.\nSo now your batch, instead of being dimension [64, 1, 28, 28], just simply becomes [64, 784]. Without flatten, you get a shape mismatch error when your image data hits the linear layer."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#model-architecture-breakdown",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#model-architecture-breakdown",
    "title": "Module 2 - Session 3: Device Management and Image Classification Setup",
    "section": "Model Architecture Breakdown",
    "text": "Model Architecture Breakdown\nLinear(784, 128):\n\n784 pixel values → 128 hidden features\n\nReLU:\n\nActivation function (non-linearity)\n\nLinear(128, 10):\n\n128 features → 10 outputs (one per digit class)\n\n\nSo now you can stack your layers. Linear(784, 128) takes those 784 pixel values and transforms them to 128 hidden features. ReLU is our activation function that keeps our positive values and zeros out the negatives. Then Linear(128, 10) takes the 128 features and turns them into 10 outputs. 10 outputs being one for each digit class. We’ve 10 digits from 0 through 9.\nNow you’re going to define the flow of the data in that forward method. Take the input, flatten it, pass it through your layers, return the output.\nSo now you have everything ready: a data pipeline that loads and pre-processes MNIST images, and a neural network that can process those images. But right now this model doesn’t know a zero from a nine. In the next session, you’re going to see how to bring this model to life with training."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#whats-next",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session3.html#whats-next",
    "title": "Module 2 - Session 3: Device Management and Image Classification Setup",
    "section": "What’s Next?",
    "text": "What’s Next?\nIn Session 4: Training and Evaluating Your Classifier we learn:\n\nSetting up loss function and optimizer\nWriting the training loop\nEvaluating on test set\nWatching your model learn!\n\n\nIn the next session, you’ll see how to set up the optimizer, define the training loop, and watch as your model learns to recognize digits with increasing accuracy. Let’s keep going!"
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#module-2-overview",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#module-2-overview",
    "title": "Module 2 - Session 1: Data and Model Building",
    "section": "Module 2 Overview",
    "text": "Module 2 Overview\nWhat will we learn?\n\nData Pipeline → handle large datasets\nBeyond Sequential → custom architectures\nOptimizers\nDevice Management\nBuilding an image classifier\n\n\nWelcome to Module 2! In this module, we’ll revisit the machine learning pipeline and see how PyTorch handles data at scale. We’ll dive deeper into loss functions and optimizers, learn about device management, and then bring it all together to build your first image classifier.\nThe question chain shows our progression: understanding data handling leads to understanding model architectures, which leads to understanding how models learn (loss and optimizers), which leads to practical implementation with device management, and finally building a complete image classifier."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#session-1-data-and-model-building",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#session-1-data-and-model-building",
    "title": "Module 2 - Session 1: Data and Model Building",
    "section": "Session 1: Data and Model Building",
    "text": "Session 1: Data and Model Building\n\nRevisit the ML pipeline with a focus on PyTorch’s data handling tools\nLearn about data management at scale\nExplore building custom model architectures beyond the Sequential API"
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#the-challenge-large-datasets",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#the-challenge-large-datasets",
    "title": "Module 2 - Session 1: Data and Model Building",
    "section": "The Challenge: Large Datasets",
    "text": "The Challenge: Large Datasets\n100,000 delivery records\nProblem: Loading all at once → runs out of memory\n\nSolution: Work with data in batches\n\nLet’s revisit the machine learning pipeline and see how PyTorch handles data. You already know about these steps from Module 1. But now, if you’re going to decode handwritten digits, you’re also going to need to understand PyTorch’s data handling tools.\nBefore we get into the complexities of image data, let’s start with something more familiar - that delivery data we looked at in Module 1. The same tools that can handle millions of delivery records can also handle millions of images. Once you see the pattern with simple data, images are going to make a lot more sense.\nSo let’s imagine your delivery company for Module 1 has grown. Instead of 10 deliveries, you now have 100,000 records to analyze. That’s a lot. Now imagine you wanted to try and load all 100,000 records at once. As you load this data, every piece needs to live in your computer’s RAM. With 100,000 records, you might be okay. But what if you had millions of records? Or if you added weather data, traffic patterns, driver info? At that scale, your computer can run out of memory and crash in no time.\nThat’s why you need to load your data piece by piece. The practical solution is to work with your data in batches - smaller, manageable chunks of the full dataset."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#pytorch-data-utilities",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#pytorch-data-utilities",
    "title": "Module 2 - Session 1: Data and Model Building",
    "section": "PyTorch Data Utilities",
    "text": "PyTorch Data Utilities\nThree core tools:\n\nTransforms - operations on each data point\nDataset - fetches samples from disk on demand\nDataLoader - serves data in batches\n\n\nBut batching is just one part of the picture. Before your data is ready for training, you need to process it, format it, and serve it in a way that your model understands. That’s where three of PyTorch’s core data utilities come in: transforms, Dataset, and DataLoader. They each handle a key part of the process, and they’re designed to work well together."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#transforms",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#transforms",
    "title": "Module 2 - Session 1: Data and Model Building",
    "section": "1. Transforms",
    "text": "1. Transforms\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=0.5, std=0.5)\n])\nToTensor: converts to tensors, scales 0-255 → 0-1\nNormalize: centers around 0, scales using standard deviation\n\nLet’s take a look at how transforms work. To apply transforms to data, you usually write something like this. Transforms are operations that run on each data point as it’s loaded, preparing your data for the model. Compose just means to do the following things in order.\nThen you have the two most common transforms: ToTensor and Normalize. Neural networks are surprisingly picky. They train much better when all inputs are small numbers, ideally centered around 0. And that’s exactly what these two transforms do.\nToTensor converts your data into PyTorch tensors and scales them to fall between the values of 0 and 1. Normalize adjusts these values even further, centering them around 0 and then scaling using standard deviation. For now, just know that these will help your model train much more effectively, and you’ll learn more about them and other transform techniques in the next module."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#dataset",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#dataset",
    "title": "Module 2 - Session 1: Data and Model Building",
    "section": "2. Dataset",
    "text": "2. Dataset\ndataset = MNIST(root='./data', train=True, \n                download=True, transform=transform)\nKey features:\n\nFetches samples from disk when asked\nDoesn’t preload everything\nHandles where data lives, how to load samples, total count\n\n\nNext up, you’re going to wrap your data in a Dataset object, which fetches each sample from disk when it’s asked to. It doesn’t preload everything in one shot, and that’s one of the secrets to handling massive datasets.\nIt handles things like where your data lives on disk, how to load a specific sample, how many total samples there are, and of course how to apply the transforms that you just saw to each sample as it’s being loaded.\nThis indicates where you store the data on your computer. train=True lets you choose between training and test sets of data. And if this is new for you, you’ll see a lot more about that when I discuss evaluation. And download=True downloads the data if it’s not already there.\nYou can retrieve a sample from your dataset simply by indexing it. In module 3, you’ll learn how to use the Dataset class to build custom datasets. But for now, we’ll stick to the pre-built ones that are available in PyTorch."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#dataloader",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#dataloader",
    "title": "Module 2 - Session 1: Data and Model Building",
    "section": "3. DataLoader",
    "text": "3. DataLoader\ndataloader = DataLoader(dataset, batch_size=64, shuffle=True)\nBatch size: how many samples per batch\nShuffle: randomize order each epoch\nMakes training on large datasets possible\n\nOnce you’ve defined your dataset, you’re going to use a DataLoader to serve the data in batches. It’s part of the pipeline that makes training on large datasets possible, by requesting one batch at a time from your dataset.\nBatch size tells the loader how many samples to serve at a time. You can also shuffle the data, which helps the model learn even more effectively during training.\nNow let’s see the complete data pipeline in action. And you’re ready to train. This pattern efficiently handles datasets that would otherwise overwhelm your computer’s memory. And whether you’re working with thousands of delivery records or millions of images, the principle stays the same: load only what you need, when you need it."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#complete-data-pipeline",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#complete-data-pipeline",
    "title": "Module 2 - Session 1: Data and Model Building",
    "section": "Complete Data Pipeline",
    "text": "Complete Data Pipeline\n# 1. Define transforms\ntransform = transforms.Compose([...])\n\n# 2. Create dataset\ntrain_dataset = MNIST(..., transform=transform)\n\n# 3. Create dataloader\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n\n# 4. Use in training loop\nfor batch in train_loader:\n    images, labels = batch\n    # train model\n\nBut getting data into your model is just the beginning. In the rest of this session, you’ll tackle the rest of the ML pipeline, and then you’ll look at how loss functions and optimizers update your model."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#beyond-sequential-custom-models",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#beyond-sequential-custom-models",
    "title": "Module 2 - Session 1: Data and Model Building",
    "section": "Beyond Sequential: Custom Models",
    "text": "Beyond Sequential: Custom Models\n\n\n\nnn.Sequential\nmodel = nn.Sequential(\n    nn.Linear(1, 20),\n    nn.ReLU(),\n    nn.Linear(20, 1)\n)\n\n\nnn.Module\nimport torch.nn.functional as F\nclass MyModel(nn.Module):\n    # defines layers\n    def __init__(self):\n        super().__init__()\n        self.layer1 = nn.Linear(1, 20)\n        self.layer2 = nn.Linear(20, 1)\n    \n    # describes data flow\n    def forward(self, x):\n        x = self.layer1(x)\n        x = F.relu(x)\n        x = self.layer2(x)\n        return x\n\n\n\nMore control, same functionality\n\nIn the last video, you saw how PyTorch helps you manage your data. With tools like Dataset, Transforms, and DataLoader, you can load, prepare, and serve data efficiently, no matter the size of your dataset.\nNow, let’s move on to the rest of the machine learning pipeline: model building, training, and evaluation. In Module 1, you saw Sequential in action. And of course, this works great, but there’s another pattern that you’ll see a lot in PyTorch: creating your model using nn.Module. This code does exactly the same thing as the Sequential version, just with more control.\nSo let’s take a closer look at the structure. Every PyTorch module class has two parts: __init__ defines your layers, and forward describes how data flows through them.\nIn __init__, you’re just defining what layers exist. It’s a little bit like gathering your tools. The actual order comes in forward, and that’s where you describe the path that data is going to take through your model.\nNow, this is similar to how Sequential orders the flow, but written in a different style. You’re going to see this pattern everywhere in PyTorch code."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#calling-the-model",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#calling-the-model",
    "title": "Module 2 - Session 1: Data and Model Building",
    "section": "Calling the Model",
    "text": "Calling the Model\nDon’t call model.forward() directly\nDo call model(input)\nPyTorch handles the forward call and essential bookkeeping\n\nBut wait, you’ve defined this forward method. How do you actually run it? You might think model.forward(). But what if I told you that Sequential is a subclass of Module, and it too has a forward method? And how did you run that model? You never actually called forward directly. It’s the same for your custom model.\nWell, when you call the model method and pass the data, PyTorch does more than just run your forward method. It also makes some internal checks, tracks the necessary math, and sets things up for updating the model later. And that’s why you always call model(input) and not model.forward(input). PyTorch will handle that forward call for you, and it’s all wrapped up in the essential bookkeeping."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#why-super.__init__",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#why-super.__init__",
    "title": "Module 2 - Session 1: Data and Model Building",
    "section": "Why super().__init__()?",
    "text": "Why super().__init__()?\nNecessary for parameter tracking\nPyTorch needs to set up a system to track all learnable parameters (weights and biases)\nWithout it, PyTorch has nowhere to register your layers\n\nSo what about this line, super().__init__()? Is it really necessary? You might think it’s just Python boilerplate, and maybe nothing bad happens if you skip it. But when you try to create your model, PyTorch needs to set up a system to track all of its learnable parameters. And these are the weights and biases that you’re going to update during training.\nSo when you call super().__init__(), it actually creates that tracking system for you. Without it, PyTorch has nowhere to register your layers. So always include it."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#training-loop-pattern",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#training-loop-pattern",
    "title": "Module 2 - Session 1: Data and Model Building",
    "section": "Training Loop Pattern",
    "text": "Training Loop Pattern\nfor batch in dataloader:\n    optimizer.zero_grad()    # Clear old calculations\n    outputs = model(inputs)  # Forward pass\n    loss = loss_fn(outputs, targets)  # Measure error\n    loss.backward()          # Calculate gradients\n    optimizer.step()         # Update weights\nOrder matters! Don’t swap these steps.\n\nNow let’s take a look at training. You’ve seen this training loop already in Module 1. This standard sequence is the core of most PyTorch training loops. zero_grad() clears out all the old calculations, backward() figures out the improvements, and step() updates your model.\nBut here’s the thing: if you don’t follow this standard order, your training might fail silently. PyTorch won’t throw an error, but your model won’t learn properly.\nFor example, what would happen if you swapped backward and step? Your code runs fine, but the model updates itself based on the previous batch’s calculations and not the current ones. Or if you put zero_grad() after backward, well, then you just threw away all of that work that backward did. What if you put zero_grad() outside the loop? Well, those calculations just pile up. Each batch will add to the previous one and your model starts making huge adjustments when it should just make tiny ones.\nThe next two videos will take a deeper dive into these topics. For now, just remember that this pattern is important. You almost always want the same order every time."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#evaluation",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#evaluation",
    "title": "Module 2 - Session 1: Data and Model Building",
    "section": "Evaluation",
    "text": "Evaluation\nmodel.eval()  # Set to evaluation mode\nwith torch.no_grad():  # Disable gradient tracking\n    for batch in test_loader:\n        outputs = model(inputs)\n        # Calculate accuracy\nTwo critical things:\n\nmodel.eval() - sets evaluation mode\ntorch.no_grad() - disables gradient tracking\n\n\nYou’ve been training your model, but how do you know it’s actually learning? That’s what evaluation is for: testing your model on new data that it hasn’t previously seen and wasn’t trained on.\nTwo critical things here. model.eval(). Be careful - this is not a method that evaluates your model as some people mistakenly think. It just sets the model into evaluation mode. You need this because it’s both more efficient computationally and some layers in your model will behave in different ways during training and evaluation.\ntorch.no_grad(). This will disable that extra tracking that PyTorch does during training. If you don’t turn it off, PyTorch will keep storing lots of details even when they’re not needed, and this wastes memory and might even crash your program during validation."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#measuring-performance",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#measuring-performance",
    "title": "Module 2 - Session 1: Data and Model Building",
    "section": "Measuring Performance",
    "text": "Measuring Performance\nFor classification: Accuracy\ncorrect = (predictions == labels).sum().item()\ntotal = labels.size(0)\naccuracy = correct / total\nCount correct predictions / total predictions\n\nNow, the most important part of evaluation is to see how well your model has performed on new data that it hasn’t seen before. Testing on the training set would be like giving the student the same test twice. The student might just memorize the answers, but you want to see if they can apply what they’ve already learned.\nSince you’re exploring image classification in this module, you can easily measure performance using accuracy. The accuracy calculation is straightforward: count how many times the model gets the classification right and divide that by the total attempts. If your model predicts 9,500 digits correctly out of 10,000, that’s 95% accuracy.\nAnd don’t forget to switch back to training mode if you are returning the model to training."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#to-sum-up",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#to-sum-up",
    "title": "Module 2 - Session 1: Data and Model Building",
    "section": "To sum up",
    "text": "To sum up\n\nData pipeline: Dataset, DataLoader, Transforms\nModel building: nn.Module\nTraining loop: for batch in dataloader:\nEvaluation: model.eval(), torch.no_grad(), accuracy\n\n\n\nData pipeline: You start by organizing your data using a Dataset object, which defines how to access a single data point (like an image and its label). Then, you wrap your dataset in a DataLoader, which efficiently batches your data, shuffles it, and feeds it into your model during training and evaluation. Data transforms (using transforms.Compose and related utilities) are applied to preprocess, normalize, and augment your data. This pipeline ensures that data flows smoothly and efficiently to your model, handling everything from preprocessing to batching.\nModel building (nn.Module): You define your neural network architecture by subclassing nn.Module. Inside this class, you declare all the layers (like nn.Linear, nn.Conv2d, etc.) and implement the forward method, which describes how the input data passes through these layers to produce an output. This modular approach lets you build simple or highly complex models by stacking layers and adding activation functions, making PyTorch flexible for both quick prototypes and advanced research.\nTraining loop (for batch in dataloader:): The heart of model training is the loop over batches of data. For each batch received from the DataLoader, you (1) run the input through the model to get predictions, (2) compute the loss by comparing predictions to the true labels, (3) perform backpropagation to compute gradients, and (4) update the model parameters using an optimizer. This iterative process gradually teaches your model to minimize the loss and improve accuracy, one batch at a time.\nEvaluation (model.eval(), torch.no_grad(), accuracy): When it’s time to review your model’s performance, you switch to evaluation mode using model.eval(), which adjusts the behavior of certain layers (like dropout and batchnorm). Wrapping your evaluation code with torch.no_grad() prevents PyTorch from tracking gradients, making evaluation faster and saving memory. Finally, you measure performance using metrics like accuracy—comparing model predictions to the true labels on unseen data to determine how well the model generalizes."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#whats-next",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session1.html#whats-next",
    "title": "Module 2 - Session 1: Data and Model Building",
    "section": "What’s Next?",
    "text": "What’s Next?\nIn Session 2: Loss Functions and Optimizers, you learn:\n\nHow loss functions measure error\nCross-entropy loss for classification\nHow optimizers use gradients to update weights\nUnderstanding backpropagation\n\n\nYou’ve now revisited the full pipeline: data loading, model building, training, and evaluation. But you’ve only scratched the surface of training. In the next session, we’re going to take a closer look at what’s happening with loss functions and optimizers - the mathematical foundations that make neural network learning possible."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session4.html#what-are-tensors",
    "href": "W4_DL/C1_M1_Getting_Started/session4.html#what-are-tensors",
    "title": "Module 1 - Session 4: Working with Tensors",
    "section": "What are Tensors?",
    "text": "What are Tensors?\nTensors are the core Data Structure in PyTorch\n\n\nAnalogy: Think of a Tensor as a container. If a Scalar is a single grape, a Vector is a row of grapes, and a Matrix is a crate of grapes, a Tensor is a shipping container full of those crates.\nSimilar to NumPy arrays, but with support for GPU acceleration and automatic differentiation."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session4.html#images-as-tensors",
    "href": "W4_DL/C1_M1_Getting_Started/session4.html#images-as-tensors",
    "title": "Module 1 - Session 4: Working with Tensors",
    "section": "Images as Tensors",
    "text": "Images as Tensors\n\nPyTorch convention ordering for images is: (channels, height, width).\n\nImages are just a special type of tensor. They are 3-dimensional tensors, with the first dimension being the height, the second dimension being the width, and the third dimension being the number of channels (RGB, RGBA, etc.)."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session4.html#why-learn-about-tensors",
    "href": "W4_DL/C1_M1_Getting_Started/session4.html#why-learn-about-tensors",
    "title": "Module 1 - Session 4: Working with Tensors",
    "section": "Why Learn About Tensors?",
    "text": "Why Learn About Tensors?\nMany PyTorch errors come from tensor issues\n\nShape mismatches\nData type problems\nDevice mismatches\n\nMaster tensors now, avoid frustration later\n\nIn the last lab, you trained a model to predict delivery times. Along the way, you’ve been using tensors, maybe without thinking too much about them. And that’s fine - until it isn’t.\nMany PyTorch errors come from tensor issues. So let’s build up your tensor skills now before those errors might derail your projects. In this session, you’ll learn how to read and understand tensor shapes, handle data types, create tensors in different ways, reshape and slice them to fit your models, and then pull out what you need."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session4.html#understanding-shapes",
    "href": "W4_DL/C1_M1_Getting_Started/session4.html#understanding-shapes",
    "title": "Module 1 - Session 4: Working with Tensors",
    "section": "Understanding Shapes",
    "text": "Understanding Shapes\ndistances.shape  # torch.Size([6, 1])\n[6, 1] means:\n\n6 samples (batch size)\n1 feature per sample\n\nShape mismatches = most common PyTorch errors\n\nLet’s start with the most important tool in your tensor toolkit: checking shapes. When you print distances.shape, you’ll get something like torch.Size([6, 1]). That tells you exactly how your data is organized.\nThere are 6 samples - that’s your batch size. And there’s 1 feature per sample - that’s the distance of each delivery. Shape mismatches are one of the most common PyTorch errors, right alongside device and dtype issues.\nSo let’s take a look at a shape that does work. Using the same single neuron model you trained earlier, pass in the distances, and it just works. Why? Because each sample has one feature, just as the model expects."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session4.html#why-batch-size-doesnt-cause-problems",
    "href": "W4_DL/C1_M1_Getting_Started/session4.html#why-batch-size-doesnt-cause-problems",
    "title": "Module 1 - Session 4: Working with Tensors",
    "section": "Why Batch Size Doesn’t Cause Problems",
    "text": "Why Batch Size Doesn’t Cause Problems\nModel expects first dimension = batch size\nThink of it like a stack of papers:\n\nModel reads each page the same way\nWhether 6 pages or 600 pages\nFirst dimension = how many\nRest = what each sample looks like\n\n\nBut what about that 6? Why doesn’t the batch size cause a problem? Well, that’s because the model expects the first dimension to be the batch size - the number of samples it will take at once.\nThink of it a little bit like a stack of papers. The model reads each page the same way, whether there are 6 pages or 600 in the stack. The first dimension is how many, and the rest describe what each sample looks like.\nSo now try passing in multiple features like distance, hour, and weather. It fails. The model was only built for one input feature. When you hit a shape mismatch, PyTorch will tell you what’s wrong, but not how to fix it. Once you see both shapes, usually the fix will be obvious."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session4.html#data-types",
    "href": "W4_DL/C1_M1_Getting_Started/session4.html#data-types",
    "title": "Module 1 - Session 4: Working with Tensors",
    "section": "Data Types",
    "text": "Data Types\n# Defaults\ntorch.tensor([1, 2, 3])        # int64\ntorch.tensor([1.0, 2.0, 3.0])  # float32\n\n# Explicit\ntorch.tensor([1, 2, 3], dtype=torch.float32)\ntensor.float()  # convert to float32\nFor neural networks: float32 is the sweet spot\n\nNow you understand shapes, let’s talk about data types. When you create a tensor, PyTorch can use defaults. Enter integers, you’ll get int64. Include a decimal point, then you’ll get float32.\nIf you want to be explicit, you can use the dtype argument. It guarantees float32 even if you forget the decimal point. Alternatively, you can use .float() to convert any tensor to float32.\nWhat happens if you mix types? PyTorch will automatically handle mixed types through type promotion. For example, if you add an int tensor and a float tensor, PyTorch will automatically convert the int to float and then return a float result, just like regular Python.\nThere are other types too, like float64 for extra precision or int8 for memory savings. But for neural networks, float32 is the sweet spot - it’s fast, accurate, and standard on modern hardware."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session4.html#creating-tensors",
    "href": "W4_DL/C1_M1_Getting_Started/session4.html#creating-tensors",
    "title": "Module 1 - Session 4: Working with Tensors",
    "section": "Creating Tensors",
    "text": "Creating Tensors\nFrom Python lists:\ntorch.tensor([[1, 2], [3, 4]])\nFrom NumPy:\ntorch.from_numpy(np_array)\nBuilt-in patterns:\ntorch.zeros(2, 3)\ntorch.ones(2, 3)\ntorch.randn(2, 3)  # random values\n\nNow that you understand types, let’s look at different ways to create tensors. The simplest way: use Python lists. And if you’re coming from NumPy, PyTorch tensors behave almost exactly the same way. You can convert a NumPy array like this. Just remember, this shares memory - if you change one, the other changes too.\nIf you need quick test data, try these built-in patterns for zeros, ones, or random values. These are incredibly useful when you’re prototyping or testing your models."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session4.html#reshaping-tensors",
    "href": "W4_DL/C1_M1_Getting_Started/session4.html#reshaping-tensors",
    "title": "Module 1 - Session 4: Working with Tensors",
    "section": "Reshaping Tensors",
    "text": "Reshaping Tensors\nCommon error: forgetting the batch dimension\n# Wrong: scalar\nsingle_value = torch.tensor(25.0)  # shape: []\n\n# Right: batch dimension\nsingle_value = torch.tensor([[25.0]])  # shape: [1, 1]\n\nOnce you have tensors, you’ll often need to reshape them to match what your model expects. Remember, PyTorch models expect input with a batch dimension, like [6, 1] that we saw earlier. That first number tells the model how many samples it’s getting.\nOne of the most common shape errors is forgetting that batch dimension. Let’s say you want to predict the delivery time for a single order, for example, 25 miles. This is a scalar, but your model expects a shape of batch size, features, which at a minimum is [1, 1]."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session4.html#adding-dimensions",
    "href": "W4_DL/C1_M1_Getting_Started/session4.html#adding-dimensions",
    "title": "Module 1 - Session 4: Working with Tensors",
    "section": "Adding Dimensions",
    "text": "Adding Dimensions\n# Add dimension\ntensor.unsqueeze(0)  # add at position 0\n\n# Remove dimensions\ntensor.squeeze()  # removes all size-1 dimensions\nAlways check shape before using unsqueeze()\n\nYou can also use unsqueeze() to add dimensions. So now it’s ready for the model. Always check the shape before you use unsqueeze().\nAnd if you’re going the other way, try just using squeeze(). squeeze() removes all dimensions of size one, and it’s great for cleaning up after batching.\nAlways print tensor.shape when you’re debugging. These tools are your first defense against shape errors."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session4.html#indexing-and-slicing",
    "href": "W4_DL/C1_M1_Getting_Started/session4.html#indexing-and-slicing",
    "title": "Module 1 - Session 4: Working with Tensors",
    "section": "Indexing and Slicing",
    "text": "Indexing and Slicing\npredictions[0]        # first prediction\npredictions[0:3]      # first three\npredictions[0].item() # convert to Python float\n.item() only works on tensors with exactly one element\n\nSometimes you need specific values from your tensors, like checking predictions or grabbing a few samples. Indexing and slicing can be used for this, and they work just like Python lists.\nThis gives the first prediction, and this gives the first three. But even a single index value is still a tensor. So if you want the actual Python value, use .item() to convert it into a float.\nBut be careful - .item() only works on tensors with exactly one element. Call it on a bigger tensor, you’ll get an error."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session4.html#multiple-features",
    "href": "W4_DL/C1_M1_Getting_Started/session4.html#multiple-features",
    "title": "Module 1 - Session 4: Working with Tensors",
    "section": "Multiple Features",
    "text": "Multiple Features\n# Shape: [batch_size, num_features]\ndata = torch.tensor([[5.0, 14.0, 1.0],  # distance, hour, weather\n                     [6.0, 15.0, 0.0]])\n\ndata[0, 1]  # first sample, second feature (hour = 14.0)\n\nSo far, we’ve looked at one feature per sample. With multiple features, you can index across both dimensions like so. You’ve now seen shapes, types, reshaping, and indexing. It’s a lot, but don’t worry - you don’t need to memorize everything. These patterns will become second nature with practice, and even the pros check the docs."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session4.html#element-wise-operations",
    "href": "W4_DL/C1_M1_Getting_Started/session4.html#element-wise-operations",
    "title": "Module 1 - Session 4: Working with Tensors",
    "section": "Element-Wise Operations",
    "text": "Element-Wise Operations\nweight = 3.4\nbias = 5.0\ndistances = torch.tensor([[5.0], [6.0], [8.0]])\n\n# Element-wise: applies to each element independently\npredictions = weight * distances + bias\nSame operation applied to all elements at once\n\nNow let’s see how PyTorch actually computes with tensors. Let’s start with a computation from your single neuron model: weight times distance plus bias.\nPyTorch’s tensor math works element-wise, so each element is operated on independently. Your computation applies the same weight to each distance, and then adds the same bias to each result. The math looks just like regular Python, but PyTorch runs these operations efficiently on all elements at once.\nThis works for scalars (single values) as well as tensors that have the same shape."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session4.html#broadcasting",
    "href": "W4_DL/C1_M1_Getting_Started/session4.html#broadcasting",
    "title": "Module 1 - Session 4: Working with Tensors",
    "section": "Broadcasting",
    "text": "Broadcasting\n\nBroadcasting is a powerful mechanism in PyTorch and NumPy that allows you to perform arithmetic operations on tensors of different shapes without manually duplicating data in memory. It makes your code faster and more memory-efficient by vectorizing operations in C rather than Python loops."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session4.html#broadcasting-example",
    "href": "W4_DL/C1_M1_Getting_Started/session4.html#broadcasting-example",
    "title": "Module 1 - Session 4: Working with Tensors",
    "section": "Broadcasting: Example",
    "text": "Broadcasting: Example\nProblem: Want to apply different adjustments to different features\nSolution: Broadcasting automatically expands dimensions\n# Instead of repeating [1.1, 1.0, 5.0] three times:\nadjustments = torch.tensor([[1.1, 1.0, 5.0]])  # shape: [1, 3]\ndata = torch.tensor([[5.0, 14.0, 1.0],\n                     [6.0, 15.0, 0.0],\n                     [8.0, 16.0, 1.0]])  # shape: [3, 3]\n\nresult = data * adjustments  # Broadcasting!\n\nBut what if you have more complex data? Imagine three deliveries where each has three features: distance, hour, and weather. And now you want to apply adjustment factors: maybe 1.1x for distance, no change for time, and a 5x penalty for bad weather.\nCreating that tensor with repeated rows works because the tensors have the same shape, but it’s redundant. Wouldn’t it be nice if you could just specify those adjustment values once? That’s where broadcasting comes in.\nWhen you add a scalar to a tensor, PyTorch automatically expands that single value to match every element. This automatic expansion is broadcasting in action."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session4.html#how-broadcasting-works",
    "href": "W4_DL/C1_M1_Getting_Started/session4.html#how-broadcasting-works",
    "title": "Module 1 - Session 4: Working with Tensors",
    "section": "How Broadcasting Works",
    "text": "How Broadcasting Works\nRule: When one dimension is 1 and the other is larger, PyTorch expands the smaller dimension\nExample:\n\n[1, 3] × [3, 1] → both become [3, 3]\n[1, 1] × [1, 3] → first becomes [1, 3]\n\n\nLet’s look at a more complex example. What happens when you combine a [1, 3] tensor with a [3, 1] tensor?\nPyTorch looks at each dimension. The first dimension: 1 versus 3. The 1 expands to 3. The second dimension: 3 versus 1. The 1 expands to 3. So both become [3, 3].\nHow would you actually use this? Remember those delivery adjustments? Instead of repeating [1.1, 1.0, 5.0] three times, you can just write this. No loops. No manual repetition. PyTorch handles it all through broadcasting.\nThis pattern appears everywhere: adjusting multiple features across batches, combining different dimensions of data, applying transformations efficiently. Once you know to look for it, you’re going to see broadcasting opportunities everywhere in deep learning."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session4.html#module-1-summary",
    "href": "W4_DL/C1_M1_Getting_Started/session4.html#module-1-summary",
    "title": "Module 1 - Session 4: Working with Tensors",
    "section": "Module 1 Summary",
    "text": "Module 1 Summary\nYou’ve learned:\n\nWhy PyTorch exists and what makes it special\nHow neural networks learn from data\nThe complete ML pipeline\nBuilding and training your first model\nActivation functions for non-linear patterns\nWorking with tensors (shapes, types, operations)\n\n\nNow you’ve covered essential tensor operations. The provided lab has additional examples that you can explore. Because like any tool, tensors will become intuitive through practice.\nBut most importantly, you’re at the end of Module 1. Congratulations! We started by exploring what makes PyTorch special. And now you’ve learned the fundamentals. You’ve worked through the machine learning pipeline. You’ve trained your first neural network. You’ve mastered tensor operations. You’ve built the foundation."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session4.html#lab-3-tensors-the-core-of-pytorch",
    "href": "W4_DL/C1_M1_Getting_Started/session4.html#lab-3-tensors-the-core-of-pytorch",
    "title": "Module 1 - Session 4: Working with Tensors",
    "section": "Lab 3: Tensors: The Core of PyTorch",
    "text": "Lab 3: Tensors: The Core of PyTorch\n\n“For the things we have to learn before we can do them, we learn by doing them.”\n\n\nCUE: START THE LAB HERE"
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session4.html#assignment-1-deeper-regression-smarter-features",
    "href": "W4_DL/C1_M1_Getting_Started/session4.html#assignment-1-deeper-regression-smarter-features",
    "title": "Module 1 - Session 4: Working with Tensors",
    "section": "Assignment 1: Deeper Regression, Smarter Features",
    "text": "Assignment 1: Deeper Regression, Smarter Features\n\n“What I cannot create, I do not understand.”\n\n\nCUE: START THE ASSIGNMENT HERE"
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session4.html#whats-next",
    "href": "W4_DL/C1_M1_Getting_Started/session4.html#whats-next",
    "title": "Module 1 - Session 4: Working with Tensors",
    "section": "What’s Next?",
    "text": "What’s Next?\nIn Module 2: Image Classification we learn:\n\nTackle classification problems\nDive deeper into how neural networks learn\nBuild your first image classifier\n\n\nUp next is the tensor lab, where you’ll practice these concepts. Followed by a graded assignment to test your skills. Then in Module 2, you’re going to tackle classification problems and dive deeper into how neural networks really learn.\nYou’ve mastered PyTorch fundamentals. It’s time to put them to work."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session2.html#the-machine-learning-pipeline",
    "href": "W4_DL/C1_M1_Getting_Started/session2.html#the-machine-learning-pipeline",
    "title": "Module 1 - Session 2: The ML Pipeline and Building Your First Model",
    "section": "The Machine Learning Pipeline",
    "text": "The Machine Learning Pipeline\nSix stages from data to deployed model\n\nThe Machine Learning Pipeline\nLast session, we saw how neural networks learn using the delivery time problem. Now, before we jump into code, we need a systematic approach. This framework will be used throughout the entire Professional Certificate, whether you’re training a delivery predictor or building image classifiers later.\nThe pipeline ensures we don’t skip critical steps and helps us understand where we are in the process at any given time."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session2.html#stage-1-data-ingestion",
    "href": "W4_DL/C1_M1_Getting_Started/session2.html#stage-1-data-ingestion",
    "title": "Module 1 - Session 2: The ML Pipeline and Building Your First Model",
    "section": "Stage 1: Data Ingestion",
    "text": "Stage 1: Data Ingestion\nGathering and organizing raw data\n\nDelivery records from company database\nMessy data: inconsistent formats, missing values, errors\nOrganize for PyTorch to work efficiently\n\n\nIt all starts with data. Before you can train any model, you need to gather your raw information and organize it so PyTorch can work with each data point efficiently.\nFor the delivery predictor, that data comes from the company’s delivery records. But here’s where things get tricky - real-world data is messy. Earlier records might list delivery times as free-text entries like “22 minutes,” while newer ones use numeric values like 22.0. There are always issues: missing values, negative delivery times, or records suggesting you were biking at 200 miles per hour.\nThis kind of messy data is the norm, not the exception. In your first lab, we’ll keep things simple with clean data, but understanding these steps helps you appreciate what goes into real-world projects."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session2.html#stage-2-data-preparation",
    "href": "W4_DL/C1_M1_Getting_Started/session2.html#stage-2-data-preparation",
    "title": "Module 1 - Session 2: The ML Pipeline and Building Your First Model",
    "section": "Stage 2: Data Preparation",
    "text": "Stage 2: Data Preparation\nCleaning, transforming, and organizing\n\nFix errors (impossible times, duplicates)\nHandle missing values\nEngineer features (addresses → distances)\n\nMost time-consuming stage in real projects\n\nGetting the data was just the beginning. Whether you’re working with delivery records, customer images, or email text, the next challenge is the same: you have to clean, transform, and organize that data into a form your model can actually learn from.\nFor delivery data, that might mean fixing errors like removing impossible delivery times or duplicate entries. It could mean handling missing values when timestamps weren’t recorded. Or engineering new features by converting addresses like “123 Oak Street” into distances like 8.2 miles.\nThis stage often takes the most time and the most code in a real project. That’s normal. Most models don’t fail because the math was wrong - they fail because the data was messy."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session2.html#stage-3-model-building",
    "href": "W4_DL/C1_M1_Getting_Started/session2.html#stage-3-model-building",
    "title": "Module 1 - Session 2: The ML Pipeline and Building Your First Model",
    "section": "Stage 3: Model Building",
    "text": "Stage 3: Model Building\nDesigning the architecture\n\nHow many neurons?\nHow are they connected?\nWhat types of layers?\n\nFor delivery predictor: one neuron (simplest architecture)\n\nNow that your data is cleaned and ready, it’s time to design the model that’s going to learn from it. Whether you’re predicting delivery times, classifying images, or analyzing text, this step is about choosing the right architecture for your problem.\nArchitecture means structure: How many neurons are you going to use? How are they connected? What types of layers does the model need?\nFor your delivery predictor, the architecture is as simple as it gets - one neuron that learns the relationship between distance and delivery time. In PyTorch, defining that model’s architecture takes just a single line of code. The beautiful thing about PyTorch is that even this simple model follows the same patterns as much more complex ones you’ll tackle later."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session2.html#stage-4-training",
    "href": "W4_DL/C1_M1_Getting_Started/session2.html#stage-4-training",
    "title": "Module 1 - Session 2: The ML Pipeline and Building Your First Model",
    "section": "Stage 4: Training",
    "text": "Stage 4: Training\nTeaching the model to make predictions\n\nFeed examples (8.2 miles → 22 minutes)\nMeasure prediction errors\nAdjust parameters to improve\nRepeat for many epochs\n\n\nHaving a good model design is just the blueprint. Next, you actually have to teach it to make good predictions. Here’s where your model starts learning.\nYou’ll feed in examples like “this delivery was 8.2 miles and took 22 minutes” or “this one was 12.5 miles and took 31 minutes.” The model will gradually start to figure out the pattern.\nIn the training stage, you’ll learn how to configure the key pieces that make this process work: How do you measure prediction errors? How do you guide the model to improve? How do you control how fast it learns? Then you’ll run the training loop, where PyTorch does the heavy lifting and your model learns from the data."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session2.html#stage-5-evaluation",
    "href": "W4_DL/C1_M1_Getting_Started/session2.html#stage-5-evaluation",
    "title": "Module 1 - Session 2: The ML Pipeline and Building Your First Model",
    "section": "Stage 5: Evaluation",
    "text": "Stage 5: Evaluation\nTesting on unseen data\n\nUse test set (held back during training)\nMeasure performance (accuracy, error)\nDetect issues and debug\n\nKey question: Does your model work well enough to trust it?\n\nEven when training finishes successfully, you’re not done yet. Now comes the real test: Can your model make a good prediction on new, unseen data?\nTo know if you have a really good model, you need to see how well it performs on new data - examples it wasn’t trained on. You’ll use a test set, a portion of the delivery data that you held back during training.\nMaybe a model predicts 28 minutes for a 15-mile delivery, but in reality it took 32 minutes. How often is your model close? How often is it way off? As you move through the course, you’ll learn how to detect deeper issues and debug models when things go wrong. But for now, the key question is simple: Does your model work well enough for you to trust it?"
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session2.html#stage-6-deployment",
    "href": "W4_DL/C1_M1_Getting_Started/session2.html#stage-6-deployment",
    "title": "Module 1 - Session 2: The ML Pipeline and Building Your First Model",
    "section": "Stage 6: Deployment",
    "text": "Stage 6: Deployment\nGetting your model into the real world\n(We’ll cover this later in the course)\n\nStage 6 is deployment - getting your model out into the real world for people to use. We’ll leave this one out of the pipeline for now and come back to it when the time comes.\nNow that you’ve seen the full picture, you’re ready to dive right in. In the rest of this session, you’ll see how even our simple delivery model follows these exact stages in PyTorch code."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session2.html#building-your-first-neural-network",
    "href": "W4_DL/C1_M1_Getting_Started/session2.html#building-your-first-neural-network",
    "title": "Module 1 - Session 2: The ML Pipeline and Building Your First Model",
    "section": "Building Your First Neural Network",
    "text": "Building Your First Neural Network\nLet’s see it in PyTorch code\n\nYou’ve seen the machine learning pipeline and understand how neural networks learn. Now let’s take a look at how it all maps to actual PyTorch code. We’ll start with the imports, then move through data preparation, model building, training, and making predictions."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session2.html#imports",
    "href": "W4_DL/C1_M1_Getting_Started/session2.html#imports",
    "title": "Module 1 - Session 2: The ML Pipeline and Building Your First Model",
    "section": "Imports",
    "text": "Imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\ntorch: core functionality\nnn: neural network components\noptim: training tools\n\n\nThese imports give you PyTorch’s core functionality. torch provides the fundamental operations, nn (neural networks) gives you components for building models, and optim provides tools for training these networks. These three modules cover most of what you’ll need for building and training models."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session2.html#preparing-data",
    "href": "W4_DL/C1_M1_Getting_Started/session2.html#preparing-data",
    "title": "Module 1 - Session 2: The ML Pipeline and Building Your First Model",
    "section": "Preparing Data",
    "text": "Preparing Data\ndistances = torch.tensor([[5.0], [6.0], [8.0], [10.0]], \n                         dtype=torch.float32)\ntimes = torch.tensor([[22.2], [25.6], [31.2], [38.5]], \n                     dtype=torch.float32)\nTensors: optimized containers for neural network math\n\nIn real projects, data ingestion and preparation are separate steps. First you gather messy data, then you clean and format it. But for this example, I’ve combined those stages and provided data that’s already clean and ready to use.\nYou’re creating tensors from Python lists, but they’re more than just lists. Tensors are optimized for the math that neural networks need to do. You’ll learn much more about them later, but for now, just think of them as containers that store and organize data in a way models understand.\nNotice how each number is wrapped in its own set of brackets. These outer brackets represent a batch - a collection of individual data points. Each inner set of brackets is one sample in the batch. Since each delivery only has one feature (distance), each sample contains just one value."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session2.html#understanding-tensor-shapes",
    "href": "W4_DL/C1_M1_Getting_Started/session2.html#understanding-tensor-shapes",
    "title": "Module 1 - Session 2: The ML Pipeline and Building Your First Model",
    "section": "Understanding Tensor Shapes",
    "text": "Understanding Tensor Shapes\ndistances = torch.tensor([[5.0], [6.0], [8.0], [10.0]])\ndistances.shape  # torch.Size([4, 1])\n\nFirst dimension: batch size (4 samples)\nSecond dimension: features per sample (1 feature)\n\n\nThe shape tells you exactly how your data is organized. [4, 1] means 4 samples, each with 1 feature. This structure is crucial - PyTorch models expect input with a batch dimension. The first number tells the model how many samples it’s getting. The rest describe what each sample looks like.\nIf you had multiple features (distance, time of day, weather), each sample would have multiple values, but the batch structure would remain the same."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session2.html#tensor-dimensions-3-dimensions",
    "href": "W4_DL/C1_M1_Getting_Started/session2.html#tensor-dimensions-3-dimensions",
    "title": "Module 1 - Session 2: The ML Pipeline and Building Your First Model",
    "section": "Tensor Dimensions: 3 dimensions",
    "text": "Tensor Dimensions: 3 dimensions\n\nHow to read brackets as dimensions"
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session2.html#creating-the-model",
    "href": "W4_DL/C1_M1_Getting_Started/session2.html#creating-the-model",
    "title": "Module 1 - Session 2: The ML Pipeline and Building Your First Model",
    "section": "Creating the Model",
    "text": "Creating the Model\nmodel = nn.Sequential(\n    nn.Linear(1, 1)  # 1 input, 1 output\n)\nSequential: container that passes data through layers in order\nLinear layer: single neuron (weight × input + bias)\n\nRemember those rigid assembly lines from early deep learning frameworks? Sequential is PyTorch’s streamlined version. It’s a container that passes data through layers in order, but makes it easy for you to swap components without all that messy rewiring.\nHere, you’re only using one layer - your single neuron. It’s technically a linear layer. The first 1 means it takes one input (distance). The second 1 means it produces one output (predicted delivery time). It applies a linear transformation to the input - that’s all the linear layer does.\nThis neuron will learn the best weight and bias to map distances to delivery times, just like finding the best-fitting line through all your data points."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session2.html#loss-function",
    "href": "W4_DL/C1_M1_Getting_Started/session2.html#loss-function",
    "title": "Module 1 - Session 2: The ML Pipeline and Building Your First Model",
    "section": "Loss Function",
    "text": "Loss Function\nloss_function = nn.MSELoss()\nMean Squared Error: measures how wrong predictions are\n\nBigger errors → bigger loss\nPerfect predictions → loss = 0\n\n\nYour model needs two tools to actually learn. The first is the loss function. We’re using Mean Squared Error loss, which measures how wrong or how right your predictions are.\nIf you predict 45 minutes when it actually took 60, that’s a bigger error than predicting 58 minutes. MSE captures this by squaring the differences, which makes bigger mistakes matter more. The goal is to minimize this loss - the lower the loss, the better your model."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session2.html#optimizer",
    "href": "W4_DL/C1_M1_Getting_Started/session2.html#optimizer",
    "title": "Module 1 - Session 2: The ML Pipeline and Building Your First Model",
    "section": "Optimizer",
    "text": "Optimizer\noptimizer = optim.SGD(model.parameters(), lr=0.01)\nSGD (Stochastic Gradient Descent):\n\nFigures out which direction to adjust weights/bias\nlr (learning rate): controls step size\n\n\nThe optimizer is the algorithm that figures out which direction to adjust your weight and bias to reduce that error. model.parameters() is how you access those values in PyTorch - in this case, just the weight and bias from your single neuron.\nlr is the learning rate. Smaller values mean you adjust parameters by smaller amounts. Larger values mean bigger adjustments. Both extremes can have challenges - too small and training is slow, too large and you might overshoot the best values.\nIf you’re curious about the math behind loss functions or optimization, you’ll get a much deeper introduction in Module 2."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session2.html#the-training-loop",
    "href": "W4_DL/C1_M1_Getting_Started/session2.html#the-training-loop",
    "title": "Module 1 - Session 2: The ML Pipeline and Building Your First Model",
    "section": "The Training Loop",
    "text": "The Training Loop\nfor epoch in range(500):\n    optimizer.zero_grad()      # Clear old calculations\n    outputs = model(distances) # Make predictions\n    loss = loss_function(outputs, times)  # Measure error\n    loss.backward()            # Calculate gradients\n    optimizer.step()           # Update weights/bias\n\nEach epoch: one full pass through training data\n\nThis is the training loop where the actual learning happens. Remember when I manually adjusted the weight and bias to get closer to the right line? This code is doing the same thing automatically, hundreds of times.\nEach full pass through the training data is called an epoch. In each epoch, the model will: (1) make predictions, (2) measure how far off those predictions are, and (3) adjust its internal parameters to improve.\nLet’s break down each line: optimizer.zero_grad() clears out all calculated values from the previous training round. Without it, PyTorch would accumulate adjustments across rounds, which would mess up your learning."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session2.html#training-loop-breakdown",
    "href": "W4_DL/C1_M1_Getting_Started/session2.html#training-loop-breakdown",
    "title": "Module 1 - Session 2: The ML Pipeline and Building Your First Model",
    "section": "Training Loop Breakdown",
    "text": "Training Loop Breakdown\n\noutputs = model(distances) - Model uses distance as input\nloss = loss_function(outputs, times) - Compares predictions to real times\nloss.backward() - Figures out how to adjust weight/bias (backpropagation)\noptimizer.step() - Makes the adjustments\n\noutputs = model(distances) tells the model to use the distance as inputs and make predictions.\nloss = loss_function(outputs, times) compares the predictions to the real times and calculates how wrong they are.\nloss.backward() figures out how to adjust the weight and bias to reduce that error. Just like when I said “I need a steeper slope,” it’s now done with calculus behind the scenes. The technical term is backpropagation.\noptimizer.step() makes all those adjustments. The model is now slightly better at predicting delivery times."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session2.html#making-predictions-inference",
    "href": "W4_DL/C1_M1_Getting_Started/session2.html#making-predictions-inference",
    "title": "Module 1 - Session 2: The ML Pipeline and Building Your First Model",
    "section": "Making Predictions (Inference)",
    "text": "Making Predictions (Inference)\nwith torch.no_grad():\n    new_distance = torch.tensor([[7.0]])\n    prediction = model(new_distance)\n    print(prediction)\ntorch.no_grad(): skip training overhead for faster inference\n\nNow that the model is trained, let’s try making a prediction. The line with torch.no_grad() tells PyTorch that you’re not training anymore, just doing inference. Training takes extra work under the hood, but for inference, we can skip all that and run much more efficiently.\nIf the model learned what it was supposed to, it should give you a good answer. But you’re going to have to try it out in the lab to see for yourself.\nSpeaking of building, that’s exactly what’s next. It’s time to get hands-on and see if your delivery job is still safe."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session2.html#lab-1-building-a-simple-neural-network",
    "href": "W4_DL/C1_M1_Getting_Started/session2.html#lab-1-building-a-simple-neural-network",
    "title": "Module 1 - Session 2: The ML Pipeline and Building Your First Model",
    "section": "Lab 1: Building a Simple Neural Network",
    "text": "Lab 1: Building a Simple Neural Network\n\n“What I hear, I forget. What I see, I remember. What I do, I understand.”\n\n\nSTART WITH LAB 1"
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session2.html#whats-next",
    "href": "W4_DL/C1_M1_Getting_Started/session2.html#whats-next",
    "title": "Module 1 - Session 2: The ML Pipeline and Building Your First Model",
    "section": "What’s Next?",
    "text": "What’s Next?\nIn Session 3: Activation Functions we learn:\n\nWhy linear models fail for complex patterns\nIntroducing non-linearity with activation functions\nReLU and other activation functions\n\n\nIn the next session, we’ll discover what happens when your delivery company expands and the relationship between distance and time becomes non-linear. We’ll learn how activation functions help neural networks model curves and complex patterns, not just straight lines."
  },
  {
    "objectID": "W3_ML/D5.html#genai-policy-reminder-submission-day",
    "href": "W3_ML/D5.html#genai-policy-reminder-submission-day",
    "title": "Machine Learning",
    "section": "GenAI policy reminder (submission day)",
    "text": "GenAI policy reminder (submission day)\nYou may use Generative AI only for clarifying questions.\n\n✅ Allowed: definitions, “what does this error mean?”, reading docs, concept explanations\n❌ Not allowed: generating your solution code, debugging by copy‑paste, writing full functions\n\n\n\n\n\n\n\nWarning\n\n\nToday is a submission day. Your repo must reflect your skill."
  },
  {
    "objectID": "W3_ML/D5.html#announcements-admin",
    "href": "W3_ML/D5.html#announcements-admin",
    "title": "Machine Learning",
    "section": "Announcements / admin",
    "text": "Announcements / admin\nWhat you submit today (minimum ✅) - updated reports/model_card.md - updated reports/eval_summary.md - uv run pytest passes - uv run ruff check . passes (install dev extra if needed) - pushed to GitHub (public)\n\n\n\n\n\n\nNote\n\n\nCapstone teams + project ideas are finalized by end of Week 5 (Jan 15, 2026)."
  },
  {
    "objectID": "W3_ML/D5.html#todays-flow",
    "href": "W3_ML/D5.html#todays-flow",
    "title": "Machine Learning",
    "section": "Today’s Flow",
    "text": "Today’s Flow\n\nSession 1 (60m): Model card = data contract + honest story\nAsr Prayer (20m)\nSession 2 (60m): Turn artifacts into a clear evaluation summary\nMaghrib Prayer (20m)\nSession 3 (60m): Final quality gate (tests, ruff, reproducibility)\nIsha Prayer (20m)\nHands-on (120m): Fill reports, run checks, push to GitHub"
  },
  {
    "objectID": "W3_ML/D5.html#learning-objectives",
    "href": "W3_ML/D5.html#learning-objectives",
    "title": "Machine Learning",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of today, you can:\n\nExplain your baseline system to a teammate in 90 seconds\nFill model_card.md with: problem, data contract, split, metrics, limitations\nFill eval_summary.md with: baseline vs model, key caveats, recommendation\nRun the full quality gate: ruff + pytest + end-to-end CLI demo\nSubmit a repo that someone else can run from the README"
  },
  {
    "objectID": "W3_ML/D5.html#warm-up-5-minutes",
    "href": "W3_ML/D5.html#warm-up-5-minutes",
    "title": "Machine Learning",
    "section": "Warm-up (5 minutes)",
    "text": "Warm-up (5 minutes)\nConfirm end-to-end still works on your latest run.\nmacOS/Linux\nuv run ml-baseline make-sample-data\nuv run ml-baseline train --target is_high_value\nrun_id=$(cat models/registry/latest.txt)\nholdout=$(ls models/runs/$run_id/tables/holdout_input.* | head -n 1)\nuv run ml-baseline predict --run latest --input \"$holdout\" --output outputs/preds.csv\nWindows PowerShell\nuv run ml-baseline make-sample-data\nuv run ml-baseline train --target is_high_value\n$run_id = Get-Content models/registry/latest.txt\n$holdout = (Get-ChildItem \"models/runs/$run_id/tables\" -Filter \"holdout_input.*\" | Select-Object -First 1).FullName\nuv run ml-baseline predict --run latest --input $holdout --output outputs/preds.csv\nCheckpoint: outputs/preds.csv exists."
  },
  {
    "objectID": "W3_ML/D5.html#the-week-3-finish-line-minimum",
    "href": "W3_ML/D5.html#the-week-3-finish-line-minimum",
    "title": "Machine Learning",
    "section": "The Week 3 finish line (minimum ✅)",
    "text": "The Week 3 finish line (minimum ✅)\nYour system is “done” when:\n\nml-baseline train saves a run folder with model + schema + metrics\nml-baseline predict produces a predictions file on new input\nreports answer: what, how well, what can go wrong, how to run\n\n\n\n\n\n\n\nTip\n\n\nA working model with no documentation is hard to trust."
  },
  {
    "objectID": "W3_ML/D5.html#session-1-objectives",
    "href": "W3_ML/D5.html#session-1-objectives",
    "title": "Machine Learning",
    "section": "Session 1 objectives",
    "text": "Session 1 objectives\n\nUnderstand what a model card is (and why teams use it)\nUpdate your model_card.md to match your actual run artifacts\nWrite limitations in a way that protects you (and your future users)"
  },
  {
    "objectID": "W3_ML/D5.html#what-is-a-model-card",
    "href": "W3_ML/D5.html#what-is-a-model-card",
    "title": "Machine Learning",
    "section": "What is a model card?",
    "text": "What is a model card?\nA model card is a short document that answers:\n\nWhat is this model for?\nWhat data does it expect? (contract)\nHow was it evaluated?\nWhat are the limitations?\nHow do I run it?\n\n\n\n\n\n\n\nNote\n\n\nThink: “If I leave the company, can a teammate understand and rerun this?”"
  },
  {
    "objectID": "W3_ML/D5.html#model-card-structure-minimum",
    "href": "W3_ML/D5.html#model-card-structure-minimum",
    "title": "Machine Learning",
    "section": "Model card structure (minimum ✅)",
    "text": "Model card structure (minimum ✅)\nKeep it simple and scannable:\n\nPrediction task (target + unit of analysis)\nData contract (required features, optional IDs, forbidden columns)\nTraining recipe (split, baseline, model family)\nResults (baseline vs model on holdout)\nLimitations + failure modes\nHow to run (train + predict commands)"
  },
  {
    "objectID": "W3_ML/D5.html#where-the-truth-lives-dont-guess",
    "href": "W3_ML/D5.html#where-the-truth-lives-dont-guess",
    "title": "Machine Learning",
    "section": "Where the truth lives (don’t guess)",
    "text": "Where the truth lives (don’t guess)\nUse your artifacts to fill the model card:\n\ndata contract: schema/input_schema.json\nrun identity: run_meta.json + models/registry/latest.txt\nmetrics: metrics/baseline_holdout.json + metrics/holdout_metrics.json\nexamples: tables/holdout_predictions.*\n\n\n\n\n\n\n\nTip\n\n\nCopy numbers from artifacts. Do not “estimate” your metrics."
  },
  {
    "objectID": "W3_ML/D5.html#micro-exercise-find-3-facts-6-minutes",
    "href": "W3_ML/D5.html#micro-exercise-find-3-facts-6-minutes",
    "title": "Machine Learning",
    "section": "Micro-exercise: find 3 facts (6 minutes)",
    "text": "Micro-exercise: find 3 facts (6 minutes)\nFrom your latest run folder, find:\n\nyour run_id\none baseline metric value\none model holdout metric value\n\nCheckpoint: you can point to the exact file for each fact."
  },
  {
    "objectID": "W3_ML/D5.html#solution-where-to-look",
    "href": "W3_ML/D5.html#solution-where-to-look",
    "title": "Machine Learning",
    "section": "Solution (where to look)",
    "text": "Solution (where to look)\n\nmodels/registry/latest.txt (or run_meta.json)\nmodels/runs/&lt;run_id&gt;/metrics/baseline_holdout.json\nmodels/runs/&lt;run_id&gt;/metrics/holdout_metrics.json"
  },
  {
    "objectID": "W3_ML/D5.html#limitations-minimum",
    "href": "W3_ML/D5.html#limitations-minimum",
    "title": "Machine Learning",
    "section": "Limitations (minimum ✅)",
    "text": "Limitations (minimum ✅)\nWrite 3–5 bullets that are true now:\n\ndata coverage limits (missing segments, small dataset)\nlabel quality assumptions (how was y created?)\nleakage risks you checked (and what you might have missed)\nwhat “good performance” does not guarantee (business caveats)\n\n\n\n\n\n\n\nWarning\n\n\nAvoid vague limits like “model may be biased.” Be specific: “performance may drop for ___ because ___.”"
  },
  {
    "objectID": "W3_ML/D5.html#session-1-recap",
    "href": "W3_ML/D5.html#session-1-recap",
    "title": "Machine Learning",
    "section": "Session 1 recap",
    "text": "Session 1 recap\n\nThe model card is your trust document\nUse artifacts as the source of truth\nClear limitations are a professional strength"
  },
  {
    "objectID": "W3_ML/D5.html#minutes",
    "href": "W3_ML/D5.html#minutes",
    "title": "Machine Learning",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: open reports/model_card.md and your latest run folder side-by-side."
  },
  {
    "objectID": "W3_ML/D5.html#session-2-objectives",
    "href": "W3_ML/D5.html#session-2-objectives",
    "title": "Machine Learning",
    "section": "Session 2 objectives",
    "text": "Session 2 objectives\n\nWrite an evaluation summary that compares baseline vs model fairly\nTranslate metrics into “what it means” (1–2 sentences)\nDo light error analysis using holdout_predictions.*"
  },
  {
    "objectID": "W3_ML/D5.html#what-is-eval_summary.md",
    "href": "W3_ML/D5.html#what-is-eval_summary.md",
    "title": "Machine Learning",
    "section": "What is eval_summary.md?",
    "text": "What is eval_summary.md?\nIt is a short decision memo:\n\nWhat you trained (so we know what we’re judging)\nResults (baseline vs model)\nWhat went wrong / where it fails\nWhether you’d ship it as a baseline\n\n\nKeep it short. The goal is clarity, not word count."
  },
  {
    "objectID": "W3_ML/D5.html#metrics-what-to-report-minimum",
    "href": "W3_ML/D5.html#metrics-what-to-report-minimum",
    "title": "Machine Learning",
    "section": "Metrics: what to report (minimum ✅)",
    "text": "Metrics: what to report (minimum ✅)\nChoose 1–2 “primary” metrics.\nClassification (common) - F1 or recall/precision (pick based on the decision) - ROC-AUC is OK as a secondary metric\nRegression (common) - MAE as primary\n\n\n\n\n\n\nTip\n\n\nReport the baseline metric next to the model metric."
  },
  {
    "objectID": "W3_ML/D5.html#micro-exercise-interpret-one-metric-6-minutes",
    "href": "W3_ML/D5.html#micro-exercise-interpret-one-metric-6-minutes",
    "title": "Machine Learning",
    "section": "Micro-exercise: interpret one metric (6 minutes)",
    "text": "Micro-exercise: interpret one metric (6 minutes)\nOpen your holdout_metrics.json and answer:\n\nWhat is your primary metric?\nIs “higher is better” or “lower is better”?\nWrite one sentence: “This means ___.”\n\nCheckpoint: your sentence is understandable by a non-ML teammate."
  },
  {
    "objectID": "W3_ML/D5.html#solution-example-sentences",
    "href": "W3_ML/D5.html#solution-example-sentences",
    "title": "Machine Learning",
    "section": "Solution (example sentences)",
    "text": "Solution (example sentences)\n\nF1: “On unseen holdout rows, the model balances precision and recall with F1 = ___.”\nRecall: “The model catches ___% of positives on holdout, which matters because missing positives is costly.”\nMAE: “On holdout, predictions are off by about ___ units on average.”"
  },
  {
    "objectID": "W3_ML/D5.html#error-analysis-minimum",
    "href": "W3_ML/D5.html#error-analysis-minimum",
    "title": "Machine Learning",
    "section": "Error analysis (minimum ✅)",
    "text": "Error analysis (minimum ✅)\nUse holdout_predictions.* to find:\n\n3–5 worst mistakes (false positives / false negatives)\na pattern (segment, feature range, missing values)\n\n\n\n\n\n\n\nNote\n\n\nYou don’t need perfect analysis. You need evidence you looked."
  },
  {
    "objectID": "W3_ML/D5.html#optional-confidence-intervals",
    "href": "W3_ML/D5.html#optional-confidence-intervals",
    "title": "Machine Learning",
    "section": "Optional ⭐: confidence intervals",
    "text": "Optional ⭐: confidence intervals\nIf your holdout_metrics.json includes a CI field (example: roc_auc_ci or mae_ci):\n\nreport it as a range\nexplain uncertainty in one sentence\n\n\nOptional does not block submission."
  },
  {
    "objectID": "W3_ML/D5.html#session-2-recap",
    "href": "W3_ML/D5.html#session-2-recap",
    "title": "Machine Learning",
    "section": "Session 2 recap",
    "text": "Session 2 recap\n\neval_summary.md is a decision memo\nAlways compare baseline vs model on the same holdout\nA little error analysis beats none"
  },
  {
    "objectID": "W3_ML/D5.html#minutes-1",
    "href": "W3_ML/D5.html#minutes-1",
    "title": "Machine Learning",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: run python -m json.tool on your metrics files and copy numbers into your report."
  },
  {
    "objectID": "W3_ML/D5.html#session-3-objectives",
    "href": "W3_ML/D5.html#session-3-objectives",
    "title": "Machine Learning",
    "section": "Session 3 objectives",
    "text": "Session 3 objectives\n\nRun the “quality gate” commands and understand failures\nAvoid the most common submission mistakes\nMake your repo easy to grade (and easy to demo)"
  },
  {
    "objectID": "W3_ML/D5.html#the-quality-gate-minimum",
    "href": "W3_ML/D5.html#the-quality-gate-minimum",
    "title": "Machine Learning",
    "section": "The quality gate (minimum ✅)",
    "text": "The quality gate (minimum ✅)\nFrom repo root:\n\nuv run pytest\nuv run ruff check .\n(optional) uv run ruff format .\n\n\n\n\n\n\n\nNote\n\n\nIf ruff is missing: uv sync --extra dev."
  },
  {
    "objectID": "W3_ML/D5.html#common-failure-modes-and-fixes",
    "href": "W3_ML/D5.html#common-failure-modes-and-fixes",
    "title": "Machine Learning",
    "section": "Common failure modes (and fixes)",
    "text": "Common failure modes (and fixes)\n\nImport errors: you edited paths/imports → check src/ package structure\nNon-determinism: missing seed usage → set seeds in splits/training\nSchema errors: predict fails on missing/extra columns → validate against input_schema.json\n\n\n\n\n\n\n\nTip\n\n\nWhen tests fail, read the assertion message first. It usually tells you what artifact is missing."
  },
  {
    "objectID": "W3_ML/D5.html#micro-exercise-make-it-gradeable-5-minutes",
    "href": "W3_ML/D5.html#micro-exercise-make-it-gradeable-5-minutes",
    "title": "Machine Learning",
    "section": "Micro-exercise: “make it gradeable” (5 minutes)",
    "text": "Micro-exercise: “make it gradeable” (5 minutes)\nAnswer in one sentence each:\n\nWhat command trains your model?\nWhat command runs prediction?\nWhere do graders find your written work?\n\nCheckpoint: you can point to the exact file paths."
  },
  {
    "objectID": "W3_ML/D5.html#solution",
    "href": "W3_ML/D5.html#solution",
    "title": "Machine Learning",
    "section": "Solution",
    "text": "Solution\n\nuv run ml-baseline train --target &lt;your_target&gt;\nuv run ml-baseline predict --run latest --input &lt;file&gt; --output outputs/preds.csv\nreports/model_card.md and reports/eval_summary.md"
  },
  {
    "objectID": "W3_ML/D5.html#session-3-recap",
    "href": "W3_ML/D5.html#session-3-recap",
    "title": "Machine Learning",
    "section": "Session 3 recap",
    "text": "Session 3 recap\n\nPassing tests + clean linting is part of “shipping”\nMake your repo easy to run from the README\nDon’t commit generated artifacts"
  },
  {
    "objectID": "W3_ML/D5.html#minutes-2",
    "href": "W3_ML/D5.html#minutes-2",
    "title": "Machine Learning",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: start Hands-on Task 1 and don’t stop until the checklist is green."
  },
  {
    "objectID": "W3_ML/D5.html#hands-on-success-criteria-today",
    "href": "W3_ML/D5.html#hands-on-success-criteria-today",
    "title": "Machine Learning",
    "section": "Hands-on success criteria (today)",
    "text": "Hands-on success criteria (today)\nMinimum ✅ - reports/model_card.md complete (no blanks) - reports/eval_summary.md complete (baseline vs model) - uv run pytest passes - uv run ruff check . passes - pushed to GitHub (public)\nOptional ⭐ - add confidence intervals to the write-up (if available) - add 1 small error slice (metrics by a segment column)"
  },
  {
    "objectID": "W3_ML/D5.html#project-layout-what-you-touch-today",
    "href": "W3_ML/D5.html#project-layout-what-you-touch-today",
    "title": "Machine Learning",
    "section": "Project layout (what you touch today)",
    "text": "Project layout (what you touch today)\nweek3-ml-baseline-system/\n  reports/                 # you edit these\n  src/                     # you edit only if tests fail\n  tests/                   # run to verify\n  models/runs/             # generated (don’t commit)\n  outputs/                 # generated (don’t commit)"
  },
  {
    "objectID": "W3_ML/D5.html#task-1-locate-your-latest-run-10-minutes",
    "href": "W3_ML/D5.html#task-1-locate-your-latest-run-10-minutes",
    "title": "Machine Learning",
    "section": "Task 1 — Locate your latest run (10 minutes)",
    "text": "Task 1 — Locate your latest run (10 minutes)\n\nRead models/registry/latest.txt\nOpen the run folder under models/runs/&lt;run_id&gt;/\nIdentify:\n\nbaseline_holdout.json\nholdout_metrics.json\n\n\nCheckpoint: you can open both JSON files."
  },
  {
    "objectID": "W3_ML/D5.html#solution-task-1",
    "href": "W3_ML/D5.html#solution-task-1",
    "title": "Machine Learning",
    "section": "Solution (Task 1)",
    "text": "Solution (Task 1)\nmacOS/Linux\nrun_id=$(cat models/registry/latest.txt)\nls models/runs/$run_id/metrics\npython -m json.tool models/runs/$run_id/metrics/baseline_holdout.json\npython -m json.tool models/runs/$run_id/metrics/holdout_metrics.json\nWindows PowerShell\n$run_id = Get-Content models/registry/latest.txt\nls \"models/runs/$run_id/metrics\"\npython -m json.tool \"models/runs/$run_id/metrics/baseline_holdout.json\"\npython -m json.tool \"models/runs/$run_id/metrics/holdout_metrics.json\""
  },
  {
    "objectID": "W3_ML/D5.html#task-2-fill-reportseval_summary.md-25-minutes",
    "href": "W3_ML/D5.html#task-2-fill-reportseval_summary.md-25-minutes",
    "title": "Machine Learning",
    "section": "Task 2 — Fill reports/eval_summary.md (25 minutes)",
    "text": "Task 2 — Fill reports/eval_summary.md (25 minutes)\n\nDescribe what you trained (model family + preprocessing)\nPaste baseline vs model metrics (holdout)\nDo light error analysis:\n\nopen tables/holdout_predictions.*\nidentify 2–3 mistakes and a pattern\n\nFinish with a recommendation: ship or not?\n\nCheckpoint: your summary includes numbers and a recommendation."
  },
  {
    "objectID": "W3_ML/D5.html#hint-quick-error-analysis-without-fancy-tools",
    "href": "W3_ML/D5.html#hint-quick-error-analysis-without-fancy-tools",
    "title": "Machine Learning",
    "section": "Hint: quick error analysis without fancy tools",
    "text": "Hint: quick error analysis without fancy tools\n\nClassification:\n\nsort by score and look at wrong predictions\nfind false positives (pred=1, y=0) and false negatives (pred=0, y=1)\n\nRegression:\n\ncompute absolute error: abs(pred - y) and sort\n\n\n\nYou can do this in a quick notebook, or export a small CSV sample and inspect it."
  },
  {
    "objectID": "W3_ML/D5.html#solution-task-2-what-complete-looks-like",
    "href": "W3_ML/D5.html#solution-task-2-what-complete-looks-like",
    "title": "Machine Learning",
    "section": "Solution (Task 2: what “complete” looks like)",
    "text": "Solution (Task 2: what “complete” looks like)\nIn reports/eval_summary.md you have:\n\nBaseline metrics: e.g., F1 = ___\nHoldout metrics: e.g., F1 = , ROC-AUC = \nWorst cases: 3 bullets\nNext fixes: 2 bullets\nRecommendation: 1–2 sentences"
  },
  {
    "objectID": "W3_ML/D5.html#task-3-fill-reportsmodel_card.md-30-minutes",
    "href": "W3_ML/D5.html#task-3-fill-reportsmodel_card.md-30-minutes",
    "title": "Machine Learning",
    "section": "Task 3 — Fill reports/model_card.md (30 minutes)",
    "text": "Task 3 — Fill reports/model_card.md (30 minutes)\n\nEnsure the data contract is explicit:\n\ntarget, unit of analysis\nrequired features + optional IDs\nforbidden columns (target + leakage)\n\nAdd the run_id you’re reporting\nAdd “how to run” commands (train + predict)\n\nCheckpoint: a teammate can run your commands without asking you questions."
  },
  {
    "objectID": "W3_ML/D5.html#model-card-template-final",
    "href": "W3_ML/D5.html#model-card-template-final",
    "title": "Machine Learning",
    "section": "Model card template (final)",
    "text": "Model card template (final)\n# Model Card — Week 3 Baseline\n\n## 1) What is the prediction?\n- **Target (y):** `__________`\n- **Unit of analysis:** one row = __________\n- **Decision supported:** __________\n\n## 2) Data contract (inference)\n- **ID passthrough columns:** __________\n- **Required feature columns (X):** __________\n- **Forbidden columns:** `__________` (target + leakage)\n\n## 3) Training recipe\n- **Split strategy:** random holdout (test_size=___, seed=___)\n- **Baseline:** Dummy (most_frequent / mean)\n- **Model family:** __________ (pipeline: preprocessing + estimator)\n\n## 4) Results (holdout)\n- **Baseline:** __________\n- **Model:** __________\n\n## 5) Limitations + failure modes\n- …\n- …\n- …\n\n## 6) How to run\n```bash\nuv run ml-baseline train --target __________\nuv run ml-baseline predict --run latest --input &lt;file&gt; --output outputs/preds.csv\n```"
  },
  {
    "objectID": "W3_ML/D5.html#task-4-run-the-quality-gate-15-minutes",
    "href": "W3_ML/D5.html#task-4-run-the-quality-gate-15-minutes",
    "title": "Machine Learning",
    "section": "Task 4 — Run the quality gate (15 minutes)",
    "text": "Task 4 — Run the quality gate (15 minutes)\n\nInstall dev tools if needed: uv sync --extra dev\nRun:\n\nuv run ruff check .\nuv run pytest\n\n\nCheckpoint: both commands exit with code 0."
  },
  {
    "objectID": "W3_ML/D5.html#solution-task-4",
    "href": "W3_ML/D5.html#solution-task-4",
    "title": "Machine Learning",
    "section": "Solution (Task 4)",
    "text": "Solution (Task 4)\nmacOS/Linux\nuv sync --extra dev\nuv run ruff check .\nuv run pytest\nWindows PowerShell\nuv sync --extra dev\nuv run ruff check .\nuv run pytest\n\n\n\n\n\n\nTip\n\n\nIf you used ruff format ., re-run tests after formatting."
  },
  {
    "objectID": "W3_ML/D5.html#task-5-git-checkpoint-submit-10-minutes",
    "href": "W3_ML/D5.html#task-5-git-checkpoint-submit-10-minutes",
    "title": "Machine Learning",
    "section": "Task 5 — Git checkpoint + submit (10 minutes)",
    "text": "Task 5 — Git checkpoint + submit (10 minutes)\n\ngit status\nCommit your report updates\nPush to GitHub\n\nCheckpoint: your latest commit is visible online."
  },
  {
    "objectID": "W3_ML/D5.html#solution-task-5",
    "href": "W3_ML/D5.html#solution-task-5",
    "title": "Machine Learning",
    "section": "Solution (Task 5)",
    "text": "Solution (Task 5)\ngit status\ngit add reports/model_card.md reports/eval_summary.md\ngit commit -m \"w3d5: finalize reports + submission\"\ngit push\n\n\n\n\n\n\nWarning\n\n\nDo not commit models/runs/ or outputs/."
  },
  {
    "objectID": "W3_ML/D5.html#debug-playbook-submission-blockers",
    "href": "W3_ML/D5.html#debug-playbook-submission-blockers",
    "title": "Machine Learning",
    "section": "Debug playbook (submission blockers)",
    "text": "Debug playbook (submission blockers)\nIf something fails:\n\nruff not found → uv sync --extra dev\ntests fail → read assertion; it usually names the missing file\npredict errors → compare input columns to schema/input_schema.json\npath issues → confirm you run from repo root (where pyproject.toml is)"
  },
  {
    "objectID": "W3_ML/D5.html#stretch-goals-optional",
    "href": "W3_ML/D5.html#stretch-goals-optional",
    "title": "Machine Learning",
    "section": "Stretch goals (optional)",
    "text": "Stretch goals (optional)\n⭐ If your minimum is done:\n\nadd 1 “slice” metric (e.g., performance by country)\ntry --threshold-strategy max_f1 (classification) and report the chosen threshold\nadd a small Plotly confusion matrix or error histogram (optional extra)"
  },
  {
    "objectID": "W3_ML/D5.html#exit-ticket",
    "href": "W3_ML/D5.html#exit-ticket",
    "title": "Machine Learning",
    "section": "Exit Ticket",
    "text": "Exit Ticket\nIn 1–2 sentences:\n\nWhat is the single most important limitation of your model?\nIf a teammate runs predict with a missing column, what should happen?\nWould you ship this baseline today? Why/why not?"
  },
  {
    "objectID": "W3_ML/D5.html#what-to-do-after-class-day-5-submission",
    "href": "W3_ML/D5.html#what-to-do-after-class-day-5-submission",
    "title": "Machine Learning",
    "section": "What to do after class (Day 5 submission)",
    "text": "What to do after class (Day 5 submission)\nDue: today (Jan 1, 2026)\n\nPush your final repo to GitHub (public)\nVerify these files are present and updated:\n\nreports/model_card.md\nreports/eval_summary.md\n\nVerify:\n\nuv run pytest\nuv run ruff check .\n\n\nDeliverable: GitHub repo link.\n\n\n\n\n\n\nTip\n\n\nBefore you submit, clone your repo into a new folder and run the quickstart commands. If it works there, it will grade well."
  },
  {
    "objectID": "W3_ML/D3.html#announcements-admin",
    "href": "W3_ML/D3.html#announcements-admin",
    "title": "Machine Learning",
    "section": "Announcements / admin",
    "text": "Announcements / admin\n\nToday we make your training run debuggable:\n\nnot just “it ran”\nbut “we can inspect mistakes and trust the metrics”\n\nTomorrow (Day 4) depends on today: predict will use your input schema\nDon’t commit generated artifacts:\n\nmodels/runs/, data/processed/, outputs/ should stay gitignored\n\n\n\n\n\n\n\n\nNote\n\n\nKeep reports/eval_summary.md open — you’ll update it with baseline vs model results."
  },
  {
    "objectID": "W3_ML/D3.html#todays-flow",
    "href": "W3_ML/D3.html#todays-flow",
    "title": "Machine Learning",
    "section": "Today’s Flow",
    "text": "Today’s Flow\n\nSession 1 (60m): Holdout metrics you can trust\nAsr Prayer (20m)\nSession 2 (60m): Save the rows (holdout predictions + holdout input)\nMaghrib Prayer (20m)\nSession 3 (60m): Input schema contract (for Day 4 predict)\nIsha Prayer (20m)\nHands-on (120m): Implement/verify artifacts + update eval summary + Git push"
  },
  {
    "objectID": "W3_ML/D3.html#learning-objectives",
    "href": "W3_ML/D3.html#learning-objectives",
    "title": "Machine Learning",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of today, you can:\n\nExplain the difference between baseline metrics and model metrics\nRead holdout_metrics.json and say what it means in plain English\nUse holdout_predictions.csv to find false positives / false negatives\nExplain why we save holdout_input.csv (inference-shaped input)\nCreate and save schema/input_schema.json from training data\nUpdate reports/eval_summary.md with baseline vs model comparison"
  },
  {
    "objectID": "W3_ML/D3.html#warm-up-5-minutes",
    "href": "W3_ML/D3.html#warm-up-5-minutes",
    "title": "Machine Learning",
    "section": "Warm-up (5 minutes)",
    "text": "Warm-up (5 minutes)\nRun yesterday’s training and find your latest run folder.\nmacOS/Linux\nuv run ml-baseline make-sample-data\nuv run ml-baseline train --target is_high_value\ncat models/registry/latest.txt\nls models/runs/$(cat models/registry/latest.txt)\nWindows PowerShell\nuv run ml-baseline make-sample-data\nuv run ml-baseline train --target is_high_value\ntype models/registry/latest.txt\nls models/runs/$(Get-Content models/registry/latest.txt)\nCheckpoint: latest run exists models/runs/&lt;run_id&gt;/."
  },
  {
    "objectID": "W3_ML/D3.html#where-today-fits-in-the-week-3-loop",
    "href": "W3_ML/D3.html#where-today-fits-in-the-week-3-loop",
    "title": "Machine Learning",
    "section": "Where today fits in the Week 3 loop",
    "text": "Where today fits in the Week 3 loop\nDefine → Split → Baseline → Train → Evaluate→Save → Predict → Report\n\nToday: Evaluate + Save artifacts.\nTomorrow: Predict CLI uses today’s schema + holdout_input."
  },
  {
    "objectID": "W3_ML/D3.html#session-1-objectives",
    "href": "W3_ML/D3.html#session-1-objectives",
    "title": "Machine Learning",
    "section": "Session 1 objectives",
    "text": "Session 1 objectives\n\nDefine “holdout metrics” in 1 sentence\nCompare baseline vs model fairly (same holdout split)\nPick one primary metric to report (don’t chase all numbers)"
  },
  {
    "objectID": "W3_ML/D3.html#why-training-metrics-are-not-enough",
    "href": "W3_ML/D3.html#why-training-metrics-are-not-enough",
    "title": "Machine Learning",
    "section": "Why training metrics are not enough",
    "text": "Why training metrics are not enough\nTraining performance can look great even when the model is useless.\n\nTraining data includes the answers (y)\nThe model can “memorize patterns” that don’t generalize\nWe evaluate on a holdout set to simulate new data\n\n\n\n\n\n\n\nWarning\n\n\nIf your holdout split is wrong (leakage / duplicates / time mix-up), your metrics will lie."
  },
  {
    "objectID": "W3_ML/D3.html#baseline-vs-model-the-only-comparison-that-matters",
    "href": "W3_ML/D3.html#baseline-vs-model-the-only-comparison-that-matters",
    "title": "Machine Learning",
    "section": "Baseline vs model (the only comparison that matters)",
    "text": "Baseline vs model (the only comparison that matters)\nBaseline - a “no-skill” prediction - sets the floor - file: metrics/baseline_holdout.json\nModel - trained pipeline - must beat the baseline - file: metrics/holdout_metrics.json\n\n\n\n\n\n\nTip\n\n\nSame split. Same holdout. Same metric. Only then you can claim improvement."
  },
  {
    "objectID": "W3_ML/D3.html#classification-3-metrics-in-plain-english",
    "href": "W3_ML/D3.html#classification-3-metrics-in-plain-english",
    "title": "Machine Learning",
    "section": "Classification: 3 metrics in plain English",
    "text": "Classification: 3 metrics in plain English\nFor binary classification:\n\nAccuracy: “How often are we correct?”\nPrecision: “When we predict positive, how often are we right?”\nRecall: “Of the true positives, how many did we catch?”\n\n\nF1 combines precision + recall (useful, but pick one primary metric first)."
  },
  {
    "objectID": "W3_ML/D3.html#regression-start-with-mae",
    "href": "W3_ML/D3.html#regression-start-with-mae",
    "title": "Machine Learning",
    "section": "Regression: start with MAE",
    "text": "Regression: start with MAE\nFor regression:\n\nMAE (Mean Absolute Error): average absolute mistake size\n(measured in the same units as the target)\n\n\nRMSE and R² exist — but MAE is the easiest to interpret first."
  },
  {
    "objectID": "W3_ML/D3.html#quick-check",
    "href": "W3_ML/D3.html#quick-check",
    "title": "Machine Learning",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: If false positives are very expensive, which metric do you usually care about more?\n\nAccuracy\n\nPrecision\n\nRecall\n\n\nAnswer: Precision (you want “predicted positive” to be trustworthy)."
  },
  {
    "objectID": "W3_ML/D3.html#micro-exercise-choose-the-primary-metric-6-minutes",
    "href": "W3_ML/D3.html#micro-exercise-choose-the-primary-metric-6-minutes",
    "title": "Machine Learning",
    "section": "Micro-exercise: choose the primary metric (6 minutes)",
    "text": "Micro-exercise: choose the primary metric (6 minutes)\nScenario: we predict high-value customers to give them an expensive benefit.\n\nWhich mistake is more expensive: false positive or false negative?\nPick a primary metric (accuracy / precision / recall).\nWrite 1 sentence: “Primary metric = ___ because ___.”\n\nCheckpoint: you can explain your choice to your partner."
  },
  {
    "objectID": "W3_ML/D3.html#solution-example",
    "href": "W3_ML/D3.html#solution-example",
    "title": "Machine Learning",
    "section": "Solution (example)",
    "text": "Solution (example)\n\nFalse positives are expensive → we waste budget on the wrong customers\nPrimary metric: precision\nSentence example: “Primary metric is precision because a positive prediction triggers an expensive action.”"
  },
  {
    "objectID": "W3_ML/D3.html#what-a-holdout-metrics-file-looks-like",
    "href": "W3_ML/D3.html#what-a-holdout-metrics-file-looks-like",
    "title": "Machine Learning",
    "section": "What a holdout metrics file looks like",
    "text": "What a holdout metrics file looks like\nExample fields (yours may include more):\n{\n  \"accuracy\": 0.82,\n  \"precision\": 0.40,\n  \"recall\": 0.25,\n  \"f1\": 0.31,\n  \"threshold\": 0.50\n}\n\n\n\n\n\n\nTip\n\n\nYou don’t have to “optimize everything.”\nReport your primary metric + 1 supporting metric."
  },
  {
    "objectID": "W3_ML/D3.html#session-1-recap",
    "href": "W3_ML/D3.html#session-1-recap",
    "title": "Machine Learning",
    "section": "Session 1 recap",
    "text": "Session 1 recap\n\nHoldout metrics simulate “new data”\nBaseline vs model is the meaningful comparison\nPick a primary metric based on the decision (FP vs FN cost)"
  },
  {
    "objectID": "W3_ML/D3.html#minutes",
    "href": "W3_ML/D3.html#minutes",
    "title": "Machine Learning",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: be ready to explain your primary metric choice."
  },
  {
    "objectID": "W3_ML/D3.html#session-2-objectives",
    "href": "W3_ML/D3.html#session-2-objectives",
    "title": "Machine Learning",
    "section": "Session 2 objectives",
    "text": "Session 2 objectives\n\nExplain why metrics alone are not enough\nSave holdout_predictions.* (the “debug table”)\nSave holdout_input.* (inference-shaped input for Day 4)"
  },
  {
    "objectID": "W3_ML/D3.html#metrics-hide-the-story-rows-show-it",
    "href": "W3_ML/D3.html#metrics-hide-the-story-rows-show-it",
    "title": "Machine Learning",
    "section": "Metrics hide the story (rows show it)",
    "text": "Metrics hide the story (rows show it)\nA single number can’t tell you:\n\nwhich rows failed\nwhether failures are concentrated in one segment\nif the model is “cheating” using an ID-like feature\n\n\n\n\n\n\n\nTip\n\n\nSaving a predictions table makes debugging possible."
  },
  {
    "objectID": "W3_ML/D3.html#holdout-predictions-table-minimum-columns",
    "href": "W3_ML/D3.html#holdout-predictions-table-minimum-columns",
    "title": "Machine Learning",
    "section": "Holdout predictions table (minimum columns)",
    "text": "Holdout predictions table (minimum columns)\nClassification - optional IDs (passthrough) - score (probability-like) - prediction (0/1 after threshold) - the true target column (for evaluation only)\nRegression - optional IDs (passthrough) - prediction - the true target column (for evaluation only)"
  },
  {
    "objectID": "W3_ML/D3.html#example-holdout_predictions.csv-classification",
    "href": "W3_ML/D3.html#example-holdout_predictions.csv-classification",
    "title": "Machine Learning",
    "section": "Example: holdout_predictions.csv (classification)",
    "text": "Example: holdout_predictions.csv (classification)\n\n\n\nuser_id\nscore\nprediction\nis_high_value\n\n\n\n\nU_001\n0.91\n1\n1\n\n\nU_002\n0.73\n1\n0\n\n\nU_003\n0.12\n0\n0\n\n\nU_004\n0.48\n0\n1\n\n\nU_005\n0.66\n1\n1\n\n\n\n\nU_002 is a false positive. U_004 is a false negative."
  },
  {
    "objectID": "W3_ML/D3.html#micro-exercise-find-the-errors-5-minutes",
    "href": "W3_ML/D3.html#micro-exercise-find-the-errors-5-minutes",
    "title": "Machine Learning",
    "section": "Micro-exercise: find the errors (5 minutes)",
    "text": "Micro-exercise: find the errors (5 minutes)\nUsing the table:\n\nMark all false positives (FP) and false negatives (FN)\nWhich is worse for our scenario: FP or FN?\nOptional: What happens if we increase the threshold from 0.50 to 0.70?\n\nCheckpoint: you can point to 1 FP and 1 FN row."
  },
  {
    "objectID": "W3_ML/D3.html#solution-example-1",
    "href": "W3_ML/D3.html#solution-example-1",
    "title": "Machine Learning",
    "section": "Solution (example)",
    "text": "Solution (example)\n\nFP: prediction=1 and target=0 → U_002\nFN: prediction=0 and target=1 → U_004\nIf we increase threshold to 0.70:\n\nfewer predicted positives → fewer FPs\nbut we might miss more true positives (recall drops) ⭐ optional idea"
  },
  {
    "objectID": "W3_ML/D3.html#why-we-save-holdout_input.",
    "href": "W3_ML/D3.html#why-we-save-holdout_input.",
    "title": "Machine Learning",
    "section": "Why we save holdout_input.*",
    "text": "Why we save holdout_input.*\nholdout_input is the holdout set without the target.\nWe save it because:\n\nit has the same shape as real inference input\ntomorrow we will run: ml-baseline predict on it\nit helps detect training/inference mismatches (skew checks later)\n\n\n\n\n\n\n\nWarning\n\n\nNever include the target column inside holdout_input."
  },
  {
    "objectID": "W3_ML/D3.html#run_meta.json-one-file-to-explain-the-run",
    "href": "W3_ML/D3.html#run_meta.json-one-file-to-explain-the-run",
    "title": "Machine Learning",
    "section": "run_meta.json (one file to explain the run)",
    "text": "run_meta.json (one file to explain the run)\nThis is a small “receipt” for your run:\n\nwhich dataset file was used (path + hash)\nwhat config was used (seed, split strategy, target)\nbaseline + model metrics\nwhere artifacts are stored inside the run folder\n\n\nYou don’t need to overthink it. You just need the habit: every run is explainable."
  },
  {
    "objectID": "W3_ML/D3.html#quick-check-1",
    "href": "W3_ML/D3.html#quick-check-1",
    "title": "Machine Learning",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: Why do we save holdout_input separately?\n\nAnswer: It’s inference-shaped input we can reuse to test prediction (and later check for skew)."
  },
  {
    "objectID": "W3_ML/D3.html#session-2-recap",
    "href": "W3_ML/D3.html#session-2-recap",
    "title": "Machine Learning",
    "section": "Session 2 recap",
    "text": "Session 2 recap\n\nSave rows, not just numbers: holdout_predictions enables debugging\nSave inference-shaped input: holdout_input enables reliable prediction testing\nStore a run receipt: run_meta.json"
  },
  {
    "objectID": "W3_ML/D3.html#minutes-1",
    "href": "W3_ML/D3.html#minutes-1",
    "title": "Machine Learning",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: open your latest run folder and inspect tables/."
  },
  {
    "objectID": "W3_ML/D3.html#session-3-objectives",
    "href": "W3_ML/D3.html#session-3-objectives",
    "title": "Machine Learning",
    "section": "Session 3 objectives",
    "text": "Session 3 objectives\n\nDefine an input schema in plain English\nSave schema/input_schema.json\nUnderstand the 2 failure modes it prevents:\n\nforbidden columns\nmissing required columns"
  },
  {
    "objectID": "W3_ML/D3.html#prediction-needs-a-contract",
    "href": "W3_ML/D3.html#prediction-needs-a-contract",
    "title": "Machine Learning",
    "section": "Prediction needs a contract",
    "text": "Prediction needs a contract\nReal life problem:\n\na teammate sends a CSV with a missing column\nor a column is renamed (age_years vs age)\nor the target accidentally appears in inference input\n\nWithout a contract, prediction becomes “guess and pray”.\n\n\n\n\n\n\nTip\n\n\nYour schema is a machine-checkable version of your dataset contract from Day 1."
  },
  {
    "objectID": "W3_ML/D3.html#what-goes-into-input_schema.json",
    "href": "W3_ML/D3.html#what-goes-into-input_schema.json",
    "title": "Machine Learning",
    "section": "What goes into input_schema.json",
    "text": "What goes into input_schema.json\nMinimum fields:\n\nrequired_feature_columns (exact list, ordered)\nfeature_dtypes (basic numeric vs text handling)\noptional_id_columns (passthrough if present)\nforbidden_columns (usually the target)"
  },
  {
    "objectID": "W3_ML/D3.html#example-input_schema.json",
    "href": "W3_ML/D3.html#example-input_schema.json",
    "title": "Machine Learning",
    "section": "Example: input_schema.json",
    "text": "Example: input_schema.json\n{\n  \"required_feature_columns\": [\"age\", \"country\", \"avg_spend_30d\"],\n  \"optional_id_columns\": [\"user_id\"],\n  \"forbidden_columns\": [\"is_high_value\"]\n}\n\nThe actual file can include dtype hints too — that’s OK."
  },
  {
    "objectID": "W3_ML/D3.html#micro-exercise-map-your-model-card-schema-6-minutes",
    "href": "W3_ML/D3.html#micro-exercise-map-your-model-card-schema-6-minutes",
    "title": "Machine Learning",
    "section": "Micro-exercise: map your model card → schema (6 minutes)",
    "text": "Micro-exercise: map your model card → schema (6 minutes)\nOpen your reports/model_card.md and write down:\n\nYour target column (forbidden at inference)\n1–2 optional ID columns (passthrough)\nYour required features (X)\n\nCheckpoint: you can say: “My inference input must include ___ and must not include ___.”"
  },
  {
    "objectID": "W3_ML/D3.html#solution-example-2",
    "href": "W3_ML/D3.html#solution-example-2",
    "title": "Machine Learning",
    "section": "Solution (example)",
    "text": "Solution (example)\n\nForbidden: target column (e.g., is_high_value)\nOptional IDs: user_id\nRequired features: everything else used by the model (age, country, avg_spend_30d, …)"
  },
  {
    "objectID": "W3_ML/D3.html#what-should-happen-when-schema-validation-fails",
    "href": "W3_ML/D3.html#what-should-happen-when-schema-validation-fails",
    "title": "Machine Learning",
    "section": "What should happen when schema validation fails?",
    "text": "What should happen when schema validation fails?\nTwo good failures:\n\nForbidden columns present (leakage risk)\nMissing required columns (model can’t run correctly)\n\n\n\n\n\n\n\nWarning\n\n\nFail fast with a clear error message. Silent fixes create silent bugs."
  },
  {
    "objectID": "W3_ML/D3.html#quick-check-2",
    "href": "W3_ML/D3.html#quick-check-2",
    "title": "Machine Learning",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: Is it okay if the target column appears in the input to predict?\n\nAnswer: No. It is a forbidden column for inference."
  },
  {
    "objectID": "W3_ML/D3.html#session-3-recap",
    "href": "W3_ML/D3.html#session-3-recap",
    "title": "Machine Learning",
    "section": "Session 3 recap",
    "text": "Session 3 recap\n\nSchema = enforceable dataset contract\nRequired features must exist; forbidden columns must not\nSaving schema today makes Day 4 prediction reliable"
  },
  {
    "objectID": "W3_ML/D3.html#minutes-2",
    "href": "W3_ML/D3.html#minutes-2",
    "title": "Machine Learning",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: start Hands-on Task 1 immediately."
  },
  {
    "objectID": "W3_ML/D3.html#hands-on-success-criteria-today",
    "href": "W3_ML/D3.html#hands-on-success-criteria-today",
    "title": "Machine Learning",
    "section": "Hands-on success criteria (today)",
    "text": "Hands-on success criteria (today)\n\nAfter ml-baseline train, your latest run has:\n\nmetrics/baseline_holdout.json\nmetrics/holdout_metrics.json\ntables/holdout_predictions.&lt;csv|parquet&gt;\ntables/holdout_input.&lt;csv|parquet&gt;\nschema/input_schema.json\nrun_meta.json\n\nYou can explain each artifact in one sentence\nYou updated reports/eval_summary.md with baseline vs model comparison\n1+ commit pushed to GitHub\n\nOptional ⭐\n\nImplement threshold selection strategy max_f1 (classification only)\nAdd a small error slice in eval_summary.md (e.g., performance by country)"
  },
  {
    "objectID": "W3_ML/D3.html#project-touch-points-day-3",
    "href": "W3_ML/D3.html#project-touch-points-day-3",
    "title": "Machine Learning",
    "section": "Project touch points (Day 3)",
    "text": "Project touch points (Day 3)\nsrc/ml_baseline/\n  train.py       # compute + save metrics/tables/schema\n  metrics.py     # metric helpers\n  schema.py      # schema contract\n  io.py          # read/write CSV/Parquet\nmodels/runs/&lt;run_id&gt;/\n  metrics/\n  tables/\n  schema/\n  run_meta.json\nreports/\n  eval_summary.md"
  },
  {
    "objectID": "W3_ML/D3.html#task-1-run-train-and-inspect-artifacts-15-minutes",
    "href": "W3_ML/D3.html#task-1-run-train-and-inspect-artifacts-15-minutes",
    "title": "Machine Learning",
    "section": "Task 1 — Run train and inspect artifacts (15 minutes)",
    "text": "Task 1 — Run train and inspect artifacts (15 minutes)\n\nTrain (or retrain) on your target\nLocate the latest run folder\nInspect metrics/ and tables/\n\nmacOS/Linux\nuv run ml-baseline train --target is_high_value\nrun_id=$(cat models/registry/latest.txt)\nls models/runs/$run_id/metrics\nls models/runs/$run_id/tables\nWindows PowerShell\nuv run ml-baseline train --target is_high_value\n$run_id = Get-Content models/registry/latest.txt\nls models/runs/$run_id/metrics\nls models/runs/$run_id/tables\nCheckpoint: you can see holdout_metrics.json or you know it’s missing and needs implementation."
  },
  {
    "objectID": "W3_ML/D3.html#solution-what-good-looks-like",
    "href": "W3_ML/D3.html#solution-what-good-looks-like",
    "title": "Machine Learning",
    "section": "Solution — what “good” looks like",
    "text": "Solution — what “good” looks like\nmodels/runs/&lt;run_id&gt;/\n  metrics/\n    baseline_holdout.json\n    holdout_metrics.json\n  tables/\n    holdout_input.csv\n    holdout_predictions.csv\n  schema/\n    input_schema.json\n  run_meta.json\n\nExtensions may be .parquet instead of .csv depending on your setup."
  },
  {
    "objectID": "W3_ML/D3.html#task-2-save-holdout-metrics-20-minutes",
    "href": "W3_ML/D3.html#task-2-save-holdout-metrics-20-minutes",
    "title": "Machine Learning",
    "section": "Task 2 — Save holdout metrics (20 minutes)",
    "text": "Task 2 — Save holdout metrics (20 minutes)\nIf holdout_metrics.json is missing:\n\nIn src/ml_baseline/train.py, after pipe.fit(...), predict on X_test\nCompute metrics\nSave JSON to run_dir/metrics/holdout_metrics.json\n\nCheckpoint: file exists and contains your primary metric."
  },
  {
    "objectID": "W3_ML/D3.html#solution-example-snippet",
    "href": "W3_ML/D3.html#solution-example-snippet",
    "title": "Machine Learning",
    "section": "Solution (example snippet)",
    "text": "Solution (example snippet)\n# after: pipe.fit(X_train, y_train)\n\nif cfg.task == \"classification\":\n    proba = pipe.predict_proba(X_test)\n    y_score = proba[:, 1] if proba.shape[1] &gt; 1 else proba[:, 0]\n    y_true = np.asarray(y_test).astype(int)\n    metrics = classification_metrics(y_true, y_score, threshold=0.5)\nelse:\n    y_pred = pipe.predict(X_test)\n    y_true = np.asarray(y_test).astype(float)\n    metrics = regression_metrics(y_true, y_pred)\n\n(run_dir / \"metrics\" / \"holdout_metrics.json\").write_text(\n    json.dumps(metrics, indent=2) + \"\\n\", encoding=\"utf-8\"\n)"
  },
  {
    "objectID": "W3_ML/D3.html#task-3-save-holdout_predictions-15-minutes",
    "href": "W3_ML/D3.html#task-3-save-holdout_predictions-15-minutes",
    "title": "Machine Learning",
    "section": "Task 3 — Save holdout_predictions (15 minutes)",
    "text": "Task 3 — Save holdout_predictions (15 minutes)\n\nCreate a predictions DataFrame\nAdd optional ID columns (passthrough)\nAdd the true target column (for evaluation)\nSave to run_dir/tables/holdout_predictions.&lt;ext&gt;\n\nCheckpoint: you can open the file and see prediction (and score if classification)."
  },
  {
    "objectID": "W3_ML/D3.html#solution-example-snippet-p",
    "href": "W3_ML/D3.html#solution-example-snippet-p",
    "title": "Machine Learning",
    "section": "Solution (example snippet) P",
    "text": "Solution (example snippet) P\n# continuing from Task 2 variables: preds, y_true\n\nif id_cols_present:\n    preds = pd.concat(\n        [\n            test_df[id_cols_present].reset_index(drop=True),\n            preds.reset_index(drop=True),\n        ],\n        axis=1,\n    )\n\npreds[cfg.target] = y_true\nwrite_tabular(preds, run_dir / \"tables\" / f\"holdout_predictions{ext}\")"
  },
  {
    "objectID": "W3_ML/D3.html#task-4-save-holdout_input-10-minutes",
    "href": "W3_ML/D3.html#task-4-save-holdout_input-10-minutes",
    "title": "Machine Learning",
    "section": "Task 4 — Save holdout_input (10 minutes)",
    "text": "Task 4 — Save holdout_input (10 minutes)\n\nStart from X_test (features-only)\nAdd optional ID columns (passthrough)\nSave to run_dir/tables/holdout_input.&lt;ext&gt;\n\nCheckpoint: holdout_input contains no target column."
  },
  {
    "objectID": "W3_ML/D3.html#solution-example-snippet-1",
    "href": "W3_ML/D3.html#solution-example-snippet-1",
    "title": "Machine Learning",
    "section": "Solution (example snippet)",
    "text": "Solution (example snippet)\nholdout_input = X_test.copy()\n\nif id_cols_present:\n    holdout_input = pd.concat(\n        [\n            test_df[id_cols_present].reset_index(drop=True),\n            holdout_input.reset_index(drop=True),\n        ],\n        axis=1,\n    )\n\nwrite_tabular(holdout_input, run_dir / \"tables\" / f\"holdout_input{ext}\")"
  },
  {
    "objectID": "W3_ML/D3.html#task-5-save-the-input-schema-10-minutes",
    "href": "W3_ML/D3.html#task-5-save-the-input-schema-10-minutes",
    "title": "Machine Learning",
    "section": "Task 5 — Save the input schema (10 minutes)",
    "text": "Task 5 — Save the input schema (10 minutes)\n\nBuild schema from your training dataframe\nSave to run_dir/schema/input_schema.json\n\nCheckpoint: the schema lists required features + forbidden target."
  },
  {
    "objectID": "W3_ML/D3.html#solution-example-snippet-2",
    "href": "W3_ML/D3.html#solution-example-snippet-2",
    "title": "Machine Learning",
    "section": "Solution (example snippet)",
    "text": "Solution (example snippet)\nschema = InputSchema.from_training_df(\n    train_df, target=cfg.target, id_cols=list(cfg.id_cols)\n)\nschema.dump(run_dir / \"schema\" / \"input_schema.json\")"
  },
  {
    "objectID": "W3_ML/D3.html#task-6-update-reportseval_summary.md-15-minutes",
    "href": "W3_ML/D3.html#task-6-update-reportseval_summary.md-15-minutes",
    "title": "Machine Learning",
    "section": "Task 6 — Update reports/eval_summary.md (15 minutes)",
    "text": "Task 6 — Update reports/eval_summary.md (15 minutes)\nFill in:\n\nDataset + target + unit of analysis (1–2 lines)\nBaseline metrics (from baseline_holdout.json)\nModel metrics (from holdout_metrics.json)\n2–3 caveats / likely failure modes\n\nCheckpoint: your eval summary compares baseline vs model using the same primary metric."
  },
  {
    "objectID": "W3_ML/D3.html#solution-a-simple-eval-summary-structure",
    "href": "W3_ML/D3.html#solution-a-simple-eval-summary-structure",
    "title": "Machine Learning",
    "section": "Solution — a simple eval summary structure",
    "text": "Solution — a simple eval summary structure\n\nRun ID: &lt;run_id&gt;\nPrimary metric: &lt;precision / recall / MAE&gt;\nBaseline: &lt;value&gt;\nModel: &lt;value&gt;\nInterpretation: “Model beats baseline by ___ (absolute)”\nCaveats: leakage risk, class imbalance, small data, etc.\n\n\n\n\n\n\n\nTip\n\n\nKeep it honest. A baseline that is “not great” is still valuable if it’s reproducible and explainable."
  },
  {
    "objectID": "W3_ML/D3.html#git-checkpoint-2-minutes",
    "href": "W3_ML/D3.html#git-checkpoint-2-minutes",
    "title": "Machine Learning",
    "section": "Git checkpoint (2 minutes)",
    "text": "Git checkpoint (2 minutes)\n\ngit status\ncommit with message: \"w3d3: save holdout metrics + artifacts\"\npush to GitHub\n\nCheckpoint: your repo shows the new commit online."
  },
  {
    "objectID": "W3_ML/D3.html#debug-playbook-when-you-get-stuck",
    "href": "W3_ML/D3.html#debug-playbook-when-you-get-stuck",
    "title": "Machine Learning",
    "section": "Debug playbook (when you get stuck)",
    "text": "Debug playbook (when you get stuck)\n\nRe-run the exact command and read the first error line\nConfirm your paths:\n\ndata/processed/features.&lt;csv|parquet&gt;\nmodels/registry/latest.txt\n\nPrint shapes:\n\nX_train.shape, X_test.shape\n\nInspect columns:\n\nX_train.columns.tolist()[:10]\n\nAsk for clarification on the error (not code)\n\n\n\n\n\n\n\nWarning\n\n\nDo not “fix” by deleting random files. Fix by understanding the contract."
  },
  {
    "objectID": "W3_ML/D3.html#stretch-goals-optional",
    "href": "W3_ML/D3.html#stretch-goals-optional",
    "title": "Machine Learning",
    "section": "Stretch goals (optional ⭐)",
    "text": "Stretch goals (optional ⭐)\n\nClassification: implement threshold selection (max_f1) and record chosen threshold\nAdd a small “error slice” table in eval_summary.md\nAdd a bootstrap CI for one metric (advanced)"
  },
  {
    "objectID": "W3_ML/D3.html#exit-ticket",
    "href": "W3_ML/D3.html#exit-ticket",
    "title": "Machine Learning",
    "section": "Exit Ticket",
    "text": "Exit Ticket\nIn 1–2 sentences each:\n\nWhy do we save holdout_predictions instead of only saving metrics?\nWhat is the purpose of input_schema.json?\nWhat comparison makes a model improvement claim meaningful?"
  },
  {
    "objectID": "W3_ML/D3.html#what-to-do-after-class-day-3-assignment",
    "href": "W3_ML/D3.html#what-to-do-after-class-day-3-assignment",
    "title": "Machine Learning",
    "section": "What to do after class (Day 3 assignment)",
    "text": "What to do after class (Day 3 assignment)\nDue: before Day 4 (Dec 31, 2025)\n\nEnsure train creates today’s artifacts on your dataset:\n\n\n\n\nholdout_metrics.json\nholdout_predictions.*\n\n\n\nholdout_input.*\nschema/input_schema.json\n\n\n\nIn holdout_predictions, identify:\n\n2 false positives and 2 false negatives (or 4 large errors for regression)\n\nAdd one paragraph to reports/eval_summary.md:\n\n“Most common failure pattern I observed was: ___”\n\nCommit + push\n\nDeliverable: GitHub repo link + latest run_id.\n\n\n\n\n\n\nTip\n\n\nTomorrow you will run predict on holdout_input. If holdout_input or schema is wrong, Day 4 will hurt."
  },
  {
    "objectID": "W3_ML/D1.html#genai-policy-reminder-week-3",
    "href": "W3_ML/D1.html#genai-policy-reminder-week-3",
    "title": "Machine Learning",
    "section": "GenAI policy reminder (Week 3)",
    "text": "GenAI policy reminder (Week 3)\nYou may use Generative AI only for clarifying questions.\n\n✅ Allowed: definitions, “what does this error mean?”, reading docs, concept explanations\n❌ Not allowed: generating your solution code, debugging by copy‑paste, writing full functions\n\n\n\n\n\n\n\nWarning\n\n\nThis week is a graded repo. If GenAI writes your training/predict code, you will not build the skill."
  },
  {
    "objectID": "W3_ML/D1.html#announcements-admin",
    "href": "W3_ML/D1.html#announcements-admin",
    "title": "Machine Learning",
    "section": "Announcements / admin",
    "text": "Announcements / admin\n\nThis week you will ship a baseline ML system (train + evaluate + batch predict)\nOffline-first: your repo must run without internet\nDaily habit: commit + push (at least 1 commit/day)\nHidden tests reward: determinism (seeded) + helpful failures (clear errors)\n\n\n\n\n\n\n\nNote\n\n\nCapstone teams + project ideas are finalized by end of Week 5 (Jan 15, 2026)."
  },
  {
    "objectID": "W3_ML/D1.html#todays-flow",
    "href": "W3_ML/D1.html#todays-flow",
    "title": "Machine Learning",
    "section": "Today’s Flow",
    "text": "Today’s Flow\n\nSession 1 (60m): ML in one picture (supervised learning basics)\nAsr Prayer (20m)\nSession 2 (60m): From feature table → dataset contract (X/y, IDs, leakage)\nMaghrib Prayer (20m)\nSession 3 (60m): Repo + CLI orientation (what you will run all week)\nIsha Prayer (20m)\nHands-on (120m): Generate sample data + draft your model card + Git push"
  },
  {
    "objectID": "W3_ML/D1.html#learning-objectives",
    "href": "W3_ML/D1.html#learning-objectives",
    "title": "Machine Learning",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of today, you can:\n\nExplain supervised learning in 1 sentence\nDistinguish training vs inference (what columns are available)\nIdentify features vs target vs ID columns in a table\nRun ml-baseline --help and ml-baseline make-sample-data\nCreate reports/model_card.md with a draft dataset contract"
  },
  {
    "objectID": "W3_ML/D1.html#warm-up-connect-week-2-week-3-5-minutes",
    "href": "W3_ML/D1.html#warm-up-connect-week-2-week-3-5-minutes",
    "title": "Machine Learning",
    "section": "Warm-up: connect Week 2 → Week 3 (5 minutes)",
    "text": "Warm-up: connect Week 2 → Week 3 (5 minutes)\nIn pairs, answer:\n\nIn Week 2, what did “one row” represent in your feature table?\nName one ID column you would keep to join predictions back.\nWhere should a feature table live in a repo?\n\nCheckpoint: you can say “one row = ”, “ID = ”, “path = data/processed/...”."
  },
  {
    "objectID": "W3_ML/D1.html#week-3-project-in-plain-english",
    "href": "W3_ML/D1.html#week-3-project-in-plain-english",
    "title": "Machine Learning",
    "section": "Week 3 project (in plain English)",
    "text": "Week 3 project (in plain English)\nBy Friday, your repo can:\n\nread a feature table from data/processed/features.&lt;csv|parquet&gt;\ntrain a baseline model and save a run folder under models/runs/&lt;run_id&gt;/\nbatch predict on a new file and write outputs/preds.csv\nexplain what you did in reports/model_card.md + reports/eval_summary.md\n\n\nToday we only build the foundation: ML basics + dataset contract + “hello CLI”."
  },
  {
    "objectID": "W3_ML/D1.html#end-state-demo-what-youll-run-later-this-week",
    "href": "W3_ML/D1.html#end-state-demo-what-youll-run-later-this-week",
    "title": "Machine Learning",
    "section": "End-state demo (what you’ll run later this week)",
    "text": "End-state demo (what you’ll run later this week)\nTrain\nuv run ml-baseline train --target is_high_value\nPredict\nuv run ml-baseline predict --run latest \\\n  --input data/processed/features.csv \\\n  --output outputs/preds.csv\n\n\n\n\n\n\nNote\n\n\nDon’t worry about the options yet. This week is: define → split → baseline → train → evaluate → save → predict → report."
  },
  {
    "objectID": "W3_ML/D1.html#session-1-objectives",
    "href": "W3_ML/D1.html#session-1-objectives",
    "title": "Machine Learning",
    "section": "Session 1 objectives",
    "text": "Session 1 objectives\n\nDefine features and target\nExplain the supervised learning loop at a high level\nTell the difference between training time and inference time"
  },
  {
    "objectID": "W3_ML/D1.html#what-is-supervised-machine-learning",
    "href": "W3_ML/D1.html#what-is-supervised-machine-learning",
    "title": "Machine Learning",
    "section": "What is supervised machine learning?",
    "text": "What is supervised machine learning?\nYou have examples where the answer is known.\n\nInput (features): information you have before a decision\nOutput (target): the label/value you want to predict\nA model learns a rule: X → y\n\n\n\n\n\n\n\nTip\n\n\nIn this bootcamp, “ML” means: “turn a table into a reliable prediction pipeline.”"
  },
  {
    "objectID": "W3_ML/D1.html#one-picture-the-supervised-learning-loop",
    "href": "W3_ML/D1.html#one-picture-the-supervised-learning-loop",
    "title": "Machine Learning",
    "section": "One picture: the supervised learning loop",
    "text": "One picture: the supervised learning loop\nFeature table (X + y)\n   |\n   | split (simulate “new data”)\n   v\nTrain split  ──&gt; fit model ──&gt; save model artifacts\nHoldout split ─&gt; evaluate  ──&gt; metrics + tables\n\nNew file (X only) ─&gt; load model ─&gt; predict ─&gt; preds.csv\n\nToday: we focus on understanding the pieces (not the math)."
  },
  {
    "objectID": "W3_ML/D1.html#features-vs-target-x-vs-y",
    "href": "W3_ML/D1.html#features-vs-target-x-vs-y",
    "title": "Machine Learning",
    "section": "Features vs target (X vs y)",
    "text": "Features vs target (X vs y)\nRemember\n\nX (features): what you know at prediction time\ny (target): what you want the model to output\nYou must decide this before training\n\nExample table\n\n\n\nuser_id\ncountry\nn_orders\ntotal_amount\nis_high_value\n\n\n\n\nu001\nUS\n8\n92.0\n1\n\n\nu002\nGB\n2\n18.5\n0\n\n\nu003\nCA\n5\n63.2\n0"
  },
  {
    "objectID": "W3_ML/D1.html#classification-vs-regression-quick-intuition",
    "href": "W3_ML/D1.html#classification-vs-regression-quick-intuition",
    "title": "Machine Learning",
    "section": "Classification vs regression (quick intuition)",
    "text": "Classification vs regression (quick intuition)\n\nClassification: predict a category (e.g., 0/1, “spam/not spam”)\nRegression: predict a number (e.g., price, demand)\n\n\n\n\n\n\n\nNote\n\n\nIn the sample data, is_high_value is classification (0 or 1)."
  },
  {
    "objectID": "W3_ML/D1.html#training-vs-inference",
    "href": "W3_ML/D1.html#training-vs-inference",
    "title": "Machine Learning",
    "section": "Training vs inference",
    "text": "Training vs inference\nDuring training:\n\nyou have features + target\nyou can measure “how good” the model is (evaluation)\n\nDuring inference (real use):\n\nyou have features only\nthe model produces predictions\n\n\n\n\n\n\n\nWarning\n\n\nIf your inference file contains the target column, you are probably leaking information."
  },
  {
    "objectID": "W3_ML/D1.html#micro-exercise-label-x-y-and-ids-5-minutes",
    "href": "W3_ML/D1.html#micro-exercise-label-x-y-and-ids-5-minutes",
    "title": "Machine Learning",
    "section": "Micro-exercise: label X, y, and IDs (5 minutes)",
    "text": "Micro-exercise: label X, y, and IDs (5 minutes)\nLook at the table below.\n\n\n\nuser_id\ncountry\nn_orders\ntotal_amount\nis_high_value\n\n\n\n\nu010\nUS\n6\n71.0\n0\n\n\n\n\nWhich column is the target (y)?\nWhich columns are features (X)?\nWhich column is an ID passthrough?\n\nCheckpoint: you can answer in 3 short phrases: “y = …”, “X = …”, “ID = …”."
  },
  {
    "objectID": "W3_ML/D1.html#solution-example",
    "href": "W3_ML/D1.html#solution-example",
    "title": "Machine Learning",
    "section": "Solution (example)",
    "text": "Solution (example)\n\ny (target): is_high_value\nID passthrough: user_id\nX (features): country, n_orders, total_amount\n\n\n(Some projects may include more ID columns, like customer_id, order_id, etc.)"
  },
  {
    "objectID": "W3_ML/D1.html#quick-check",
    "href": "W3_ML/D1.html#quick-check",
    "title": "Machine Learning",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: At inference time, do we have the target column?\n\nAnswer: No. Inference input should be X only (plus optional ID columns)."
  },
  {
    "objectID": "W3_ML/D1.html#session-1-recap",
    "href": "W3_ML/D1.html#session-1-recap",
    "title": "Machine Learning",
    "section": "Session 1 recap",
    "text": "Session 1 recap\n\nSupervised ML learns X → y from labeled examples\nTraining has X + y; inference has X only\nYour first job is to define the problem clearly (target + unit of analysis)"
  },
  {
    "objectID": "W3_ML/D1.html#minutes",
    "href": "W3_ML/D1.html#minutes",
    "title": "Machine Learning",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: be ready to explain your unit of analysis in 1 sentence."
  },
  {
    "objectID": "W3_ML/D1.html#session-2-objectives",
    "href": "W3_ML/D1.html#session-2-objectives",
    "title": "Machine Learning",
    "section": "Session 2 objectives",
    "text": "Session 2 objectives\n\nDefine unit of analysis (what one row means)\nSeparate features vs target vs IDs in a real dataset\nUnderstand leakage as “cheating” and avoid it\nStart a dataset contract in a model card"
  },
  {
    "objectID": "W3_ML/D1.html#what-is-a-feature-table-week-2-recap",
    "href": "W3_ML/D1.html#what-is-a-feature-table-week-2-recap",
    "title": "Machine Learning",
    "section": "What is a feature table? (Week 2 recap)",
    "text": "What is a feature table? (Week 2 recap)\nA feature table is a dataset designed for modeling.\n\nOne row = one prediction\nColumns are “things you know” (features), plus (sometimes) the target\nStored under: data/processed/\n\n\n\n\n\n\n\nTip\n\n\nWeek 3 starts from the feature table. We do not start from raw data."
  },
  {
    "objectID": "W3_ML/D1.html#unit-of-analysis-uoa",
    "href": "W3_ML/D1.html#unit-of-analysis-uoa",
    "title": "Machine Learning",
    "section": "Unit of analysis (UoA)",
    "text": "Unit of analysis (UoA)\nThe unit of analysis answers:\n\n“What does one row represent?”\n\nExamples:\n\none row = one user\none row = one transaction\none row = one day per store\n\n\n\n\n\n\n\nNote\n\n\nIf you change the unit of analysis, you changed the problem."
  },
  {
    "objectID": "W3_ML/D1.html#the-3-column-types-you-must-name",
    "href": "W3_ML/D1.html#the-3-column-types-you-must-name",
    "title": "Machine Learning",
    "section": "The 3 column types you must name",
    "text": "The 3 column types you must name\n\nTarget (y): what you want to predict\nFeatures (X): what the model is allowed to use\nID passthrough: kept for joining predictions back (not used as signal)\n\n\nToday you’ll write these down. Later you’ll enforce them in a schema file."
  },
  {
    "objectID": "W3_ML/D1.html#why-keep-id-columns",
    "href": "W3_ML/D1.html#why-keep-id-columns",
    "title": "Machine Learning",
    "section": "Why keep ID columns?",
    "text": "Why keep ID columns?\nID passthrough columns are useful because:\n\nyou need to join predictions back to real entities\nyou can debug mistakes (“which row was wrong?”)\nyou can group results (later) for error analysis\n\n\n\n\n\n\n\nWarning\n\n\nIDs are often unique. If you train on them directly, models can “memorize” instead of learning."
  },
  {
    "objectID": "W3_ML/D1.html#leakage-cheating-plain-english",
    "href": "W3_ML/D1.html#leakage-cheating-plain-english",
    "title": "Machine Learning",
    "section": "Leakage (cheating) — plain English",
    "text": "Leakage (cheating) — plain English\nLeakage means your features contain information you would not have at prediction time.\n\n“future” information\npost-outcome information\ndirect copies/encodings of the target\n\n\n\n\n\n\n\nTip\n\n\nLeakage can make metrics look amazing… and then fail in real life."
  },
  {
    "objectID": "W3_ML/D1.html#micro-exercise-spot-the-leakage-risk-6-minutes",
    "href": "W3_ML/D1.html#micro-exercise-spot-the-leakage-risk-6-minutes",
    "title": "Machine Learning",
    "section": "Micro-exercise: spot the leakage risk (6 minutes)",
    "text": "Micro-exercise: spot the leakage risk (6 minutes)\nWhich feature is leakage if you’re predicting “will the user be high value next month?”\n\nn_orders_last_30_days\n\ntotal_spend_next_30_days\n\ncountry\n\n\nNow answer: why?\nCheckpoint: you can explain your choice in 1 sentence."
  },
  {
    "objectID": "W3_ML/D1.html#solution-leakage-exercise",
    "href": "W3_ML/D1.html#solution-leakage-exercise",
    "title": "Machine Learning",
    "section": "Solution (leakage exercise)",
    "text": "Solution (leakage exercise)\nB is leakage because it uses information from the future (next 30 days).\n\nA and C could be valid features (they exist before the future happens)"
  },
  {
    "objectID": "W3_ML/D1.html#the-dataset-contract-youll-write-today",
    "href": "W3_ML/D1.html#the-dataset-contract-youll-write-today",
    "title": "Machine Learning",
    "section": "The dataset contract you’ll write today",
    "text": "The dataset contract you’ll write today\nIn reports/model_card.md, write:\n\nUnit of analysis (one row = …)\nTarget name + what it means\nID passthrough columns\nFeatures allowed at inference\nForbidden columns (target + obvious leakage fields)\nA first guess of your primary metric (we’ll refine later)"
  },
  {
    "objectID": "W3_ML/D1.html#quick-check-1",
    "href": "W3_ML/D1.html#quick-check-1",
    "title": "Machine Learning",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: Why do we keep ID columns if we don’t train on them?\n\nAnswer: So we can join predictions back, debug errors, and report results per entity."
  },
  {
    "objectID": "W3_ML/D1.html#session-2-recap",
    "href": "W3_ML/D1.html#session-2-recap",
    "title": "Machine Learning",
    "section": "Session 2 recap",
    "text": "Session 2 recap\n\nA feature table is “one row = one prediction”\nYou must name: target, features, IDs\nLeakage = using information you won’t have at prediction time"
  },
  {
    "objectID": "W3_ML/D1.html#minutes-1",
    "href": "W3_ML/D1.html#minutes-1",
    "title": "Machine Learning",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: open the Week 3 repo and run ml-baseline --help."
  },
  {
    "objectID": "W3_ML/D1.html#session-3-objectives",
    "href": "W3_ML/D1.html#session-3-objectives",
    "title": "Machine Learning",
    "section": "Session 3 objectives",
    "text": "Session 3 objectives\n\nUnderstand the Week 3 repo layout (only the important folders)\nRun the CLI help and generate sample data\nKnow where outputs should be written"
  },
  {
    "objectID": "W3_ML/D1.html#repo-tour-what-matters-this-week",
    "href": "W3_ML/D1.html#repo-tour-what-matters-this-week",
    "title": "Machine Learning",
    "section": "Repo tour (what matters this week)",
    "text": "Repo tour (what matters this week)\nweek3-ml-baseline-system/\n  data/processed/        # your features table lives here\n  src/ml_baseline/       # library + CLI code\n  models/                # saved runs + registry\n  reports/               # model_card.md + eval_summary.md\n  tests/                 # unit tests (visible)"
  },
  {
    "objectID": "W3_ML/D1.html#the-cli-is-your-interface",
    "href": "W3_ML/D1.html#the-cli-is-your-interface",
    "title": "Machine Learning",
    "section": "The CLI is your interface",
    "text": "The CLI is your interface\nWhy we use a CLI:\n\none command = a repeatable action (train / predict)\ngraders (and teammates) can run it exactly\neasier to debug than “mystery notebook state”\n\n\n\n\n\n\n\nTip\n\n\nIf ml-baseline --help works, your project is already more shippable."
  },
  {
    "objectID": "W3_ML/D1.html#commands-youll-use-today-mac-vs-windows",
    "href": "W3_ML/D1.html#commands-youll-use-today-mac-vs-windows",
    "title": "Machine Learning",
    "section": "Commands you’ll use today (Mac vs Windows)",
    "text": "Commands you’ll use today (Mac vs Windows)\nmacOS/Linux\ncd week3-ml-baseline-system\nuv sync\nuv run ml-baseline --help\nuv run ml-baseline make-sample-data\nWindows PowerShell\ncd week3-ml-baseline-system\nuv sync\nuv run ml-baseline --help\nuv run ml-baseline make-sample-data\n\nIf pytest is missing later: uv sync --extra dev"
  },
  {
    "objectID": "W3_ML/D1.html#micro-exercise-read-cli-help-5-minutes",
    "href": "W3_ML/D1.html#micro-exercise-read-cli-help-5-minutes",
    "title": "Machine Learning",
    "section": "Micro-exercise: read CLI help (5 minutes)",
    "text": "Micro-exercise: read CLI help (5 minutes)\n\nRun: uv run ml-baseline --help\nFind:\n\nthe command name that creates sample data\none option that belongs to train\n\nDon’t understand an option? Ignore it for now.\n\nCheckpoint: you can point to make-sample-data in the help output."
  },
  {
    "objectID": "W3_ML/D1.html#solution-what-to-notice-in-help-output",
    "href": "W3_ML/D1.html#solution-what-to-notice-in-help-output",
    "title": "Machine Learning",
    "section": "Solution: what to notice in help output",
    "text": "Solution: what to notice in help output\n\nCommands are listed (e.g., make-sample-data, train, predict)\nHelp text tells you what each command does\nOptions (--target, --seed, …) are the “knobs” you’ll use later"
  },
  {
    "objectID": "W3_ML/D1.html#checkpoint",
    "href": "W3_ML/D1.html#checkpoint",
    "title": "Machine Learning",
    "section": "Checkpoint",
    "text": "Checkpoint\nRaise your hand when:\n\nuv run ml-baseline --help works\ndata/processed/features.* exists after make-sample-data\n\n\nWalk around. If someone is stuck, check: 1) they are in the repo root 2) uv sync ran 3) uv run uses the project env"
  },
  {
    "objectID": "W3_ML/D1.html#session-3-recap",
    "href": "W3_ML/D1.html#session-3-recap",
    "title": "Machine Learning",
    "section": "Session 3 recap",
    "text": "Session 3 recap\n\nThe repo is organized to ship: data/ → models/ → reports/\nThe CLI is the “front door” to your system\nToday’s minimum is: help works + sample data + model card draft"
  },
  {
    "objectID": "W3_ML/D1.html#minutes-2",
    "href": "W3_ML/D1.html#minutes-2",
    "title": "Machine Learning",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: start Hands-on Task 1 (setup) immediately."
  },
  {
    "objectID": "W3_ML/D1.html#hands-on-success-criteria-today",
    "href": "W3_ML/D1.html#hands-on-success-criteria-today",
    "title": "Machine Learning",
    "section": "Hands-on success criteria (today)",
    "text": "Hands-on success criteria (today)\nMinimum ✅\n\nuv run ml-baseline --help works\nuv run ml-baseline make-sample-data writes data/processed/features.*\nreports/model_card.md exists and is filled (draft)\n1+ commit pushed to GitHub\n\nOptional ⭐\n\nIf you install pyarrow, you can work with Parquet (.parquet) too"
  },
  {
    "objectID": "W3_ML/D1.html#project-layout-top-levels",
    "href": "W3_ML/D1.html#project-layout-top-levels",
    "title": "Machine Learning",
    "section": "Project layout (top levels)",
    "text": "Project layout (top levels)\nweek3-ml-baseline-system/\n  data/processed/\n  models/\n  outputs/\n  reports/\n  src/\n  tests/"
  },
  {
    "objectID": "W3_ML/D1.html#task-1-setup-the-week-3-repo-15-minutes",
    "href": "W3_ML/D1.html#task-1-setup-the-week-3-repo-15-minutes",
    "title": "Machine Learning",
    "section": "Task 1 — Setup the Week 3 repo (15 minutes)",
    "text": "Task 1 — Setup the Week 3 repo (15 minutes)\n\nOpen the repo folder: week3-ml-baseline-system/\nRun uv sync\nVerify the CLI runs: uv run ml-baseline --help\n\nCheckpoint: the help text prints and exit code is 0."
  },
  {
    "objectID": "W3_ML/D1.html#hint-common-setup-issues",
    "href": "W3_ML/D1.html#hint-common-setup-issues",
    "title": "Machine Learning",
    "section": "Hint: common setup issues",
    "text": "Hint: common setup issues\n\n\n\n\n\n\nWarning\n\n\nIf a command fails, don’t panic—read the error carefully.\n\n\n\n\n“command not found: uv” → install uv (Week 1 skill)\n“No such file or directory” → you are in the wrong folder\n“python version” errors → use Python 3.11+"
  },
  {
    "objectID": "W3_ML/D1.html#solution-task-1",
    "href": "W3_ML/D1.html#solution-task-1",
    "title": "Machine Learning",
    "section": "Solution (Task 1)",
    "text": "Solution (Task 1)\nmacOS/Linux\ncd week3-ml-baseline-system\nuv sync\nuv run ml-baseline --help\nWindows PowerShell\ncd week3-ml-baseline-system\nuv sync\nuv run ml-baseline --help"
  },
  {
    "objectID": "W3_ML/D1.html#task-2-generate-sample-data-15-minutes",
    "href": "W3_ML/D1.html#task-2-generate-sample-data-15-minutes",
    "title": "Machine Learning",
    "section": "Task 2 — Generate sample data (15 minutes)",
    "text": "Task 2 — Generate sample data (15 minutes)\n\nRun: uv run ml-baseline make-sample-data\nConfirm the file exists:\n\ndata/processed/features.csv (or features.parquet)\n\n\nCheckpoint: you can open the file and see columns."
  },
  {
    "objectID": "W3_ML/D1.html#solution-task-2",
    "href": "W3_ML/D1.html#solution-task-2",
    "title": "Machine Learning",
    "section": "Solution (Task 2)",
    "text": "Solution (Task 2)\nmacOS/Linux\nuv run ml-baseline make-sample-data\nls -la data/processed\nhead -n 5 data/processed/features.csv\nWindows PowerShell\nuv run ml-baseline make-sample-data\ndir data/processed\nGet-Content data/processed/features.csv -TotalCount 5\n\nIf your file is features.parquet, that’s fine (it means Parquet is supported on your machine)."
  },
  {
    "objectID": "W3_ML/D1.html#task-3-inspect-the-columns-15-minutes",
    "href": "W3_ML/D1.html#task-3-inspect-the-columns-15-minutes",
    "title": "Machine Learning",
    "section": "Task 3 — Inspect the columns (15 minutes)",
    "text": "Task 3 — Inspect the columns (15 minutes)\n\nList the columns in features.*\nWrite down:\n\ntarget\nID passthrough\nfeatures\n\n\nCheckpoint: you can say: “y = …, ID = …, X = …”."
  },
  {
    "objectID": "W3_ML/D1.html#solution-task-3",
    "href": "W3_ML/D1.html#solution-task-3",
    "title": "Machine Learning",
    "section": "Solution (Task 3)",
    "text": "Solution (Task 3)\nFor the sample feature table:\n\nTarget (y): is_high_value\nID passthrough: user_id\nFeatures (X): country, n_orders, avg_amount, total_amount"
  },
  {
    "objectID": "W3_ML/D1.html#task-4-draft-your-model-card-25-minutes",
    "href": "W3_ML/D1.html#task-4-draft-your-model-card-25-minutes",
    "title": "Machine Learning",
    "section": "Task 4 — Draft your model card (25 minutes)",
    "text": "Task 4 — Draft your model card (25 minutes)\n\nCreate: reports/model_card.md\nFill in the dataset contract:\n\nunit of analysis\ntarget meaning\nfeatures + IDs\nforbidden columns (at least the target)\n\nKeep it short and clear (you will improve it on Day 5)\n\nCheckpoint: your model card has no blank placeholders."
  },
  {
    "objectID": "W3_ML/D1.html#model-card-template-copypaste",
    "href": "W3_ML/D1.html#model-card-template-copypaste",
    "title": "Machine Learning",
    "section": "Model card template (copy/paste)",
    "text": "Model card template (copy/paste)\n# Model Card — Week 3 (Draft)\n\n## 1) What is the prediction?\n- **Target (y):** `__________`\n- **Unit of analysis:** one row = __________\n- **Decision supported:** __________\n\n## 2) Data contract (inference)\n- **ID passthrough columns:** __________\n- **Required feature columns (X):** __________\n- **Forbidden columns:** target + leakage fields\n\n## 3) Evaluation plan (fill on Day 2–3)\n- Split strategy: __________\n- Primary metric: __________"
  },
  {
    "objectID": "W3_ML/D1.html#task-5-git-checkpoint-10-minutes",
    "href": "W3_ML/D1.html#task-5-git-checkpoint-10-minutes",
    "title": "Machine Learning",
    "section": "Task 5 — Git checkpoint (10 minutes)",
    "text": "Task 5 — Git checkpoint (10 minutes)\n\ngit status\nCommit with a clear message (example below)\nPush to GitHub\n\nCheckpoint: your new commit is visible online."
  },
  {
    "objectID": "W3_ML/D1.html#solution-task-5",
    "href": "W3_ML/D1.html#solution-task-5",
    "title": "Machine Learning",
    "section": "Solution (Task 5)",
    "text": "Solution (Task 5)\ngit status\ngit add reports/model_card.md data/processed/ || true\ngit commit -m \"w3d1: sample data + model card draft\"\ngit push\n\n\n\n\n\n\nTip\n\n\nSmall commits are a superpower. Don’t wait until the end of the week."
  },
  {
    "objectID": "W3_ML/D1.html#vibe-coding-safe-version",
    "href": "W3_ML/D1.html#vibe-coding-safe-version",
    "title": "Machine Learning",
    "section": "Vibe coding (safe version)",
    "text": "Vibe coding (safe version)\n\nWrite the plan in 5 bullets (no code yet)\nImplement the smallest piece\nRun → break → read error → fix\nCommit\nRepeat\n\n\n\n\n\n\n\nWarning\n\n\nDo not ask GenAI to write your solution code. Ask it to explain concepts or errors."
  },
  {
    "objectID": "W3_ML/D1.html#debug-playbook",
    "href": "W3_ML/D1.html#debug-playbook",
    "title": "Machine Learning",
    "section": "Debug playbook",
    "text": "Debug playbook\nWhen stuck:\n\nRe-run with --help and confirm you’re using the repo environment (uv run ...)\nConfirm you are in the repo root (you should see pyproject.toml)\nRead the error top-to-bottom (file + line + message)\nMake one small change, then re-run"
  },
  {
    "objectID": "W3_ML/D1.html#stretch-goals-optional",
    "href": "W3_ML/D1.html#stretch-goals-optional",
    "title": "Machine Learning",
    "section": "Stretch goals (optional)",
    "text": "Stretch goals (optional)\n⭐ If you finish early:\n\nInstall Parquet support: uv sync --extra parquet\nGenerate features.parquet and open it\nStart thinking about your real dataset’s target + unit of analysis"
  },
  {
    "objectID": "W3_ML/D1.html#exit-ticket",
    "href": "W3_ML/D1.html#exit-ticket",
    "title": "Machine Learning",
    "section": "Exit Ticket",
    "text": "Exit Ticket\nIn 1–2 sentences each:\n\nWhat is the difference between features and target?\nWhy is leakage dangerous?\nWhat is your unit of analysis for the sample dataset?"
  },
  {
    "objectID": "W3_ML/D1.html#what-to-do-after-class-day-1-assignment",
    "href": "W3_ML/D1.html#what-to-do-after-class-day-1-assignment",
    "title": "Machine Learning",
    "section": "What to do after class (Day 1 assignment)",
    "text": "What to do after class (Day 1 assignment)\nDue: before Day 2 (Dec 29, 2025)\n\nEnsure these commands work:\n\nuv run ml-baseline --help\nuv run ml-baseline make-sample-data\n\nCommit + push your reports/model_card.md draft\n\nDeliverable: GitHub repo link with your Day 1 commit(s).\n\n\n\n\n\n\nTip\n\n\nAdd 1–2 commits with clear messages. Don’t wait until the last minute."
  },
  {
    "objectID": "W2_Data/W2_Summary.html#week-2-focus",
    "href": "W2_Data/W2_Summary.html#week-2-focus",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Week 2 Focus",
    "text": "Week 2 Focus\nWeek 2 focuses on developing professional data handling skills—from raw data ingestion to clean, well-documented datasets ready for modeling.\nCore Philosophy: Good data beats clever models. Build it carefully."
  },
  {
    "objectID": "W2_Data/W2_Summary.html#learning-objectives",
    "href": "W2_Data/W2_Summary.html#learning-objectives",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of Week 2, you should be able to:\n\nThink systematically about data workflows\nAssess and improve data quality\nClean and transform real-world datasets\nHandle dates, times, and outliers correctly\nPerform effective exploratory data analysis\nProduce clean, documented datasets ready for modeling"
  },
  {
    "objectID": "W2_Data/W2_Summary.html#the-7-step-process",
    "href": "W2_Data/W2_Summary.html#the-7-step-process",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "The 7-Step Process",
    "text": "The 7-Step Process\nThe week follows a structured workflow (repeat every project):\n\nLoad (from raw/cache)\nVerify (columns, types, key uniqueness, row counts, missingness)\nClean (types, missing, duplicates, normalization)\nTransform (joins, reshape, feature engineering)\nAnalyze (stats tables, comparisons, bootstraps)\nVisualize (charts with titles/labels + export)\nConclude (written summary + caveats + next questions)"
  },
  {
    "objectID": "W2_Data/W2_Summary.html#day-1-goal",
    "href": "W2_Data/W2_Summary.html#day-1-goal",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Day 1 Goal",
    "text": "Day 1 Goal\nSet up a clean project scaffold and produce your first processed Parquet output."
  },
  {
    "objectID": "W2_Data/W2_Summary.html#offline-first-mindset",
    "href": "W2_Data/W2_Summary.html#offline-first-mindset",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Offline-First Mindset",
    "text": "Offline-First Mindset\nConcept: Projects run without internet dependency.\nCode Pattern:\n# Cache-first extraction\ndef fetch_json_cached(url: str, cache_path: Path, *, ttl_s: int | None = None) -&gt; dict:\n    if cache_path.exists() and ttl_s is None:\n        # Offline-first: reuse cache if present\n        return json.loads(cache_path.read_text(encoding=\"utf-8\"))\n    # Only fetch if cache missing or expired\n    ..."
  },
  {
    "objectID": "W2_Data/W2_Summary.html#data-separation-by-role",
    "href": "W2_Data/W2_Summary.html#data-separation-by-role",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Data Separation by Role",
    "text": "Data Separation by Role\nConcept: Separate data by purpose to prevent chaos.\nCode Pattern:\n@dataclass(frozen=True)\nclass Paths:\n    root: Path\n    raw: Path      # immutable inputs (never edited)\n    cache: Path   # API responses (safe to delete)\n    processed: Path  # clean, typed outputs (idempotent)\n\ndef make_paths(root: Path) -&gt; Paths:\n    data = root / \"data\"\n    return Paths(\n        root=root,\n        raw=data / \"raw\",\n        cache=data / \"cache\",\n        processed=data / \"processed\",\n    )"
  },
  {
    "objectID": "W2_Data/W2_Summary.html#idempotent-outputs",
    "href": "W2_Data/W2_Summary.html#idempotent-outputs",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Idempotent Outputs",
    "text": "Idempotent Outputs\nConcept: Rerunning produces the same results (safe to overwrite).\nCode Pattern:\n# Good: overwrite (idempotent)\ndf.to_parquet(\"data/processed/orders.parquet\", index=False)\n\n# Bad: append (not idempotent)\ndf.to_csv(\"data/processed/orders.csv\", mode=\"a\", index=False)  # ❌ duplicates accumulate"
  },
  {
    "objectID": "W2_Data/W2_Summary.html#schema-aware-io",
    "href": "W2_Data/W2_Summary.html#schema-aware-io",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Schema-Aware I/O",
    "text": "Schema-Aware I/O\nConcept: Explicit dtypes prevent silent corruption (especially IDs).\nCode Pattern:\ndef read_orders_csv(path: Path) -&gt; pd.DataFrame:\n    return pd.read_csv(\n        path,\n        dtype={\"order_id\": \"string\", \"user_id\": \"string\"},  # IDs as strings!\n        na_values=[\"\", \"NA\", \"N/A\", \"null\", \"None\"],\n        keep_default_na=True,\n    )"
  },
  {
    "objectID": "W2_Data/W2_Summary.html#parquet-for-processed-data",
    "href": "W2_Data/W2_Summary.html#parquet-for-processed-data",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Parquet for Processed Data",
    "text": "Parquet for Processed Data\nConcept: Parquet preserves types, is faster, and smaller than CSV.\nCode Pattern:\ndef write_parquet(df: pd.DataFrame, path: Path) -&gt; None:\n    path.parent.mkdir(parents=True, exist_ok=True)\n    df.to_parquet(path, index=False)  # Preserves dtypes automatically\n\ndef read_parquet(path: Path) -&gt; pd.DataFrame:\n    return pd.read_parquet(path)  # Types restored automatically"
  },
  {
    "objectID": "W2_Data/W2_Summary.html#day-2-goal",
    "href": "W2_Data/W2_Summary.html#day-2-goal",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Day 2 Goal",
    "text": "Day 2 Goal\nMake your dataset trustworthy by adding checks and cleaning for missingness, duplicates, and text normalization."
  },
  {
    "objectID": "W2_Data/W2_Summary.html#fail-fast-validation",
    "href": "W2_Data/W2_Summary.html#fail-fast-validation",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Fail Fast Validation",
    "text": "Fail Fast Validation\nConcept: Validate assumptions early with clear errors.\nCode Pattern:\ndef require_columns(df: pd.DataFrame, cols: list[str]) -&gt; None:\n    missing = [c for c in cols if c not in df.columns]\n    assert not missing, f\"Missing columns: {missing}\"\n\ndef assert_unique_key(df: pd.DataFrame, key: str, *, allow_na: bool = False) -&gt; None:\n    if not allow_na:\n        assert df[key].notna().all(), f\"{key} contains NA\"\n    dup = df[key].duplicated(keep=False) & df[key].notna()\n    assert not dup.any(), f\"{key} not unique; {dup.sum()} duplicate rows\""
  },
  {
    "objectID": "W2_Data/W2_Summary.html#missingness-strategy",
    "href": "W2_Data/W2_Summary.html#missingness-strategy",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Missingness Strategy",
    "text": "Missingness Strategy\nConcept: Measure first, avoid blanket drops, default to flagging.\nCode Pattern:\ndef missingness_report(df: pd.DataFrame) -&gt; pd.DataFrame:\n    n = len(df)\n    return (\n        df.isna().sum()\n          .rename(\"n_missing\")\n          .to_frame()\n          .assign(p_missing=lambda t: t[\"n_missing\"] / n)\n          .sort_values(\"p_missing\", ascending=False)\n    )\n\ndef add_missing_flags(df: pd.DataFrame, cols: list[str]) -&gt; pd.DataFrame:\n    out = df.copy()\n    for c in cols:\n        out[f\"{c}__isna\"] = out[c].isna()  # Keep missingness visible\n    return out"
  },
  {
    "objectID": "W2_Data/W2_Summary.html#text-normalization",
    "href": "W2_Data/W2_Summary.html#text-normalization",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Text Normalization",
    "text": "Text Normalization\nConcept: Normalize categories to prevent fake groups.\nCode Pattern:\nimport re\n_ws = re.compile(r\"\\s+\")\n\ndef normalize_text(s: pd.Series) -&gt; pd.Series:\n    return (\n        s.astype(\"string\")\n         .str.strip()\n         .str.casefold()  # Robust lowercase\n         .str.replace(_ws, \" \", regex=True)  # Collapse whitespace\n    )\n\ndef apply_mapping(s: pd.Series, mapping: dict[str, str]) -&gt; pd.Series:\n    return s.map(lambda x: mapping.get(x, x))  # Controlled synonyms"
  },
  {
    "objectID": "W2_Data/W2_Summary.html#day-3-goal",
    "href": "W2_Data/W2_Summary.html#day-3-goal",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Day 3 Goal",
    "text": "Day 3 Goal\nBuild an analytics-ready table by parsing time correctly, handling outliers safely, and joining without corrupting data."
  },
  {
    "objectID": "W2_Data/W2_Summary.html#datetime-parsing",
    "href": "W2_Data/W2_Summary.html#datetime-parsing",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Datetime Parsing",
    "text": "Datetime Parsing\nConcept: Parse safely with error handling and timezone awareness.\nCode Pattern:\ndef parse_datetime(df: pd.DataFrame, col: str, *, utc: bool = True) -&gt; pd.DataFrame:\n    dt = pd.to_datetime(df[col], errors=\"coerce\", utc=utc)  # Invalid → missing\n    return df.assign(**{col: dt})\n\ndef add_time_parts(df: pd.DataFrame, ts_col: str) -&gt; pd.DataFrame:\n    ts = df[ts_col]\n    return df.assign(\n        date=ts.dt.date,\n        year=ts.dt.year,\n        month=ts.dt.to_period(\"M\").astype(\"string\"),\n        dow=ts.dt.day_name(),\n        hour=ts.dt.hour,\n    )"
  },
  {
    "objectID": "W2_Data/W2_Summary.html#outlier-management",
    "href": "W2_Data/W2_Summary.html#outlier-management",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Outlier Management",
    "text": "Outlier Management\nConcept: Identify outliers, flag them, cap for visualization (don’t delete).\nCode Pattern:\ndef iqr_bounds(s: pd.Series, k: float = 1.5) -&gt; tuple[float, float]:\n    q1 = s.quantile(0.25)\n    q3 = s.quantile(0.75)\n    iqr = q3 - q1\n    return float(q1 - k * iqr), float(q3 + k * iqr)\n\ndef winsorize(s: pd.Series, lo: float = 0.01, hi: float = 0.99) -&gt; pd.Series:\n    a, b = s.quantile(lo), s.quantile(hi)\n    return s.clip(lower=a, upper=b)  # Cap for charts, keep rows"
  },
  {
    "objectID": "W2_Data/W2_Summary.html#safe-joins",
    "href": "W2_Data/W2_Summary.html#safe-joins",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Safe Joins",
    "text": "Safe Joins\nConcept: Validate cardinality, check row counts, prevent explosions.\nCode Pattern:\ndef safe_left_join(\n    left: pd.DataFrame,\n    right: pd.DataFrame,\n    on: str | list[str],\n    *,\n    validate: str,  # \"many_to_one\", \"one_to_one\", etc.\n    suffixes: tuple[str, str] = (\"\", \"_r\"),\n) -&gt; pd.DataFrame:\n    return left.merge(\n        right,\n        how=\"left\",\n        on=on,\n        validate=validate,  # Prevents join explosions\n        suffixes=suffixes,\n    )\n\n# Usage: orders (many) → users (one)\nassert_unique_key(users, \"user_id\")  # Pre-check\njoined = safe_left_join(orders, users, on=\"user_id\", validate=\"many_to_one\")\nassert len(joined) == len(orders), \"Row count changed (join explosion?)\""
  },
  {
    "objectID": "W2_Data/W2_Summary.html#day-4-goal",
    "href": "W2_Data/W2_Summary.html#day-4-goal",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Day 4 Goal",
    "text": "Day 4 Goal\nTurn analytics_table.parquet into answers: 3–6 questions, clear tables, clear charts, and at least one bootstrap interval."
  },
  {
    "objectID": "W2_Data/W2_Summary.html#eda-workflow",
    "href": "W2_Data/W2_Summary.html#eda-workflow",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "EDA Workflow",
    "text": "EDA Workflow\nConcept: Audit → Questions → Tables + Charts → Interpretations + Caveats.\nCode Pattern:\n# 1. Audit first\nprint(\"rows:\", len(df))\nprint(df.dtypes.head(10))\nprint(df.isna().sum().sort_values(ascending=False).head(5))\n\n# 2. Write measurable questions\n# \"How does revenue differ by country?\"\n\n# 3. Answer with tables\nsummary = (\n    df.groupby(\"country\", dropna=False)\n      .agg(\n          n=(\"order_id\", \"size\"),\n          revenue=(\"amount\", \"sum\"),\n          aov=(\"amount\", \"mean\"),\n      )\n      .reset_index()\n      .sort_values(\"revenue\", ascending=False)\n)"
  },
  {
    "objectID": "W2_Data/W2_Summary.html#plotly-visualization",
    "href": "W2_Data/W2_Summary.html#plotly-visualization",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Plotly Visualization",
    "text": "Plotly Visualization\nConcept: Use one library, consistent anatomy, export figures.\nCode Pattern:\nimport plotly.express as px\nfrom pathlib import Path\n\ndef save_fig(fig, path: Path, *, scale: int = 2) -&gt; None:\n    path.parent.mkdir(parents=True, exist_ok=True)\n    fig.write_image(str(path), scale=scale)  # Requires kaleido\n\n# Bar chart (sorted)\nd = revenue_by_country.sort_values(\"revenue\", ascending=False)\nfig = px.bar(d, x=\"country\", y=\"revenue\", title=\"Revenue by country (All time)\")\nfig.update_layout(title={\"x\": 0.02})\nfig.update_xaxes(title_text=\"Country\")\nfig.update_yaxes(title_text=\"Revenue\")\nsave_fig(fig, Path(\"reports/figures/revenue_by_country.png\"))"
  },
  {
    "objectID": "W2_Data/W2_Summary.html#bootstrap-uncertainty",
    "href": "W2_Data/W2_Summary.html#bootstrap-uncertainty",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Bootstrap Uncertainty",
    "text": "Bootstrap Uncertainty\nConcept: Quantify uncertainty with simulation-based confidence intervals.\nCode Pattern:\nimport numpy as np\nimport pandas as pd\n\ndef bootstrap_diff_means(a: pd.Series, b: pd.Series, *, n_boot: int = 2000, seed: int = 0) -&gt; dict:\n    rng = np.random.default_rng(seed)  # Fixed seed for reproducibility\n    a = pd.to_numeric(a, errors=\"coerce\").dropna().to_numpy()\n    b = pd.to_numeric(b, errors=\"coerce\").dropna().to_numpy()\n    \n    diffs = []\n    for _ in range(n_boot):\n        sa = rng.choice(a, size=len(a), replace=True)  # Resample with replacement\n        sb = rng.choice(b, size=len(b), replace=True)\n        diffs.append(sa.mean() - sb.mean())\n    diffs = np.array(diffs)\n    \n    return {\n        \"diff_mean\": float(a.mean() - b.mean()),\n        \"ci_low\": float(np.quantile(diffs, 0.025)),\n        \"ci_high\": float(np.quantile(diffs, 0.975)),\n    }"
  },
  {
    "objectID": "W2_Data/W2_Summary.html#day-5-goal",
    "href": "W2_Data/W2_Summary.html#day-5-goal",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Day 5 Goal",
    "text": "Day 5 Goal\nPackage Week 2 work as a job-ready handoff: reproducible ETL → processed datasets → EDA notebook → exported figures → written summary."
  },
  {
    "objectID": "W2_Data/W2_Summary.html#etl-structure",
    "href": "W2_Data/W2_Summary.html#etl-structure",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "ETL Structure",
    "text": "ETL Structure\nConcept: Separate Extract, Transform, Load with logging and validation.\nCode Pattern:\n@dataclass(frozen=True)\nclass ETLConfig:\n    root: Path\n    raw_orders: Path\n    raw_users: Path\n    out_analytics: Path\n    run_meta: Path\n\ndef load_inputs(cfg: ETLConfig) -&gt; tuple[pd.DataFrame, pd.DataFrame]:\n    orders = read_orders_csv(cfg.raw_orders)\n    users = read_users_csv(cfg.raw_users)\n    return orders, users\n\ndef transform(orders: pd.DataFrame, users: pd.DataFrame) -&gt; pd.DataFrame:\n    require_columns(orders, [\"order_id\", \"user_id\", \"amount\", \"created_at\", \"status\"])\n    assert_unique_key(users, \"user_id\")\n    \n    return (\n        orders.pipe(enforce_schema)\n              .pipe(parse_datetime, col=\"created_at\", utc=True)\n              .pipe(add_time_parts, ts_col=\"created_at\")\n              .pipe(lambda d: safe_left_join(d, users, on=\"user_id\", validate=\"many_to_one\"))\n    )\n\ndef run_etl(cfg: ETLConfig) -&gt; None:\n    logging.basicConfig(level=logging.INFO)\n    log = logging.getLogger(__name__)\n    \n    log.info(\"Loading inputs\")\n    orders, users = load_inputs(cfg)\n    \n    log.info(\"Transforming (orders=%s, users=%s)\", len(orders), len(users))\n    analytics = transform(orders, users)\n    \n    log.info(\"Writing output: %s (%s rows)\", cfg.out_analytics, len(analytics))\n    write_parquet(analytics, cfg.out_analytics)\n    write_run_meta(cfg, rows_out=len(analytics))"
  },
  {
    "objectID": "W2_Data/W2_Summary.html#run-metadata",
    "href": "W2_Data/W2_Summary.html#run-metadata",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Run Metadata",
    "text": "Run Metadata\nConcept: Track config, counts, and quality stats for reproducibility.\nCode Pattern:\nimport json\nfrom dataclasses import asdict\n\ndef write_run_meta(cfg: ETLConfig, *, rows_out: int, missing_ts: int, match_rate: float) -&gt; None:\n    meta = {\n        \"rows_out\": rows_out,\n        \"missing_created_at\": missing_ts,\n        \"country_match_rate\": match_rate,\n        \"config\": {k: str(v) for k, v in asdict(cfg).items()},\n    }\n    cfg.run_meta.parent.mkdir(parents=True, exist_ok=True)\n    cfg.run_meta.write_text(json.dumps(meta, indent=2), encoding=\"utf-8\")"
  },
  {
    "objectID": "W2_Data/W2_Summary.html#standard-folder-layout",
    "href": "W2_Data/W2_Summary.html#standard-folder-layout",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Standard Folder Layout",
    "text": "Standard Folder Layout\nConcept: Consistent structure prevents path chaos.\nCode Pattern:\nweek2-data-work/\n  data/\n    raw/            # immutable inputs\n    cache/          # API responses (safe to delete)\n    processed/      # clean, typed outputs (idempotent)\n    external/       # reference data\n  notebooks/        # EDA (reads processed/)\n  reports/\n    figures/        # exported images\n    summary.md      # written findings\n  src/bootcamp_data/\n    config.py       # Paths dataclass\n    io.py           # I/O helpers\n    quality.py      # Validation functions\n    transforms.py   # Pure transform functions\n    joins.py        # Safe join helpers\n    etl.py          # ETL pipeline\n  scripts/\n    run_etl.py      # Entrypoint"
  },
  {
    "objectID": "W2_Data/W2_Summary.html#rules-that-prevent-pain",
    "href": "W2_Data/W2_Summary.html#rules-that-prevent-pain",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Rules That Prevent Pain",
    "text": "Rules That Prevent Pain\nConcept: Follow conventions to avoid common bugs.\nCode Patterns:\n# ✅ Raw is immutable\n# Never edit files under data/raw/\n\n# ✅ Processed is idempotent\ndf.to_parquet(\"data/processed/orders.parquet\", index=False)  # Overwrite OK\n\n# ✅ One source of truth for paths\np = make_paths(ROOT)\norders = read_orders_csv(p.raw / \"orders.csv\")\n\n# ✅ Schema-aware: IDs as strings\ndtype={\"user_id\": \"string\", \"order_id\": \"string\"}\n\n# ✅ Fail fast\nrequire_columns(df, [\"order_id\", \"user_id\", \"amount\"])\nassert_unique_key(users, \"user_id\")"
  },
  {
    "objectID": "W2_Data/W2_Summary.html#pure-transform-functions",
    "href": "W2_Data/W2_Summary.html#pure-transform-functions",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Pure Transform Functions",
    "text": "Pure Transform Functions\nConcept: Transforms are df -&gt; df, no I/O inside.\nCode Pattern:\ndef clean_orders(df: pd.DataFrame) -&gt; pd.DataFrame:\n    return (\n        df.pipe(enforce_schema)\n          .pipe(parse_datetime, col=\"created_at\", utc=True)\n          .assign(status_clean=lambda d: normalize_text(d[\"status\"]))\n          .pipe(add_missing_flags, cols=[\"amount\", \"quantity\"])\n    )\n\n# I/O happens outside\norders = read_orders_csv(path)\norders_clean = clean_orders(orders)\nwrite_parquet(orders_clean, output_path)"
  },
  {
    "objectID": "W2_Data/W2_Summary.html#pipeline-with-.pipe",
    "href": "W2_Data/W2_Summary.html#pipeline-with-.pipe",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Pipeline with .pipe()",
    "text": "Pipeline with .pipe()\nConcept: Readable top-to-bottom flow.\nCode Pattern:\nanalytics = (\n    orders\n    .pipe(enforce_schema)\n    .pipe(parse_datetime, col=\"created_at\", utc=True)\n    .pipe(add_time_parts, ts_col=\"created_at\")\n    .pipe(lambda d: safe_left_join(d, users, on=\"user_id\", validate=\"many_to_one\"))\n    .assign(amount_winsor=lambda d: winsorize(d[\"amount\"]))\n)"
  },
  {
    "objectID": "W2_Data/W2_Summary.html#dtype-inference-lies",
    "href": "W2_Data/W2_Summary.html#dtype-inference-lies",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Dtype Inference Lies",
    "text": "Dtype Inference Lies\nConcept: Pandas guesses wrong, leading zeros lost forever.\nCode Pattern:\n# ❌ Bad: pandas infers int64\ndf = pd.read_csv(\"orders.csv\")\n# order_id \"0007\" becomes 7 (unrecoverable)\n\n# ✅ Good: explicit dtype\ndf = pd.read_csv(\"orders.csv\", dtype={\"order_id\": \"string\"})\n# order_id \"0007\" stays \"0007\""
  },
  {
    "objectID": "W2_Data/W2_Summary.html#join-explosions",
    "href": "W2_Data/W2_Summary.html#join-explosions",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Join Explosions",
    "text": "Join Explosions\nConcept: Keys not unique → row count multiplies.\nCode Pattern:\n# ❌ Bad: no validation\njoined = orders.merge(users, on=\"user_id\", how=\"left\")\n# If users has duplicates, joined has more rows than orders!\n\n# ✅ Good: validate first\nassert_unique_key(users, \"user_id\")  # Pre-check\njoined = safe_left_join(orders, users, on=\"user_id\", validate=\"many_to_one\")\nassert len(joined) == len(orders), \"Row count changed\""
  },
  {
    "objectID": "W2_Data/W2_Summary.html#blanket-.dropna",
    "href": "W2_Data/W2_Summary.html#blanket-.dropna",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Blanket .dropna()",
    "text": "Blanket .dropna()\nConcept: Silently deletes data and biases results.\nCode Pattern:\n# ❌ Bad: loses information\ndf = df.dropna()  # Deletes rows, may bias analysis\n\n# ✅ Good: flag missingness\ndf = add_missing_flags(df, cols=[\"amount\", \"quantity\"])\n# Now you can analyze: \"Are missing amounts more common in one country?\""
  },
  {
    "objectID": "W2_Data/W2_Summary.html#submission-checklist",
    "href": "W2_Data/W2_Summary.html#submission-checklist",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Submission Checklist",
    "text": "Submission Checklist\nBy the end of Week 2, you should have:\n\nReproducible ETL (scripts/run_etl.py)\nProcessed Datasets (data/processed/*.parquet)\nEDA Notebook (notebooks/eda.ipynb)\nExported Figures (reports/figures/*.png)\nWritten Summary (reports/summary.md)\nDocumentation (README.md)"
  },
  {
    "objectID": "W2_Data/W2_Summary.html#outcome",
    "href": "W2_Data/W2_Summary.html#outcome",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Outcome",
    "text": "Outcome\nBy the end of Week 2, you will produce a reproducible data pipeline and a final dataset that can be confidently handed off for modeling.\nWeek 2 ensures you can be trusted with data.\nAfter this week, you should be able to hand a dataset to a teammate and say:\n\n“This data is clean, documented, and ready to use.”\n\nThese skills form the backbone of all machine learning and AI systems that follow."
  },
  {
    "objectID": "W2_Data/W2_Summary.html#essential-functions",
    "href": "W2_Data/W2_Summary.html#essential-functions",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Essential Functions",
    "text": "Essential Functions\nI/O:\nread_orders_csv(path) -&gt; DataFrame\nwrite_parquet(df, path) -&gt; None\nread_parquet(path) -&gt; DataFrame\nQuality:\nrequire_columns(df, cols) -&gt; None\nassert_non_empty(df, name) -&gt; None\nassert_unique_key(df, key) -&gt; None\nassert_in_range(s, lo, hi, name) -&gt; None\nTransforms:\nenforce_schema(df) -&gt; DataFrame\nmissingness_report(df) -&gt; DataFrame\nadd_missing_flags(df, cols) -&gt; DataFrame\nnormalize_text(s) -&gt; Series\nparse_datetime(df, col, utc=True) -&gt; DataFrame\nadd_time_parts(df, ts_col) -&gt; DataFrame\nwinsorize(s, lo=0.01, hi=0.99) -&gt; Series\nsafe_left_join(left, right, on, validate, suffixes) -&gt; DataFrame\nEDA:\ndescribe_numeric(df, col) -&gt; Series\nbootstrap_diff_means(a, b, n_boot=2000, seed=0) -&gt; dict"
  },
  {
    "objectID": "W2_Data/W2_Summary.html#final-message",
    "href": "W2_Data/W2_Summary.html#final-message",
    "title": "Week 2 Summary: Data Work (ETL + EDA)",
    "section": "Final Message",
    "text": "Final Message\nGood data beats clever models. Build it carefully. 📊✨"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#todays-flow",
    "href": "W2_Data/D4_Visual_Analysis.html#todays-flow",
    "title": "Data Work (ETL + EDA)",
    "section": "Today’s Flow",
    "text": "Today’s Flow\n\nSession 1 (60m): Chart choice (data‑to‑viz thinking) + notebook workflow rules\nAsr Prayer (20m)\nSession 2 (60m): Plotly Express patterns + exporting figures (HTML/PNG)\nMaghrib Prayer (20m)\nSession 3 (60m): Comparison thinking + bootstrap uncertainty + writing the summary\nIsha Prayer (20m)\nHands-on (120m): Build notebooks/day4_eda.ipynb + export figures + write reports/summary.md"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#learning-objectives",
    "href": "W2_Data/D4_Visual_Analysis.html#learning-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of today, you can:\n\nchoose an appropriate visualization based on question + data types (data-to-viz style)\nuse Plotly Express as your one plotting library (and customize labels/layout)\nexport interactive figures to reports/figures/*.html (offline-friendly)\nanswer 3–6 concrete questions with tables + charts + short interpretations\ncompute a practical uncertainty estimate using a bootstrap interval\nship a readable reports/summary.md with findings + definitions + caveats"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#warm-up-5-minutes-verify-inputs-exist",
    "href": "W2_Data/D4_Visual_Analysis.html#warm-up-5-minutes-verify-inputs-exist",
    "title": "Data Work (ETL + EDA)",
    "section": "Warm-up (5 minutes): verify inputs exist",
    "text": "Warm-up (5 minutes): verify inputs exist\nDay 4 EDA reads from processed data (not raw).\nFrom repo root:\nmacOS/Linux\nuv run python -m scripts.run_day2_validate_and_report\nuv run python -c \"from pathlib import Path; print(Path('data/processed/orders_enriched.parquet').exists())\"\nWindows PowerShell\nuv run python -m scripts.run_day2_validate_and_report\nuv run python -c \"from pathlib import Path; print(Path('data/processed/orders_enriched.parquet').exists())\"\nCheckpoint: prints True."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#warm-up-5-minutes-verify-plotly-is-available",
    "href": "W2_Data/D4_Visual_Analysis.html#warm-up-5-minutes-verify-plotly-is-available",
    "title": "Data Work (ETL + EDA)",
    "section": "Warm-up (5 minutes): verify Plotly is available",
    "text": "Warm-up (5 minutes): verify Plotly is available\nmacOS/Linux\nuv run python -c \"import plotly; print('plotly ok', plotly.__version__)\"\nWindows PowerShell\nuv run python -c \"import plotly; print('plotly ok', plotly.__version__)\"\n\n\n\n\n\n\nTip\n\n\nIf this fails, install Plotly now (required today):\nuv add plotly"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#quick-review-week-2-so-far",
    "href": "W2_Data/D4_Visual_Analysis.html#quick-review-week-2-so-far",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick review: Week 2 so far",
    "text": "Quick review: Week 2 so far\n\nDay 1: scaffold + typed I/O + offline-first data layout\nDay 2: checks + cleaning + safe join → orders_enriched.parquet\nDay 3: datetimes + outliers (flag/cap), EDA helpers (tables)\n\n\n\n\n\n\n\nNote\n\n\nToday is the “EDA handoff”: the notebook answers questions and the repo contains exported figures + a written summary."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#todays-end-state-what-you-will-commit",
    "href": "W2_Data/D4_Visual_Analysis.html#todays-end-state-what-you-will-commit",
    "title": "Data Work (ETL + EDA)",
    "section": "Today’s end state (what you will commit)",
    "text": "Today’s end state (what you will commit)\n\nnotebooks/day4_eda.ipynb (reads from data/processed/)\nreports/figures/ with 3–6 Plotly exports (.html required; .png optional)\nreports/summary.md (findings + definitions + caveats)\ndata/processed/orders_features.parquet (analysis-ready; built once, reused)"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#session-1-objectives",
    "href": "W2_Data/D4_Visual_Analysis.html#session-1-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 1 objectives",
    "text": "Session 1 objectives\nBy the end of this session, you can:\n\nmap a question → a chart type\nrecognize your variable types (categorical / numeric / datetime)\navoid the most common chart mistakes (pie, unsorted bars, missing n, dual axes)\nexplain “why notebook, not script” for EDA (and what belongs where)"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#notebook-workflow-rules-bootcamp-standard",
    "href": "W2_Data/D4_Visual_Analysis.html#notebook-workflow-rules-bootcamp-standard",
    "title": "Data Work (ETL + EDA)",
    "section": "Notebook workflow rules (bootcamp standard)",
    "text": "Notebook workflow rules (bootcamp standard)\nNotebooks are for exploration + explanation.\nRules:\n\nNotebook reads from data/processed/ (never data/raw/)\nETL belongs in scripts/modules (idempotent), not hidden notebook cells\nEvery chart has:\n\na real title (time window + metric + segment)\naxis labels with units\nenough context to not mislead\n\n\n\n\n\n\n\n\nWarning\n\n\nIf your notebook can’t be re-run top-to-bottom without manual fixes, it’s not a deliverable."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#variable-types-fast-mental-model",
    "href": "W2_Data/D4_Visual_Analysis.html#variable-types-fast-mental-model",
    "title": "Data Work (ETL + EDA)",
    "section": "Variable types (fast mental model)",
    "text": "Variable types (fast mental model)\n\nCategorical: country, status, product_category\nNumeric: amount, quantity, rating\nDatetime: created_at, event_time, month\nBoolean: is_refund, is_outlier\n\nYou’ll choose charts based on question type + variable types."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#chart-choice-question-chart-default-moves",
    "href": "W2_Data/D4_Visual_Analysis.html#chart-choice-question-chart-default-moves",
    "title": "Data Work (ETL + EDA)",
    "section": "Chart choice: question → chart (default moves)",
    "text": "Chart choice: question → chart (default moves)\nUse the simplest chart that answers the question:\n\nCompare categories (cat → value) → sorted bar / dot plot\n\nTrend over time (time → value) → line\nDistribution (numeric) → histogram (and maybe box for quick compare)\nRelationship (num vs num) → scatter\nComposition (parts of whole across a dimension) → stacked bar / stacked area\nRates vs volume → use two charts (avoid dual axes)\n\n\n\n\n\n\n\nTip\n\n\nYour default should be “table → bar/line/scatter/hist”. Make pies rare."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#chart-choice-cheat-sheet-data-to-viz-style",
    "href": "W2_Data/D4_Visual_Analysis.html#chart-choice-cheat-sheet-data-to-viz-style",
    "title": "Data Work (ETL + EDA)",
    "section": "Chart choice cheat sheet (data-to-viz style)",
    "text": "Chart choice cheat sheet (data-to-viz style)\n\n\n\n\n\n\n\n\n\nYou want to…\nData types\nBest default\nCommon trap\n\n\n\n\nCompare categories\ncategorical + numeric\nbar (sorted)\nunsorted bars, too many categories\n\n\nSee a trend\ndatetime + numeric\nline\nmixing time zones / missing dates\n\n\nUnderstand spread\nnumeric\nhistogram\nusing mean only on skewed data\n\n\nCompare distributions\ncategorical + numeric\nhistogram facets / box\nbox plots with tiny groups\n\n\nFind relationships\nnumeric + numeric\nscatter\noverplotting without aggregation\n\n\nShow composition\ncategorical + categorical\nstacked bar\npie charts for many categories"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#micro-exercise-6-minutes-choose-the-chart",
    "href": "W2_Data/D4_Visual_Analysis.html#micro-exercise-6-minutes-choose-the-chart",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise (6 minutes): choose the chart",
    "text": "Micro-exercise (6 minutes): choose the chart\nFor each question, pick the best default chart:\n\n“Which countries generate the most revenue?”\n“How does revenue change month-to-month?”\n“Is order amount skewed or roughly normal?”\n“Do refunds have lower order amounts than paid orders?”\n\nCheckpoint: answer with 4 chart choices (one each)."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#solution",
    "href": "W2_Data/D4_Visual_Analysis.html#solution",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution",
    "text": "Solution\n\nSorted bar (top countries by revenue)\n\nLine (monthly revenue)\n\nHistogram (amount distribution; consider log scale if heavy tail)\n\nHistogram facets or box by status_clean (plus show group sizes)"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#the-5-most-common-eda-chart-mistakes",
    "href": "W2_Data/D4_Visual_Analysis.html#the-5-most-common-eda-chart-mistakes",
    "title": "Data Work (ETL + EDA)",
    "section": "The 5 most common “EDA chart mistakes”",
    "text": "The 5 most common “EDA chart mistakes”\n\nBars not sorted (hard to read)\nMissing units/time window in titles\nComparing averages without showing n\nDual y-axes (often misleading)\nPie charts for more than ~3–4 categories\n\n\n\n\n\n\n\nNote\n\n\nMost chart quality comes from: sorting, labeling, and choosing the right level of aggregation."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#eda-structure-what-your-notebook-should-look-like",
    "href": "W2_Data/D4_Visual_Analysis.html#eda-structure-what-your-notebook-should-look-like",
    "title": "Data Work (ETL + EDA)",
    "section": "EDA structure (what your notebook should look like)",
    "text": "EDA structure (what your notebook should look like)\nA job-ready EDA notebook answers 3–6 questions:\nFor each question:\n\ndefine metric + filters\ncompute a table\nchart the table (or chart the raw distribution)\nwrite 2–3 sentences: what it means + 1 caveat"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#quick-check",
    "href": "W2_Data/D4_Visual_Analysis.html#quick-check",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: Why do we export figures to reports/figures/ instead of leaving them only inside the notebook?\n\nAnswer: figures are stable artifacts you can share, review, and reference from the written summary (and diff in Git if needed)."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#minutes",
    "href": "W2_Data/D4_Visual_Analysis.html#minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: we’ll learn the Plotly patterns we’ll use for every chart today."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#session-2-objectives",
    "href": "W2_Data/D4_Visual_Analysis.html#session-2-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 2 objectives",
    "text": "Session 2 objectives\nBy the end of this session, you can:\n\nbuild the core chart types with plotly.express\ncustomize chart anatomy (titles, labels, axes)\nexport figures to .html (offline-friendly) and optionally .png\nuse long/tidy data when plotting grouped metrics"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#plotly-mental-model-2-minutes",
    "href": "W2_Data/D4_Visual_Analysis.html#plotly-mental-model-2-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Plotly mental model (2 minutes)",
    "text": "Plotly mental model (2 minutes)\n\nplotly.express → fast chart creation (px.bar, px.line, …)\nfig.update_layout(...) → titles, margins, legend, theme\nfig.update_xaxes/yaxes(...) → axis labels, tick formatting\nExport:\n\nfig.write_html(...) ✅ works offline (recommended)\nfig.write_image(...) ✅ requires kaleido (optional)"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#install-note-png-export-is-optional",
    "href": "W2_Data/D4_Visual_Analysis.html#install-note-png-export-is-optional",
    "title": "Data Work (ETL + EDA)",
    "section": "Install note: PNG export is optional",
    "text": "Install note: PNG export is optional\nIf you want .png exports:\nuv add kaleido\nIf you can’t install it (offline), export .html and keep going."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#canonical-plotly-patterns-you-will-reuse-these",
    "href": "W2_Data/D4_Visual_Analysis.html#canonical-plotly-patterns-you-will-reuse-these",
    "title": "Data Work (ETL + EDA)",
    "section": "Canonical Plotly patterns (you will reuse these)",
    "text": "Canonical Plotly patterns (you will reuse these)\nimport plotly.express as px\n\n# bar (categories)\nfig = px.bar(df, x=\"country\", y=\"revenue\", title=\"Revenue by country\")\n\n# line (trend)\nfig = px.line(df, x=\"month\", y=\"revenue\", title=\"Monthly revenue\")\n\n# histogram (distribution)\nfig = px.histogram(df, x=\"amount\", nbins=50, title=\"Amount distribution\")\n\n# scatter (relationship)\nfig = px.scatter(df, x=\"quantity\", y=\"amount\", title=\"Amount vs quantity\")"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#sorting-categories-non-negotiable-for-readability",
    "href": "W2_Data/D4_Visual_Analysis.html#sorting-categories-non-negotiable-for-readability",
    "title": "Data Work (ETL + EDA)",
    "section": "Sorting categories (non-negotiable for readability)",
    "text": "Sorting categories (non-negotiable for readability)\nPlotly won’t magically sort categories the way you intend.\nDo this:\nd = df.sort_values(\"revenue\", ascending=False)\nfig = px.bar(d, x=\"country\", y=\"revenue\", title=\"Revenue by country (sorted)\")"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#make-charts-self-contained-labels-units",
    "href": "W2_Data/D4_Visual_Analysis.html#make-charts-self-contained-labels-units",
    "title": "Data Work (ETL + EDA)",
    "section": "Make charts self-contained (labels + units)",
    "text": "Make charts self-contained (labels + units)\nfig.update_layout(title={\"x\": 0.02})\nfig.update_xaxes(title_text=\"Country\")\nfig.update_yaxes(title_text=\"Revenue (USD)\")\n\n\n\n\n\n\nTip\n\n\nIf you copy a chart into a slide with no context, it should still make sense."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#export-figures-offline-first",
    "href": "W2_Data/D4_Visual_Analysis.html#export-figures-offline-first",
    "title": "Data Work (ETL + EDA)",
    "section": "Export figures (offline-first)",
    "text": "Export figures (offline-first)\nPrefer HTML exports with embedded JS:\nfrom pathlib import Path\n\nout = Path(\"reports/figures\")\nout.mkdir(parents=True, exist_ok=True)\n\nfig.write_html(out / \"day4_revenue_by_country.html\", include_plotlyjs=\"embed\")\nOptional PNG (if Kaleido installed):\nfig.write_image(out / \"day4_revenue_by_country.png\", scale=2)"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#micro-exercise-8-minutes-fix-a-bad-chart",
    "href": "W2_Data/D4_Visual_Analysis.html#micro-exercise-8-minutes-fix-a-bad-chart",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise (8 minutes): fix a bad chart",
    "text": "Micro-exercise (8 minutes): fix a bad chart\nYou have a bar chart that:\n\nis unsorted\nhas no axis labels\nhas a vague title\n\nWrite the 3 lines to fix it.\nCheckpoint: you wrote: sort + update_layout + axis labels."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#solution-1",
    "href": "W2_Data/D4_Visual_Analysis.html#solution-1",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution",
    "text": "Solution\nd = d.sort_values(\"revenue\", ascending=False)\nfig = px.bar(d, x=\"country\", y=\"revenue\", title=\"Revenue by country (Jan–Dec 2025)\")\nfig.update_layout(title={\"x\": 0.02})\nfig.update_xaxes(title_text=\"Country\")\nfig.update_yaxes(title_text=\"Revenue (USD)\")"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#tidy-data-reminder-for-plotting",
    "href": "W2_Data/D4_Visual_Analysis.html#tidy-data-reminder-for-plotting",
    "title": "Data Work (ETL + EDA)",
    "section": "Tidy data reminder (for plotting)",
    "text": "Tidy data reminder (for plotting)\nIf you want multiple metrics on the same chart or facet:\n\nlong format is usually easiest\nuse melt() to go wide → long\n\nExample:\nlong = wide.melt(\n    id_vars=[\"month\"],\n    value_vars=[\"revenue\", \"n_orders\"],\n    var_name=\"metric\",\n    value_name=\"value\",\n)\nfig = px.line(long, x=\"month\", y=\"value\", color=\"metric\", title=\"Metrics over time\")"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#minutes-1",
    "href": "W2_Data/D4_Visual_Analysis.html#minutes-1",
    "title": "Data Work (ETL + EDA)",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: we’ll add “comparison thinking” + bootstrap intervals so our conclusions are honest."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#session-3-objectives",
    "href": "W2_Data/D4_Visual_Analysis.html#session-3-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 3 objectives",
    "text": "Session 3 objectives\nBy the end of this session, you can:\n\ncompute rates/ratios correctly (with denominators)\nreport effect sizes (absolute + relative)\nbuild a bootstrap interval for a difference in means or rates\nwrite a short, credible reports/summary.md"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#comparison-thinking-the-eda-upgrade",
    "href": "W2_Data/D4_Visual_Analysis.html#comparison-thinking-the-eda-upgrade",
    "title": "Data Work (ETL + EDA)",
    "section": "Comparison thinking (the EDA upgrade)",
    "text": "Comparison thinking (the EDA upgrade)\nWhen you compare groups, always include:\n\nn (sample size)\nabsolute difference (e.g., +$2.10)\nrelative difference (e.g., +8%)\na caveat if groups are tiny or biased\n\n\n\n\n\n\n\nWarning\n\n\nAverages without n are how analysts accidentally lie."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#ratesratios-always-show-numerator-denominator",
    "href": "W2_Data/D4_Visual_Analysis.html#ratesratios-always-show-numerator-denominator",
    "title": "Data Work (ETL + EDA)",
    "section": "Rates/ratios: always show numerator + denominator",
    "text": "Rates/ratios: always show numerator + denominator\nExample: refund rate by country\n\nnumerator: n_refund\ndenominator: n_total\nrate: n_refund / n_total\n\nYour report should show all three."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#bootstrap-intervals-practical-uncertainty",
    "href": "W2_Data/D4_Visual_Analysis.html#bootstrap-intervals-practical-uncertainty",
    "title": "Data Work (ETL + EDA)",
    "section": "Bootstrap intervals (practical uncertainty)",
    "text": "Bootstrap intervals (practical uncertainty)\nBootstrap answers: “If I re-sampled my data, how much could this estimate vary?”\nUse it when:\n\ncomparing means/medians between groups\ncomparing rates (refund rate, conversion rate)\nyou want a rough uncertainty range without heavy theory\n\nKeep it reproducible:\n\nfix a random seed"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#minimal-bootstrap-template-difference-in-means",
    "href": "W2_Data/D4_Visual_Analysis.html#minimal-bootstrap-template-difference-in-means",
    "title": "Data Work (ETL + EDA)",
    "section": "Minimal bootstrap template (difference in means)",
    "text": "Minimal bootstrap template (difference in means)\nimport numpy as np\nimport pandas as pd\n\ndef bootstrap_diff_means(a: pd.Series, b: pd.Series, *, n_boot: int = 2000, seed: int = 0) -&gt; dict:\n    rng = np.random.default_rng(seed)\n    a = pd.to_numeric(a, errors=\"coerce\").dropna().to_numpy()\n    b = pd.to_numeric(b, errors=\"coerce\").dropna().to_numpy()\n    assert len(a) &gt; 0 and len(b) &gt; 0\n\n    diffs = []\n    for _ in range(n_boot):\n        sa = rng.choice(a, size=len(a), replace=True)\n        sb = rng.choice(b, size=len(b), replace=True)\n        diffs.append(sa.mean() - sb.mean())\n\n    diffs = np.array(diffs)\n    return {\n        \"diff_mean\": float(a.mean() - b.mean()),\n        \"ci_low\": float(np.quantile(diffs, 0.025)),\n        \"ci_high\": float(np.quantile(diffs, 0.975)),\n        \"n_a\": int(len(a)),\n        \"n_b\": int(len(b)),\n    }"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#micro-exercise-7-minutes-interpret-a-bootstrap-result",
    "href": "W2_Data/D4_Visual_Analysis.html#micro-exercise-7-minutes-interpret-a-bootstrap-result",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise (7 minutes): interpret a bootstrap result",
    "text": "Micro-exercise (7 minutes): interpret a bootstrap result\nYou compute:\n\ndiff_mean = +3.2\n95% CI = [-0.4, +6.9]\n\nWrite one honest sentence.\nCheckpoint: mention uncertainty and that zero is inside the CI."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#solution-2",
    "href": "W2_Data/D4_Visual_Analysis.html#solution-2",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution",
    "text": "Solution\n“Group A’s mean is about +3.2 higher than Group B, but the bootstrap interval includes 0, so the difference is uncertain with this data (may be small or not real).”"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#writing-reportssummary.md-template",
    "href": "W2_Data/D4_Visual_Analysis.html#writing-reportssummary.md-template",
    "title": "Data Work (ETL + EDA)",
    "section": "Writing reports/summary.md (template)",
    "text": "Writing reports/summary.md (template)\nYour summary should include:\n\nKey findings (3–6 bullets with numbers)\nDefinitions (what filters/metrics mean)\nData quality caveats (missingness, join coverage, outliers)\nNext questions (what you’d check next)\n\n\n\n\n\n\n\nTip\n\n\nIf your summary can’t be read in under 2 minutes, it’s too long."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#minutes-2",
    "href": "W2_Data/D4_Visual_Analysis.html#minutes-2",
    "title": "Data Work (ETL + EDA)",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: we’ll build the Day 4 notebook and export your figures + summary."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#hands-on-success-criteria-today",
    "href": "W2_Data/D4_Visual_Analysis.html#hands-on-success-criteria-today",
    "title": "Data Work (ETL + EDA)",
    "section": "Hands-on success criteria (today)",
    "text": "Hands-on success criteria (today)\nBy the end, you should have:\n\ndata/processed/orders_features.parquet (created once, reused)\nnotebooks/day4_eda.ipynb that runs top-to-bottom\nreports/figures/ with 3–6 exports (.html required)\nreports/summary.md including at least one bootstrap CI\nat least 2 commits pushed to GitHub"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#project-layout-day-4-focus",
    "href": "W2_Data/D4_Visual_Analysis.html#project-layout-day-4-focus",
    "title": "Data Work (ETL + EDA)",
    "section": "Project layout (Day 4 focus)",
    "text": "Project layout (Day 4 focus)\ndata/\n  processed/\n    orders_enriched.parquet\n    orders_features.parquet      # NEW today\nnotebooks/\n  day4_eda.ipynb                 # NEW today\nreports/\n  figures/\n    day4_*.html                  # NEW today (required)\n    day4_*.png                   # optional (kaleido)\n  summary.md                     # NEW today\nscripts/\n  run_day4_make_features.py      # NEW today (small, idempotent)"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#task-0-create-the-notebook-folder-2-minutes",
    "href": "W2_Data/D4_Visual_Analysis.html#task-0-create-the-notebook-folder-2-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 0 — Create the notebook folder (2 minutes)",
    "text": "Task 0 — Create the notebook folder (2 minutes)\nFrom repo root:\nmkdir -p notebooks\n(Windows PowerShell)\nNew-Item -ItemType Directory -Force notebooks | Out-Null"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#task-1-build-orders_features.parquet-20-minutes",
    "href": "W2_Data/D4_Visual_Analysis.html#task-1-build-orders_features.parquet-20-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 1 — Build orders_features.parquet (20 minutes)",
    "text": "Task 1 — Build orders_features.parquet (20 minutes)\nCreate scripts/run_day4_make_features.py that:\n\nreads data/processed/orders_enriched.parquet\nparses created_at (UTC)\nadds time parts (month, dow, hour)\nflags outliers + creates amount_winsor\nwrites data/processed/orders_features.parquet (idempotent)\n\nCheckpoint: the file exists and reloading shows &gt; 0 rows."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#task-1-solution-scriptsrun_day4_make_features.py",
    "href": "W2_Data/D4_Visual_Analysis.html#task-1-solution-scriptsrun_day4_make_features.py",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 1 — Solution: scripts/run_day4_make_features.py",
    "text": "Task 1 — Solution: scripts/run_day4_make_features.py\nfrom __future__ import annotations\n\nfrom pathlib import Path\nimport pandas as pd\n\nfrom bootcamp_data.io import read_parquet, write_parquet\nfrom bootcamp_data.checks import require_columns, assert_non_empty\nfrom bootcamp_data.transforms import parse_datetime, add_time_parts, winsorize, add_outlier_flag, add_missing_flags\n\n\ndef main() -&gt; None:\n    root = Path(__file__).resolve().parents[1]\n    in_path = root / \"data\" / \"processed\" / \"orders_enriched.parquet\"\n    out_path = root / \"data\" / \"processed\" / \"orders_features.parquet\"\n\n    df = read_parquet(in_path)\n    assert_non_empty(df, df_name=\"orders_enriched\")\n    require_columns(df, [\"order_id\", \"user_id\", \"amount\", \"created_at\", \"country\", \"status_clean\"], df_name=\"orders_enriched\")\n\n    d = df.copy()\n    d = parse_datetime(d, \"created_at\", utc=True)\n    d = add_time_parts(d, \"created_at\")\n    d[\"amount_winsor\"] = winsorize(d[\"amount\"])\n    d = add_outlier_flag(d, \"amount\", k=1.5)\n    d = add_missing_flags(d, [\"amount\", \"created_at\", \"country\", \"status_clean\"])\n\n    write_parquet(d, out_path)\n    print(\"wrote:\", out_path, \"rows:\", len(d))\n\n\nif __name__ == \"__main__\":\n    main()"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#task-1-run-it-2-minutes",
    "href": "W2_Data/D4_Visual_Analysis.html#task-1-run-it-2-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 1 — Run it (2 minutes)",
    "text": "Task 1 — Run it (2 minutes)\nmacOS/Linux\nuv run python -m scripts.run_day4_make_features\nWindows PowerShell\nuv run python -m scripts.run_day4_make_features"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#task-2-create-notebooksday4_eda.ipynb-10-minutes",
    "href": "W2_Data/D4_Visual_Analysis.html#task-2-create-notebooksday4_eda.ipynb-10-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 2 — Create notebooks/day4_eda.ipynb (10 minutes)",
    "text": "Task 2 — Create notebooks/day4_eda.ipynb (10 minutes)\nIn VS Code:\n\nCreate a new notebook: notebooks/day4_eda.ipynb\nSelect the interpreter from your uv environment\nAdd a title cell + an “inputs” cell\n\n\n\n\n\n\n\nNote\n\n\nIf your notebook kernel can’t start, install ipykernel:\nuv add ipykernel"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#task-2-notebook-outline-copy-this-structure",
    "href": "W2_Data/D4_Visual_Analysis.html#task-2-notebook-outline-copy-this-structure",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 2 — Notebook outline (copy this structure)",
    "text": "Task 2 — Notebook outline (copy this structure)\nYour notebook should have these sections:\n\nLoad\nAudit (shape, dtypes, missingness, outlier rate)\nQuestions (3–6):\n\ntable → chart → interpretation (+ caveat)\n\nBootstrap comparison (1 example)\nExport figures + write reports/summary.md"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#task-3-add-reusable-helpers-copy-into-notebook",
    "href": "W2_Data/D4_Visual_Analysis.html#task-3-add-reusable-helpers-copy-into-notebook",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 3 — Add reusable helpers (copy into notebook)",
    "text": "Task 3 — Add reusable helpers (copy into notebook)\nfrom pathlib import Path\nimport pandas as pd\nimport plotly.express as px\n\nROOT = Path(\"..\")  # notebooks/ → repo root\nFIGS = ROOT / \"reports\" / \"figures\"\nFIGS.mkdir(parents=True, exist_ok=True)\n\ndef save_html(fig, name: str) -&gt; Path:\n    p = FIGS / f\"{name}.html\"\n    fig.write_html(p, include_plotlyjs=\"embed\")\n    return p"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#task-4-load-features-copy-into-notebook",
    "href": "W2_Data/D4_Visual_Analysis.html#task-4-load-features-copy-into-notebook",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 4 — Load features (copy into notebook)",
    "text": "Task 4 — Load features (copy into notebook)\ndf = pd.read_parquet(ROOT / \"data\" / \"processed\" / \"orders_features.parquet\")\ndf.head()\nCheckpoint: you see rows, and created_at is datetime-like."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#task-5-your-3-required-charts-45-minutes",
    "href": "W2_Data/D4_Visual_Analysis.html#task-5-your-3-required-charts-45-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 5 — Your 3 “required charts” (45 minutes)",
    "text": "Task 5 — Your 3 “required charts” (45 minutes)\nMake at least these three:\n\nTop countries by revenue (sorted bar)\nMonthly revenue trend (line)\nAmount distribution (histogram; consider using amount_winsor)\n\nExport each with save_html(fig, \"day4_&lt;name&gt;\")."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#task-5-example-revenue-by-country-bar",
    "href": "W2_Data/D4_Visual_Analysis.html#task-5-example-revenue-by-country-bar",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 5 — Example: revenue by country (bar)",
    "text": "Task 5 — Example: revenue by country (bar)\nby_country = (\n    df.groupby(\"country\", dropna=False)[\"amount\"]\n      .sum(min_count=1)\n      .rename(\"revenue\")\n      .reset_index()\n      .sort_values(\"revenue\", ascending=False)\n      .head(15)\n)\n\nfig = px.bar(by_country, x=\"country\", y=\"revenue\", title=\"Revenue by country (top 15)\")\nfig.update_layout(title={\"x\": 0.02})\nfig.update_xaxes(title_text=\"Country\")\nfig.update_yaxes(title_text=\"Revenue\")\nsave_html(fig, \"day4_revenue_by_country\")"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#task-6-bootstrap-pick-one-comparison-25-minutes",
    "href": "W2_Data/D4_Visual_Analysis.html#task-6-bootstrap-pick-one-comparison-25-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 6 — Bootstrap: pick one comparison (25 minutes)",
    "text": "Task 6 — Bootstrap: pick one comparison (25 minutes)\nChoose one:\n\nmean amount in top country vs 2nd country\nmean amount for paid vs refund\nrefund rate in top country vs all others\n\nCompute a bootstrap interval and include it as a bullet in your summary."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#task-6-example-bootstrap-mean-difference-two-countries",
    "href": "W2_Data/D4_Visual_Analysis.html#task-6-example-bootstrap-mean-difference-two-countries",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 6 — Example: bootstrap mean difference (two countries)",
    "text": "Task 6 — Example: bootstrap mean difference (two countries)\nimport numpy as np\n\ntop2 = by_country[\"country\"].head(2).tolist()\na = df.loc[df[\"country\"].eq(top2[0]), \"amount\"]\nb = df.loc[df[\"country\"].eq(top2[1]), \"amount\"]\n\nres = bootstrap_diff_means(a, b, n_boot=2000, seed=0)\nres\nInterpretation rule: if CI crosses 0, be cautious."
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#task-7-write-reportssummary.md-from-the-notebook-20-minutes",
    "href": "W2_Data/D4_Visual_Analysis.html#task-7-write-reportssummary.md-from-the-notebook-20-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 7 — Write reports/summary.md from the notebook (20 minutes)",
    "text": "Task 7 — Write reports/summary.md from the notebook (20 minutes)\nMinimum content:\n\n3–6 bullet findings (with numbers)\n1 bootstrap result bullet (diff + CI + n)\ncaveats (missingness, join coverage, outliers)\nlinks to exported figures"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#task-7-example-summary-writer-copy-into-notebook",
    "href": "W2_Data/D4_Visual_Analysis.html#task-7-example-summary-writer-copy-into-notebook",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 7 — Example summary writer (copy into notebook)",
    "text": "Task 7 — Example summary writer (copy into notebook)\nsummary = f\"\"\"# Project Summary (Day 4)\n\n## Key findings\n- Top revenue country: **{by_country.iloc[0]['country']}** (revenue={by_country.iloc[0]['revenue']:.2f})\n- (Add 2–4 more bullets from your tables/charts.)\n- Bootstrap mean diff ({top2[0]} - {top2[1]}): **{res['diff_mean']:.2f}** (95% CI [{res['ci_low']:.2f}, {res['ci_high']:.2f}], n={res['n_a']} vs {res['n_b']})\n\n## Figures\n- [Revenue by country](figures/day4_revenue_by_country.html)\n- (Add your other figure links.)\n\n## Caveats / assumptions\n- Totals use raw `amount`; `amount_winsor` is for visualization only.\n- Outliers are flagged, not removed.\n- Date parsing errors become missing timestamps.\n\"\"\"\n\nout = ROOT / \"reports\" / \"summary.md\"\nout.write_text(summary, encoding=\"utf-8\")\nprint(\"wrote:\", out)"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#task-8-git-checkpoint-5-minutes",
    "href": "W2_Data/D4_Visual_Analysis.html#task-8-git-checkpoint-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 8 — Git checkpoint (5 minutes)",
    "text": "Task 8 — Git checkpoint (5 minutes)\nCommit your Day 4 deliverables.\ngit add -A\ngit commit -m \"w2d4: plotly EDA notebook + figures + summary\"\ngit push"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#debug-playbook-day-4",
    "href": "W2_Data/D4_Visual_Analysis.html#debug-playbook-day-4",
    "title": "Data Work (ETL + EDA)",
    "section": "Debug playbook (Day 4)",
    "text": "Debug playbook (Day 4)\nIf you get stuck:\n\nConfirm you’re in the repo root (paths matter)\nRebuild inputs: run Day 2 again (scripts.run_day2_validate_and_report)\nIf Plotly import fails: uv add plotly\nIf notebook kernel fails: uv add ipykernel\nIf a chart looks wrong: check the table first (row counts + sorting)\nIf bootstrap looks unstable: print group sizes; avoid tiny groups"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#exit-ticket",
    "href": "W2_Data/D4_Visual_Analysis.html#exit-ticket",
    "title": "Data Work (ETL + EDA)",
    "section": "Exit Ticket",
    "text": "Exit Ticket\nIn 1–2 sentences:\nHow do you decide between a bar chart, line chart, histogram, and scatter plot? (Answer using: question type + variable types.)"
  },
  {
    "objectID": "W2_Data/D4_Visual_Analysis.html#day-4-assignment-end-of-day",
    "href": "W2_Data/D4_Visual_Analysis.html#day-4-assignment-end-of-day",
    "title": "Data Work (ETL + EDA)",
    "section": "Day 4 assignment (end of day)",
    "text": "Day 4 assignment (end of day)\nDue: before Day 5 starts (2025-12-25)\n\nNotebook: notebooks/day4_eda.ipynb runs top-to-bottom\nExport at least 3 Plotly figures to reports/figures/*.html\nWrite reports/summary.md including one bootstrap CI\nPush at least 2 commits (one mid-way, one final)\n\n\n\n\n\n\n\nTip\n\n\nIf your repo ignores data/processed/, that’s fine—your scripts must recreate it reliably."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#policy-genai-usage",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#policy-genai-usage",
    "title": "Data Work (ETL + EDA)",
    "section": "Policy: GenAI usage",
    "text": "Policy: GenAI usage\n\n✅ Allowed: clarifying questions (definitions, error explanations)\n❌ Not allowed: generating code, writing solutions, or debugging by copy-paste\nIf unsure: ask the instructor first\n\n\n\n\n\n\n\nTip\n\n\nIn this course: you build skill by typing, running, breaking, and fixing."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#todays-flow",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#todays-flow",
    "title": "Data Work (ETL + EDA)",
    "section": "Today’s Flow",
    "text": "Today’s Flow\n\nSession 1 (60m): Datetime parsing + time parts\nAsr Prayer (20m)\nSession 2 (60m): Outliers + sanity checks + core pandas ops\nMaghrib Prayer (20m)\nSession 3 (60m): Safe joins + join validation + .pipe() design\nIsha Prayer (20m)\nHands-on (120m): Build analytics_table.parquet (time + join + outlier flags)"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#learning-objectives",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#learning-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of today, you can:\n\nparse datetime columns safely using pd.to_datetime(..., errors=\"coerce\")\nadd time parts (date/month/day-of-week/hour) for grouping\nidentify outliers using percentiles / IQR and choose a safe policy\nuse core pandas ops for real work (.loc, .assign, groupby/agg)\njoin tables safely with merge(validate=...) and detect join explosions\nwrite data/processed/analytics_table.parquet"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#warm-up-5-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#warm-up-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Warm-up (5 minutes)",
    "text": "Warm-up (5 minutes)\nRun Day 2 and confirm cleaned output exists.\nmacOS/Linux\nsource .venv/bin/activate\npython scripts/run_day2_clean.py\npython -c \"import pandas as pd; df=pd.read_parquet('data/processed/orders_clean.parquet'); print(len(df)); print(df.dtypes)\"\nWindows PowerShell\n.\\\\.venv\\\\Scripts\\\\Activate.ps1\npython scripts\\\\run_day2_clean.py\npython -c \"import pandas as pd; df=pd.read_parquet('data/processed/orders_clean.parquet'); print(len(df)); print(df.dtypes)\"\nCheckpoint: orders_clean.parquet exists and loads without errors."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#where-we-are-in-the-weekly-workflow",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#where-we-are-in-the-weekly-workflow",
    "title": "Data Work (ETL + EDA)",
    "section": "Where we are in the weekly workflow",
    "text": "Where we are in the weekly workflow\nCanonical flow:\n\nLoad ✅\nVerify ✅\nClean ✅\nTransform ✅ (today starts)\nAnalyze (Day 4)\nVisualize (Day 4)\nConclude (Day 5)"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#session-1-objectives",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#session-1-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 1 objectives",
    "text": "Session 1 objectives\nBy the end of this session, you can:\n\nexplain why datetime parsing is a correctness problem\nparse timestamps safely with errors=\"coerce\"\nhandle time zones intentionally (naive vs UTC-aware)\nadd time parts for grouping (month, day-of-week, hour)"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#context-time-based-analysis-is-fragile",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#context-time-based-analysis-is-fragile",
    "title": "Data Work (ETL + EDA)",
    "section": "Context: time-based analysis is fragile",
    "text": "Context: time-based analysis is fragile\nIf time is wrong, you get wrong:\n\ntrends\ncohorts\n“before vs after”\n“most recent” sorting\n\nDatetime mistakes often don’t crash — they silently lie."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-timestamps-vs-strings",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-timestamps-vs-strings",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: timestamps vs strings",
    "text": "Concept: timestamps vs strings\nA timestamp should be:\n\na real datetime type (datetime64[ns], often UTC-aware)\nsortable by time\ngroupable by month/week/day\n\nA string “looks like time” but behaves like text."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#quick-demo-sorting-strings-can-mislead",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#quick-demo-sorting-strings-can-mislead",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick demo: sorting strings can mislead",
    "text": "Quick demo: sorting strings can mislead\nIf you sort strings:\n\n\"2025-2-1\" may come after \"2025-12-1\" (lexicographic)\n\nIf you sort datetimes:\n\nyou get true chronological order"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-safe-parsing-default",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-safe-parsing-default",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: safe parsing default",
    "text": "Concept: safe parsing default\nUse:\n\npd.to_datetime(..., errors=\"coerce\", utc=True)\n\nWhy?\n\ninvalid formats become missing (you can measure/fix)\nutc=True prevents mixing naive and aware timestamps"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#example-parse_datetimedf-col",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#example-parse_datetimedf-col",
    "title": "Data Work (ETL + EDA)",
    "section": "Example: parse_datetime(df, col)",
    "text": "Example: parse_datetime(df, col)\nimport pandas as pd\n\ndef parse_datetime(df: pd.DataFrame, col: str, *, utc: bool = True)\n                   -&gt; pd.DataFrame:\ndt = pd.to_datetime(df[col], errors=\"coerce\", utc=utc)\nreturn df.assign(**{col: dt})"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-parse-created_at-6-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-parse-created_at-6-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: parse created_at (6 minutes)",
    "text": "Micro-exercise: parse created_at (6 minutes)\n\nLoad data/processed/orders_clean.parquet\nParse created_at using errors=\"coerce\" and utc=True\nCount missing timestamps after parsing\n\nCheckpoint: created_at dtype becomes datetime and you can count missing values."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-example",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-example",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\nimport pandas as pd\n\norders = pd.read_parquet(\"data/processed/orders_clean.parquet\")\norders2 = parse_datetime(orders, \"created_at\", utc=True)\n\nprint(orders2[\"created_at\"].dtype)\nprint(\"n_missing_created_at:\", orders2[\"created_at\"].isna().sum())"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#quick-check",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#quick-check",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: What does errors=\"coerce\" do?\n\nAnswer: invalid datetime strings become missing values instead of raising an exception."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#pitfall-ambiguous-date-formats",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#pitfall-ambiguous-date-formats",
    "title": "Data Work (ETL + EDA)",
    "section": "Pitfall: ambiguous date formats",
    "text": "Pitfall: ambiguous date formats\n03/04/2025 could be:\n\nMarch 4 (MM/DD)\nApril 3 (DD/MM)\n\nRule: don’t guess. If you have ambiguous formats, you need a plan."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-time-zones-naive-vs-aware",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-time-zones-naive-vs-aware",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: time zones (naive vs aware)",
    "text": "Concept: time zones (naive vs aware)\n\nNaive: no timezone info (dangerous when mixing sources)\nAware: has timezone (e.g., UTC)\n\nOperational default:\n\nstore event timestamps in UTC\nconvert to local time only for display (later)"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#quick-check-1",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#quick-check-1",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: If some timestamps are UTC and some are local time, what breaks?\n\nAnswer: comparisons and ordering (you might put events in the wrong day/hour)."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-add-time-parts-for-grouping",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-add-time-parts-for-grouping",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: add time parts for grouping",
    "text": "Concept: add time parts for grouping\nCommon derived fields:\n\ndate (for daily tables)\nmonth (for trend grouping)\ndow (day-of-week)\nhour (hour-of-day)\n\nThese turn “timestamp” into “group keys”."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#example-add_time_partsdf-ts_col",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#example-add_time_partsdf-ts_col",
    "title": "Data Work (ETL + EDA)",
    "section": "Example: add_time_parts(df, ts_col)",
    "text": "Example: add_time_parts(df, ts_col)\nimport pandas as pd\n\ndef add_time_parts(df: pd.DataFrame, ts_col: str) \n                  -&gt; pd.DataFrame:\nts = df[ts_col]\nreturn df.assign(\ndate=ts.dt.date,\nyear=ts.dt.year,\nmonth=ts.dt.to_period(\"M\").astype(\"string\"),\ndow=ts.dt.day_name(),\nhour=ts.dt.hour,\n)"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-add-month-day-of-week-6-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-add-month-day-of-week-6-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: add month + day-of-week (6 minutes)",
    "text": "Micro-exercise: add month + day-of-week (6 minutes)\n\nParse created_at\nAdd time parts\nPrint the first 5 rows of: created_at, month, dow, hour\n\nCheckpoint: these columns exist and look reasonable."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-example-1",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-example-1",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\norders3 = (\n    orders.pipe(parse_datetime, col=\"created_at\", utc=True)\n          .pipe(add_time_parts, ts_col=\"created_at\")\n)\n\nprint(orders3[[\"created_at\",\"month\",\"dow\",\"hour\"]].head())"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#why-we-used-.pipe-here",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#why-we-used-.pipe-here",
    "title": "Data Work (ETL + EDA)",
    "section": "Why we used .pipe() here",
    "text": "Why we used .pipe() here\n.pipe() helps you read transformations top-to-bottom:\n\nload\nparse\nadd time parts\n\nThis is the “pure functions” style we’ll use all week."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-one-question-you-can-now-answer-3-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-one-question-you-can-now-answer-3-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: one question you can now answer (3 minutes)",
    "text": "Micro-exercise: one question you can now answer (3 minutes)\nWrite ONE question you can answer now that you have month and dow.\nExamples:\n\n“How many orders per month?”\n“Do refunds happen more on certain days?”\n\nCheckpoint: a single, measurable sentence."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-good-time-based-questions",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-good-time-based-questions",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution: good time-based questions",
    "text": "Solution: good time-based questions\nExamples:\n\n“How many orders per month (n)?”\n“What is refund rate by day-of-week?”\n“What hour has the most orders?”\n\nThe key: quantify and compare."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#quick-check-2",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#quick-check-2",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: Why do we add time parts instead of grouping by raw timestamps?\n\nAnswer: raw timestamps are too granular; time parts create useful group keys (month/day/hour)."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#session-1-recap",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#session-1-recap",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 1 recap",
    "text": "Session 1 recap\n\nParse timestamps safely (errors=\"coerce\", often utc=True)\nMeasure invalid timestamps (missing after parse)\nAdd time parts to make grouping easy (month/dow/hour)\nPrefer pipelines of pure transforms with .pipe()"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: we’ll handle outliers and practice pandas ops that matter daily."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#session-2-objectives",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#session-2-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 2 objectives",
    "text": "Session 2 objectives\nBy the end of this session, you can:\n\nexplain why outliers distort averages and charts\ncompute percentile summaries (p1/p50/p99)\ncompute IQR bounds and flag outliers\nchoose a safe outlier policy (flag / cap for visualization)"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#session-2-objectives-1",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#session-2-objectives-1",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 2 objectives",
    "text": "Session 2 objectives\nBy the end of this session, you can:\n\nuse core pandas operations:\n\nselection (.loc)\nassignment (.assign)\ngroupby/agg for totals and rates"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#context-outliers-are-not-always-bad",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#context-outliers-are-not-always-bad",
    "title": "Data Work (ETL + EDA)",
    "section": "Context: outliers are not always “bad”",
    "text": "Context: outliers are not always “bad”\nOutliers could be:\n\ndata entry errors (wrong units)\ngenuine rare events (VIP purchases)\nfraud spikes\nprice changes\n\nRule: don’t delete first. Identify + decide."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-why-outliers-distort-means",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-why-outliers-distort-means",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: why outliers distort means",
    "text": "Concept: why outliers distort means\nMean is sensitive to extremes.\nIf one order is 1000× bigger than others:\n\nmean revenue jumps\ncharts flatten\n“typical order” becomes misleading\n\nBetter: include median and percentiles."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#quick-check-3",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#quick-check-3",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: Which is more robust to outliers: mean or median?\n\nAnswer: median."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-start-with-percentiles",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-start-with-percentiles",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: start with percentiles",
    "text": "Concept: start with percentiles\nA simple first look:\n\np50 (median)\np90\np99\n\nIf p99 is wildly larger than p50, you likely have a heavy tail or errors."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#example-percentile-summary-tiny",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#example-percentile-summary-tiny",
    "title": "Data Work (ETL + EDA)",
    "section": "Example: percentile summary (tiny)",
    "text": "Example: percentile summary (tiny)\ns = orders[\"amount\"].dropna()\nprint(s.quantile([0.5, 0.9, 0.99]))"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-compute-p50p90p99-6-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-compute-p50p90p99-6-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: compute p50/p90/p99 (6 minutes)",
    "text": "Micro-exercise: compute p50/p90/p99 (6 minutes)\n\nLoad orders_clean.parquet\nCompute p50, p90, p99 for amount (ignore missing)\nWrite down the numbers\n\nCheckpoint: you can explain what each percentile means."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-example-2",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-example-2",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\nimport pandas as pd\norders = pd.read_parquet(\"data/processed/orders_clean.parquet\")\ns = orders[\"amount\"].dropna()\nprint(s.quantile([0.5, 0.9, 0.99]))"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-iqr-bounds-practical",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-iqr-bounds-practical",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: IQR bounds (practical)",
    "text": "Concept: IQR bounds (practical)\nIQR method:\n\nQ1 = 25th percentile\nQ3 = 75th percentile\nIQR = Q3 - Q1\nbounds: [Q1 - 1.5*IQR, Q3 + 1.5*IQR]\n\nWe use bounds to flag “extreme” values."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#example-iqr_boundss",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#example-iqr_boundss",
    "title": "Data Work (ETL + EDA)",
    "section": "Example: iqr_bounds(s)",
    "text": "Example: iqr_bounds(s)\ndef iqr_bounds(s, k=1.5):\n    q1 = s.quantile(0.25)\n    q3 = s.quantile(0.75)\n    iqr = q3 - q1\n    return float(q1 - k*iqr), float(q3 + k*iqr)"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-count-outliers-7-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-count-outliers-7-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: count outliers (7 minutes)",
    "text": "Micro-exercise: count outliers (7 minutes)\n\nCompute IQR bounds for amount\nCount how many rows are outside bounds\n\nCheckpoint: you can print n_outliers."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-example-3",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-example-3",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\nimport pandas as pd\n\norders = pd.read_parquet(\"data/processed/orders_clean.parquet\")\ns = orders[\"amount\"].dropna()\n\nlo, hi = iqr_bounds(s, k=1.5)\nn_out = ((orders[\"amount\"] &lt; lo) | (orders[\"amount\"] &gt; hi)).sum()\nprint(\"bounds:\", lo, hi)\nprint(\"n_outliers:\", int(n_out))"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-safe-outlier-policy-for-eda",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-safe-outlier-policy-for-eda",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: safe outlier policy for EDA",
    "text": "Concept: safe outlier policy for EDA\nGood defaults for Week 2 analytics work:\n\nkeep rows (don’t delete silently)\nadd an is_outlier flag\noptionally create a capped version for charts (winsorize)"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#example-winsorize-cap-for-viz",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#example-winsorize-cap-for-viz",
    "title": "Data Work (ETL + EDA)",
    "section": "Example: winsorize (cap for viz)",
    "text": "Example: winsorize (cap for viz)\ndef winsorize(s, lo=0.01, hi=0.99):\n    a, b = s.quantile(lo), s.quantile(hi)\n    return s.clip(lower=a, upper=b)"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-create-amount_winsor-6-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-create-amount_winsor-6-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: create amount_winsor (6 minutes)",
    "text": "Micro-exercise: create amount_winsor (6 minutes)\nCreate a new column:\n\namount_winsor = winsorize(amount, 0.01, 0.99)\n\nCheckpoint: min/max of amount_winsor are within p1/p99."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-example-4",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-example-4",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\norders2 = orders.assign(amount_winsor=winsorize(orders[\"amount\"]))\nprint(orders2[\"amount_winsor\"].min(), orders2[\"amount_winsor\"].max())"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#quick-check-4",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#quick-check-4",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: Why do we cap values for visualization instead of deleting outliers?\n\nAnswer: deletion can remove real events; capping preserves rows while making charts readable."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#transition-pandas-operations-youll-use-daily",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#transition-pandas-operations-youll-use-daily",
    "title": "Data Work (ETL + EDA)",
    "section": "Transition: pandas operations you’ll use daily",
    "text": "Transition: pandas operations you’ll use daily\nMost data work is:\n\nselect rows/columns\nassign new columns\ngroup and aggregate\nreshape occasionally\n\nYou don’t need 100 pandas tricks — you need a few high-ROI ones."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#core-pattern-1-selection-with-.loc",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#core-pattern-1-selection-with-.loc",
    "title": "Data Work (ETL + EDA)",
    "section": "Core pattern 1: selection with .loc",
    "text": "Core pattern 1: selection with .loc\n\n\n\n\n\n\nTip\n\n\nAvoid chained indexing. Use .loc[...] for clarity and correctness.\n\n\n\nExample:\npaid = orders.loc[orders[\"status_clean\"].eq(\"paid\"), [\"user_id\",\"amount\"]]"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-filter-paid-orders-5-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-filter-paid-orders-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: filter “paid” orders (5 minutes)",
    "text": "Micro-exercise: filter “paid” orders (5 minutes)\n\nFilter rows where status_clean == \"paid\"\nKeep columns: user_id, amount\nCount rows\n\nCheckpoint: you can print n_paid."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-example-5",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-example-5",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\npaid = orders.loc[orders[\"status_clean\"].eq(\"paid\"), [\"user_id\",\"amount\"]]\nprint(\"n_paid:\", len(paid))"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#core-pattern-2-assignment-with-.assign",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#core-pattern-2-assignment-with-.assign",
    "title": "Data Work (ETL + EDA)",
    "section": "Core pattern 2: assignment with .assign",
    "text": "Core pattern 2: assignment with .assign\nUse .assign() to add columns without messing with chained assignment.\nExample:\norders2 = orders.assign(amount_usd=lambda d: d[\"amount\"] * 1.0)"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-add-a-boolean-column-4-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-add-a-boolean-column-4-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: add a boolean column (4 minutes)",
    "text": "Micro-exercise: add a boolean column (4 minutes)\nAdd:\n\nis_refund = (status_clean == \"refund\")\n\nCheckpoint: is_refund exists and contains True/False."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-example-6",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-example-6",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\norders2 = orders.assign(is_refund=orders[\"status_clean\"].eq(\"refund\"))\nprint(orders2[\"is_refund\"].value_counts(dropna=False))"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#core-pattern-3-groupbyagg",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#core-pattern-3-groupbyagg",
    "title": "Data Work (ETL + EDA)",
    "section": "Core pattern 3: groupby/agg",
    "text": "Core pattern 3: groupby/agg\nMost analytics tables come from:\n\ngroupby\nagg\nreset_index\n\nExample pattern:\nsummary = (\n  orders.groupby(\"user_id\")\n        .agg(n=(\"order_id\",\"size\"), revenue=(\"amount\",\"sum\"))\n        .reset_index()\n)"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-revenue-per-user-7-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-revenue-per-user-7-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: revenue per user (7 minutes)",
    "text": "Micro-exercise: revenue per user (7 minutes)\nCompute per-user summary:\n\nn_orders\nrevenue (sum of amount)\n\nCheckpoint: you produce a DataFrame with one row per user."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-example-7",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-example-7",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\nper_user = (\n    orders.groupby(\"user_id\", dropna=False)\n          .agg(\n              n_orders=(\"order_id\", \"size\"),\n              revenue=(\"amount\", \"sum\"),\n              aov=(\"amount\", \"mean\"), #Average Order Value\n              med_amount=(\"amount\", \"median\"),\n          )\n          .reset_index()\n)\nprint(per_user)"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-rates-need-numerator-denominator",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-rates-need-numerator-denominator",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: rates need numerator + denominator",
    "text": "Concept: rates need numerator + denominator\n“Refund rate” example:\n\nnumerator: number of refunds\ndenominator: total orders\n\nAlways show both, then compute the ratio."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#example-refund-rate-table-pattern",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#example-refund-rate-table-pattern",
    "title": "Data Work (ETL + EDA)",
    "section": "Example: refund rate table (pattern)",
    "text": "Example: refund rate table (pattern)\nrate = (\n    orders.assign(is_refund=orders[\"status_clean\"].eq(\"refund\"))\n          .groupby(\"user_id\")\n          .agg(refunds=(\"is_refund\",\"sum\"), total=(\"is_refund\",\"size\"))\n          # The sum here counts the True (refunded) rows only. \n          # While the size counts the entire column \n          # (The aggregate is still just a boolean mask)\n          .assign(refund_rate=lambda t: t[\"refunds\"] / t[\"total\"])\n          .reset_index()\n)"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#quick-check-5",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#quick-check-5",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: Why should you include sample size (total) with a rate?\n\nAnswer: because rates from small groups are noisy and misleading."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#optional-tidy-data-mental-model-preview",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#optional-tidy-data-mental-model-preview",
    "title": "Data Work (ETL + EDA)",
    "section": "Optional: tidy data mental model (preview)",
    "text": "Optional: tidy data mental model (preview)\nTidy idea:\n\neach variable is a column\neach observation is a row\neach observational unit is a table\n\nWe reshape when data is not tidy."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#example-wide-long-with-melt",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#example-wide-long-with-melt",
    "title": "Data Work (ETL + EDA)",
    "section": "Example: wide → long with melt",
    "text": "Example: wide → long with melt\nlong = df.melt(\n    id_vars=[\"user_id\",\"date\"],\n    value_vars=[\"clicks\",\"views\"],\n    var_name=\"metric\",\n    value_name=\"value\",\n)"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-predict-the-output-3-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-predict-the-output-3-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: predict the output (3 minutes)",
    "text": "Micro-exercise: predict the output (3 minutes)\nIf metric is \"clicks\" and \"views\":\n\nhow many rows will long have compared to the original?\n\nCheckpoint: answer in one sentence."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-predict-the-output",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-predict-the-output",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution: predict the output",
    "text": "Solution: predict the output\nIf you melt 2 value columns, you usually get about 2× as many rows (one row per metric per original row)."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#session-2-recap",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#session-2-recap",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 2 recap",
    "text": "Session 2 recap\n\nStart with percentiles and IQR to understand outliers\nPrefer: flag outliers + cap for visualization (don’t delete silently)\nUse high-ROI pandas ops:\n\n.loc, .assign, groupby/agg\n\nRates require numerator + denominator"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#minutes-1",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#minutes-1",
    "title": "Data Work (ETL + EDA)",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: we’ll join orders + users safely and prevent join explosions."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#session-3-objectives",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#session-3-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 3 objectives",
    "text": "Session 3 objectives\nBy the end of this session, you can:\n\nexplain common join types (left / inner / outer) in operational terms\nprevent join explosions with key checks + validate=...\ndetect key dtype mismatches (\"001\" vs 1)\nimplement a safe_left_join(...) helper\nbuild an “analytics table” from orders + users"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#context-joins-are-the-1-analytics-disaster",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#context-joins-are-the-1-analytics-disaster",
    "title": "Data Work (ETL + EDA)",
    "section": "Context: joins are the #1 analytics disaster",
    "text": "Context: joins are the #1 analytics disaster\nMost wrong dashboards come from wrong joins:\n\nduplicated rows (join explosion)\nmissing matches (dtype mismatch)\nsilently dropped data (inner join used by accident)\n\nWe prevent this with pre-checks + validation."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-join-types-operational-meaning",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-join-types-operational-meaning",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: join types (operational meaning)",
    "text": "Concept: join types (operational meaning)\n\nLeft join: keep all rows from main table, enrich with lookup (most common)\nInner join: keep only matches (can silently drop data)\nOuter join: reconciliation (see what’s missing on each side)"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#quick-check-6",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#quick-check-6",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: If you want to keep all orders, which join is most appropriate?\n\nAnswer: left join (orders left, users right)."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-join-cardinality-why-validation-exists",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-join-cardinality-why-validation-exists",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: join cardinality (why validation exists)",
    "text": "Concept: join cardinality (why validation exists)\nCommon situations:\n\norders (many) → users (one)\nevents (many) → lookup table (one)\n\nIf “one side” isn’t unique, your left join can multiply rows.\nThat’s a join explosion."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#example-the-row-count-rule-of-thumb",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#example-the-row-count-rule-of-thumb",
    "title": "Data Work (ETL + EDA)",
    "section": "Example: the row count rule of thumb",
    "text": "Example: the row count rule of thumb\nFor a true left join:\n\nlen(joined) == len(left) should hold\n\nIf rows increased:\n\nyou probably joined on a non-unique key (many-to-many)"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-join-sanity-check-3-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-join-sanity-check-3-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: join sanity check (3 minutes)",
    "text": "Micro-exercise: join sanity check (3 minutes)\nIf orders has 10 rows and users has 4 rows…\nAfter a left join of orders onto users, how many rows should you have?\nCheckpoint: answer with a number (and why)."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-join-sanity-check",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-join-sanity-check",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution: join sanity check",
    "text": "Solution: join sanity check\nYou should still have 10 rows (all orders remain). If you got &gt;10, you likely had a join explosion."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#pitfall-dtype-mismatch-breaks-matches",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#pitfall-dtype-mismatch-breaks-matches",
    "title": "Data Work (ETL + EDA)",
    "section": "Pitfall: dtype mismatch breaks matches",
    "text": "Pitfall: dtype mismatch breaks matches\nIf orders.user_id is \"0007\" (string) but users.user_id is 7 (int):\n\njoin matches fail\nenriched columns become missing (NaN)\n\nThis is why Day 1 forced IDs as strings."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-spot-the-mismatch-4-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-spot-the-mismatch-4-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: spot the mismatch (4 minutes)",
    "text": "Micro-exercise: spot the mismatch (4 minutes)\nWhich join keys will match?\n\nleft has \"001\", right has \"001\"\nleft has \"001\", right has 1\nleft has 1, right has 1\n\nCheckpoint: choose A/B/C that will match."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-spot-the-mismatch",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-spot-the-mismatch",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution: spot the mismatch",
    "text": "Solution: spot the mismatch\n\nA matches (string == string)\nB does not match (string != int)\nC matches (int == int)"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-validate-joins-with-pandas",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-validate-joins-with-pandas",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: validate joins with pandas",
    "text": "Concept: validate joins with pandas\nPandas merge supports validate= to enforce expected cardinality.\nExamples:\n\n\"many_to_one\": left may repeat keys; right must be unique\n\"one_to_one\": both sides unique\n\"many_to_many\": allowed, but dangerous for analytics tables"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#example-safe-left-join-helper",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#example-safe-left-join-helper",
    "title": "Data Work (ETL + EDA)",
    "section": "Example: safe left join helper",
    "text": "Example: safe left join helper\nimport pandas as pd\n\ndef safe_left_join(left: pd.DataFrame, right: pd.DataFrame, on,\\\n   *, validate: str, suffixes=(\"\", \"_r\")):\n  \n  return left.merge(right,how=\"left\", \n                    on=on,validate=validate,\n                    suffixes=suffixes,\n)"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-choose-validate-option-3-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-choose-validate-option-3-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: choose validate option (3 minutes)",
    "text": "Micro-exercise: choose validate option (3 minutes)\nWe join:\n\norders (many rows per user)\nusers (one row per user)\n\nWhich validate is correct?\n\none_to_one\nmany_to_one\nmany_to_many\n\nCheckpoint: choose A/B/C."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-choose-validate-option",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-choose-validate-option",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution: choose validate option",
    "text": "Solution: choose validate option\nB) many_to_one (many orders map to one user)."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-pre-check-the-one-side",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-pre-check-the-one-side",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: pre-check the “one” side",
    "text": "Concept: pre-check the “one” side\nBefore joining, assert the lookup table is unique:\n\nassert_unique_key(users, \"user_id\")\n\nThis catches join explosions early."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#debug-drill-reproduce-a-join-explosion-predict",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#debug-drill-reproduce-a-join-explosion-predict",
    "title": "Data Work (ETL + EDA)",
    "section": "Debug drill: reproduce a join explosion (predict)",
    "text": "Debug drill: reproduce a join explosion (predict)\nImagine users accidentally has two rows for user_id=\"0001\".\nWhat happens to orders for \"0001\" after a left join?\n\nAnswer: each order for \"0001\" duplicates (row count increases)."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#example-post-join-checks-row-count-match-rate",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#example-post-join-checks-row-count-match-rate",
    "title": "Data Work (ETL + EDA)",
    "section": "Example: post-join checks (row count + match rate)",
    "text": "Example: post-join checks (row count + match rate)\nAfter join:\n\nassert row count didn’t change\nmeasure match rate in new columns (e.g., country missing rate)\n\nThese are cheap and powerful."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-join-and-check-row-count-7-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-join-and-check-row-count-7-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: join and check row count (7 minutes)",
    "text": "Micro-exercise: join and check row count (7 minutes)\n\nLoad orders_clean.parquet and users.parquet\nRun assert_unique_key(users, \"user_id\")\nJoin with safe_left_join(..., validate=\"many_to_one\")\nAssert row count stayed the same\n\nCheckpoint: join succeeds and row counts match."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-example-8",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-example-8",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\nimport pandas as pd\nfrom bootcamp_data.quality import assert_unique_key\nfrom bootcamp_data.transforms import parse_datetime, add_time_parts\nfrom bootcamp_data.joins import safe_left_join  # (we'll create this in hands-on)\n\norders = pd.read_parquet(\"data/processed/orders_clean.parquet\")\nusers  = pd.read_parquet(\"data/processed/users.parquet\")\n\nassert_unique_key(users, \"user_id\")\n\njoined = safe_left_join(orders, users, on=\"user_id\", validate=\"many_to_one\", suffixes=(\"\", \"_user\"))\nassert len(joined) == len(orders), \"Row count changed (possible join explosion)\"\nprint(joined[[\"user_id\",\"country\"]].head())\n\nIf bootcamp_data.joins does not exist yet, they will implement it in hands-on."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#quick-check-7",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#quick-check-7",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: What does validate=\"many_to_one\" protect you from?\n\nAnswer: it prevents “users” from having duplicate keys that would multiply rows in the join."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-transformation-design-pure-functions-piping",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#concept-transformation-design-pure-functions-piping",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: transformation design (pure functions + piping)",
    "text": "Concept: transformation design (pure functions + piping)\nGood ETL design:\n\ntransforms are pure: df -&gt; df\nI/O is separate from transforms\npipelines read top-to-bottom via .pipe()\n\nThis makes your ETL readable and testable."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#example-analytics-table-builder-pattern",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#example-analytics-table-builder-pattern",
    "title": "Data Work (ETL + EDA)",
    "section": "Example: analytics table builder (pattern)",
    "text": "Example: analytics table builder (pattern)\ndef build_analytics_table(orders, users):\n    return (\n    orders\n    .pipe(parse_datetime, col=\"created_at\", utc=True)\n    .pipe(add_time_parts, ts_col=\"created_at\")\n    .pipe(lambda d: safe_left_join(d, users, on=\"user_id\",\n        validate=\"many_to_one\", suffixes=(\"\", \"_user\")))\n    )"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-explain-the-pipeline-3-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#micro-exercise-explain-the-pipeline-3-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: explain the pipeline (3 minutes)",
    "text": "Micro-exercise: explain the pipeline (3 minutes)\nIn one sentence:\nWhat does each .pipe(...) step do?\nCheckpoint: you can narrate the pipeline without looking at code details."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-explain-the-pipeline",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-explain-the-pipeline",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution: explain the pipeline",
    "text": "Solution: explain the pipeline\n\nparse time → adds datetime type\nadd time parts → creates grouping keys\nsafe left join → enrich orders with user fields without row explosions"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#session-3-recap",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#session-3-recap",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 3 recap",
    "text": "Session 3 recap\n\nLeft join is the default for analytics enrichment\nValidate cardinality with merge(validate=...)\nPre-check uniqueness on the “one” side\nPost-check row count + match rate\nUse pure transforms + .pipe() to build an analytics-ready table"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#minutes-2",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#minutes-2",
    "title": "Data Work (ETL + EDA)",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: we’ll implement datetime + outlier + join helpers and write analytics_table.parquet."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#hands-on-success-criteria-today",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#hands-on-success-criteria-today",
    "title": "Data Work (ETL + EDA)",
    "section": "Hands-on success criteria (today)",
    "text": "Hands-on success criteria (today)\nBy the end, you should have:\n\ndatetime helpers in transforms.py:\n\nparse_datetime, add_time_parts\n\noutlier helpers in transforms.py:\n\niqr_bounds, winsorize (+ optional add_outlier_flag)\n\njoin helper module joins.py with safe_left_join\nscript scripts/run_day3_build_analytics.py that writes:\n\ndata/processed/analytics_table.parquet\n\nat least one commit pushed to GitHub"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#updated-project-layout-what-you-add-today",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#updated-project-layout-what-you-add-today",
    "title": "Data Work (ETL + EDA)",
    "section": "Updated project layout (what you add today)",
    "text": "Updated project layout (what you add today)\nsrc/bootcamp_data/\n  transforms.py   # add datetime + outlier helpers\n  joins.py        # NEW today (safe_left_join)\nscripts/\n  run_day3_build_analytics.py\ndata/processed/\n  analytics_table.parquet"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#vibe-coding-safe-version",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#vibe-coding-safe-version",
    "title": "Data Work (ETL + EDA)",
    "section": "Vibe coding (safe version)",
    "text": "Vibe coding (safe version)\n\nWrite the plan in 5 bullets (no code yet)\nImplement the smallest piece\nRun → break → read error → fix\nCommit\nRepeat"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#task-1-add-datetime-transforms-20-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#task-1-add-datetime-transforms-20-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 1 — Add datetime transforms (20 minutes)",
    "text": "Task 1 — Add datetime transforms (20 minutes)\nIn src/bootcamp_data/transforms.py, add:\n\nparse_datetime(df, col, utc=True)\nadd_time_parts(df, ts_col)\n\nCheckpoint: you can import them and run on orders_clean.parquet."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#hint-remember-.dt-only-works-on-datetimes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#hint-remember-.dt-only-works-on-datetimes",
    "title": "Data Work (ETL + EDA)",
    "section": "Hint — remember .dt only works on datetimes",
    "text": "Hint — remember .dt only works on datetimes\nIf you get:\n\nAttributeError: Can only use .dt accessor with datetimelike values\n\nIt means you forgot to parse the column first."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-datetime-transforms-append",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-datetime-transforms-append",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — datetime transforms (append)",
    "text": "Solution — datetime transforms (append)\nimport pandas as pd\n\ndef parse_datetime(df: pd.DataFrame, col: str, *, utc: bool = True) -&gt; pd.DataFrame:\n    dt = pd.to_datetime(df[col], errors=\"coerce\", utc=utc)\n    return df.assign(**{col: dt})\n\ndef add_time_parts(df: pd.DataFrame, ts_col: str) -&gt; pd.DataFrame:\n    ts = df[ts_col]\n    return df.assign(\n    date=ts.dt.date,\n    year=ts.dt.year,\n    month=ts.dt.to_period(\"M\").astype(\"string\"),\n    dow=ts.dt.day_name(),\n    hour=ts.dt.hour,\n    )"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#task-2-add-outlier-helpers-20-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#task-2-add-outlier-helpers-20-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 2 — Add outlier helpers (20 minutes)",
    "text": "Task 2 — Add outlier helpers (20 minutes)\nIn src/bootcamp_data/transforms.py, add:\n\niqr_bounds(s, k=1.5)\nwinsorize(s, lo=0.01, hi=0.99)\n\nCheckpoint: you can compute bounds for amount."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-outlier-helpers-append",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-outlier-helpers-append",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — outlier helpers (append)",
    "text": "Solution — outlier helpers (append)\nimport pandas as pd\n\ndef iqr_bounds(s: pd.Series, k: float = 1.5) -&gt; tuple[float, float]:\n    x = s.dropna()\n    q1 = x.quantile(0.25)\n    q3 = x.quantile(0.75)\n    iqr = q3 - q1\n    return float(q1 - k * iqr), float(q3 + k * iqr)\n\ndef winsorize(s: pd.Series, lo: float = 0.01, hi: float = 0.99) -&gt; pd.Series:\n    x = s.dropna()\n    a, b = x.quantile(lo), x.quantile(hi)\n    return s.clip(lower=a, upper=b)"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#task-3-optional-add-an-outlier-flag-helper-10-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#task-3-optional-add-an-outlier-flag-helper-10-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 3 — (Optional) Add an outlier flag helper (10 minutes)",
    "text": "Task 3 — (Optional) Add an outlier flag helper (10 minutes)\nAdd a helper:\n\nadd_outlier_flag(df, col, k=1.5) -&gt; df\n\nCheckpoint: you get a boolean column like amount__is_outlier."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-outlier-flag-optional",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-outlier-flag-optional",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — outlier flag (optional)",
    "text": "Solution — outlier flag (optional)\nimport pandas as pd\n\ndef add_outlier_flag(df: pd.DataFrame, col: str, *, k: float = 1.5) -&gt; pd.DataFrame:\n    lo, hi = iqr_bounds(df[col], k=k)\n    return df.assign(**{f\"{col}__is_outlier\": (df[col] &lt; lo) | (df[col] &gt; hi)})"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#task-4-create-joins.py-with-safe_left_join-15-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#task-4-create-joins.py-with-safe_left_join-15-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 4 — Create joins.py with safe_left_join (15 minutes)",
    "text": "Task 4 — Create joins.py with safe_left_join (15 minutes)\nCreate src/bootcamp_data/joins.py with:\n\nsafe_left_join(left, right, on, validate, suffixes=...)\n\nCheckpoint: you can import it: from bootcamp_data.joins import safe_left_join."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#hint-keep-joins-in-one-place",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#hint-keep-joins-in-one-place",
    "title": "Data Work (ETL + EDA)",
    "section": "Hint — keep joins in one place",
    "text": "Hint — keep joins in one place\n\n\n\n\n\n\nTip\n\n\nIf every notebook writes its own join logic, you’ll eventually get inconsistent results. One helper keeps the team consistent."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-srcbootcamp_datajoins.py",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-srcbootcamp_datajoins.py",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — src/bootcamp_data/joins.py",
    "text": "Solution — src/bootcamp_data/joins.py\nfrom __future__ import annotations\nimport pandas as pd\n\ndef safe_left_join(\n    left: pd.DataFrame,\n    right: pd.DataFrame,\n    on: str | list[str],\n    *,\n    validate: str,\n    suffixes: tuple[str, str] = (\"\", \"_r\"),\n    ) -&gt; pd.DataFrame:\n    return left.merge(right, how=\"left\", on=on, validate=validate, suffixes=suffixes)"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#task-5-build-the-analytics-table-script-30-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#task-5-build-the-analytics-table-script-30-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 5 — Build the analytics table script (30 minutes)",
    "text": "Task 5 — Build the analytics table script (30 minutes)\nCreate scripts/run_day3_build_analytics.py that:\n\nloads orders_clean.parquet and users.parquet\nchecks:\n\nrequired columns\nassert_unique_key(users, \"user_id\")\n\nparses created_at\nadds time parts\njoins orders → users safely (validate=\"many_to_one\")\nadds:\n\namount_winsor\noptional amount__is_outlier\n\nwrites data/processed/analytics_table.parquet\n\nCheckpoint: script runs and writes the file."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#hint-include-evidence-prints",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#hint-include-evidence-prints",
    "title": "Data Work (ETL + EDA)",
    "section": "Hint — include evidence prints",
    "text": "Hint — include evidence prints\nPrint:\n\nrow counts before/after join\nmissing created_at after parsing\nmatch rate for country after join\n\nThis makes debugging fast."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-scriptsrun_day3_build_analytics.py",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-scriptsrun_day3_build_analytics.py",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — scripts/run_day3_build_analytics.py",
    "text": "Solution — scripts/run_day3_build_analytics.py\nfrom pathlib import Path\nimport pandas as pd\n\nfrom bootcamp_data.config import make_paths\nfrom bootcamp_data.quality import require_columns, assert_non_empty, assert_unique_key\nfrom bootcamp_data.transforms import parse_datetime, add_time_parts, winsorize, add_outlier_flag\nfrom bootcamp_data.joins import safe_left_join\n\nROOT = Path(**file**).resolve().parents[1]\n\ndef main() -&gt; None:\n    p = make_paths(ROOT)\n    orders = pd.read_parquet(p.processed / \"orders_clean.parquet\")\n    users  = pd.read_parquet(p.processed / \"users.parquet\")\n\n    require_columns(orders, [\"order_id\",\"user_id\",\"amount\",\"quantity\",\"created_at\",\"status_clean\"])\n    require_columns(users, [\"user_id\",\"country\",\"signup_date\"])\n    assert_non_empty(orders, \"orders_clean\")\n    assert_non_empty(users, \"users\")\n\n    assert_unique_key(users, \"user_id\")\n\n    # Continued on next slide"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-scriptsrun_day3_build_analytics.py-1",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-scriptsrun_day3_build_analytics.py-1",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — scripts/run_day3_build_analytics.py",
    "text": "Solution — scripts/run_day3_build_analytics.py\n# time\n    orders_t = (\n        orders\n        .pipe(parse_datetime, col=\"created_at\", utc=True)\n        .pipe(add_time_parts, ts_col=\"created_at\")\n    )\n\n    n_missing_ts = int(orders_t[\"created_at\"].isna().sum())\n    print(\"missing created_at after parse:\", n_missing_ts, \"/\", len(orders_t))\n\n# join (orders many -&gt; users one)\njoined = safe_left_join(\n    orders_t,\n    users,\n    on=\"user_id\",\n    validate=\"many_to_one\",\n    suffixes=(\"\", \"_user\"),\n)\n# Continued on next slide"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-scriptsrun_day3_build_analytics.py-2",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-scriptsrun_day3_build_analytics.py-2",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — scripts/run_day3_build_analytics.py",
    "text": "Solution — scripts/run_day3_build_analytics.py\nassert len(joined) == len(orders_t), \"Row count changed (join explosion?)\"\n\nmatch_rate = 1.0 - float(joined[\"country\"].isna().mean())\nprint(\"rows:\", len(joined))\nprint(\"country match rate:\", round(match_rate, 3))\n\n# outliers (keep rows; cap for viz)\njoined = joined.assign(amount_winsor=winsorize(joined[\"amount\"]))\njoined = add_outlier_flag(joined, \"amount\", k=1.5)\n\nout_path = p.processed / \"analytics_table.parquet\"\nout_path.parent.mkdir(parents=True, exist_ok=True)\njoined.to_parquet(out_path, index=False)\nprint(\"wrote:\", out_path)\n\nif **name** == \"**main**\":\n    main()\n\nIf add_outlier_flag is optional and not implemented, comment out that line or implement it in Task 3."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#task-6-run-verify-15-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#task-6-run-verify-15-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 6 — Run + verify (15 minutes)",
    "text": "Task 6 — Run + verify (15 minutes)\nRun the script and verify:\n\nfile exists: data/processed/analytics_table.parquet\njoin didn’t change row count\nmonth/dow/hour columns exist\namount_winsor exists\namount__is_outlier exists\n\nCheckpoint: you can load and print the first 5 rows."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-run-verify",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-run-verify",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — run + verify",
    "text": "Solution — run + verify\nmacOS/Linux\npython scripts/run_day3_build_analytics.py\npython -c \"import pandas as pd; df=pd.read_parquet('data/processed/analytics_table.parquet'); print(df.columns.tolist()); print(df[['user_id','country','month','amount','amount_winsor','amount__is_outlier']].head())\"\nWindows PowerShell\npython scripts\\\\run_day3_build_analytics.py\npython -c \"import pandas as pd; df=pd.read_parquet('data/processed/analytics_table.parquet'); print(df.columns.tolist()); print(df[['user_id','country','month','amount','amount_winsor','amount__is_outlier']].head())\""
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#task-7-add-one-mini-summary-table-10-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#task-7-add-one-mini-summary-table-10-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 7 — Add one mini summary table (10 minutes)",
    "text": "Task 7 — Add one mini summary table (10 minutes)\nIn the Day 3 script, after joining, compute:\n\nrevenue by country (sum of amount)\ncount of orders by country\n\nPrint it (or save to reports/revenue_by_country.csv).\nCheckpoint: you can see a small table in the terminal (or in reports/)."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-revenue-by-country-example",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-revenue-by-country-example",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — revenue by country (example)",
    "text": "Solution — revenue by country (example)\nsummary = (\n    joined.groupby(\"country\", dropna=False)\n          .agg(n=(\"order_id\",\"size\"), revenue=(\"amount\",\"sum\"))\n          .reset_index()\n          .sort_values(\"revenue\", ascending=False)\n)\nprint(summary)\n# Optional: summary.to_csv(ROOT/\"reports\"/\"revenue_by_country.csv\", index=False)"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#git-checkpoint-5-minutes",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#git-checkpoint-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Git checkpoint (5 minutes)",
    "text": "Git checkpoint (5 minutes)\n\ngit status\ncommit with message: \"w2d3: datetime + outliers + safe join + analytics table\"\npush to GitHub\n\nCheckpoint: repo shows your new commit online."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-git-commands",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#solution-git-commands",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — git commands",
    "text": "Solution — git commands\ngit add -A\ngit commit -m \"w2d3: datetime + outliers + safe join + analytics table\"\ngit push"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#debug-playbook-day-3-edition",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#debug-playbook-day-3-edition",
    "title": "Data Work (ETL + EDA)",
    "section": "Debug playbook (Day 3 edition)",
    "text": "Debug playbook (Day 3 edition)\nWhen the pipeline looks wrong:\n\nDatetime: check created_at dtype + missing count after parse\nJoin: check key dtypes match; check assert_unique_key on lookup table\nRow counts: len(left) vs len(joined)\nMatch rate: % missing in enriched columns (e.g., country)\nOutliers: print percentiles and bounds; don’t delete rows silently"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#stretch-goals-optional",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#stretch-goals-optional",
    "title": "Data Work (ETL + EDA)",
    "section": "Stretch goals (optional)",
    "text": "Stretch goals (optional)\nIf you finish early:\n\nAdd a check: assert joined[\"country\"].isna().mean() &lt; 0.2 (example threshold)\nAdd a small _run_meta.json next to analytics output:\n\nrows, missing timestamps, match rate\n\nAdd signup_date parsing for users (similar to created_at)"
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#exit-ticket",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#exit-ticket",
    "title": "Data Work (ETL + EDA)",
    "section": "Exit Ticket",
    "text": "Exit Ticket\nIn 1–2 sentences:\nName 2 join disasters and how we prevent them."
  },
  {
    "objectID": "W2_Data/D3_Datetimes_Outliers - Copy.html#what-to-do-after-class-day-3-assignment",
    "href": "W2_Data/D3_Datetimes_Outliers - Copy.html#what-to-do-after-class-day-3-assignment",
    "title": "Data Work (ETL + EDA)",
    "section": "What to do after class (Day 3 assignment)",
    "text": "What to do after class (Day 3 assignment)\nDue: before Day 4 starts\n\nEnsure scripts/run_day3_build_analytics.py runs from a fresh terminal\nPush your changes to GitHub\nConfirm these files exist:\n\nsrc/bootcamp_data/joins.py\ndata/processed/analytics_table.parquet\n\n\nDeliverable: GitHub repo link + screenshot of analytics_table.parquet columns printed in terminal.\n\n\n\n\n\n\nTip\n\n\nTomorrow we do EDA. If your joins and datetimes are wrong, your charts will lie."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#bootcamp-calendar",
    "href": "W2_Data/D1_Data_Workflow.html#bootcamp-calendar",
    "title": "Data Work (ETL + EDA)",
    "section": "Bootcamp calendar",
    "text": "Bootcamp calendar\n\nWeek 1: Python & Tooling\nWeek 2: Data Work (ETL + EDA)\nWeek 3: Machine Learning\nWeek 4: Deep Learning & Computer Vision\nWeek 5: LLM-based NLP\nWeek 6: Building AI Apps\nWeek 7: Agentic AI & Practical MLOps\nWeek 8: Capstone Sprint + Job Readiness"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#week-2-focus",
    "href": "W2_Data/D1_Data_Workflow.html#week-2-focus",
    "title": "Data Work (ETL + EDA)",
    "section": "Week 2 focus",
    "text": "Week 2 focus\nThis week is Data Work (ETL + EDA).\n\nInternet is not reliable → we work offline-first\nWe ship a reproducible pipeline (raw → processed → notebook)\nGitHub is daily (small commits, clear messages)\n\n\nWeek 1 gave you: CLI + packages + uv + Git. Week 2 adds: pandas + schema discipline + offline-first ETL."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#todays-flow",
    "href": "W2_Data/D1_Data_Workflow.html#todays-flow",
    "title": "Data Work (ETL + EDA)",
    "section": "Today’s Flow",
    "text": "Today’s Flow\n\nSession 1 (60m): Offline-first mindset + project layout\nAsr Prayer (20m)\nSession 2 (60m): Data sources + caching patterns\nMaghrib Prayer (20m)\nSession 3 (60m): pandas I/O + schema basics (IDs, missing values, Parquet)\nIsha Prayer (20m)\nHands-on (120m): Scaffold repo + load raw → processed Parquet"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#learning-objectives",
    "href": "W2_Data/D1_Data_Workflow.html#learning-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of today, you can:\n\nexplain raw vs cache vs processed (and why we separate them)\nscaffold a repo with a standard data project layout\nrun project code the right way (avoid ModuleNotFoundError)\nload CSV in pandas with explicit dtypes (IDs as strings)\nwrite Parquet outputs to data/processed/\nimplement a minimal schema enforcement step (enforce_schema)\npush a working Day 1 baseline to GitHub"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#warm-up-5-minutes",
    "href": "W2_Data/D1_Data_Workflow.html#warm-up-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Warm-up (5 minutes)",
    "text": "Warm-up (5 minutes)\nSanity-check your toolchain (you will use these every day).\nuv --version\ngit --version\npython -V\nCheckpoint: you can run all three commands with no errors."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#quick-review-uv-daily-workflow",
    "href": "W2_Data/D1_Data_Workflow.html#quick-review-uv-daily-workflow",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick review: uv daily workflow",
    "text": "Quick review: uv daily workflow\nThree commands you will use all week:\n\nuv venv → create .venv/\nuv pip install ... → install dependencies into the env\nuv run &lt;command&gt; → run using the env (no “wrong python” accidents)\n\nExample:\nuv run python -c \"import pandas as pd; print(pd.__version__)\"\n\nYou learned uv in Week 1. Today we’ll use it as our default toolchain."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#this-weeks-project-high-level",
    "href": "W2_Data/D1_Data_Workflow.html#this-weeks-project-high-level",
    "title": "Data Work (ETL + EDA)",
    "section": "This week’s project (high-level)",
    "text": "This week’s project (high-level)\nProject: Offline‑First ETL + EDA Mini Analytics Pipeline\nYou will ship:\n\nETL code that runs end‑to‑end (load → verify → clean → transform → write)\ndata/processed/*.parquet outputs that are safe to overwrite\nan EDA notebook that reads only processed data\na short reports/summary.md (findings + caveats)"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#choose-your-week-2-dataset-today",
    "href": "W2_Data/D1_Data_Workflow.html#choose-your-week-2-dataset-today",
    "title": "Data Work (ETL + EDA)",
    "section": "Choose your Week 2 dataset (today)",
    "text": "Choose your Week 2 dataset (today)\nFor the rest of Week 2, you’ll build a full ETL + EDA project on one real dataset.\nYou may use:\n\nKaggle (download + unzip a snapshot)\nHuggingFace Datasets (load_dataset(...) → snapshot to disk)\nDirect URL / API (download with httpx + cache)\nA teammate-provided file (CSV/JSON/Parquet)\n\nDataset rubric (so exercises work smoothly):\n\n≥ 1 categorical column (e.g., country, status, category)\n≥ 1 numeric column (e.g., amount, quantity, rating)\n≥ 1 datetime/timestamp column (e.g., created_at)\n≥ 1,000 rows recommended (distributions + outliers are visible)\nBonus: a join key (e.g., user_id, product_id, store_id)\n\n\n\n\n\n\n\nNote\n\n\nIn class we’ll use a tiny toy dataset (orders.csv + users.csv) to validate patterns quickly.\nFor your weekly project, pick a real dataset and repeat the same workflow.\n\n\n\n\n\n\n\n\n\nWarning\n\n\nDon’t commit raw data or API tokens to GitHub. Commit scripts + metadata so others can reproduce the download."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#end-state-by-end-of-today",
    "href": "W2_Data/D1_Data_Workflow.html#end-state-by-end-of-today",
    "title": "Data Work (ETL + EDA)",
    "section": "End-state (by end of today)",
    "text": "End-state (by end of today)\nBy the end of Day 1, your repo should contain:\n\na standard folder layout (data/, bootcamp_data/, scripts/, reports/)\nbootcamp_data/config.py, bootcamp_data/io.py, bootcamp_data/transforms.py\na runnable entrypoint: python -m scripts.run_day1_load\nat least one processed output in data/processed/ (Parquet preferred)\na reproducibility breadcrumb for your project dataset:\n\ndata/raw/_source_meta.json (where your data came from)\noptionally: scripts/download_data.py (how to download it again)\n\nat least one commit pushed to GitHub"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#tool-stack-this-week-minimal-high-roi",
    "href": "W2_Data/D1_Data_Workflow.html#tool-stack-this-week-minimal-high-roi",
    "title": "Data Work (ETL + EDA)",
    "section": "Tool stack this week (minimal + high ROI)",
    "text": "Tool stack this week (minimal + high ROI)\n\npandas — load/clean/join/reshape/EDA (DataFrame)\npyarrow + Parquet — fast, typed processed files\nhttpx — extraction (but cached)\nlogging — evidence during runs (row counts, dtypes)\nPlotly (Day 4) — one plotting library\nDuckDB (Day 5) — local SQL on files\n(Optional) datasets / kaggle — download catalog datasets (HuggingFace / Kaggle) and snapshot to data/raw/\n\n\nRule: avoid tool sprawl. Keep it small and shippable."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#canonical-workflow-repeat-every-project",
    "href": "W2_Data/D1_Data_Workflow.html#canonical-workflow-repeat-every-project",
    "title": "Data Work (ETL + EDA)",
    "section": "Canonical workflow (repeat every project)",
    "text": "Canonical workflow (repeat every project)\n\nLoad (raw/cache)\nVerify (schema, dtypes, keys, row counts)\nClean (missingness, duplicates, normalization)\nTransform (joins, reshape, features)\nAnalyze (tables + comparisons)\nVisualize (Plotly, export figures)\nConclude (written summary + caveats)\n\n\n\nThis week: notebooks focus on steps 4–7 using data/processed/."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#session-1-objectives",
    "href": "W2_Data/D1_Data_Workflow.html#session-1-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 1 objectives",
    "text": "Session 1 objectives\nBy the end of this session, you can:\n\ndefine offline-first for data work\nexplain the purpose of raw/, cache/, processed/, external/\ndescribe “raw immutable” and “processed idempotent”\nrun code using modules (so imports work without hacks)\ncentralize project paths using pathlib.Path"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#context-why-offline-first-is-worth-it",
    "href": "W2_Data/D1_Data_Workflow.html#context-why-offline-first-is-worth-it",
    "title": "Data Work (ETL + EDA)",
    "section": "Context: why “offline-first” is worth it",
    "text": "Context: why “offline-first” is worth it\nYou will re-run your ETL many times:\n\ndebugging\nadding a cleaning rule\nfixing a dtype bug\nadding a feature column\n\nIf your pipeline depends on the internet, you lose time."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#concept-raw-vs-cache-vs-processed-vs-external",
    "href": "W2_Data/D1_Data_Workflow.html#concept-raw-vs-cache-vs-processed-vs-external",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: raw vs cache vs processed vs external",
    "text": "Concept: raw vs cache vs processed vs external\nOffline-first projects separate data by role:\n\nraw: original snapshots (never edited)\ncache: downloads/API responses (safe to delete)\nprocessed: clean, typed outputs (safe to recreate / overwrite)\nexternal: reference drops (manual downloads you want to keep)"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#example-folder-roles-mental-model",
    "href": "W2_Data/D1_Data_Workflow.html#example-folder-roles-mental-model",
    "title": "Data Work (ETL + EDA)",
    "section": "Example: folder roles (mental model)",
    "text": "Example: folder roles (mental model)\n\n\ndata/raw/\n\nimmutable inputs\n“source of truth”\nnever edited\n\n\ndata/cache/\n\nAPI responses\nintermediate downloads\nsafe to delete\n\n\ndata/processed/\n\nclean + typed\nanalysis-ready\nsafe to overwrite\n\n\ndata/external/\n\nmanual reference\nlookup tables\nrarely changes"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#micro-exercise-classify-these-files-5-minutes",
    "href": "W2_Data/D1_Data_Workflow.html#micro-exercise-classify-these-files-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: classify these files (5 minutes)",
    "text": "Micro-exercise: classify these files (5 minutes)\nPut each file into the correct folder:\n\norders.csv you received from a teammate\nusers_api_page_1.json downloaded from an endpoint\norders_clean.parquet generated by your ETL\ncountry_codes.xlsx you manually downloaded as reference\n\nCheckpoint: you can justify your choices in 1 sentence each."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#solution-classification",
    "href": "W2_Data/D1_Data_Workflow.html#solution-classification",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution: classification",
    "text": "Solution: classification\n\norders.csv → data/raw/\nusers_api_page_1.json → data/cache/\norders_clean.parquet → data/processed/\ncountry_codes.xlsx → data/external/"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#quick-check",
    "href": "W2_Data/D1_Data_Workflow.html#quick-check",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: Why should data/raw/ be “immutable”?\n\nAnswer: if you edit raw data, you lose the ability to reproduce results and debug changes."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#concept-idempotent-processed-outputs",
    "href": "W2_Data/D1_Data_Workflow.html#concept-idempotent-processed-outputs",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: idempotent processed outputs",
    "text": "Concept: idempotent processed outputs\nIdempotent: re-running the pipeline produces the same processed outputs (given same inputs + config).\nGood pattern:\n\noverwrite data/processed/orders.parquet every run\n\nBad pattern:\n\nappend to data/processed/orders.csv every run"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#micro-exercise-spot-the-idempotency-bug-6-minutes",
    "href": "W2_Data/D1_Data_Workflow.html#micro-exercise-spot-the-idempotency-bug-6-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: spot the idempotency bug (6 minutes)",
    "text": "Micro-exercise: spot the idempotency bug (6 minutes)\nYou run this twice:\ndf.to_csv(\"data/processed/orders.csv\", mode=\"a\", index=False, header=False)\n\nWhat goes wrong on run #2?\nRewrite it to be idempotent.\nBonus: write Parquet instead of CSV.\n\nCheckpoint: your fixed code is safe to run 20 times."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#solution-idempotent-write-example",
    "href": "W2_Data/D1_Data_Workflow.html#solution-idempotent-write-example",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution: idempotent write (example)",
    "text": "Solution: idempotent write (example)\n# safest default: overwrite\ndf.to_parquet(\"data/processed/orders.parquet\", index=False)\n\n\n\n\n\n\nNote\n\n\nIf you truly need incremental data, do it intentionally (partitioned folders, dedupe keys). Default for this bootcamp: overwrite processed outputs."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#quick-check-1",
    "href": "W2_Data/D1_Data_Workflow.html#quick-check-1",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: What is the most common symptom of a non‑idempotent pipeline?\n\nAnswer: row counts grow every run even when inputs didn’t change."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#context-imports-fail-when-you-run-code-the-wrong-way",
    "href": "W2_Data/D1_Data_Workflow.html#context-imports-fail-when-you-run-code-the-wrong-way",
    "title": "Data Work (ETL + EDA)",
    "section": "Context: imports fail when you run code “the wrong way”",
    "text": "Context: imports fail when you run code “the wrong way”\nA very common Day 1 error:\n\nModuleNotFoundError: No module named 'bootcamp_data'\n\nThis usually happens when you run a file by path (Python changes where it searches)."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#concept-our-no-pain-run-rule",
    "href": "W2_Data/D1_Data_Workflow.html#concept-our-no-pain-run-rule",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: our “no pain” run rule",
    "text": "Concept: our “no pain” run rule\nRule: run entrypoints as modules from the repo root.\n\n✅ python -m scripts.run_day1_load\n❌ python scripts/run_day1_load.py (easy to break imports)\n\n\n\n\n\n\n\nWarning\n\n\nAvoid “fixing” imports by editing runtime paths in your code. If imports fail: change how you run, or fix the package structure."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#micro-exercise-choose-the-right-command-4-minutes",
    "href": "W2_Data/D1_Data_Workflow.html#micro-exercise-choose-the-right-command-4-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: choose the right command (4 minutes)",
    "text": "Micro-exercise: choose the right command (4 minutes)\nYour repo looks like this:\nweek2-data-work/\n  bootcamp_data/\n  scripts/\nYou want to run the loader.\nWhich command is correct?\n\npython scripts/run_day1_load.py\npython -m scripts.run_day1_load\n\nCheckpoint: you can explain why one works and the other often fails."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#solution-choose-the-right-command",
    "href": "W2_Data/D1_Data_Workflow.html#solution-choose-the-right-command",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution: choose the right command",
    "text": "Solution: choose the right command\nCorrect: B) python -m scripts.run_day1_load\nReason: running as a module keeps the repo root on Python’s import search path."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#context-project-layout-prevents-path-chaos",
    "href": "W2_Data/D1_Data_Workflow.html#context-project-layout-prevents-path-chaos",
    "title": "Data Work (ETL + EDA)",
    "section": "Context: project layout prevents “path chaos”",
    "text": "Context: project layout prevents “path chaos”\nIf everyone uses different paths:\n\nnotebooks break\nscripts break\nteammates can’t run your repo\n\nWe fix this with a consistent layout + a central paths config."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#example-repo-tree-day-1-target",
    "href": "W2_Data/D1_Data_Workflow.html#example-repo-tree-day-1-target",
    "title": "Data Work (ETL + EDA)",
    "section": "Example: repo tree (Day 1 target)",
    "text": "Example: repo tree (Day 1 target)\nweek2-data-work/\n  data/{raw,cache,processed,external}/\n  notebooks/\n  reports/figures/\n  scripts/\n    __init__.py\n    run_day1_load.py\n  bootcamp_data/\n    __init__.py\n    config.py\n    io.py\n    transforms.py"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#quick-check-2",
    "href": "W2_Data/D1_Data_Workflow.html#quick-check-2",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: What folder should notebooks read from?\n\nAnswer: data/processed/ (not data/raw/)."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#concept-one-source-of-truth-for-paths",
    "href": "W2_Data/D1_Data_Workflow.html#concept-one-source-of-truth-for-paths",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: one source of truth for paths",
    "text": "Concept: one source of truth for paths\nHardcoding strings like \"../data/raw/orders.csv\" breaks when:\n\nyou run from a different folder\nsomeone uses Windows paths\nfiles move\n\nUse pathlib.Path + a central config.py."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#quick-review-dataclass-why-we-use-it",
    "href": "W2_Data/D1_Data_Workflow.html#quick-review-dataclass-why-we-use-it",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick review: @dataclass (why we use it)",
    "text": "Quick review: @dataclass (why we use it)\nA dataclass is a lightweight way to make a “data container” class.\n\nauto-generates __init__ for you (less boilerplate)\ngives a readable repr (nice for debugging)\nfrozen=True makes it immutable (prevents accidental edits)\n\nToday we use it to store project paths in one place."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#example-paths-make_paths-pattern",
    "href": "W2_Data/D1_Data_Workflow.html#example-paths-make_paths-pattern",
    "title": "Data Work (ETL + EDA)",
    "section": "Example: Paths + make_paths (pattern)",
    "text": "Example: Paths + make_paths (pattern)\nfrom dataclasses import dataclass\nfrom pathlib import Path\n\n@dataclass(frozen=True)\nclass Paths:\n    root: Path\n    raw: Path\n    cache: Path\n    processed: Path\n    external: Path\n\ndef make_paths(root: Path) -&gt; Paths:\n    data = root / \"data\"\n    return Paths(\n        root=root,\n        raw=data / \"raw\",\n        cache=data / \"cache\",\n        processed=data / \"processed\",\n        external=data / \"external\",\n    )"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#micro-exercise-implement-make_paths-6-minutes",
    "href": "W2_Data/D1_Data_Workflow.html#micro-exercise-implement-make_paths-6-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: implement make_paths (6 minutes)",
    "text": "Micro-exercise: implement make_paths (6 minutes)\nCreate bootcamp_data/config.py with:\n\na Paths dataclass\na make_paths(root: Path) function\nraw/cache/processed/external paths under root/data/\n\nCheckpoint: in a Python REPL, make_paths(Path.cwd()).processed prints a real folder path."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#solution-bootcamp_dataconfig.py-example",
    "href": "W2_Data/D1_Data_Workflow.html#solution-bootcamp_dataconfig.py-example",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution: bootcamp_data/config.py (example)",
    "text": "Solution: bootcamp_data/config.py (example)\nfrom dataclasses import dataclass\nfrom pathlib import Path\n\n@dataclass(frozen=True)\nclass Paths:\n    root: Path\n    raw: Path\n    cache: Path\n    processed: Path\n    external: Path\n\ndef make_paths(root: Path) -&gt; Paths:\n    data = root / \"data\"\n    return Paths(\n        root=root,\n        raw=data / \"raw\",\n        cache=data / \"cache\",\n        processed=data / \"processed\",\n        external=data / \"external\",\n    )"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#quick-check-3",
    "href": "W2_Data/D1_Data_Workflow.html#quick-check-3",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: Why use Path objects instead of plain strings?\n\nAnswer: Path handles OS differences and safe joins (root / \"data\" / \"raw\")."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#session-1-recap",
    "href": "W2_Data/D1_Data_Workflow.html#session-1-recap",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 1 recap",
    "text": "Session 1 recap\n\nOffline-first = your project runs without internet\nSeparate data by role: raw / cache / processed / external\nProcessed outputs should be idempotent (safe reruns)\nRun entrypoints as modules: python -m ...\nCentralize paths with pathlib.Path in config.py"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#minutes",
    "href": "W2_Data/D1_Data_Workflow.html#minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: open your repo and locate data/raw, data/processed, bootcamp_data/, and scripts/."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#session-2-objectives",
    "href": "W2_Data/D1_Data_Workflow.html#session-2-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 2 objectives",
    "text": "Session 2 objectives\nBy the end of this session, you can:\n\nidentify common data sources (CSV/JSON/API) and catalog sources (Kaggle, HuggingFace)\ndownload a dataset via Kaggle, HuggingFace, or a direct URL\nwrite a raw snapshot to data/raw/ and record source metadata\nimplement an offline-first cache read/write pattern (reuse cache when present)\nexplain why CSV needs guardrails (dtype, separators, missing markers)"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#data-sources-you-can-use-and-how-we-treat-them",
    "href": "W2_Data/D1_Data_Workflow.html#data-sources-you-can-use-and-how-we-treat-them",
    "title": "Data Work (ETL + EDA)",
    "section": "Data sources you can use (and how we treat them)",
    "text": "Data sources you can use (and how we treat them)\nYou’ll see data in a few common “shapes”:\n\n\n\n\n\n\n\n\n\nSource\nTypical format\nWhere it goes\nOffline-first rule\n\n\n\n\nKaggle dataset\nZIP → CSV\ndata/cache/ (zip) → data/raw/ (snapshot)\npin a snapshot + record metadata\n\n\nHuggingFace Datasets\nArrow → pandas\ndata/raw/ (snapshot)\nload once → save locally\n\n\nDirect URL download\nCSV/JSON/ZIP\ndata/cache/ → data/raw/\ncache the bytes + record the URL\n\n\nAPI extraction\nJSON pages\ndata/cache/\nnever “depend on live calls”\n\n\nTeammate drop\nCSV/Parquet\ndata/raw/\ntreat as immutable input\n\n\n\n\nWe care about repeatability, not “where it came from”. Your repo should run even when Wi‑Fi is bad."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#path-a-kaggle-cli-snapshot-download",
    "href": "W2_Data/D1_Data_Workflow.html#path-a-kaggle-cli-snapshot-download",
    "title": "Data Work (ETL + EDA)",
    "section": "Path A — Kaggle (CLI) snapshot download",
    "text": "Path A — Kaggle (CLI) snapshot download\nKaggle is great for realistic tabular datasets, but it requires a one‑time API token setup.\nOne-time setup (per machine): 1. Create a Kaggle account (if you don’t have one) 2. In Kaggle → Account → create a new API token → download kaggle.json 3. Move it to:\n\nmacOS/Linux: ~/.kaggle/kaggle.json\nWindows: C:\\Users\\&lt;you&gt;\\.kaggle\\kaggle.json\n\n\n(macOS/Linux) fix permissions:\n\nchmod 600 ~/.kaggle/kaggle.json\n\n\n\n\n\n\nWarning\n\n\nNever commit kaggle.json to your repo. It contains credentials."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#kaggle-download-cache-raw-example-commands",
    "href": "W2_Data/D1_Data_Workflow.html#kaggle-download-cache-raw-example-commands",
    "title": "Data Work (ETL + EDA)",
    "section": "Kaggle download → cache → raw (example commands)",
    "text": "Kaggle download → cache → raw (example commands)\nInstall the CLI (if needed):\nuv pip install kaggle\nDownload a dataset ZIP into data/cache/ and unzip a snapshot into data/raw/:\n# from repo root\nDATASET_ID=\"&lt;kaggle-owner&gt;/&lt;kaggle-dataset-slug&gt;\"\n\nmkdir -p data/cache/kaggle data/raw/kaggle\nkaggle datasets download -d \"$DATASET_ID\" -p data/cache/kaggle --unzip\n# move/copy the extracted files into a snapshot folder you will not edit\n\nDifferent Kaggle datasets unzip into different filenames. Your job is to decide the snapshot folder name and record it in metadata."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#path-b-huggingface-datasets-python-snapshot",
    "href": "W2_Data/D1_Data_Workflow.html#path-b-huggingface-datasets-python-snapshot",
    "title": "Data Work (ETL + EDA)",
    "section": "Path B — HuggingFace Datasets (Python) snapshot",
    "text": "Path B — HuggingFace Datasets (Python) snapshot\nHuggingFace datasets load into memory (or stream), then you save a local snapshot.\nInstall:\nuv pip install datasets\nMinimal snapshot example (save as Parquet):\nfrom pathlib import Path\nfrom datasets import load_dataset\n\nout_dir = Path(\"data/raw/hf_my_dataset\")\nout_dir.mkdir(parents=True, exist_ok=True)\n\nds = load_dataset(\"&lt;dataset_name&gt;\", split=\"train\")  # change name/split\ndf = ds.to_pandas()\ndf.to_parquet(out_dir / \"train.parquet\", index=False)\n\n\n\n\n\n\nNote\n\n\nOffline-first rule: once you have a local snapshot, your ETL reads from disk, not from HuggingFace."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#path-c-direct-url-download-csvzip-snapshot",
    "href": "W2_Data/D1_Data_Workflow.html#path-c-direct-url-download-csvzip-snapshot",
    "title": "Data Work (ETL + EDA)",
    "section": "Path C — Direct URL download (CSV/ZIP) snapshot",
    "text": "Path C — Direct URL download (CSV/ZIP) snapshot\nThis is the most universal option: if you have a URL, you can cache it.\nfrom pathlib import Path\nimport httpx\n\ndef download_bytes(url: str, out_path: Path) -&gt; None:\n    out_path.parent.mkdir(parents=True, exist_ok=True)\n    with httpx.Client(timeout=60.0, follow_redirects=True) as client:\n        r = client.get(url)\n        r.raise_for_status()\n        out_path.write_bytes(r.content)\n\ndownload_bytes(\n    url=\"&lt;paste-a-csv-or-zip-url&gt;\",\n    out_path=Path(\"data/cache/downloads/source_file.zip\"),\n)\nThen unzip/copy into data/raw/&lt;snapshot_name&gt;/ and treat it as immutable."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#raw-snapshot-metadata-required",
    "href": "W2_Data/D1_Data_Workflow.html#raw-snapshot-metadata-required",
    "title": "Data Work (ETL + EDA)",
    "section": "Raw snapshot metadata (required)",
    "text": "Raw snapshot metadata (required)\nEvery raw snapshot should have a tiny metadata record so someone else can reproduce it.\nRecommended location (simple): data/raw/_source_meta.json\nExample:\n{\n  \"dataset_name\": \"my_week2_project\",\n  \"source\": \"kaggle | huggingface | url | teammate\",\n  \"dataset_id_or_url\": \"…\",\n  \"downloaded_at_utc\": \"2025-12-21T10:15:00Z\",\n  \"raw_snapshot_folder\": \"data/raw/my_week2_project/\",\n  \"files\": [\"train.parquet\"],\n  \"notes\": \"any caveats (sampling, filters, auth)\"\n}\n\nWe’ll expand metadata later (row counts, schema summary, git commit). Today: just make sure the origin is documented."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#starter-scriptsdownload_data.py-project-dataset",
    "href": "W2_Data/D1_Data_Workflow.html#starter-scriptsdownload_data.py-project-dataset",
    "title": "Data Work (ETL + EDA)",
    "section": "Starter: scripts/download_data.py (project dataset)",
    "text": "Starter: scripts/download_data.py (project dataset)\nKeep dataset acquisition repeatable by putting it in one script.\nMinimum for Day 1: support one of (URL / HuggingFace / Kaggle).\nStretch: support 2–3 sources in the same file.\nTiny URL downloader (works everywhere):\nfrom __future__ import annotations\nfrom pathlib import Path\nimport json\nfrom datetime import datetime, timezone\nimport httpx\n\ndef download(url: str, out_path: Path) -&gt; None:\n    out_path.parent.mkdir(parents=True, exist_ok=True)\n    with httpx.Client(timeout=60.0, follow_redirects=True) as client:\n        r = client.get(url)\n        r.raise_for_status()\n        out_path.write_bytes(r.content)\n\ndef write_meta(meta_path: Path, meta: dict) -&gt; None:\n    meta_path.parent.mkdir(parents=True, exist_ok=True)\n    meta_path.write_text(json.dumps(meta, indent=2), encoding=\"utf-8\")\n\ndef main() -&gt; None:\n    url = \"&lt;paste-url&gt;\"\n    out_path = Path(\"data/cache/downloads/source_file.csv\")\n    download(url, out_path)\n\n    write_meta(\n        Path(\"data/raw/_source_meta.json\"),\n        {\n            \"dataset_name\": \"my_week2_project\",\n            \"source\": \"url\",\n            \"dataset_id_or_url\": url,\n            \"downloaded_at_utc\": datetime.now(timezone.utc).isoformat(),\n            \"raw_snapshot_folder\": \"data/raw/my_week2_project/\",\n            \"files\": [],\n            \"notes\": \"downloaded bytes cached; raw snapshot extracted separately\"\n        },\n    )\n\nif __name__ == \"__main__\":\n    main()\n\n\n\n\n\n\nNote\n\n\nThis script is your “repro button” — it doesn’t need to be fancy. It just needs to be honest and rerunnable."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#context-extraction-is-where-silent-drift-starts",
    "href": "W2_Data/D1_Data_Workflow.html#context-extraction-is-where-silent-drift-starts",
    "title": "Data Work (ETL + EDA)",
    "section": "Context: extraction is where “silent drift” starts",
    "text": "Context: extraction is where “silent drift” starts\nTwo common failure modes:\n\nupstream data changes → your results change\nextraction fails partially → you analyze incomplete data\n\nYour job: make extraction reproducible."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#concept-minimal-extraction-checklist",
    "href": "W2_Data/D1_Data_Workflow.html#concept-minimal-extraction-checklist",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: minimal extraction checklist",
    "text": "Concept: minimal extraction checklist\nBefore you trust extracted data:\n\ndid you get all pages (pagination)?\ndid you record params/time window?\ndid you store a snapshot (cache)?\ndid you validate row count / file size?"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#example-minimal-extraction-metadata-json",
    "href": "W2_Data/D1_Data_Workflow.html#example-minimal-extraction-metadata-json",
    "title": "Data Work (ETL + EDA)",
    "section": "Example: minimal extraction metadata (JSON)",
    "text": "Example: minimal extraction metadata (JSON)\n{\n  \"timestamp_utc\": \"2025-12-21T09:15:00Z\",\n  \"source\": \"api\",\n  \"endpoint\": \"/v1/users\",\n  \"params\": {\"page\": 1, \"per_page\": 100},\n  \"status_code\": 200\n}\n\nStore this next to the cached file (same name + .meta.json)."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#micro-exercise-design-the-metadata-file-5-minutes",
    "href": "W2_Data/D1_Data_Workflow.html#micro-exercise-design-the-metadata-file-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: design the metadata file (5 minutes)",
    "text": "Micro-exercise: design the metadata file (5 minutes)\nYou downloaded: data/cache/users_page_1.json\n\nWhat should the metadata filename be?\nList 4 keys you will store.\n\nCheckpoint: your filename ends with .meta.json and your keys support reproducibility."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#solution-metadata-naming-keys",
    "href": "W2_Data/D1_Data_Workflow.html#solution-metadata-naming-keys",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution: metadata naming + keys",
    "text": "Solution: metadata naming + keys\n\nfilename: data/cache/users_page_1.meta.json\nkeys (example):\n\ntimestamp_utc\nendpoint\nparams\nstatus_code"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#quick-check-4",
    "href": "W2_Data/D1_Data_Workflow.html#quick-check-4",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: If you don’t store params, what breaks later?\n\nAnswer: you can’t reproduce which slice of data you extracted (numbers won’t match)."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#context-caching-keeps-you-productive",
    "href": "W2_Data/D1_Data_Workflow.html#context-caching-keeps-you-productive",
    "title": "Data Work (ETL + EDA)",
    "section": "Context: caching keeps you productive",
    "text": "Context: caching keeps you productive\nInternet is unreliable.\nCaching means:\n\nfirst run: download → save to data/cache/\nnext runs: read from cache (fast, offline)"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#concept-offline-first-caching-policy",
    "href": "W2_Data/D1_Data_Workflow.html#concept-offline-first-caching-policy",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: offline-first caching policy",
    "text": "Concept: offline-first caching policy\nOperational rule:\n\nif cache exists → use it\nonly re-download when you choose (manual delete or TTL refresh)\n\nThis prevents “live calls” from breaking your workflow."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#quick-review-httpx-in-60-seconds",
    "href": "W2_Data/D1_Data_Workflow.html#quick-review-httpx-in-60-seconds",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick review: httpx in 60 seconds",
    "text": "Quick review: httpx in 60 seconds\n\nhttpx is a Python HTTP client (like requests)\nyou call an endpoint and get JSON back\nyou must cache the response for reproducibility\n\n\nToday’s code is a pattern. We don’t depend on live internet during labs."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#example-fetch_json_cached-offline-first",
    "href": "W2_Data/D1_Data_Workflow.html#example-fetch_json_cached-offline-first",
    "title": "Data Work (ETL + EDA)",
    "section": "Example: fetch_json_cached (offline-first)",
    "text": "Example: fetch_json_cached (offline-first)\nfrom pathlib import Path\nimport json\nimport time\nimport httpx\n\ndef fetch_json_cached(url: str, cache_path: Path, *, ttl_s: int | None = None) -&gt; dict:\n    \"\"\"Offline-first JSON fetch with optional TTL.\"\"\"\n    cache_path.parent.mkdir(parents=True, exist_ok=True)\n\n    # Offline-first default: if cache exists, use it (unless TTL says it's too old)\n    if cache_path.exists():\n        age_s = time.time() - cache_path.stat().st_mtime\n        if ttl_s is None or age_s &lt; ttl_s:\n            return json.loads(cache_path.read_text(encoding=\"utf-8\"))\n\n    # Otherwise: fetch and overwrite cache\n    with httpx.Client(timeout=20.0) as client:\n        r = client.get(url)\n        r.raise_for_status()\n        data = r.json()\n\n    cache_path.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n    return data"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#micro-exercise-predict-caching-behavior-4-minutes",
    "href": "W2_Data/D1_Data_Workflow.html#micro-exercise-predict-caching-behavior-4-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: predict caching behavior (4 minutes)",
    "text": "Micro-exercise: predict caching behavior (4 minutes)\nAssume cache_path already exists.\nWhat happens?\n\nttl_s=None\nttl_s=3600 and cache age is 10 minutes\nttl_s=3600 and cache age is 3 days\n\nCheckpoint: you can answer all 3 without running code."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#solution-predict-caching-behavior",
    "href": "W2_Data/D1_Data_Workflow.html#solution-predict-caching-behavior",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution: predict caching behavior",
    "text": "Solution: predict caching behavior\n\nttl_s=None → read from cache (offline-first default)\nttl_s=3600 and age 10m → read from cache\nttl_s=3600 and age 3d → re-download then overwrite cache"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#quick-check-5",
    "href": "W2_Data/D1_Data_Workflow.html#quick-check-5",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: When is ttl_s=None a good default?\n\nAnswer: when you want the pipeline to run offline and you refresh cache manually."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#quick-review-pandas-tables-in-python",
    "href": "W2_Data/D1_Data_Workflow.html#quick-review-pandas-tables-in-python",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick review: pandas = “tables in Python”",
    "text": "Quick review: pandas = “tables in Python”\nIn Week 1 you used csv.DictReader (rows = dicts).\nIn Week 2 we mostly use pandas (tables):\n\npd.read_csv(...) → DataFrame\ndf.head() → preview\ndf.shape → row/col count\ndf.dtypes → types (important!)\n\nBridge (manual ↔︎ pandas):\nimport pandas as pd\n\n# list[dict] → DataFrame\nrows = [{\"a\": 1, \"b\": \"x\"}, {\"a\": 2, \"b\": \"y\"}]\ndf = pd.DataFrame(rows)\n\n# DataFrame → list[dict] (records)\nrecords = df.to_dict(orient=\"records\")\n\n\n\n\n\n\nTip\n\n\npandas is powerful, but it can guess types wrong. That’s why we add guardrails."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#context-csv-is-a-lowest-common-denominator",
    "href": "W2_Data/D1_Data_Workflow.html#context-csv-is-a-lowest-common-denominator",
    "title": "Data Work (ETL + EDA)",
    "section": "Context: CSV is a “lowest common denominator”",
    "text": "Context: CSV is a “lowest common denominator”\nCSV is common, but it is fragile:\n\nencoding surprises\nseparators differ (; vs ,)\ndecimal separators differ (1,23 vs 1.23)\nmissing markers vary (NA, null, empty)"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#concept-read_csv-guardrails-high-roi-options",
    "href": "W2_Data/D1_Data_Workflow.html#concept-read_csv-guardrails-high-roi-options",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: read_csv guardrails (high ROI options)",
    "text": "Concept: read_csv guardrails (high ROI options)\nWhen reading CSV, consider:\n\ndtype= (especially IDs)\nna_values= (custom missing markers)\nencoding=\nsep=\ndecimal="
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#micro-exercise-write-a-guarded-read_csv-6-minutes",
    "href": "W2_Data/D1_Data_Workflow.html#micro-exercise-write-a-guarded-read_csv-6-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: write a guarded read_csv (6 minutes)",
    "text": "Micro-exercise: write a guarded read_csv (6 minutes)\nScenario:\n\nseparator is ;\ndecimals use comma: 12,50\nIDs like 0007 must keep leading zeros\n\nWrite the pd.read_csv(...) call.\nCheckpoint: your call includes sep, decimal, and dtype for IDs."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#solution-guarded-pd.read_csv-example",
    "href": "W2_Data/D1_Data_Workflow.html#solution-guarded-pd.read_csv-example",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution: guarded pd.read_csv (example)",
    "text": "Solution: guarded pd.read_csv (example)\nimport pandas as pd\n\ndf = pd.read_csv(\n    path,\n    sep=\";\",\n    decimal=\",\",\n    dtype={\"user_id\": \"string\", \"order_id\": \"string\"},\n    na_values=[\"\", \"NA\", \"null\"],\n)"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#session-2-recap",
    "href": "W2_Data/D1_Data_Workflow.html#session-2-recap",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 2 recap",
    "text": "Session 2 recap\n\nExtraction must be reproducible (cache + metadata)\nOffline-first caching: reuse cache when present\nCSV needs guardrails (dtype, sep, decimal, na_values)\nNext: schema discipline + Parquet outputs"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#minutes-1",
    "href": "W2_Data/D1_Data_Workflow.html#minutes-1",
    "title": "Data Work (ETL + EDA)",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: open your editor and be ready to write io.py and transforms.py."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#session-3-objectives",
    "href": "W2_Data/D1_Data_Workflow.html#session-3-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 3 objectives",
    "text": "Session 3 objectives\nBy the end of this session, you can:\n\nexplain why pandas dtype inference can be dangerous\ntreat IDs as strings (avoid silent corruption)\nwrite and read Parquet with pandas\ncentralize I/O in io.py\nimplement a minimal enforce_schema(df) transform"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#pandas-muscle-memory-3-moves",
    "href": "W2_Data/D1_Data_Workflow.html#pandas-muscle-memory-3-moves",
    "title": "Data Work (ETL + EDA)",
    "section": "pandas muscle memory (3 moves)",
    "text": "pandas muscle memory (3 moves)\nWhen you load any dataset, do this first:\n\ndf.head() → sanity check values\ndf.shape → row/col count\ndf.dtypes → confirm types (especially IDs)\n\n\nThis takes 10 seconds and prevents 2 hours of confusion."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#context-pandas-inference-can-silently-corrupt-meaning",
    "href": "W2_Data/D1_Data_Workflow.html#context-pandas-inference-can-silently-corrupt-meaning",
    "title": "Data Work (ETL + EDA)",
    "section": "Context: pandas inference can silently corrupt meaning",
    "text": "Context: pandas inference can silently corrupt meaning\nIf pandas guesses wrong, you might lose information without an error.\nClassic example:\n\nID 00123 becomes 123 (leading zeros lost forever)"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#concept-treat-ids-as-strings",
    "href": "W2_Data/D1_Data_Workflow.html#concept-treat-ids-as-strings",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: treat IDs as strings",
    "text": "Concept: treat IDs as strings\nOperational rules:\n\nIDs are strings unless you truly compute on them\nuse pandas nullable dtypes when missing values exist:\n\n\"string\", \"Int64\", \"Float64\", \"boolean\""
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#example-the-leading-zero-bug",
    "href": "W2_Data/D1_Data_Workflow.html#example-the-leading-zero-bug",
    "title": "Data Work (ETL + EDA)",
    "section": "Example: the leading-zero bug",
    "text": "Example: the leading-zero bug\nimport pandas as pd\n\ndf = pd.read_csv(\"orders.csv\")  # risky default\nprint(df.dtypes)\nRisk\n\nuser_id becomes int64\n0007 becomes 7\njoins fail later"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#micro-exercise-choose-dtypes-6-minutes",
    "href": "W2_Data/D1_Data_Workflow.html#micro-exercise-choose-dtypes-6-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: choose dtypes (6 minutes)",
    "text": "Micro-exercise: choose dtypes (6 minutes)\nYou have orders.csv with columns:\n\norder_id, user_id, amount, quantity, created_at, status\n\nWrite:\n\na dtype={...} mapping for IDs\na 1-sentence rule for quantity when missing values exist\n\nCheckpoint: your mapping keeps leading zeros."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#solution-dtype-mapping-rule",
    "href": "W2_Data/D1_Data_Workflow.html#solution-dtype-mapping-rule",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution: dtype mapping + rule",
    "text": "Solution: dtype mapping + rule\ndtype = {\n    \"order_id\": \"string\",\n    \"user_id\": \"string\",\n}\nRule: if quantity is “integer but can be missing”, use \"Int64\" after parsing."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#quick-check-6",
    "href": "W2_Data/D1_Data_Workflow.html#quick-check-6",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: If quantity is an integer but has missing values, what dtype should you use?\n\nAnswer: \"Int64\" (nullable integer), not plain int64."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#concept-why-parquet-for-processed-outputs",
    "href": "W2_Data/D1_Data_Workflow.html#concept-why-parquet-for-processed-outputs",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: why Parquet for processed outputs",
    "text": "Concept: why Parquet for processed outputs\nParquet is a columnar file format that:\n\npreserves dtypes (critical for processed data)\nis smaller than CSV (compression)\nloads faster for analytics workflows"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#example-write-read-parquet",
    "href": "W2_Data/D1_Data_Workflow.html#example-write-read-parquet",
    "title": "Data Work (ETL + EDA)",
    "section": "Example: write + read Parquet",
    "text": "Example: write + read Parquet\ndf.to_parquet(\"data/processed/orders.parquet\", index=False)\ndf2 = pd.read_parquet(\"data/processed/orders.parquet\")\n\n\n\n\n\n\nNote\n\n\nParquet requires an engine. We use pyarrow this week."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#context-centralize-io-in-io.py",
    "href": "W2_Data/D1_Data_Workflow.html#context-centralize-io-in-io.py",
    "title": "Data Work (ETL + EDA)",
    "section": "Context: centralize I/O in io.py",
    "text": "Context: centralize I/O in io.py\nIf every notebook reads data differently:\n\nmissing values differ\ndtypes differ\nresults differ\n\nCentralized I/O makes team work consistent."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#concept-four-core-io-helpers",
    "href": "W2_Data/D1_Data_Workflow.html#concept-four-core-io-helpers",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: four core I/O helpers",
    "text": "Concept: four core I/O helpers\nIn bootcamp_data/io.py:\n\nread_orders_csv(path) -&gt; DataFrame\nread_users_csv(path) -&gt; DataFrame\nwrite_parquet(df, path) -&gt; None\nread_parquet(path) -&gt; DataFrame"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#example-io.py-pattern",
    "href": "W2_Data/D1_Data_Workflow.html#example-io.py-pattern",
    "title": "Data Work (ETL + EDA)",
    "section": "Example: io.py pattern",
    "text": "Example: io.py pattern\nfrom pathlib import Path\nimport pandas as pd\n\nNA = [\"\", \"NA\", \"N/A\", \"null\", \"None\"]\n\ndef read_orders_csv(path: Path) -&gt; pd.DataFrame:\n    return pd.read_csv(\n        path,\n        dtype={\"order_id\": \"string\", \"user_id\": \"string\"},\n        na_values=NA,\n        keep_default_na=True,\n    )\n\ndef write_parquet(df: pd.DataFrame, path: Path) -&gt; None:\n    path.parent.mkdir(parents=True, exist_ok=True)\n    df.to_parquet(path, index=False)"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#micro-exercise-add-one-more-guardrail-5-minutes",
    "href": "W2_Data/D1_Data_Workflow.html#micro-exercise-add-one-more-guardrail-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: add one more guardrail (5 minutes)",
    "text": "Micro-exercise: add one more guardrail (5 minutes)\nIn your read_orders_csv(...), add one extra guardrail:\nChoose one:\n\nsep=\";\"\nencoding=\"utf-8\"\ndecimal=\",\"\n\nCheckpoint: you can explain why your chosen guardrail matters."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#solution-example-guardrail",
    "href": "W2_Data/D1_Data_Workflow.html#solution-example-guardrail",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution: example guardrail",
    "text": "Solution: example guardrail\ndef read_orders_csv(path: Path) -&gt; pd.DataFrame:\n    return pd.read_csv(\n        path,\n        dtype={\"order_id\": \"string\", \"user_id\": \"string\"},\n        na_values=NA,\n        keep_default_na=True,\n        encoding=\"utf-8\",\n    )"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#concept-schema-enforcement-is-a-correctness-step",
    "href": "W2_Data/D1_Data_Workflow.html#concept-schema-enforcement-is-a-correctness-step",
    "title": "Data Work (ETL + EDA)",
    "section": "Concept: schema enforcement is a correctness step",
    "text": "Concept: schema enforcement is a correctness step\nEven with dtype=..., you often need:\n\nnumeric parsing (amount, quantity)\nnormalization (status casing)\nconsistent missing values\n\nWe enforce types after loading."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#example-enforce_schemadf-minimal",
    "href": "W2_Data/D1_Data_Workflow.html#example-enforce_schemadf-minimal",
    "title": "Data Work (ETL + EDA)",
    "section": "Example: enforce_schema(df) (minimal)",
    "text": "Example: enforce_schema(df) (minimal)\nimport pandas as pd\n\ndef enforce_schema(df: pd.DataFrame) -&gt; pd.DataFrame:\n    return df.assign(\n        order_id=df[\"order_id\"].astype(\"string\"),\n        user_id=df[\"user_id\"].astype(\"string\"),\n        amount=pd.to_numeric(df[\"amount\"], errors=\"coerce\").astype(\"Float64\"),\n        quantity=pd.to_numeric(df[\"quantity\"], errors=\"coerce\").astype(\"Int64\"),\n        status=df[\"status\"].astype(\"string\").str.strip().str.lower(),\n    )"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#micro-exercise-make-parsing-non-crashy-5-minutes",
    "href": "W2_Data/D1_Data_Workflow.html#micro-exercise-make-parsing-non-crashy-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: make parsing “non-crashy” (5 minutes)",
    "text": "Micro-exercise: make parsing “non-crashy” (5 minutes)\nComplete this safely:\namount = pd.to_numeric(df[\"amount\"], errors=____).astype(\"Float64\")\nquantity = pd.to_numeric(df[\"quantity\"], errors=____).astype(\"Int64\")\nCheckpoint: invalid values become missing (not crashes)."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#solution-parsing-with-coercion",
    "href": "W2_Data/D1_Data_Workflow.html#solution-parsing-with-coercion",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution: parsing with coercion",
    "text": "Solution: parsing with coercion\namount = pd.to_numeric(df[\"amount\"], errors=\"coerce\").astype(\"Float64\")\nquantity = pd.to_numeric(df[\"quantity\"], errors=\"coerce\").astype(\"Int64\")"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#quick-check-7",
    "href": "W2_Data/D1_Data_Workflow.html#quick-check-7",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: What does errors=\"coerce\" do?\n\nAnswer: invalid values become missing (NaN) instead of raising an exception."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#session-3-recap",
    "href": "W2_Data/D1_Data_Workflow.html#session-3-recap",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 3 recap",
    "text": "Session 3 recap\n\npandas inference can silently break IDs → keep IDs as strings\nParquet preserves dtypes and loads fast → use it for processed data\ncentralize loading/writing in io.py\nuse enforce_schema as a small, testable correctness step"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#tomorrow-verify-becomes-code-fail-fast",
    "href": "W2_Data/D1_Data_Workflow.html#tomorrow-verify-becomes-code-fail-fast",
    "title": "Data Work (ETL + EDA)",
    "section": "Tomorrow: “Verify” becomes code (fail fast)",
    "text": "Tomorrow: “Verify” becomes code (fail fast)\nDay 2 we’ll turn assumptions into checks, like:\n\nrequired columns\nnon-empty datasets\nunique keys (before joins)\nmissingness report (per column)\nsimple range checks (e.g., amount &gt;= 0)\n\nWhy it matters: catching bad data early prevents join disasters and wasted debugging."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#minutes-2",
    "href": "W2_Data/D1_Data_Workflow.html#minutes-2",
    "title": "Data Work (ETL + EDA)",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: we will scaffold the repo and write our first processed Parquet file."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#quick-review-logging-beats-mystery-debugging",
    "href": "W2_Data/D1_Data_Workflow.html#quick-review-logging-beats-mystery-debugging",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick review: logging beats “mystery debugging”",
    "text": "Quick review: logging beats “mystery debugging”\nIn data pipelines, you want evidence during every run:\n\nrow counts\ndtypes\noutput paths\n\nMinimal pattern:\nimport logging\nlogging.basicConfig(level=logging.INFO, format=\"%(levelname)s %(name)s: %(message)s\")\nlog = logging.getLogger(__name__)\nlog.info(\"rows=%s\", len(df))\n\n\n\n\n\n\nTip\n\n\nStart with logging. Use notebooks for exploration, not for pipelines."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#hands-on-success-criteria-today",
    "href": "W2_Data/D1_Data_Workflow.html#hands-on-success-criteria-today",
    "title": "Data Work (ETL + EDA)",
    "section": "Hands-on success criteria (today)",
    "text": "Hands-on success criteria (today)\nBy the end, you should have:\n\na repo with the standard folder layout\nconfig.py, io.py, transforms.py inside bootcamp_data/\nraw inputs in data/raw/ (toy dataset is fine for in-class)\ndata/raw/_source_meta.json documenting where your project dataset comes from\na runnable module: python -m scripts.run_day1_load\nat least one processed Parquet created by your code (e.g., data/processed/orders.parquet)\nat least one commit pushed to GitHub"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#project-layout-target",
    "href": "W2_Data/D1_Data_Workflow.html#project-layout-target",
    "title": "Data Work (ETL + EDA)",
    "section": "Project layout (target)",
    "text": "Project layout (target)\nweek2-data-work/\n  data/\n    raw/            # immutable inputs\n    cache/          # API responses (optional today)\n    processed/      # your Parquet outputs\n    external/       # reference drops (optional)\n  reports/figures/\n  scripts/\n    __init__.py\n    run_day1_load.py\n  bootcamp_data/\n    __init__.py\n    config.py\n    io.py\n    transforms.py\n  README.md\n  requirements.txt"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#vibe-coding-safe-version",
    "href": "W2_Data/D1_Data_Workflow.html#vibe-coding-safe-version",
    "title": "Data Work (ETL + EDA)",
    "section": "Vibe coding (safe version)",
    "text": "Vibe coding (safe version)\n\nWrite the plan in 5 bullets (no code yet)\nImplement the smallest piece\nRun → break → read error → fix\nCommit\nRepeat\n\n\n\n\n\n\n\nWarning\n\n\nDo not ask GenAI to write your solution code. Ask it to explain concepts or errors."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#task-1-create-folders-initialize-git-10-minutes",
    "href": "W2_Data/D1_Data_Workflow.html#task-1-create-folders-initialize-git-10-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 1 — Create folders + initialize git (10 minutes)",
    "text": "Task 1 — Create folders + initialize git (10 minutes)\n\nCreate the repo folders (data/, bootcamp_data/, scripts/, reports/)\nInitialize git\nCreate an empty README.md\nAdd __init__.py files (so folders can be imported as packages)\n\nCheckpoint: git status shows your new files."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#solution-folders-git",
    "href": "W2_Data/D1_Data_Workflow.html#solution-folders-git",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — folders + git",
    "text": "Solution — folders + git\nmacOS/Linux\nmkdir -p data/{raw,cache,processed,external}\nmkdir -p reports/figures scripts bootcamp_data notebooks\ntouch README.md bootcamp_data/__init__.py scripts/__init__.py\ngit init\nWindows PowerShell\nmkdir data, reports, scripts, bootcamp_data, notebooks\nmkdir data\\raw, data\\cache, data\\processed, data\\external\nmkdir reports\\figures\nni README.md -ItemType File\nni bootcamp_data\\__init__.py -ItemType File\nni scripts\\__init__.py -ItemType File\ngit init"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#task-2-create-a-uv-environment-install-deps-15-minutes",
    "href": "W2_Data/D1_Data_Workflow.html#task-2-create-a-uv-environment-install-deps-15-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 2 — Create a uv environment + install deps (15 minutes)",
    "text": "Task 2 — Create a uv environment + install deps (15 minutes)\n\nCreate a virtual environment with uv\nActivate it\nInstall core deps: pandas, pyarrow, httpx\nOptional (for dataset downloading today): datasets (HuggingFace), kaggle (Kaggle CLI)\nFreeze requirements.txt\n\nCheckpoint: python -c \"import pandas; import pyarrow; import httpx\" runs with no error."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#hint-common-environment-mistakes",
    "href": "W2_Data/D1_Data_Workflow.html#hint-common-environment-mistakes",
    "title": "Data Work (ETL + EDA)",
    "section": "Hint — common environment mistakes",
    "text": "Hint — common environment mistakes\nMost Day 1 issues come from:\n\nthe wrong Python interpreter\nforgetting to activate the environment\ninstalling packages globally by accident\n\nQuick checks:\n\nwhich python (macOS/Linux)\nGet-Command python (Windows PowerShell)"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#solution-uv-venv-deps",
    "href": "W2_Data/D1_Data_Workflow.html#solution-uv-venv-deps",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — uv venv + deps",
    "text": "Solution — uv venv + deps\nmacOS/Linux\nuv venv\nsource .venv/bin/activate\n\n# core (required)\nuv pip install pandas pyarrow httpx\n\n# optional (only if you plan to use these sources today)\n# uv pip install datasets kaggle\n\nuv pip freeze &gt; requirements.txt\npython -c \"import pandas; import pyarrow; import httpx; print('ok')\"\nWindows PowerShell\nuv venv\n.\\.venv\\Scripts\\Activate.ps1\n\n# core (required)\nuv pip install pandas pyarrow httpx\n\n# optional (only if you plan to use these sources today)\n# uv pip install datasets kaggle\n\nuv pip freeze &gt; requirements.txt\npython -c \"import pandas; import pyarrow; import httpx; print('ok')\"\n\n\n\n\n\n\nWarning\n\n\nIf pyarrow install fails, ask the instructor. Fallback: you can write CSV today, but Parquet is strongly preferred for Week 2."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#task-3-acquire-raw-data-two-tracks-1025-minutes",
    "href": "W2_Data/D1_Data_Workflow.html#task-3-acquire-raw-data-two-tracks-1025-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 3 — Acquire raw data (two tracks) (10–25 minutes)",
    "text": "Task 3 — Acquire raw data (two tracks) (10–25 minutes)\nTrack A (in-class, recommended): create the tiny toy dataset below:\n\ndata/raw/orders.csv\ndata/raw/users.csv\n\nThis lets you validate your pipeline quickly.\nTrack B (weekly project): download a real dataset (Kaggle / HuggingFace / URL) into a snapshot folder like:\n\ndata/raw/&lt;your_dataset_name&gt;/\n\n…and record provenance in:\n\ndata/raw/_source_meta.json\n\nCheckpoint: you have some raw data to run through today’s loader, and you know where your project dataset will come from."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#track-a-solution-dataraworders.csv-toy-dataset",
    "href": "W2_Data/D1_Data_Workflow.html#track-a-solution-dataraworders.csv-toy-dataset",
    "title": "Data Work (ETL + EDA)",
    "section": "Track A solution — data/raw/orders.csv (toy dataset)",
    "text": "Track A solution — data/raw/orders.csv (toy dataset)\norder_id,user_id,amount,quantity,created_at,status\nA0001,0001,12.50,1,2025-12-01T10:05:00Z,Paid\nA0002,0002,8.00,2,2025-12-01T11:10:00Z,paid\nA0003,0003,not_a_number,1,2025-12-02T09:00:00Z,Refund\nA0004,0001,25.00,,2025-12-03T14:30:00Z,PAID\nA0005,0004,100.00,1,not_a_date,paid"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#track-a-solution-datarawusers.csv-toy-dataset",
    "href": "W2_Data/D1_Data_Workflow.html#track-a-solution-datarawusers.csv-toy-dataset",
    "title": "Data Work (ETL + EDA)",
    "section": "Track A solution — data/raw/users.csv (toy dataset)",
    "text": "Track A solution — data/raw/users.csv (toy dataset)\nuser_id,country,signup_date\n0001,SA,2025-11-15\n0002,SA,2025-11-20\n0003,AE,2025-11-22\n0004,SA,2025-11-25"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#task-3.5-add-dataraw_source_meta.json-5-minutes",
    "href": "W2_Data/D1_Data_Workflow.html#task-3.5-add-dataraw_source_meta.json-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 3.5 — Add data/raw/_source_meta.json (5 minutes)",
    "text": "Task 3.5 — Add data/raw/_source_meta.json (5 minutes)\nCreate a tiny provenance record for your raw snapshot.\nEven if you’re using the toy dataset today, practice the habit — you’ll keep this file for your weekly project.\nExample (edit values to match your situation):\n{\n  \"dataset_name\": \"toy_orders_users\",\n  \"source\": \"in_class_toy\",\n  \"dataset_id_or_url\": \"n/a\",\n  \"downloaded_at_utc\": \"2025-12-21T00:00:00Z\",\n  \"raw_snapshot_folder\": \"data/raw/\",\n  \"files\": [\"orders.csv\", \"users.csv\"],\n  \"notes\": \"Toy dataset used for Week 2 Day 1 scaffolding.\"\n}\n\nTomorrow we’ll generate additional metadata automatically (row counts, schema summary)."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#task-4-implement-config.py-12-minutes",
    "href": "W2_Data/D1_Data_Workflow.html#task-4-implement-config.py-12-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 4 — Implement config.py (12 minutes)",
    "text": "Task 4 — Implement config.py (12 minutes)\nCreate bootcamp_data/config.py:\n\nPaths dataclass\nmake_paths(root: Path) -&gt; Paths\n\nCheckpoint: a tiny snippet prints a valid processed path."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#solution-bootcamp_dataconfig.py",
    "href": "W2_Data/D1_Data_Workflow.html#solution-bootcamp_dataconfig.py",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — bootcamp_data/config.py",
    "text": "Solution — bootcamp_data/config.py\nfrom dataclasses import dataclass\nfrom pathlib import Path\n\n@dataclass(frozen=True)\nclass Paths:\n    root: Path\n    raw: Path\n    cache: Path\n    processed: Path\n    external: Path\n\ndef make_paths(root: Path) -&gt; Paths:\n    data = root / \"data\"\n    return Paths(\n        root=root,\n        raw=data / \"raw\",\n        cache=data / \"cache\",\n        processed=data / \"processed\",\n        external=data / \"external\",\n    )"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#task-5-implement-io.py-18-minutes",
    "href": "W2_Data/D1_Data_Workflow.html#task-5-implement-io.py-18-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 5 — Implement io.py (18 minutes)",
    "text": "Task 5 — Implement io.py (18 minutes)\nCreate bootcamp_data/io.py with:\n\nread_orders_csv(path: Path) -&gt; pd.DataFrame\nread_users_csv(path: Path) -&gt; pd.DataFrame\nwrite_parquet(df, path)\nread_parquet(path)\n\nCheckpoint: you can import these functions without errors."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#solution-bootcamp_dataio.py",
    "href": "W2_Data/D1_Data_Workflow.html#solution-bootcamp_dataio.py",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — bootcamp_data/io.py",
    "text": "Solution — bootcamp_data/io.py\nfrom pathlib import Path\nimport pandas as pd\n\nNA = [\"\", \"NA\", \"N/A\", \"null\", \"None\"]\n\ndef read_orders_csv(path: Path) -&gt; pd.DataFrame:\n    return pd.read_csv(\n        path,\n        dtype={\"order_id\": \"string\", \"user_id\": \"string\"},\n        na_values=NA,\n        keep_default_na=True,\n        encoding=\"utf-8\",\n    )\n\ndef read_users_csv(path: Path) -&gt; pd.DataFrame:\n    return pd.read_csv(\n        path,\n        dtype={\"user_id\": \"string\"},\n        na_values=NA,\n        keep_default_na=True,\n        encoding=\"utf-8\",\n    )\n\ndef write_parquet(df: pd.DataFrame, path: Path) -&gt; None:\n    path.parent.mkdir(parents=True, exist_ok=True)\n    df.to_parquet(path, index=False)\n\ndef read_parquet(path: Path) -&gt; pd.DataFrame:\n    return pd.read_parquet(path)"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#task-6-add-transforms.py-with-enforce_schema-15-minutes",
    "href": "W2_Data/D1_Data_Workflow.html#task-6-add-transforms.py-with-enforce_schema-15-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 6 — Add transforms.py with enforce_schema (15 minutes)",
    "text": "Task 6 — Add transforms.py with enforce_schema (15 minutes)\nCreate bootcamp_data/transforms.py:\n\nimplement enforce_schema(df) -&gt; df\nconvert amount and quantity using pd.to_numeric(..., errors=\"coerce\")\nnormalize status to lowercase\n\nCheckpoint: enforce_schema returns Float64 / Int64 dtypes and cleaned status."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#solution-bootcamp_datatransforms.py-minimal",
    "href": "W2_Data/D1_Data_Workflow.html#solution-bootcamp_datatransforms.py-minimal",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — bootcamp_data/transforms.py (minimal)",
    "text": "Solution — bootcamp_data/transforms.py (minimal)\nimport pandas as pd\n\ndef enforce_schema(df: pd.DataFrame) -&gt; pd.DataFrame:\n    return df.assign(\n        order_id=df[\"order_id\"].astype(\"string\"),\n        user_id=df[\"user_id\"].astype(\"string\"),\n        amount=pd.to_numeric(df[\"amount\"], errors=\"coerce\").astype(\"Float64\"),\n        quantity=pd.to_numeric(df[\"quantity\"], errors=\"coerce\").astype(\"Int64\"),\n        status=df[\"status\"].astype(\"string\").str.strip().str.lower(),\n    )"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#task-7-write-the-day-1-loader-module-20-minutes",
    "href": "W2_Data/D1_Data_Workflow.html#task-7-write-the-day-1-loader-module-20-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 7 — Write the Day 1 loader module (20 minutes)",
    "text": "Task 7 — Write the Day 1 loader module (20 minutes)\nCreate scripts/run_day1_load.py:\n\ncompute ROOT (repo root)\nbuild paths with make_paths(ROOT)\nread raw CSVs\napply enforce_schema to orders\nwrite Parquet outputs to data/processed/\nprint or log evidence (row counts + dtypes)\n\nCheckpoint: python -m scripts.run_day1_load creates data/processed/orders.parquet."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#hint-compute-the-project-root-robustly",
    "href": "W2_Data/D1_Data_Workflow.html#hint-compute-the-project-root-robustly",
    "title": "Data Work (ETL + EDA)",
    "section": "Hint — compute the project root robustly",
    "text": "Hint — compute the project root robustly\nIn scripts/run_day1_load.py:\nfrom pathlib import Path\nROOT = Path(__file__).resolve().parents[1]\nThis works even if you run commands from different folders."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#solution-scriptsrun_day1_load.py",
    "href": "W2_Data/D1_Data_Workflow.html#solution-scriptsrun_day1_load.py",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — scripts/run_day1_load.py",
    "text": "Solution — scripts/run_day1_load.py\nfrom pathlib import Path\nimport logging\n\nfrom bootcamp_data.config import make_paths\nfrom bootcamp_data.io import read_orders_csv, read_users_csv, write_parquet\nfrom bootcamp_data.transforms import enforce_schema\n\nlog = logging.getLogger(__name__)\n\ndef main() -&gt; None:\n    logging.basicConfig(level=logging.INFO, format=\"%(levelname)s %(name)s: %(message)s\")\n\n    ROOT = Path(__file__).resolve().parents[1]\n    p = make_paths(ROOT)\n\n    orders = enforce_schema(read_orders_csv(p.raw / \"orders.csv\"))\n    users = read_users_csv(p.raw / \"users.csv\")\n\n    log.info(\"Loaded rows: orders=%s users=%s\", len(orders), len(users))\n    log.info(\"Orders dtypes:\\n%s\", orders.dtypes)\n\n    write_parquet(orders, p.processed / \"orders.parquet\")\n    write_parquet(users, p.processed / \"users.parquet\")\n\n    log.info(\"Wrote processed files to: %s\", p.processed)\n\nif __name__ == \"__main__\":\n    main()\n\n\n\n\n\n\nTip\n\n\nRun it as a module from the repo root:\n\npython -m scripts.run_day1_load"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#task-8-run-verify-outputs-10-minutes",
    "href": "W2_Data/D1_Data_Workflow.html#task-8-run-verify-outputs-10-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 8 — Run + verify outputs (10 minutes)",
    "text": "Task 8 — Run + verify outputs (10 minutes)\nRun the loader and verify:\n\nprocessed files exist\nIDs stayed as strings\ninvalid amount became missing\n\nCheckpoint: you can load Parquet back into pandas and see expected dtypes."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#solution-run-verify",
    "href": "W2_Data/D1_Data_Workflow.html#solution-run-verify",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — run + verify",
    "text": "Solution — run + verify\nmacOS/Linux\nuv run python -m scripts.run_day1_load\nuv run python -c \"import pandas as pd; df=pd.read_parquet('data/processed/orders.parquet'); print(df.dtypes); print(df.head())\"\nWindows PowerShell\nuv run python -m scripts.run_day1_load\nuv run python -c \"import pandas as pd; df=pd.read_parquet('data/processed/orders.parquet'); print(df.dtypes); print(df.head())\""
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#git-checkpoint-5-minutes",
    "href": "W2_Data/D1_Data_Workflow.html#git-checkpoint-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Git checkpoint (5 minutes)",
    "text": "Git checkpoint (5 minutes)\n\ngit status\ncommit with message: \"w2d1: scaffold + typed io + first processed parquet\"\npush to GitHub\n\nCheckpoint: you can see your commit online."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#solution-git-commands",
    "href": "W2_Data/D1_Data_Workflow.html#solution-git-commands",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — git commands",
    "text": "Solution — git commands\ngit add -A\ngit commit -m \"w2d1: scaffold + typed io + first processed parquet\"\ngit branch -M main\ngit remote add origin &lt;YOUR_REPO_URL&gt;\ngit push -u origin main\n\nIf you already have a remote, skip the git remote add step."
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#debug-playbook",
    "href": "W2_Data/D1_Data_Workflow.html#debug-playbook",
    "title": "Data Work (ETL + EDA)",
    "section": "Debug playbook",
    "text": "Debug playbook\nWhen stuck:\n\nRead the full error (don’t guess)\nIdentify: file + line number\nPrint/log: ROOT, paths, row counts, df.dtypes\nFix the smallest thing\nRe-run\n\nCommon Day 1 fixes:\n\nIf imports fail: run with python -m ... from repo root\nIf modules are missing: install deps in the activated uv environment\nIf Parquet write fails: confirm pyarrow installed"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#stretch-goals-optional",
    "href": "W2_Data/D1_Data_Workflow.html#stretch-goals-optional",
    "title": "Data Work (ETL + EDA)",
    "section": "Stretch goals (optional)",
    "text": "Stretch goals (optional)\nIf you finish early:\n\ncreate scripts/download_data.py for your project dataset (Kaggle / HF / URL)\nwrite data/processed/_run_meta.json with row counts + output paths\nadd a README.md section: “How to run Day 1”\nadd one assertion: assert str(orders[\"user_id\"].dtype) == \"string\""
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#exit-ticket",
    "href": "W2_Data/D1_Data_Workflow.html#exit-ticket",
    "title": "Data Work (ETL + EDA)",
    "section": "Exit Ticket",
    "text": "Exit Ticket\nIn 1–2 sentences:\nWhy do we keep IDs as strings and prefer Parquet for processed outputs?"
  },
  {
    "objectID": "W2_Data/D1_Data_Workflow.html#what-to-do-after-class-day-1-assignment",
    "href": "W2_Data/D1_Data_Workflow.html#what-to-do-after-class-day-1-assignment",
    "title": "Data Work (ETL + EDA)",
    "section": "What to do after class (Day 1 assignment)",
    "text": "What to do after class (Day 1 assignment)\nDue: before Day 2 starts\nToday’s work becomes the foundation of your Week 2 data project.\n\nPick your Week 2 project dataset (Kaggle / HuggingFace / URL).\nCreate / update data/raw/_source_meta.json with:\n\nsource\ndataset_id_or_url\ndownloaded_at_utc\nraw_snapshot_folder\nfiles\n\nMake the download reproducible:\n\nPreferred: add scripts/download_data.py (support at least one of: Kaggle, HF, URL)\nMinimum: add a README section with exact commands you used\n\nEnsure python -m scripts.run_day1_load works from a fresh terminal.\nConfirm you can create at least one processed Parquet file in data/processed/.\nPush at least one commit to GitHub.\n\nDeliverable: GitHub repo link + evidence of:\n\ndata/raw/_source_meta.json (contents)\na processed Parquet file in data/processed/\nthe commands/script used to acquire the project dataset\n\n\n\n\n\n\n\nTip\n\n\nCommit early. Commit often. Future you will thank you."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#todays-flow",
    "href": "W1_Python/D4_Streamlit_GUI.html#todays-flow",
    "title": "Python & Tooling",
    "section": "Today’s Flow",
    "text": "Today’s Flow\n\nSession 1 (60m): Streamlit basics (how it thinks)\nAsr Prayer (20m)\nSession 2 (60m): Connect Streamlit → your csv_profiler package\nMaghrib Prayer (20m)\nSession 3 (60m): Optional: httpx for loading CSVs from URLs + better error UX\nIsha Prayer (20m)\nHands-on (120m): CSV Profiler — Part 4 (Streamlit)"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#learning-objectives",
    "href": "W1_Python/D4_Streamlit_GUI.html#learning-objectives",
    "title": "Python & Tooling",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of today, you can:\n\nExplain Streamlit’s rerun model and why widgets “cause reruns”\nBuild a simple Streamlit UI using sidebar + widgets\nLoad CSV data from:\n\nfile upload (required)\nlocal path (optional)\nURL via httpx (stretch)\n\nReuse your package functions:\n\nprofile_rows()\nrender_markdown()\n\nExport profiling results as:\n\ndownloadable JSON + Markdown\nsaved to outputs/ on disk (local run)"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#quick-refresher-running-the-project-and-pythonpath",
    "href": "W1_Python/D4_Streamlit_GUI.html#quick-refresher-running-the-project-and-pythonpath",
    "title": "Python & Tooling",
    "section": "Quick refresher: running the project (and PYTHONPATH)",
    "text": "Quick refresher: running the project (and PYTHONPATH)\nYour code is split into:\n\nsrc/csv_profiler/ → your package (profiling + rendering logic)\napp.py → your Streamlit script (UI only)\n\nBecause the package is inside src/, we run commands with PYTHONPATH=src so Python can import it.\nmacOS/Linux\nPYTHONPATH=src uv run python -m csv_profiler.cli profile data/sample.csv\nPYTHONPATH=src uv run streamlit run app.py\nWindows PowerShell\n$env:PYTHONPATH=\"src\"\nuv run python -m csv_profiler.cli profile data/sample.csv\nuv run streamlit run app.py\n\n\n\n\n\n\nTip\n\n\nIf your project does not have a src/ folder (flat layout), you can usually omit PYTHONPATH=src."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#warm-up-5-minutes",
    "href": "W1_Python/D4_Streamlit_GUI.html#warm-up-5-minutes",
    "title": "Python & Tooling",
    "section": "Warm-up (5 minutes)",
    "text": "Warm-up (5 minutes)\nRun your Day 3 CLI to confirm your profiler still works.\nmacOS/Linux\ncd ~/bootcamp/csv-profiler\nPYTHONPATH=src uv run python -m csv_profiler.cli profile data/sample.csv --preview\nWindows PowerShell\ncd ~/bootcamp/csv-profiler\n$env:PYTHONPATH=\"src\"\nuv run python -m csv_profiler.cli profile data/sample.csv --preview\nCheckpoint: you still get:\n\noutputs/report.json\noutputs/report.md\n\n\n--preview just prints a small preview so you know the CLI is reading the file correctly.\n\n\nDo: Walk around. If someone can’t run it, pair them with a peer for 2 minutes.\nAsk: “What does PYTHONPATH=src do?”\nTimebox: 5 minutes."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#week-project-progress-where-we-are",
    "href": "W1_Python/D4_Streamlit_GUI.html#week-project-progress-where-we-are",
    "title": "Python & Tooling",
    "section": "Week project progress (where we are)",
    "text": "Week project progress (where we are)\nYou already have:\n\nPackage: src/csv_profiler/\nCLI: python -m csv_profiler.cli profile ...\nJSON report + Markdown report\n\nToday you add:\n\napp.py Streamlit GUI\nUpload CSV → profile → preview → export\n\nTomorrow you add:\n\ngit + GitHub submission (deadline tomorrow 11:59pm)"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#session-1-objectives",
    "href": "W1_Python/D4_Streamlit_GUI.html#session-1-objectives",
    "title": "Python & Tooling",
    "section": "Session 1 objectives",
    "text": "Session 1 objectives\n\nInstall and run Streamlit using uv\nUnderstand the rerun mental model\nUse core widgets:\n\nst.file_uploader, st.button, st.checkbox\n\nDisplay data and results:\n\nst.write, st.table, st.json"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#what-is-streamlit",
    "href": "W1_Python/D4_Streamlit_GUI.html#what-is-streamlit",
    "title": "Python & Tooling",
    "section": "What is Streamlit?",
    "text": "What is Streamlit?\nStreamlit lets you build a web app with only Python.\nYou write:\n\na single Python script (app.py)\nthat script renders UI + responds to interactions\n\nYou get:\n\na local web app (usually at http://localhost:8501)\nno HTML/CSS/JS required"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#mental-model-streamlit-reruns-your-script",
    "href": "W1_Python/D4_Streamlit_GUI.html#mental-model-streamlit-reruns-your-script",
    "title": "Python & Tooling",
    "section": "Mental model: Streamlit reruns your script",
    "text": "Mental model: Streamlit reruns your script\nEvery user interaction triggers a rerun:\n\nchanging a widget value\nclicking a button\nuploading a file\n\nImplications\n\ndon’t put slow work at the top of the file\nuse buttons and caching for expensive steps\nuse st.session_state to remember results\n\n\nSay: It’s not a server with “routes” like Flask. It’s a script that re-executes.\nAsk: “If the script reruns, why don’t we lose everything?”\nAnswer: session state helps."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#install-streamlit-once",
    "href": "W1_Python/D4_Streamlit_GUI.html#install-streamlit-once",
    "title": "Python & Tooling",
    "section": "Install Streamlit (once)",
    "text": "Install Streamlit (once)\nFrom your project folder:\nuv pip install streamlit\nThen run:\nPYTHONPATH=src uv run streamlit run app.py\n\n\n\n\n\n\nTip\n\n\nIf PYTHONPATH=src feels annoying, keep a small run script later. For today, just use it."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#your-first-streamlit-app-hello",
    "href": "W1_Python/D4_Streamlit_GUI.html#your-first-streamlit-app-hello",
    "title": "Python & Tooling",
    "section": "Your first Streamlit app (Hello)",
    "text": "Your first Streamlit app (Hello)\nCreate app.py in the project root:\nimport streamlit as st\n\nst.set_page_config(page_title=\"CSV Profiler\", layout=\"wide\")\nst.title(\"CSV Profiler\")\nst.caption(\"Week 01 • Day 04 — Streamlit GUI\")\nYou should see a page with a title."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#quick-check",
    "href": "W1_Python/D4_Streamlit_GUI.html#quick-check",
    "title": "Python & Tooling",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: If you edit app.py and save… what happens?\nA. The page updates automatically\nB. You must restart Streamlit\nC. It updates only if you refresh the browser\n\nAnswer: Usually A (Streamlit hot-reloads), but sometimes you’ll refresh."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#sidebar-layout-pattern",
    "href": "W1_Python/D4_Streamlit_GUI.html#sidebar-layout-pattern",
    "title": "Python & Tooling",
    "section": "Sidebar layout pattern",
    "text": "Sidebar layout pattern\nMost Streamlit apps use a sidebar for inputs:\nimport streamlit as st\n\nst.sidebar.header(\"Inputs\")\nsource = st.sidebar.selectbox(\"Data source\", [\"Upload\", \"Local path\"])\nst.write(\"Selected:\", source)\nRule of thumb: Inputs in sidebar, results in main area."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#python-refresher-how-well-represent-csv-data",
    "href": "W1_Python/D4_Streamlit_GUI.html#python-refresher-how-well-represent-csv-data",
    "title": "Python & Tooling",
    "section": "Python refresher: how we’ll represent CSV data",
    "text": "Python refresher: how we’ll represent CSV data\nWhen we parse a CSV, we’ll store it as:\n\nrows → a list\neach item in rows → a dict (one CSV row)\n\nExample:\nrows = [\n    {\"name\": \"Aisha\", \"age\": \"23\"},\n    {\"name\": \"Fahad\", \"age\": \"31\"},\n]\n\nDict keys = column headers\n\nDict values = strings from the CSV (we can convert later)\n\nAccessing a value from a dict (by key):\nrow = {\"name\": \"Aisha\", \"age\": \"23\"}\nname_value = row[\"name\"]   # \"Aisha\""
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#python-refresher-first-5-rows-list-slicing",
    "href": "W1_Python/D4_Streamlit_GUI.html#python-refresher-first-5-rows-list-slicing",
    "title": "Python & Tooling",
    "section": "Python refresher: “first 5 rows” (list slicing)",
    "text": "Python refresher: “first 5 rows” (list slicing)\nA list can be “sliced” to take a smaller piece:\npreview_rows = rows[:5]   # first 5 (or fewer)\nAlso, list items are accessed by index (starting from 0):\n# Only do this if the list is not empty:\nfirst_row = rows[0]\nWe’ll use slicing for previews, and sometimes rows[0] to look at the first row."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#showing-data-without-extra-libraries",
    "href": "W1_Python/D4_Streamlit_GUI.html#showing-data-without-extra-libraries",
    "title": "Python & Tooling",
    "section": "Showing data without extra libraries",
    "text": "Showing data without extra libraries\nIf you have Python objects:\n\nlist of dicts\ndict\nlist of strings\n\nStreamlit can still display them:\nst.write(rows[:5])\nst.json({\"example\": \"any dict works\"})\nst.write(\"Rows:\", len(rows))\n\n\nIf you happen to have pandas, st.dataframe(df) is great but optional."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#file-upload-st.file_uploader",
    "href": "W1_Python/D4_Streamlit_GUI.html#file-upload-st.file_uploader",
    "title": "Python & Tooling",
    "section": "File upload: st.file_uploader",
    "text": "File upload: st.file_uploader\nThis widget returns an uploaded file object (or None):\nuploaded = st.file_uploader(\"Upload a CSV\", type=[\"csv\"])\nif uploaded is not None:\n    st.write(\"Filename:\", uploaded.name)\n    st.write(\"Size (bytes):\", uploaded.size)"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#python-refresher-bytes-vs-text-why-we-call-.decode...",
    "href": "W1_Python/D4_Streamlit_GUI.html#python-refresher-bytes-vs-text-why-we-call-.decode...",
    "title": "Python & Tooling",
    "section": "Python refresher: bytes vs text (why we call .decode(...))",
    "text": "Python refresher: bytes vs text (why we call .decode(...))\n\nuploaded.getvalue() returns bytes (raw file data)\ncsv.DictReader(...) expects text (a string)\n\nSo we decode bytes → text:\nraw = uploaded.getvalue()          # bytes\ntext = raw.decode(\"utf-8-sig\")     # str (text)\n\"utf-8-sig\" helps with CSVs exported from Excel."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#parsing-uploaded-csv-standard-library",
    "href": "W1_Python/D4_Streamlit_GUI.html#parsing-uploaded-csv-standard-library",
    "title": "Python & Tooling",
    "section": "Parsing uploaded CSV (standard library)",
    "text": "Parsing uploaded CSV (standard library)\nWe’ll:\n\nDecode bytes → text\nWrap the text in a file-like object (StringIO)\nUse csv.DictReader to get dictionaries per row\n\nimport csv\nfrom io import StringIO\ntext = uploaded.getvalue().decode(\"utf-8-sig\")\nfile_like = StringIO(text)\nreader = csv.DictReader(file_like)   # each row becomes a dict\nrows = list(reader)                  # list of dicts\nCheckpoint: rows is a list[dict[str, str]]."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#common-pitfall-encoding",
    "href": "W1_Python/D4_Streamlit_GUI.html#common-pitfall-encoding",
    "title": "Python & Tooling",
    "section": "Common pitfall: encoding",
    "text": "Common pitfall: encoding\nIf you get decoding errors:\n\ntry \"utf-8-sig\" (common with Excel exports)\navoid “guessing” too much—log what you tried\n\ndata = uploaded.getvalue().decode(\"utf-8-sig\")"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#activity-find-the-rerun",
    "href": "W1_Python/D4_Streamlit_GUI.html#activity-find-the-rerun",
    "title": "Python & Tooling",
    "section": "Activity: “Find the rerun”",
    "text": "Activity: “Find the rerun”\n\nAdd a checkbox:\n\nshow_preview = st.checkbox(\"Show preview\", value=True)\n\nUpload a CSV.\nToggle the checkbox.\n\nQuestion: Did it rerun? How do you know?\n\nSay: Look for clues: random numbers change, “uploaded name” re-prints, etc.\nTimebox: 5 minutes."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#task-1-hello-streamlit-10-minutes",
    "href": "W1_Python/D4_Streamlit_GUI.html#task-1-hello-streamlit-10-minutes",
    "title": "Python & Tooling",
    "section": "Task 1 — Hello Streamlit (10 minutes)",
    "text": "Task 1 — Hello Streamlit (10 minutes)\nCreate app.py that:\n\nsets page title\nshows a title + short caption\nshows one sidebar selectbox\n\nCheckpoint: App runs and shows UI."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#solution-task-1",
    "href": "W1_Python/D4_Streamlit_GUI.html#solution-task-1",
    "title": "Python & Tooling",
    "section": "Solution — Task 1",
    "text": "Solution — Task 1\nimport streamlit as st\n\nst.set_page_config(page_title=\"CSV Profiler\", layout=\"wide\")\n\nst.title(\"CSV Profiler\")\nst.caption(\"Upload a CSV → profile it → export JSON + Markdown\")\n\nst.sidebar.header(\"Inputs\")\nsource = st.sidebar.selectbox(\"Data source\", [\"Upload\"])\nst.write(\"Selected:\", source)\nRun:\nPYTHONPATH=src uv run streamlit run app.py"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#task-2-upload-preview-15-minutes",
    "href": "W1_Python/D4_Streamlit_GUI.html#task-2-upload-preview-15-minutes",
    "title": "Python & Tooling",
    "section": "Task 2 — Upload + preview (15 minutes)",
    "text": "Task 2 — Upload + preview (15 minutes)\nAdd:\n\nst.file_uploader(..., type=[\"csv\"])\nshow:\n\nfile name\nfirst 5 rows (only if a checkbox is checked)\n\n\nCheckpoint: Uploading a CSV shows a preview."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#solution-task-2-upload-preview",
    "href": "W1_Python/D4_Streamlit_GUI.html#solution-task-2-upload-preview",
    "title": "Python & Tooling",
    "section": "Solution — Task 2 (upload + preview)",
    "text": "Solution — Task 2 (upload + preview)\nimport csv\nfrom io import StringIO\nimport streamlit as st\n\nst.set_page_config(page_title=\"CSV Profiler\", layout=\"wide\")\nst.title(\"CSV Profiler\")\n\nuploaded = st.file_uploader(\"Upload a CSV\", type=[\"csv\"])\nshow_preview = st.checkbox(\"Show preview\", value=True)\n\nif uploaded is not None:\n    text = uploaded.getvalue().decode(\"utf-8-sig\")\n    rows = list(csv.DictReader(StringIO(text)))\n\n    st.write(\"Filename:\", uploaded.name)\n    st.write(\"Rows loaded:\", len(rows))\n\n    if show_preview:\n        st.write(rows[:5])\nelse:\n    st.info(\"Upload a CSV to begin.\")"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#layout-helper-st.columns-metric",
    "href": "W1_Python/D4_Streamlit_GUI.html#layout-helper-st.columns-metric",
    "title": "Python & Tooling",
    "section": "Layout helper: st.columns + metric",
    "text": "Layout helper: st.columns + metric\nst.columns(n) creates side-by-side containers you can write into.\ncols = st.columns(2)\ncols[0].metric(\"Rows\", 1200)\ncols[1].metric(\"Columns\", 35)\nWe’ll use this to make summaries easier to read."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#task-3-show-rowcolumn-counts-10-minutes",
    "href": "W1_Python/D4_Streamlit_GUI.html#task-3-show-rowcolumn-counts-10-minutes",
    "title": "Python & Tooling",
    "section": "Task 3 — Show row/column counts (10 minutes)",
    "text": "Task 3 — Show row/column counts (10 minutes)\nAfter loading rows:\n\ncompute:\n\nn_rows\nn_cols\n\nshow them as metrics\n\nCheckpoint: numbers match what you expect."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#solution-task-3-counts",
    "href": "W1_Python/D4_Streamlit_GUI.html#solution-task-3-counts",
    "title": "Python & Tooling",
    "section": "Solution — Task 3 (counts)",
    "text": "Solution — Task 3 (counts)\nn_rows = len(rows)\n\nn_cols = 0\nif n_rows &gt; 0:\n    n_cols = len(rows[0])\n\ncols = st.columns(2)\ncols[0].metric(\"Rows\", n_rows)\ncols[1].metric(\"Columns\", n_cols)\n\nSay: This is the same pattern you’ll use for the profile summary."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#recap-session-1",
    "href": "W1_Python/D4_Streamlit_GUI.html#recap-session-1",
    "title": "Python & Tooling",
    "section": "Recap (Session 1)",
    "text": "Recap (Session 1)\n\nStreamlit reruns your script on every interaction\nst.sidebar is great for inputs\nYou can load CSV using only csv + StringIO\nNext: reuse your real profiling library (not demo code)"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#session-2-objectives",
    "href": "W1_Python/D4_Streamlit_GUI.html#session-2-objectives",
    "title": "Python & Tooling",
    "section": "Session 2 objectives",
    "text": "Session 2 objectives\n\nImport and call your profiling functions from Streamlit\nDisplay report content in a readable way\nExport outputs:\n\ndownload buttons\nsave-to-disk button (local run)"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#ui-architecture-keep-logic-in-the-package",
    "href": "W1_Python/D4_Streamlit_GUI.html#ui-architecture-keep-logic-in-the-package",
    "title": "Python & Tooling",
    "section": "UI architecture: keep logic in the package",
    "text": "UI architecture: keep logic in the package\nBad (hard to test):\n\nall parsing + profiling inside app.py\n\nGood (reusable):\n\ncsv_profiler/ handles reading/profiling/rendering\napp.py only handles inputs + display\n\nToday we’ll reuse:\n\ncsv_profiler.profiling.profile_rows\ncsv_profiler.render.render_markdown"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#importing-your-package-inside-streamlit",
    "href": "W1_Python/D4_Streamlit_GUI.html#importing-your-package-inside-streamlit",
    "title": "Python & Tooling",
    "section": "Importing your package inside Streamlit",
    "text": "Importing your package inside Streamlit\nBecause your package lives in src/, you must run with:\nPYTHONPATH=src uv run streamlit run app.py\nWindows PowerShell:\n$env:PYTHONPATH=\"src\"\nuv run streamlit run app.py\n\n\n\n\n\n\nWarning\n\n\nIf you see ModuleNotFoundError: csv_profiler, it’s almost always PYTHONPATH."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#generate-report-should-be-a-button",
    "href": "W1_Python/D4_Streamlit_GUI.html#generate-report-should-be-a-button",
    "title": "Python & Tooling",
    "section": "“Generate report” should be a button",
    "text": "“Generate report” should be a button\nProfiling can be expensive.\nPattern:\n\nload data (fast)\nclick button to profile (slow)\nsave results in st.session_state\n\nif st.button(\"Generate report\"):\n    report = profile_rows(rows)\n    st.session_state[\"report\"] = report"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#displaying-the-report-human-friendly",
    "href": "W1_Python/D4_Streamlit_GUI.html#displaying-the-report-human-friendly",
    "title": "Python & Tooling",
    "section": "Displaying the report (human-friendly)",
    "text": "Displaying the report (human-friendly)\nShow:\n\nSummary metrics: rows, cols\nA table of column profiles\nA “raw JSON” expander for debugging\n\nStreamlit pattern: use an expander to hide “too much detail”:\nst.write(report[\"columns\"])\n\nwith st.expander(\"Raw JSON (debug)\", expanded=False):\n    st.json(report)\n\nThe with ...: block means: “put the UI elements inside this expander.”"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#task-4-call-profile_rows-15-minutes",
    "href": "W1_Python/D4_Streamlit_GUI.html#task-4-call-profile_rows-15-minutes",
    "title": "Python & Tooling",
    "section": "Task 4 — Call profile_rows() (15 minutes)",
    "text": "Task 4 — Call profile_rows() (15 minutes)\nIn app.py:\n\nImport:\n\nfrom csv_profiler.profiling import profile_rows\n\nWhen a CSV is uploaded:\n\nparse rows\nclick “Generate report”\nstore report in session state\n\n\nCheckpoint: Find n_rows and n_cols in report."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#solution-task-4-profile-button-session-state",
    "href": "W1_Python/D4_Streamlit_GUI.html#solution-task-4-profile-button-session-state",
    "title": "Python & Tooling",
    "section": "Solution — Task 4 (profile button + session state)",
    "text": "Solution — Task 4 (profile button + session state)\nfrom csv_profiler.profiling import profile_rows\n\nif uploaded is not None:\n    text = uploaded.getvalue().decode(\"utf-8-sig\")\n    rows = list(csv.DictReader(StringIO(text)))\n\n    if st.button(\"Generate report\"):\n        st.session_state[\"report\"] = profile_rows(rows)\n\nreport = st.session_state.get(\"report\")\nif report is not None:\n    st.write(\"Rows:\", report[\"n_rows\"])\n    st.write(\"Cols:\", report[\"n_cols\"])"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#task-5-render-markdown-preview-10-minutes",
    "href": "W1_Python/D4_Streamlit_GUI.html#task-5-render-markdown-preview-10-minutes",
    "title": "Python & Tooling",
    "section": "Task 5 — Render Markdown preview (10 minutes)",
    "text": "Task 5 — Render Markdown preview (10 minutes)\nImport and use:\nfrom csv_profiler.render import render_markdown\nShow Markdown preview:\n\nst.markdown(render_markdown(report))\n\nCheckpoint: You see headings + a columns table."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#solution-task-5-markdown-preview",
    "href": "W1_Python/D4_Streamlit_GUI.html#solution-task-5-markdown-preview",
    "title": "Python & Tooling",
    "section": "Solution — Task 5 (Markdown preview)",
    "text": "Solution — Task 5 (Markdown preview)\nfrom csv_profiler.render import render_markdown\n\nif report is not None:\n    st.subheader(\"Markdown preview\")\n    st.markdown(render_markdown(report))\n\n\n\n\n\n\nTip\n\n\nIf it looks too long, put the preview in an expander."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#export-outputs-download-buttons",
    "href": "W1_Python/D4_Streamlit_GUI.html#export-outputs-download-buttons",
    "title": "Python & Tooling",
    "section": "Export outputs: download buttons",
    "text": "Export outputs: download buttons\nStudents often confuse “download” vs “save”.\nFor a local app, do both:\n\ndownload buttons for convenience\nsave-to-disk for the project requirement\n\nDownload buttons:\nst.download_button(\"Get JSON\", data=json_text, file_name=\"report.json\")\nst.download_button(\"Get Markdown\", data=md_text, file_name=\"report.md\")"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#task-6-download-json-markdown-10-minutes",
    "href": "W1_Python/D4_Streamlit_GUI.html#task-6-download-json-markdown-10-minutes",
    "title": "Python & Tooling",
    "section": "Task 6 — Download JSON + Markdown (10 minutes)",
    "text": "Task 6 — Download JSON + Markdown (10 minutes)\nWhen report exists:\n\nproduce json_text with json.dumps(..., indent=2, ensure_ascii=False)\nproduce md_text with render_markdown(report)\nadd two download buttons\n\nCheckpoint: you can download both files."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#solution-task-6-download-buttons",
    "href": "W1_Python/D4_Streamlit_GUI.html#solution-task-6-download-buttons",
    "title": "Python & Tooling",
    "section": "Solution — Task 6 (download buttons)",
    "text": "Solution — Task 6 (download buttons)\nimport json\nfrom csv_profiler.render import render_markdown\n\nif report is not None:\n    json_text = json.dumps(report, indent=2, ensure_ascii=False)\n    md_text = render_markdown(report)\n\n    l, r = st.columns(2)\n    l.download_button(\"Get JSON\", data=json_text, file_name=\"report.json\")\n    r.download_button(\"Get Markdown\", data=md_text, file_name=\"report.md\")\n\n\n\n\n\n\nTip\n\n\nl, r = x is a quick way to unpack iterables. The above is equivalent to:\ncols = st.columns(2)\nl = cols[0]  # left column\nr = cols[1]  # right column"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#export-outputs-save-to-disk-local-run",
    "href": "W1_Python/D4_Streamlit_GUI.html#export-outputs-save-to-disk-local-run",
    "title": "Python & Tooling",
    "section": "Export outputs: save to disk (local run)",
    "text": "Export outputs: save to disk (local run)\nUse pathlib.Path:\nfrom pathlib import Path\n\nout_dir = Path(\"outputs\")\nout_dir.mkdir(parents=True, exist_ok=True)\n(out_dir / \"report.json\").write_text(json_text, encoding=\"utf-8\")\n(out_dir / \"report.md\").write_text(md_text, encoding=\"utf-8\")\nThen show success with st.success(...)."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#quick-check-1",
    "href": "W1_Python/D4_Streamlit_GUI.html#quick-check-1",
    "title": "Python & Tooling",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: Why is “save to disk” sometimes a bad idea in a deployed web app?\n\nAnswer: The server may be shared, ephemeral, or read-only. For this bootcamp, you run locally, so it’s fine."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#recap-session-2",
    "href": "W1_Python/D4_Streamlit_GUI.html#recap-session-2",
    "title": "Python & Tooling",
    "section": "Recap (Session 2)",
    "text": "Recap (Session 2)\n\nYou can reuse your profiling package in Streamlit\nUse a button for expensive work\nStore results in st.session_state\nExport both:\n\ndownload buttons\nsave-to-disk button"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#session-3-objectives",
    "href": "W1_Python/D4_Streamlit_GUI.html#session-3-objectives",
    "title": "Python & Tooling",
    "section": "Session 3 objectives",
    "text": "Session 3 objectives\n\nFetch CSV data from a URL using httpx.get()\nParse remote CSV safely (timeouts + status checks)\nImprove Streamlit error messages (st.error, st.warning, st.stop)\n(Stretch) Reduce repeated work using caching"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#why-load-from-a-url",
    "href": "W1_Python/D4_Streamlit_GUI.html#why-load-from-a-url",
    "title": "Python & Tooling",
    "section": "Why load from a URL?",
    "text": "Why load from a URL?\nUse cases:\n\ninstructor provides a dataset link\nyou test quickly without moving files\nyou compare multiple CSV sources\n\nRule: Always validate the URL and handle failures."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#install-httpx-optional",
    "href": "W1_Python/D4_Streamlit_GUI.html#install-httpx-optional",
    "title": "Python & Tooling",
    "section": "Install httpx (optional)",
    "text": "Install httpx (optional)\nuv pip install httpx\nThen in Python:\nimport httpx"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#httpx-minimal-safe-get-pattern",
    "href": "W1_Python/D4_Streamlit_GUI.html#httpx-minimal-safe-get-pattern",
    "title": "Python & Tooling",
    "section": "httpx: minimal safe GET pattern",
    "text": "httpx: minimal safe GET pattern\nimport httpx\n\nr = httpx.get(url, timeout=10.0)\nr.raise_for_status()\ntext = r.text\nWhat this gives you:\n\na timeout (no infinite waiting)\nclear error for 404/500 responses"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#parse-remote-csv-from-text",
    "href": "W1_Python/D4_Streamlit_GUI.html#parse-remote-csv-from-text",
    "title": "Python & Tooling",
    "section": "Parse remote CSV from text",
    "text": "Parse remote CSV from text\nSame trick as upload:\nimport csv\nfrom io import StringIO\n\nrows = list(csv.DictReader(StringIO(text)))\nCheckpoint: rows is a list of dictionaries."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#better-streamlit-errors",
    "href": "W1_Python/D4_Streamlit_GUI.html#better-streamlit-errors",
    "title": "Python & Tooling",
    "section": "Better Streamlit errors",
    "text": "Better Streamlit errors\nUse:\n\nst.error(\"...\") for blocking problems\nst.warning(\"...\") for non-blocking issues\nst.stop() to stop the current run cleanly\n\nExample:\nif len(rows) == 0:\n    st.error(\"CSV loaded but has no data rows.\")\n    st.stop()"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#python-refresher-tryexcept-catch-failures",
    "href": "W1_Python/D4_Streamlit_GUI.html#python-refresher-tryexcept-catch-failures",
    "title": "Python & Tooling",
    "section": "Python refresher: try/except (catch failures)",
    "text": "Python refresher: try/except (catch failures)\nWhen we do a network request, it can fail:\n\nbad URL\nno internet\n404 / 500 errors\ntimeout\n\nWe don’t want the whole app to crash, so we catch the error and show a friendly message:\ntry:\n    # risky code\n    ...\nexcept Exception as e:\n    st.error(\"Something went wrong: \" + str(e))\n    st.stop()\n\ne is the error object. str(e) turns it into a readable message."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#task-7-add-load-from-url-15-minutes",
    "href": "W1_Python/D4_Streamlit_GUI.html#task-7-add-load-from-url-15-minutes",
    "title": "Python & Tooling",
    "section": "Task 7 — Add “Load from URL” (15 minutes)",
    "text": "Task 7 — Add “Load from URL” (15 minutes)\nIn the sidebar:\n\nadd a checkbox: “Load from URL”\nif checked:\n\nshow a text input for URL\nuse httpx.get() to fetch\nparse CSV rows\nprofile like normal\n\n\nCheckpoint: A valid URL produces a report."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#solution-task-7-url-loader",
    "href": "W1_Python/D4_Streamlit_GUI.html#solution-task-7-url-loader",
    "title": "Python & Tooling",
    "section": "Solution — Task 7 (URL loader)",
    "text": "Solution — Task 7 (URL loader)\nimport csv\nfrom io import StringIO\nimport httpx\n\nuse_url = st.sidebar.checkbox(\"Load from URL\", value=False)\n\nurl = \"\"\nif use_url:\n    url = st.sidebar.text_input(\"CSV URL\", placeholder=\"https://.../data.csv\")\n\nif use_url:\n    if url == \"\":\n        st.warning(\"Paste a URL to load a CSV.\")\n        st.stop()\n\n    try:\n        r = httpx.get(url, timeout=10.0)\n        r.raise_for_status()\n        text = r.text\n        rows = list(csv.DictReader(StringIO(text)))\n    except Exception as e:\n        st.error(\"Failed to load URL: \" + str(e))\n        st.stop()\n\n\nThis is “stretch”: upload-only is required; URL loading is optional."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#stretch-caching-expensive-work-optional",
    "href": "W1_Python/D4_Streamlit_GUI.html#stretch-caching-expensive-work-optional",
    "title": "Python & Tooling",
    "section": "Stretch: caching expensive work (optional)",
    "text": "Stretch: caching expensive work (optional)\nIf profiling takes time, cache the result.\n@st.cache_data\ndef cached_profile(rows):\n    return profile_rows(rows)\nThen call cached_profile(rows).\n\nThe line starting with @ is a decorator: it changes how the function runs (here: remembers results). You don’t need to write your own decorators today.\n\n\n\n\n\n\n\nWarning\n\n\nCaching can hide bugs when you change code. Use it only after your logic works."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#mini-quiz-what-should-have-a-timeout",
    "href": "W1_Python/D4_Streamlit_GUI.html#mini-quiz-what-should-have-a-timeout",
    "title": "Python & Tooling",
    "section": "Mini-quiz: what should have a timeout?",
    "text": "Mini-quiz: what should have a timeout?\nA. HTTP requests\nB. Disk reads\nC. Profiling computation\nD. All of the above\n\nAnswer: D. At minimum: HTTP requests."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#recap-session-3",
    "href": "W1_Python/D4_Streamlit_GUI.html#recap-session-3",
    "title": "Python & Tooling",
    "section": "Recap (Session 3)",
    "text": "Recap (Session 3)\n\nhttpx.get(url, timeout=...) + raise_for_status() is a good baseline\nUse Streamlit error patterns to keep UX clean\nCaching is optional, but useful for performance"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#hands-on-goal",
    "href": "W1_Python/D4_Streamlit_GUI.html#hands-on-goal",
    "title": "Python & Tooling",
    "section": "Hands-on goal",
    "text": "Hands-on goal\nBy the end of the lab, your project has:\n\napp.py (Streamlit GUI)\nUpload CSV → profile → preview\nExport:\n\ndownload JSON + Markdown\nsave JSON + Markdown to outputs/\n\n\nYou should be able to demo in 60 seconds."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#success-criteria-what-we-will-check",
    "href": "W1_Python/D4_Streamlit_GUI.html#success-criteria-what-we-will-check",
    "title": "Python & Tooling",
    "section": "Success criteria (what we will check)",
    "text": "Success criteria (what we will check)\nYour Streamlit app must:\n\nRun with uv (same environment as the CLI)\nRead a CSV using file upload\nGenerate a profiling report using your package code\nExport outputs as JSON + Markdown\nHandle basic errors:\n\nno file uploaded\nempty CSV"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#hands-on-checklist",
    "href": "W1_Python/D4_Streamlit_GUI.html#hands-on-checklist",
    "title": "Python & Tooling",
    "section": "Hands-on checklist",
    "text": "Hands-on checklist\nCommands you should be able to run:\n# CLI\nPYTHONPATH=src uv run python -m csv_profiler.cli profile data/sample.csv\n\n# GUI\nPYTHONPATH=src uv run streamlit run app.py"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#task-1-create-app.py-scaffold-10-minutes",
    "href": "W1_Python/D4_Streamlit_GUI.html#task-1-create-app.py-scaffold-10-minutes",
    "title": "Python & Tooling",
    "section": "Task 1 — Create app.py scaffold (10 minutes)",
    "text": "Task 1 — Create app.py scaffold (10 minutes)\napp.py should contain:\n\nst.set_page_config(...)\ntitle + caption\nsidebar section called “Inputs”\nempty placeholders for:\n\nrows\nreport\n\n\nCheckpoint: App starts and looks clean."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#solution-task-1-scaffold",
    "href": "W1_Python/D4_Streamlit_GUI.html#solution-task-1-scaffold",
    "title": "Python & Tooling",
    "section": "Solution — Task 1 scaffold",
    "text": "Solution — Task 1 scaffold\nimport streamlit as st\n\nst.set_page_config(page_title=\"CSV Profiler\", layout=\"wide\")\n\nst.title(\"CSV Profiler\")\nst.caption(\"Upload CSV → profile → export JSON + Markdown\")\n\nst.sidebar.header(\"Inputs\")\n\nrows = None\nreport = st.session_state.get(\"report\")"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#task-2-upload-csv-and-parse-rows-15-minutes",
    "href": "W1_Python/D4_Streamlit_GUI.html#task-2-upload-csv-and-parse-rows-15-minutes",
    "title": "Python & Tooling",
    "section": "Task 2 — Upload CSV and parse rows (15 minutes)",
    "text": "Task 2 — Upload CSV and parse rows (15 minutes)\nAdd:\n\nuploaded = st.file_uploader(...)\nparse into rows (a list of dictionaries)\nshow a preview toggle + preview\n\nCheckpoint: preview shows reasonable values."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#solution-task-2-upload-parse",
    "href": "W1_Python/D4_Streamlit_GUI.html#solution-task-2-upload-parse",
    "title": "Python & Tooling",
    "section": "Solution — Task 2 (upload + parse)",
    "text": "Solution — Task 2 (upload + parse)\nimport csv\nfrom io import StringIO\n\nuploaded = st.file_uploader(\"Upload a CSV\", type=[\"csv\"])\nshow_preview = st.sidebar.checkbox(\"Show preview\", value=True)\n\nif uploaded is not None:\n    text = uploaded.getvalue().decode(\"utf-8-sig\")\n    rows = list(csv.DictReader(StringIO(text)))\n\n    if show_preview:\n        st.subheader(\"Preview\")\n        st.write(rows[:5])\nelse:\n    st.info(\"Upload a CSV to begin.\")"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#task-3-generate-report-button-15-minutes",
    "href": "W1_Python/D4_Streamlit_GUI.html#task-3-generate-report-button-15-minutes",
    "title": "Python & Tooling",
    "section": "Task 3 — Generate report (button) (15 minutes)",
    "text": "Task 3 — Generate report (button) (15 minutes)\nWhen rows exist:\n\nshow a button: “Generate report”\ncompute report using profile_rows(rows)\nstore in st.session_state[\"report\"]\n\nCheckpoint: report summary displays rows/cols."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#solution-task-3-generate-report",
    "href": "W1_Python/D4_Streamlit_GUI.html#solution-task-3-generate-report",
    "title": "Python & Tooling",
    "section": "Solution — Task 3 (generate report)",
    "text": "Solution — Task 3 (generate report)\nfrom csv_profiler.profiling import profile_rows\n\nif rows is not None:\n    if len(rows) &gt; 0:\n        if st.button(\"Generate report\"):\n            st.session_state[\"report\"] = profile_rows(rows)\n\nreport = st.session_state.get(\"report\")\nif report is not None:\n    cols = st.columns(2)\n    cols[0].metric(\"Rows\", report[\"n_rows\"])\n    cols[1].metric(\"Columns\", report[\"n_cols\"])"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#task-4-show-column-table-markdown-preview-15-minutes",
    "href": "W1_Python/D4_Streamlit_GUI.html#task-4-show-column-table-markdown-preview-15-minutes",
    "title": "Python & Tooling",
    "section": "Task 4 — Show column table + Markdown preview (15 minutes)",
    "text": "Task 4 — Show column table + Markdown preview (15 minutes)\nDisplay:\n\nreport[\"columns\"] in a readable format\nMarkdown preview using render_markdown(report) (prefer an expander)\n\nCheckpoint: Markdown contains the table."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#solution-task-4-display",
    "href": "W1_Python/D4_Streamlit_GUI.html#solution-task-4-display",
    "title": "Python & Tooling",
    "section": "Solution — Task 4 (display)",
    "text": "Solution — Task 4 (display)\nfrom csv_profiler.render import render_markdown\n\nif report is not None:\n    st.subheader(\"Columns\")\n    st.write(report[\"columns\"])\n\n    with st.expander(\"Markdown preview\", expanded=False):\n        st.markdown(render_markdown(report))"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#task-5-export-download-save-20-minutes",
    "href": "W1_Python/D4_Streamlit_GUI.html#task-5-export-download-save-20-minutes",
    "title": "Python & Tooling",
    "section": "Task 5 — Export (download + save) (20 minutes)",
    "text": "Task 5 — Export (download + save) (20 minutes)\nAdd exports:\n\nDownload JSON + Markdown\nSave JSON + Markdown to outputs/\n\nUI suggestion:\n\na text input for report_name (default: report)\na button: “Save to outputs/”\n\nCheckpoint: report.json & report.md in outputs/."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#solution-task-5-exports",
    "href": "W1_Python/D4_Streamlit_GUI.html#solution-task-5-exports",
    "title": "Python & Tooling",
    "section": "Solution — Task 5 (exports)",
    "text": "Solution — Task 5 (exports)\nimport json\nfrom pathlib import Path\nfrom csv_profiler.render import render_markdown\n\nif report is not None:\n    report_name = st.sidebar.text_input(\"Report name\", value=\"report\")\n\n    json_file = report_name + \".json\"\n    json_text = json.dumps(report, indent=2, ensure_ascii=False)\n\n    md_file = report_name + \".md\"\n    md_text = render_markdown(report)\n\n    c1, c2 = st.columns(2)\n    c1.download_button(\"Download JSON\", data=json_text, file_name=json_file)\n    c2.download_button(\"Download Markdown\", data=md_text, file_name=md_file)\n\n    if st.button(\"Save to outputs/\"):\n        out_dir = Path(\"outputs\")\n        out_dir.mkdir(parents=True, exist_ok=True)\n        (out_dir / json_file).write_text(json_text, encoding=\"utf-8\")\n        (out_dir / md_file).write_text(md_text, encoding=\"utf-8\")\n        st.success(\"Saved outputs/\" + json_file + \" and outputs/\" + md_file)"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#task-6-error-handling-polish-10-minutes",
    "href": "W1_Python/D4_Streamlit_GUI.html#task-6-error-handling-polish-10-minutes",
    "title": "Python & Tooling",
    "section": "Task 6 — Error handling polish (10 minutes)",
    "text": "Task 6 — Error handling polish (10 minutes)\nAdd friendly errors:\n\nIf uploaded CSV has no rows:\n\nshow st.error(...)\nstop execution\n\nIf rows exists but the first row has no columns (no headers detected):\n\nshow st.warning(...)\n\n\nCheckpoint: app never crashes with a Python traceback for these cases."
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#solution-task-6-safe-guards",
    "href": "W1_Python/D4_Streamlit_GUI.html#solution-task-6-safe-guards",
    "title": "Python & Tooling",
    "section": "Solution — Task 6 (safe guards)",
    "text": "Solution — Task 6 (safe guards)\nif uploaded is not None:\n    text = uploaded.getvalue().decode(\"utf-8-sig\")\n    rows = list(csv.DictReader(StringIO(text)))\n\n    if len(rows) == 0:\n        st.error(\"CSV has no data. Upload a CSV with at least 1 row.\")\n        st.stop()\n\n    if len(rows[0]) == 0:\n        st.warning(\"CSV has no headers (no columns detected).\")"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#run-verify-5-minutes",
    "href": "W1_Python/D4_Streamlit_GUI.html#run-verify-5-minutes",
    "title": "Python & Tooling",
    "section": "Run + verify (5 minutes)",
    "text": "Run + verify (5 minutes)\nRun:\nPYTHONPATH=src uv run streamlit run app.py\nVerify:\n\nUpload works\nGenerate report works\nDownload works\nSave-to-disk works"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#troubleshooting",
    "href": "W1_Python/D4_Streamlit_GUI.html#troubleshooting",
    "title": "Python & Tooling",
    "section": "Troubleshooting",
    "text": "Troubleshooting\nProblem: ModuleNotFoundError: csv_profiler\nFix: run with PYTHONPATH=src (and be in the project root)\nProblem: Streamlit command not found\nFix: uv pip install streamlit\nProblem: Upload works, but profiling fails\nFix: print a sample row: st.write(rows[0]) to inspect keys/values"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#stretch-tasks-if-you-finish-early",
    "href": "W1_Python/D4_Streamlit_GUI.html#stretch-tasks-if-you-finish-early",
    "title": "Python & Tooling",
    "section": "Stretch tasks (if you finish early)",
    "text": "Stretch tasks (if you finish early)\n\nAdd a “Top missing columns” section:\n\nsort by missing_pct and show top 5\n\nAdd a filter:\n\nshow only columns of type number\n\nAdd a timing display:\n\nshow report[\"timing_ms\"] if present (or measure in app)"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#recap-day-4",
    "href": "W1_Python/D4_Streamlit_GUI.html#recap-day-4",
    "title": "Python & Tooling",
    "section": "Recap (Day 4)",
    "text": "Recap (Day 4)\nYou now have:\n\na working Streamlit GUI for your profiler\nexports to JSON + Markdown\nbasic error handling\n\nTomorrow:\n\nGit + GitHub workflow\nfinal polish and submission by tomorrow 11:59pm"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#exit-ticket",
    "href": "W1_Python/D4_Streamlit_GUI.html#exit-ticket",
    "title": "Python & Tooling",
    "section": "Exit Ticket",
    "text": "Exit Ticket\nIn 1–2 sentences:\nWhat part of Streamlit felt most “different” from normal Python scripts?"
  },
  {
    "objectID": "W1_Python/D4_Streamlit_GUI.html#what-to-do-after-class-day-4-assignment",
    "href": "W1_Python/D4_Streamlit_GUI.html#what-to-do-after-class-day-4-assignment",
    "title": "Python & Tooling",
    "section": "What to do after class (Day 4 assignment)",
    "text": "What to do after class (Day 4 assignment)\nDue: before Day 5 starts (Thu, 18 Dec 2025)\n\nMake the UI demo-ready:\n\nnice headings and layout\nclear buttons\n\nAdd one UX improvement:\n\nst.expander, st.tabs, or st.columns\n\nConfirm these commands work:\n\nPYTHONPATH=src uv run python -m csv_profiler.cli profile data/sample.csv\nPYTHONPATH=src uv run streamlit run app.py\nDeliverable: updated project folder (ready to be committed + pushed tomorrow)."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#todays-flow",
    "href": "W1_Python/D2_Functions_Files.html#todays-flow",
    "title": "Python & Tooling",
    "section": "Today’s Flow",
    "text": "Today’s Flow\n\nSession 1 (60m): Procedural programming with functions\nAsr Prayer (20m)\nSession 2 (60m): Strings + formatting → generate Markdown reports\nMaghrib Prayer (20m)\nSession 3 (60m): Files + pathlib + csv + json\nIsha Prayer (20m)\nHands-on (120m): CSV Profiler — Part 2 (type inference + numeric stats)"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#learning-objectives",
    "href": "W1_Python/D2_Functions_Files.html#learning-objectives",
    "title": "Python & Tooling",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of today, you can:\n\nWrite reusable functions (args, defaults, *args, **kwargs, keyword-only)\nUse built-ins like enumerate, zip, sorted, any, all\nGenerate clean Markdown with f-strings + join()\nUse pathlib.Path for safe paths\nRead CSVs with csv.DictReader and write JSON with json.dumps()\nUpgrade your profiler: type inference + stats\nAdd type hints to clarify inputs/outputs (name: str, -&gt; float | None)\nUse lambda for tiny one-off helper functions (mostly with key=)"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#warm-up-5-minutes",
    "href": "W1_Python/D2_Functions_Files.html#warm-up-5-minutes",
    "title": "Python & Tooling",
    "section": "Warm-up (5 minutes)",
    "text": "Warm-up (5 minutes)\nOpen your Day 1 project and run it.\nTarget command (Unix/macOS):\ncd ~/bootcamp/csv-profiler\nuv run python main.py\nTarget command (Windows PowerShell):\ncd $HOME\\bootcamp\\csv-profiler\nuv run python main.py\nCheckpoint: outputs/report.json and outputs/report.md are created."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#if-imports-fail-quick-fixes-2-common-layouts",
    "href": "W1_Python/D2_Functions_Files.html#if-imports-fail-quick-fixes-2-common-layouts",
    "title": "Python & Tooling",
    "section": "If imports fail: quick fixes (2 common layouts)",
    "text": "If imports fail: quick fixes (2 common layouts)\nIf you see ModuleNotFoundError: No module named 'csv_profiler', Python can’t find your project package.\nLayout A (recommended this week): package folder next to main.py\ncsv-profiler/\n  main.py\n  csv_profiler/\n    __init__.py\n    ...\nRun:\nuv run python main.py"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#if-imports-fail-quick-fixes-2-common-layouts-1",
    "href": "W1_Python/D2_Functions_Files.html#if-imports-fail-quick-fixes-2-common-layouts-1",
    "title": "Python & Tooling",
    "section": "If imports fail: quick fixes (2 common layouts)",
    "text": "If imports fail: quick fixes (2 common layouts)\nLayout B (src layout): package folder inside src/\ncsv-profiler/\n  main.py\n  src/\n    csv_profiler/\n      __init__.py\n      ...\nRun with PYTHONPATH=src:\n\nUnix/macOS:\n\nPYTHONPATH=src uv run python main.py\n\nWindows PowerShell:\n\n$env:PYTHONPATH=\"src\"\nuv run python main.py\n\n\n\n\n\n\nTip\n\n\nWe’ll formalize packaging later. For now, pick one layout and keep moving."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#week-project-progress",
    "href": "W1_Python/D2_Functions_Files.html#week-project-progress",
    "title": "Python & Tooling",
    "section": "Week project progress",
    "text": "Week project progress\nYou already have (Day 1):\n\nRead a CSV into rows: a list of dictionaries (each row looks like {\"age\": \"19\", \"name\": \"Aisha\"})\nCompute a basic report (rows/columns + missing count)\nWrite report.json and report.md\n\nToday you will add:\n\nColumn type inference: number vs text\nNumeric stats: min, max, mean, unique\nCleaner Markdown structure (tables + sections)"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#quick-recap-python-building-blocks-well-use-today",
    "href": "W1_Python/D2_Functions_Files.html#quick-recap-python-building-blocks-well-use-today",
    "title": "Python & Tooling",
    "section": "Quick recap: Python building blocks we’ll use today",
    "text": "Quick recap: Python building blocks we’ll use today\nYou don’t need to be a Python expert — but we will use these basics repeatedly:\n\nLists: values = [], values.append(x)\nDicts: row[\"age\"] and safe access row.get(\"age\", \"\")\nfor loops: repeat work for each item in a list\nNone: means “no value” (we’ll use it for “couldn’t parse”)\nImports: import csv, from pathlib import Path\n\nrow = {\"age\": \"19\", \"name\": \"Aisha\"}\nage_text = row.get(\"age\", \"\")   # returns \"\" if the key is missing\n\nfor ch in age_text:\n    print(ch)\n\n\nIf you see “type hints” (x: int, -&gt; str) in reference code online: don’t stress — we’ll introduce them later today. They’re optional metadata."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#session-1-objectives",
    "href": "W1_Python/D2_Functions_Files.html#session-1-objectives",
    "title": "Python & Tooling",
    "section": "Session 1 objectives",
    "text": "Session 1 objectives\n\nExplain why we refactor into functions\nWrite functions with clear inputs/outputs\nUse different parameter styles safely\nUse built-ins that make your code shorter and clearer"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#why-functions-in-one-sentence",
    "href": "W1_Python/D2_Functions_Files.html#why-functions-in-one-sentence",
    "title": "Python & Tooling",
    "section": "Why functions? (in one sentence)",
    "text": "Why functions? (in one sentence)\nA function lets you name a piece of logic so you can:\n\nreuse it\ntest it\nread it later without re-thinking it\nchange it in one place\n\n\n\nIn this project, “profiling” becomes a set of small functions you can compose."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#anatomy-of-a-function",
    "href": "W1_Python/D2_Functions_Files.html#anatomy-of-a-function",
    "title": "Python & Tooling",
    "section": "Anatomy of a function",
    "text": "Anatomy of a function\ndef greet(name):\n    \"\"\"Return a friendly greeting.\"\"\"\n    return \"Hello \" + name + \"!\"\n\ndef creates the function\nparameters go inside (...)\nindentation defines the function body\nreturn sends a value back to the caller\ndocstrings (triple quotes) are optional but helpful"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#type-hints-optional-inputsoutputs-labels",
    "href": "W1_Python/D2_Functions_Files.html#type-hints-optional-inputsoutputs-labels",
    "title": "Python & Tooling",
    "section": "Type hints: optional inputs/outputs “labels”",
    "text": "Type hints: optional inputs/outputs “labels”\nType hints tell readers (and tooling) what you expect.\ndef greet(name: str) -&gt; str:\n    return \"Hello \" + name + \"!\"\n\nname: str means “I expect a string”\n-&gt; str describes the return value\nhints don’t change behavior — they’re metadata\n\n\n\n\n\n\n\nTip\n\n\nHints are helpful when a function can return different things, like float | None (“either a float or missing”)."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#mini-exercise-add-type-hints-2-minutes",
    "href": "W1_Python/D2_Functions_Files.html#mini-exercise-add-type-hints-2-minutes",
    "title": "Python & Tooling",
    "section": "Mini-exercise — add type hints (2 minutes)",
    "text": "Mini-exercise — add type hints (2 minutes)\nAdd type hints (no body changes):\ndef add(a, b=1.0):\n    return a + b\n\ndef clean_text(s):\n    return s.strip().casefold()\n\nCheckpoint: your headers look like:\ndef add(a: float, b: float = 1.0) -&gt; float: ...\ndef clean_text(s: str) -&gt; str: ...\n\n\n\nIf you’re not sure, guess — hints are easy to adjust later."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#side-effects-vs-return-values",
    "href": "W1_Python/D2_Functions_Files.html#side-effects-vs-return-values",
    "title": "Python & Tooling",
    "section": "Side effects vs return values",
    "text": "Side effects vs return values\n\n\n\n\n\n\nDefinition\n\n\nA function’s side effect is any change to the system’s state during its execution apart from its retun value\n\n\n\nPure-ish (good for profiling):\ndef mean(values: list[float]) -&gt; float:\n    return sum(values) / len(values)\nSide effect (still useful, but keep controlled):\ndef write_text(path: str, text: str) -&gt; None:\n    open(path, \"w\").write(text)\n\n\n\n\n\n\nWarning\n\n\nTry to keep profiling logic mostly “return values”. Keep I/O (reading/writing files) in a small number of places."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#parameters-defaults-most-common",
    "href": "W1_Python/D2_Functions_Files.html#parameters-defaults-most-common",
    "title": "Python & Tooling",
    "section": "Parameters + defaults (most common)",
    "text": "Parameters + defaults (most common)\ndef add(a, b=1.0):\n    return a + b\nCalls:\nadd(1, 2)\nadd(7)\nadd(a=1, b=2)\nadd(b=2, a=1)"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#quick-check",
    "href": "W1_Python/D2_Functions_Files.html#quick-check",
    "title": "Python & Tooling",
    "section": "Quick Check",
    "text": "Quick Check\nWhat is printed?\ndef add(a, b=1):\n    return a + b\n\nprint(add(10))\nprint(add(10, 5))\n\nAnswer: 11 then 15"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#args-many-positional-arguments",
    "href": "W1_Python/D2_Functions_Files.html#args-many-positional-arguments",
    "title": "Python & Tooling",
    "section": "*args: “many positional arguments”",
    "text": "*args: “many positional arguments”\ndef accumulate(*numbers: float) -&gt; float:\n    total = 0.0\n    for n in numbers:\n        total += n\n    return total\n\naccumulate(1, 2, 3)     # 6.0\naccumulate(5)           # 5.0\naccumulate()            # 0.0"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#kwargs-many-keyword-arguments",
    "href": "W1_Python/D2_Functions_Files.html#kwargs-many-keyword-arguments",
    "title": "Python & Tooling",
    "section": "**kwargs: “many keyword arguments”",
    "text": "**kwargs: “many keyword arguments”\ndef double(**values: float) -&gt; dict[str, float]:\n    # values is a dict: {name: number}\n    out = {}\n    for k, v in values.items():\n        out[k] = v * 2\n    return out\n\ndouble(a=1, b=2)  # {\"a\": 2, \"b\": 4}\n\n\n\nvalues is a dict containing the extra keyword arguments\n.items() lets you loop over (key, value) pairs\nIn this week, we’ll mostly use **kwargs for optional config later"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#positional-only-and-keyword-only-parameters",
    "href": "W1_Python/D2_Functions_Files.html#positional-only-and-keyword-only-parameters",
    "title": "Python & Tooling",
    "section": "Positional-only and keyword-only parameters",
    "text": "Positional-only and keyword-only parameters\n# a: positional-only\n# b: positional-or-keyword\n# c: keyword-only\ndef f(a, /, b, *, c):\n    print(a, b, c)\n\nf(1, 2, c=3)\nf(1, b=2, c=3)\nWhy care?\n\nkeyword-only parameters make call sites more readable\npositional-only can protect APIs from accidental misuse"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#common-built-in-functions-youll-use-today",
    "href": "W1_Python/D2_Functions_Files.html#common-built-in-functions-youll-use-today",
    "title": "Python & Tooling",
    "section": "Common built-in functions you’ll use today",
    "text": "Common built-in functions you’ll use today\n\nSequence math: len, sum, min, max, all, any\nSequence helpers: sorted, reversed, enumerate, zip\nIteration: range, iter, next"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#enumerate-index-value",
    "href": "W1_Python/D2_Functions_Files.html#enumerate-index-value",
    "title": "Python & Tooling",
    "section": "enumerate: index + value",
    "text": "enumerate: index + value\nInstead of:\ni = 0\nfor line in lines:\n    print(i, line)\n    i += 1\nUse:\nfor i, line in enumerate(lines):\n    print(i, line)"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#zip-walk-multiple-lists-together",
    "href": "W1_Python/D2_Functions_Files.html#zip-walk-multiple-lists-together",
    "title": "Python & Tooling",
    "section": "zip: walk multiple lists together",
    "text": "zip: walk multiple lists together\nnames = [\"A\", \"B\", \"C\"]\nages = [20, 21, 19]\n\nfor name, age in zip(names, ages):\n    print(name, age)\n\n\nIn the report, zip() can pair column names with stats."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#sorted-keep-original-list-unchanged",
    "href": "W1_Python/D2_Functions_Files.html#sorted-keep-original-list-unchanged",
    "title": "Python & Tooling",
    "section": "sorted: keep original list unchanged",
    "text": "sorted: keep original list unchanged\nvalues = [3, 1, 2]\nprint(sorted(values))   # [1, 2, 3]\nprint(values)           # [3, 1, 2]\nAlso useful with a key:\nsorted(words, key=len)"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#sorted...-key...-reversetrue-custom-ordering",
    "href": "W1_Python/D2_Functions_Files.html#sorted...-key...-reversetrue-custom-ordering",
    "title": "Python & Tooling",
    "section": "sorted(..., key=..., reverse=True): custom ordering",
    "text": "sorted(..., key=..., reverse=True): custom ordering\nSometimes you’re sorting pairs like (\"value\", count) and you want to sort by the count.\nA “pair” here is a 2-item tuple (think “small fixed list”).\npairs = [(\"a\", 2), (\"b\", 5), (\"c\", 1)]\n\ndef by_count(pair: tuple[str, int]) -&gt; int:\n    return pair[1]\n\nprint(sorted(pairs, key=by_count, reverse=True))\n# [('b', 5), ('a', 2), ('c', 1)]\n\n\nWe’ll use this pattern to compute “top values” for text columns."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#lambda-a-tiny-function-inline-common-with-key",
    "href": "W1_Python/D2_Functions_Files.html#lambda-a-tiny-function-inline-common-with-key",
    "title": "Python & Tooling",
    "section": "Lambda: a tiny function inline (common with key=)",
    "text": "Lambda: a tiny function inline (common with key=)\nSometimes you need a “throwaway” helper for a single call.\n# same result as defining `by_count(...)`\nsorted(pairs, key=lambda pair: pair[1], reverse=True)\n\nsyntax: lambda &lt;inputs&gt;: &lt;expression&gt;\nlambdas are one expression (no multi-line bodies)\nif you want reuse, comments, or tests → use def\n\n\n\nYou’ll most often see lambdas with sorted, min, and max."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#mini-exercise-lambda-sorted-3-minutes",
    "href": "W1_Python/D2_Functions_Files.html#mini-exercise-lambda-sorted-3-minutes",
    "title": "Python & Tooling",
    "section": "Mini-exercise — lambda + sorted (3 minutes)",
    "text": "Mini-exercise — lambda + sorted (3 minutes)\nSort words by length, longest first:\nwords = [\"python\", \"ai\", \"bootcamp\", \"data\"]\nsorted_words = sorted(words, key=..., reverse=True)\nprint(sorted_words)\nCheckpoint: ['bootcamp', 'python', 'data', 'ai']\n\n\n\n\n\n\nTip\n\n\nYour key= function gets one word at a time and returns the sort key."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#mapfilter-vs-comprehensions",
    "href": "W1_Python/D2_Functions_Files.html#mapfilter-vs-comprehensions",
    "title": "Python & Tooling",
    "section": "Map/filter vs comprehensions",
    "text": "Map/filter vs comprehensions\nThese work:\nlist(map(lambda x: x * 2, [1, 2, 3]))\nlist(filter(lambda x: x % 2 == 0, [1, 2, 3, 4]))\nBut for readability, prefer:\n[x * 2 for x in [1, 2, 3]]\n[x for x in [1, 2, 3, 4] if x % 2 == 0]"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#cleaning-csv-text-values-strip-casefold",
    "href": "W1_Python/D2_Functions_Files.html#cleaning-csv-text-values-strip-casefold",
    "title": "Python & Tooling",
    "section": "Cleaning CSV text values: strip() + casefold()",
    "text": "Cleaning CSV text values: strip() + casefold()\nCSV values arrive as text, and they often include extra spaces or inconsistent capitalization.\ns = \"  NA  \"\nprint(s.strip())            # \"NA\"\nprint(s.strip().casefold()) # \"na\"\nWe’ll use this idea in is_missing(...)."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#mini-exercise-1-5-minutes",
    "href": "W1_Python/D2_Functions_Files.html#mini-exercise-1-5-minutes",
    "title": "Python & Tooling",
    "section": "Mini-exercise 1 (5 minutes)",
    "text": "Mini-exercise 1 (5 minutes)\nWrite a function:\ndef is_missing(value: str | None) -&gt; bool:\n    \"\"\"True for empty / null-ish CSV values.\"\"\"\n    ...\nTreat these as missing (case-insensitive):\n\n\"\"\n\"na\", \"n/a\"\n\"null\", \"none\", \"nan\"\nwhitespace-only strings\n\nCheckpoint: is_missing(\" NA \") is True."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#solution-is_missing",
    "href": "W1_Python/D2_Functions_Files.html#solution-is_missing",
    "title": "Python & Tooling",
    "section": "Solution — is_missing",
    "text": "Solution — is_missing\nMISSING = {\"\", \"na\", \"n/a\", \"null\", \"none\", \"nan\"}\n\ndef is_missing(value: str | None) -&gt; bool:\n    if value is None:\n        return True\n    cleaned = value.strip().casefold()\n    return cleaned in MISSING\n\n\n\n\n\n\nTip\n\n\nUse casefold() (stronger than lower()) for case-insensitive checks."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#tryexcept-safe-parsing-youll-use-this-a-lot",
    "href": "W1_Python/D2_Functions_Files.html#tryexcept-safe-parsing-youll-use-this-a-lot",
    "title": "Python & Tooling",
    "section": "try/except: safe parsing (you’ll use this a lot)",
    "text": "try/except: safe parsing (you’ll use this a lot)\nCSV values arrive as strings. Converting to a number can fail (example: \"abc\").\nvalue = \"3.14\"\n\ntry:\n    x = float(value)\nexcept ValueError:\n    x = None\n\nCode inside try: runs first\nIf Python hits a ValueError, it jumps to except:\nWe return/use None to mean “couldn’t parse”"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#mini-exercise-2-6-minutes",
    "href": "W1_Python/D2_Functions_Files.html#mini-exercise-2-6-minutes",
    "title": "Python & Tooling",
    "section": "Mini-exercise 2 (6 minutes)",
    "text": "Mini-exercise 2 (6 minutes)\nWrite a safe parser:\ndef try_float(value: str) -&gt; float | None:\n    \"\"\"Return float(value) or None if it fails.\"\"\"\n    ...\nCheckpoint: try_float(\"3.14\") → 3.14, try_float(\"abc\") → None"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#solution-try_float",
    "href": "W1_Python/D2_Functions_Files.html#solution-try_float",
    "title": "Python & Tooling",
    "section": "Solution — try_float",
    "text": "Solution — try_float\ndef try_float(value: str) -&gt; float | None:\n    try:\n        return float(value)\n    except ValueError:\n        return None"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#type-inference-simple-rule",
    "href": "W1_Python/D2_Functions_Files.html#type-inference-simple-rule",
    "title": "Python & Tooling",
    "section": "Type inference (simple rule)",
    "text": "Type inference (simple rule)\nFor a list of strings:\n\nignore missing values\nif every remaining value parses as float → number\nelse → text\n\n\n\nThis is a safe baseline. Later we can add a “mostly numeric” threshold."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#example-infer-type",
    "href": "W1_Python/D2_Functions_Files.html#example-infer-type",
    "title": "Python & Tooling",
    "section": "Example: infer type",
    "text": "Example: infer type\ndef infer_type(values: list[str]) -&gt; str:\n    usable = [v for v in values if not is_missing(v)]\n    if not usable:\n        return \"text\"\n    for v in usable:\n        if try_float(v) is None:\n            return \"text\"\n    return \"number\""
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#quick-check-1",
    "href": "W1_Python/D2_Functions_Files.html#quick-check-1",
    "title": "Python & Tooling",
    "section": "Quick Check",
    "text": "Quick Check\nIf a column has values: [\"1\", \"2\", \"3\", \"x\"]\n\nWith the simple rule, is it number or text?\n\n\nAnswer: text (because \"x\" is not numeric)"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#advanced-features-you-saw-them-in-the-reference",
    "href": "W1_Python/D2_Functions_Files.html#advanced-features-you-saw-them-in-the-reference",
    "title": "Python & Tooling",
    "section": "Advanced features (you saw them in the reference)",
    "text": "Advanced features (you saw them in the reference)\nYou will see these patterns later, but you don’t need them for today’s assignment:\n\nrecursion\nclosures + nonlocal\ngenerators (yield)\ndecorators (@something)\nglobal (usually avoid)\n\n\n\n\n\n\n\nWarning\n\n\nIf you don’t need a “fancy tool”, don’t use it yet. Write the simplest working code."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#recursion-rare-but-you-should-recognize-it",
    "href": "W1_Python/D2_Functions_Files.html#recursion-rare-but-you-should-recognize-it",
    "title": "Python & Tooling",
    "section": "Recursion (rare, but you should recognize it)",
    "text": "Recursion (rare, but you should recognize it)\nA function that calls itself needs:\n\na base case (stop condition)\na step that moves toward the base case\n\ndef count_down(n: int) -&gt; None:\n    if n &lt; 0:\n        return\n    print(n)\n    count_down(n - 1)\n\n\nIn data work, recursion is uncommon. Loops are usually simpler."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#closures-nonlocal-state-without-globals",
    "href": "W1_Python/D2_Functions_Files.html#closures-nonlocal-state-without-globals",
    "title": "Python & Tooling",
    "section": "Closures + nonlocal (state without globals)",
    "text": "Closures + nonlocal (state without globals)\nA nested function can “remember” variables from the outer function.\ndef make_counter():\n    i = 0\n    def inc():\n        nonlocal i\n        i += 1\n        return i\n    return inc\n\nc = make_counter()\nc()  # 1\nc()  # 2"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#decorators-wrapping-a-function",
    "href": "W1_Python/D2_Functions_Files.html#decorators-wrapping-a-function",
    "title": "Python & Tooling",
    "section": "Decorators (wrapping a function)",
    "text": "Decorators (wrapping a function)\nA decorator takes a function and returns a new function.\ndef logged(fn):\n    def wrapper(*args, **kwargs):\n        print(\"Calling:\", fn.__name__)\n        return fn(*args, **kwargs)\n    return wrapper\n\n@logged\ndef add(a, b):\n    return a + b"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#global-exists-but-avoid-it",
    "href": "W1_Python/D2_Functions_Files.html#global-exists-but-avoid-it",
    "title": "Python & Tooling",
    "section": "global (exists, but avoid it)",
    "text": "global (exists, but avoid it)\nx = 0\n\ndef f():\n    global x\n    x += 1\n    print(x)\nWhy avoid?\n\nmakes bugs harder to trace\nbreaks testability"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#common-pitfall-mutable-default-arguments",
    "href": "W1_Python/D2_Functions_Files.html#common-pitfall-mutable-default-arguments",
    "title": "Python & Tooling",
    "section": "Common pitfall: mutable default arguments",
    "text": "Common pitfall: mutable default arguments\nBad:\ndef add_item(x, items=[]):\n    items.append(x)\n    return items\nBetter:\ndef add_item(x, items=None):\n    if items is None:\n        items = []\n    items.append(x)\n    return items\n\n\n\n\n\n\nWarning\n\n\nDefault value is evaluated and created only once, not on each function call."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#optional-generators-in-one-slide",
    "href": "W1_Python/D2_Functions_Files.html#optional-generators-in-one-slide",
    "title": "Python & Tooling",
    "section": "(Optional) Generators in one slide",
    "text": "(Optional) Generators in one slide\ndef counter():\n    yield 1\n    yield 2\n    yield 3\n\nfor x in counter():\n    print(x)\nWhy mention it?\n\ngenerators let you process data without holding everything in memory\nwe will keep today’s CSV small → lists are fine"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#recap-session-1",
    "href": "W1_Python/D2_Functions_Files.html#recap-session-1",
    "title": "Python & Tooling",
    "section": "Recap (Session 1)",
    "text": "Recap (Session 1)\n\nFunctions make your code reusable and readable\nLearn parameter styles (*args, **kwargs, keyword-only)\nUse built-ins (enumerate, zip, sorted) to write less code\nImplement core helpers: is_missing, try_float, infer_type"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#session-2-objectives",
    "href": "W1_Python/D2_Functions_Files.html#session-2-objectives",
    "title": "Python & Tooling",
    "section": "Session 2 objectives",
    "text": "Session 2 objectives\n\nUse f-strings + format specs for readable numbers\nBuild Markdown using lists of lines + join\nProduce a report that a human can skim in 30 seconds"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#markdown-is-just-text",
    "href": "W1_Python/D2_Functions_Files.html#markdown-is-just-text",
    "title": "Python & Tooling",
    "section": "Markdown is just text",
    "text": "Markdown is just text\nYour strategy:\n\nBuild lines: list[str] (a list of strings)\ntext = \"\\n\".join(lines) + \"\\n\"\nWrite to a file\n\nNotes: - lines.append(\"...\") adds one line - lines.extend(other_lines) adds many lines (when a helper returns a list of lines)\nThis avoids painful string concatenation."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#f-strings-readable-and-powerful",
    "href": "W1_Python/D2_Functions_Files.html#f-strings-readable-and-powerful",
    "title": "Python & Tooling",
    "section": "f-strings: readable and powerful",
    "text": "f-strings: readable and powerful\nrows = 1234567\nmissing_pct = 0.03456\n\nprint(f\"Rows: {rows:,}\")\nprint(f\"Missing: {missing_pct:.1%}\")\nExample output:\n\nRows: 1,234,567\nMissing: 3.5%"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#format-specs-youll-actually-use",
    "href": "W1_Python/D2_Functions_Files.html#format-specs-youll-actually-use",
    "title": "Python & Tooling",
    "section": "Format specs you’ll actually use",
    "text": "Format specs you’ll actually use\n\n:, → thousands separators\n.2f → 2 decimals\n.1% → percent with 1 decimal\n&gt;10 / &lt;10 → align width\n\nExample:\nvalue = 5 / 3\nprint(f\"{value:&gt;8.2f}\")"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#building-a-section-pattern",
    "href": "W1_Python/D2_Functions_Files.html#building-a-section-pattern",
    "title": "Python & Tooling",
    "section": "Building a section (pattern)",
    "text": "Building a section (pattern)\nlines = []\nlines.append(\"# CSV Profiling Report\")\nlines.append(\"\")\nlines.append(\"## Summary\")\nlines.append(f\"- Rows: {n_rows:,}\")\ntext = \"\\n\".join(lines) + \"\\n\""
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#imports-refresher-use-code-from-libraries",
    "href": "W1_Python/D2_Functions_Files.html#imports-refresher-use-code-from-libraries",
    "title": "Python & Tooling",
    "section": "Imports refresher: use code from libraries",
    "text": "Imports refresher: use code from libraries\nPython ships with lots of useful modules (CSV, JSON, dates…).\nTwo common styles:\nimport json\nfrom datetime import datetime\n\nnow = datetime.now()\nprint(json.dumps({\"time\": str(now)}))\n\n\nIf you can run main.py, you already used imports — this is just a reminder."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#mini-exercise-3-6-minutes",
    "href": "W1_Python/D2_Functions_Files.html#mini-exercise-3-6-minutes",
    "title": "Python & Tooling",
    "section": "Mini-exercise 3 (6 minutes)",
    "text": "Mini-exercise 3 (6 minutes)\nCreate a function that returns a markdown header block:\nfrom datetime import datetime\n\ndef md_header(source: str) -&gt; list[str]:\n    \"\"\"Return lines for the top of the report.\"\"\"\n    ...\nMust include:\n\ntitle line # CSV Profiling Report\nsource file name\ngenerated time (datetime.now().isoformat(timespec=\"seconds\"))"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#solution-md_header",
    "href": "W1_Python/D2_Functions_Files.html#solution-md_header",
    "title": "Python & Tooling",
    "section": "Solution — md_header",
    "text": "Solution — md_header\nfrom datetime import datetime\n\ndef md_header(source: str) -&gt; list[str]:\n    ts = datetime.now().isoformat(timespec=\"seconds\")\n    return [\n        \"# CSV Profiling Report\",\n        \"\",\n        f\"- **Source:** `{source}`\",\n        f\"- **Generated:** `{ts}`\",\n        \"\",\n    ]"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#markdown-tables-quick-pattern",
    "href": "W1_Python/D2_Functions_Files.html#markdown-tables-quick-pattern",
    "title": "Python & Tooling",
    "section": "Markdown tables (quick pattern)",
    "text": "Markdown tables (quick pattern)\n| Column | Type | Missing | Unique |\n|---|---:|---:|---:|\n| age | number | 0 (0.0%) | 12 |\nRules:\n\nthe second line is the “separator”\nalign numeric columns with ---: (optional but nice)"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#mini-exercise-4-8-minutes",
    "href": "W1_Python/D2_Functions_Files.html#mini-exercise-4-8-minutes",
    "title": "Python & Tooling",
    "section": "Mini-exercise 4 (8 minutes)",
    "text": "Mini-exercise 4 (8 minutes)\nWrite a function to render the table header:\ndef md_table_header() -&gt; list[str]:\n    ...\nIt should return:\n\nheader row\nseparator row"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#solution-md_table_header",
    "href": "W1_Python/D2_Functions_Files.html#solution-md_table_header",
    "title": "Python & Tooling",
    "section": "Solution — md_table_header",
    "text": "Solution — md_table_header\ndef md_table_header() -&gt; list[str]:\n    return [\n        \"| Column | Type | Missing | Unique |\",\n        \"|---|---:|---:|---:|\",\n    ]"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#rendering-one-row-pattern",
    "href": "W1_Python/D2_Functions_Files.html#rendering-one-row-pattern",
    "title": "Python & Tooling",
    "section": "Rendering one row (pattern)",
    "text": "Rendering one row (pattern)\ndef md_col_row(name: str, type_: str, missing: int, missing_pct: float, unique: int) -&gt; str:\n    return f\"| `{name}` | {type_} | {missing} ({missing_pct:.1%}) | {unique} |\"\n\n\n\n\n\n\nTip\n\n\ntype is a built-in reserved keyword in Python. When you need to use it as a variable name, a common convention is to append an underscore (e.g., type_) to avoid conflicts while keeping the name meaningful."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#mini-exercise-5-7-minutes",
    "href": "W1_Python/D2_Functions_Files.html#mini-exercise-5-7-minutes",
    "title": "Python & Tooling",
    "section": "Mini-exercise 5 (7 minutes)",
    "text": "Mini-exercise 5 (7 minutes)\nWrite:\ndef md_bullets(items: list[str]) -&gt; list[str]:\n    \"\"\"Turn ['a','b'] into ['- a','- b']\"\"\"\n    ..."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#solution-md_bullets",
    "href": "W1_Python/D2_Functions_Files.html#solution-md_bullets",
    "title": "Python & Tooling",
    "section": "Solution — md_bullets",
    "text": "Solution — md_bullets\ndef md_bullets(items: list[str]) -&gt; list[str]:\n    return [f\"- {x}\" for x in items]"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#common-string-cleaning-moves",
    "href": "W1_Python/D2_Functions_Files.html#common-string-cleaning-moves",
    "title": "Python & Tooling",
    "section": "Common string “cleaning” moves",
    "text": "Common string “cleaning” moves\nWhen working with CSVs:\n\nstrip() to remove whitespace\ncasefold() for robust lowercasing\nreplace() to normalize text\nsplit() to break things apart\njoin() to assemble output"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#quick-check-2",
    "href": "W1_Python/D2_Functions_Files.html#quick-check-2",
    "title": "Python & Tooling",
    "section": "Quick Check",
    "text": "Quick Check\nWhat is the output?\ns = \"  NA  \"\nprint(s.strip().casefold())\n\nAnswer: na"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#recap-session-2",
    "href": "W1_Python/D2_Functions_Files.html#recap-session-2",
    "title": "Python & Tooling",
    "section": "Recap (Session 2)",
    "text": "Recap (Session 2)\n\nBuild Markdown using lines + \"\\n\".join(lines)\nUse f-string format specs for readable numbers\nUse small rendering helpers (md_header, md_table_header, md_col_row)"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#session-3-objectives",
    "href": "W1_Python/D2_Functions_Files.html#session-3-objectives",
    "title": "Python & Tooling",
    "section": "Session 3 objectives",
    "text": "Session 3 objectives\n\nUse pathlib.Path instead of fragile string paths\nRead CSV robustly with csv.DictReader\nWrite JSON with stable formatting\nApply safe file-writing habits (mkdir, encoding, newline)"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#pathlib.path-is-your-default",
    "href": "W1_Python/D2_Functions_Files.html#pathlib.path-is-your-default",
    "title": "Python & Tooling",
    "section": "pathlib.Path is your default",
    "text": "pathlib.Path is your default\nfrom pathlib import Path\n\np = Path(\"data\") / \"sample.csv\"\nprint(p.exists())\nprint(p.suffix)   # \".csv\"\nprint(p.stem)     # \"sample\"\nWhy?\n\ncross-platform paths\neasy parent folders\nclearer code"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#safe-write-file-pattern",
    "href": "W1_Python/D2_Functions_Files.html#safe-write-file-pattern",
    "title": "Python & Tooling",
    "section": "Safe “write file” pattern",
    "text": "Safe “write file” pattern\nfrom pathlib import Path\n\ndef write_text(path: str | Path, text: str) -&gt; None:\n    path = Path(path)\n    path.parent.mkdir(parents=True, exist_ok=True)\n    path.write_text(text, encoding=\"utf-8\")"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#quick-check-3",
    "href": "W1_Python/D2_Functions_Files.html#quick-check-3",
    "title": "Python & Tooling",
    "section": "Quick Check",
    "text": "Quick Check\nWhy do we use mkdir(parents=True, exist_ok=True)?\nA. It deletes old folders\nB. It creates folders if missing, and doesn’t crash if they exist\nC. It makes the file smaller\n\nAnswer: B"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#with-blocks-open-files-safely",
    "href": "W1_Python/D2_Functions_Files.html#with-blocks-open-files-safely",
    "title": "Python & Tooling",
    "section": "with blocks: open files safely",
    "text": "with blocks: open files safely\nWhen you open a file, you should close it. The with ... as ...: pattern closes it automatically (even if something errors).\nfrom pathlib import Path\n\npath = Path(\"data/sample.csv\")\n\nwith path.open(\"r\", encoding=\"utf-8\") as f:\n    first_line = f.readline()\n\nprint(first_line)\n\n\nSame idea for writing: open → write → automatically close."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#csv-reading-dictreader",
    "href": "W1_Python/D2_Functions_Files.html#csv-reading-dictreader",
    "title": "Python & Tooling",
    "section": "CSV reading: DictReader",
    "text": "CSV reading: DictReader\nfrom csv import DictReader\nfrom pathlib import Path\n\ndef read_csv_rows(path: str | Path) -&gt; list[dict[str, str]]:\n    path = Path(path)\n    with path.open(\"r\", encoding=\"utf-8\", newline=\"\") as f:\n        return [dict(row) for row in DictReader(f)]\nNotes:\n\nnewline=\"\" is recommended for CSV files\nvalues come as strings → you parse them"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#mini-exercise-6-7-minutes",
    "href": "W1_Python/D2_Functions_Files.html#mini-exercise-6-7-minutes",
    "title": "Python & Tooling",
    "section": "Mini-exercise 6 (7 minutes)",
    "text": "Mini-exercise 6 (7 minutes)\nWrite a helper to get columns names from rows:\ndef get_columns(rows: list[dict[str, str]]) -&gt; list[str]:\n    ...\nRules:\n\nif rows is empty → return []\notherwise use the first row’s keys"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#solution-get_columns",
    "href": "W1_Python/D2_Functions_Files.html#solution-get_columns",
    "title": "Python & Tooling",
    "section": "Solution — get_columns",
    "text": "Solution — get_columns\ndef get_columns(rows: list[dict[str, str]]) -&gt; list[str]:\n    if not rows:\n        return []\n    return list(rows[0].keys())"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#json-writing-stable-and-readable",
    "href": "W1_Python/D2_Functions_Files.html#json-writing-stable-and-readable",
    "title": "Python & Tooling",
    "section": "JSON writing: stable and readable",
    "text": "JSON writing: stable and readable\nimport json\nfrom pathlib import Path\n\ndef write_json(report: dict, path: str | Path) -&gt; None:\n    path = Path(path)\n    path.parent.mkdir(parents=True, exist_ok=True)\n    text = json.dumps(report, indent=2, ensure_ascii=False) + \"\\n\"\n    path.write_text(text, encoding=\"utf-8\")\n\n\nNotice how report can be any dict."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#designing-your-report-schema-practical",
    "href": "W1_Python/D2_Functions_Files.html#designing-your-report-schema-practical",
    "title": "Python & Tooling",
    "section": "Designing your report schema (practical)",
    "text": "Designing your report schema (practical)\nKeep it simple and stable:\nreport = {\n  \"source\": {\"path\": \"...\"},\n  \"summary\": {\"rows\": 100, \"columns\": 8},\n  \"columns\": {\n     \"age\": {\"type\": \"number\", \"missing\": 2, \"unique\": 31, \"min\": 0.0, ...},\n     \"city\": {\"type\": \"text\", \"missing\": 0, \"unique\": 5, \"top\": [{\"value\": \"Riyadh\", \"count\": 20}]},\n  }\n}\n\n\n\n\n\n\nTip\n\n\nA clear schema makes your CLI and Streamlit app easy later."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#optional-base64-vs-pickle-30-seconds",
    "href": "W1_Python/D2_Functions_Files.html#optional-base64-vs-pickle-30-seconds",
    "title": "Python & Tooling",
    "section": "Optional: base64 vs pickle (30 seconds)",
    "text": "Optional: base64 vs pickle (30 seconds)\n\nbase64: text encoding of bytes (useful for transport)\npickle: Python-only serialization\n\n\n\n\n\n\n\nWarning\n\n\nNever unpickle data from someone you don’t trust. Pickle can execute code during loading."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#recap-session-3",
    "href": "W1_Python/D2_Functions_Files.html#recap-session-3",
    "title": "Python & Tooling",
    "section": "Recap (Session 3)",
    "text": "Recap (Session 3)\n\nUse Path for paths + folder creation\nRead CSV with DictReader\nWrite JSON with json.dumps(..., indent=2)\nDefine a clear report schema"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#hands-on-success-criteria-what-done-means",
    "href": "W1_Python/D2_Functions_Files.html#hands-on-success-criteria-what-done-means",
    "title": "Python & Tooling",
    "section": "Hands-on success criteria (what “done” means)",
    "text": "Hands-on success criteria (what “done” means)\nBy the end of the day:\n\nYour profiler detects number vs text\nFor numeric columns you compute: count, missing, unique, min, max, mean\nYou generate:\n\noutputs/report.json\noutputs/report.md (with a summary + a table + per-column details)"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#lab-rules-to-stay-productive",
    "href": "W1_Python/D2_Functions_Files.html#lab-rules-to-stay-productive",
    "title": "Python & Tooling",
    "section": "Lab rules (to stay productive)",
    "text": "Lab rules (to stay productive)\n\nWork in pairs (driver / navigator), switch every 15 minutes\nKeep functions small (10–25 lines)\nIf stuck &gt; 5 minutes:\n\nwrite down the exact error\nread it out loud\nthen ask the instructor/TA\n\nVibe coding (safe version): Plan &gt; Smallest Piece &gt; Run &gt; Commit."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#task-0-create-a-today-branch-optional",
    "href": "W1_Python/D2_Functions_Files.html#task-0-create-a-today-branch-optional",
    "title": "Python & Tooling",
    "section": "Task 0 — Create a “today branch” (optional)",
    "text": "Task 0 — Create a “today branch” (optional)\nIf you already know Git:\ngit checkout -b day2\nIf you don’t know Git yet: skip this. We’ll cover Git later this week."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#task-1-add-shared-helpers-10-minutes",
    "href": "W1_Python/D2_Functions_Files.html#task-1-add-shared-helpers-10-minutes",
    "title": "Python & Tooling",
    "section": "Task 1 — Add shared helpers (10 minutes)",
    "text": "Task 1 — Add shared helpers (10 minutes)\nIn csv_profiler/profile.py (or src/csv_profiler/profile.py if you’re using the src layout), add:\n\nis_missing(value)\ntry_float(value)\ninfer_type(values)\n\nCheckpoint: you can call these from a Python REPL and they behave correctly."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#solution-helpers-example",
    "href": "W1_Python/D2_Functions_Files.html#solution-helpers-example",
    "title": "Python & Tooling",
    "section": "Solution — helpers (example)",
    "text": "Solution — helpers (example)\nMISSING = {\"\", \"na\", \"n/a\", \"null\", \"none\", \"nan\"}\n\ndef is_missing(value: str | None) -&gt; bool:\n    if value is None:\n        return True\n    return value.strip().casefold() in MISSING\n\ndef try_float(value: str) -&gt; float | None:\n    try:\n        return float(value)\n    except ValueError:\n        return None\n\ndef infer_type(values: list[str]) -&gt; str:\n    usable = [v for v in values if not is_missing(v)]\n    if not usable:\n        return \"text\"\n    for v in usable:\n        if try_float(v) is None:\n            return \"text\"\n    return \"number\""
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#task-2-extract-column-values-10-minutes",
    "href": "W1_Python/D2_Functions_Files.html#task-2-extract-column-values-10-minutes",
    "title": "Python & Tooling",
    "section": "Task 2 — Extract column values (10 minutes)",
    "text": "Task 2 — Extract column values (10 minutes)\nAdd a helper:\ndef column_values(rows: list[dict[str, str]], col: str) -&gt; list[str]:\n    ...\nRules:\n\nreturn one value per row (use row.get(col, \"\"))\nkeep as strings (parsing happens later)\n\n\n\nrow.get(col, \"\") means: “give me the value for this column, or \"\" if the key is missing.”"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#solution-column_values",
    "href": "W1_Python/D2_Functions_Files.html#solution-column_values",
    "title": "Python & Tooling",
    "section": "Solution — column_values",
    "text": "Solution — column_values\ndef column_values(rows: list[dict[str, str]], col: str) -&gt; list[str]:\n    return [row.get(col, \"\") for row in rows]"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#task-3-numeric-stats-function-15-minutes",
    "href": "W1_Python/D2_Functions_Files.html#task-3-numeric-stats-function-15-minutes",
    "title": "Python & Tooling",
    "section": "Task 3 — Numeric stats function (15 minutes)",
    "text": "Task 3 — Numeric stats function (15 minutes)\nImplement:\ndef numeric_stats(values: list[str]) -&gt; dict:\n    \"\"\"Compute stats for numeric column values (strings).\"\"\"\n    ...\nRequirements:\n\nignore missing values\nparse remaining values as floats\ncompute: count, missing, unique, min, max, mean"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#hint-numeric-stats-strategy",
    "href": "W1_Python/D2_Functions_Files.html#hint-numeric-stats-strategy",
    "title": "Python & Tooling",
    "section": "Hint — numeric stats strategy",
    "text": "Hint — numeric stats strategy\n\nusable = [v for v in values if not is_missing(v)]\nnums = [try_float(v) for v in usable]\nif any None → treat as text elsewhere (don’t call this function)\ncompute stats:\n\ncount = len(nums)\nunique = len(set(nums))\nmin(nums), max(nums), sum(nums)/count\n\n\n\n\n\n\n\n\nTip\n\n\nset(nums) removes duplicates. So len(set(nums)) is “how many distinct values?”"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#solution-numeric_stats-example",
    "href": "W1_Python/D2_Functions_Files.html#solution-numeric_stats-example",
    "title": "Python & Tooling",
    "section": "Solution — numeric_stats (example)",
    "text": "Solution — numeric_stats (example)\ndef numeric_stats(values: list[str]) -&gt; dict:\n    usable = [v for v in values if not is_missing(v)]\n    missing = len(values) - len(usable)\n    nums: list[float] = []\n    for v in usable:\n        x = try_float(v)\n        if x is None:\n            raise ValueError(f\"Non-numeric value found: `{v}`\")\n        nums.append(x)\n\n    count = len(nums)\n    unique = len(set(nums))\n    return {\n        \"count\": count,\n        \"missing\": missing,\n        \"unique\": unique,\n        \"min\": min(nums) if nums else None,\n        \"max\": max(nums) if nums else None,\n        \"mean\": (sum(nums) / count) if count else None,\n    }\n\n\nWe raise an error if something is non-numeric. That makes bugs loud."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#task-4-text-stats-function-15-minutes",
    "href": "W1_Python/D2_Functions_Files.html#task-4-text-stats-function-15-minutes",
    "title": "Python & Tooling",
    "section": "Task 4 — Text stats function (15 minutes)",
    "text": "Task 4 — Text stats function (15 minutes)\nImplement:\ndef text_stats(values: list[str], top_k: int = 5) -&gt; dict:\n    ...\nRequirements:\n\nignore missing values\ncompute: count, missing, unique\ncompute top: top_k most common values with counts"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#hint-counting-text-values",
    "href": "W1_Python/D2_Functions_Files.html#hint-counting-text-values",
    "title": "Python & Tooling",
    "section": "Hint — counting text values",
    "text": "Hint — counting text values\nYou can implement counts with a dict:\ncounts: dict[str, int] = {}\nfor v in usable:\n    counts[v] = counts.get(v, 0) + 1\nThen sort by count descending:\ntop = sorted(counts.items(), key=lambda kv: kv[1], reverse=True)[:top_k]"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#solution-text_stats-example",
    "href": "W1_Python/D2_Functions_Files.html#solution-text_stats-example",
    "title": "Python & Tooling",
    "section": "Solution — text_stats (example)",
    "text": "Solution — text_stats (example)\ndef text_stats(values: list[str], top_k: int = 5) -&gt; dict:\n    usable = [v for v in values if not is_missing(v)]\n    missing = len(values) - len(usable)\n\n    counts: dict[str, int] = {}\n    for v in usable:\n        counts[v] = counts.get(v, 0) + 1\n\n    top_items = sorted(counts.items(), key=lambda kv: kv[1], reverse=True)[:top_k]\n    top = [{\"value\": v, \"count\": c} for v, c in top_items]\n\n    return {\n        \"count\": len(usable),\n        \"missing\": missing,\n        \"unique\": len(counts),\n        \"top\": top,\n    }"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#task-5-upgrade-basic_profile-20-minutes",
    "href": "W1_Python/D2_Functions_Files.html#task-5-upgrade-basic_profile-20-minutes",
    "title": "Python & Tooling",
    "section": "Task 5 — Upgrade basic_profile (20 minutes)",
    "text": "Task 5 — Upgrade basic_profile (20 minutes)\nUpdate basic_profile(rows) so it returns:\n\nsource (path optional for now)\nsummary: rows, columns\ncolumns: a dict keyed by column name with:\n\ntype (number/text)\nstats from numeric_stats or text_stats\n\n\nCheckpoint: report[\"columns\"][\"age\"][\"type\"] == \"number\" (for your sample data)."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#solution-basic_profile-example",
    "href": "W1_Python/D2_Functions_Files.html#solution-basic_profile-example",
    "title": "Python & Tooling",
    "section": "Solution — basic_profile (example)",
    "text": "Solution — basic_profile (example)\ndef basic_profile(rows: list[dict[str, str]]) -&gt; dict:\n    cols = get_columns(rows)\n    report = {\n        \"summary\": {\n            \"rows\": len(rows),\n            \"columns\": len(cols),\n            \"column_names\": cols,\n        },\n        \"columns\": {},\n    }\n\n    for col in cols:\n        values = column_values(rows, col)\n        type_ = infer_type(values)\n        if type_ == \"number\":\n            stats = numeric_stats(values)\n        else:\n            stats = text_stats(values)\n        report[\"columns\"][col] = {\"type\": type_, **stats}\n\n    return report\n\n\n\n\n\n\nTip\n\n\n**stats is a way to unpack a dict and copy all its items in a new dict. The same thing can be done for lists or any iterable but with a single asterisk (e.g., [\"Majid\", *names, \"Sami\"])."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#task-6-upgrade-write_markdown-25-minutes",
    "href": "W1_Python/D2_Functions_Files.html#task-6-upgrade-write_markdown-25-minutes",
    "title": "Python & Tooling",
    "section": "Task 6 — Upgrade write_markdown (25 minutes)",
    "text": "Task 6 — Upgrade write_markdown (25 minutes)\nIn csv_profiler/render.py (or src/csv_profiler/render.py if you’re using the src layout), update write_markdown(report, path) to include:\n\nHeader block (md_header(...))\nSummary bullets:\n\nrows, columns\n\nA table: one row per column (type, missing %, unique)\nPer-column details section:\n\nFor numeric: min/max/mean\nFor text: top values list"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#hint-computing-missing-percentage",
    "href": "W1_Python/D2_Functions_Files.html#hint-computing-missing-percentage",
    "title": "Python & Tooling",
    "section": "Hint — computing missing percentage",
    "text": "Hint — computing missing percentage\nrows = report[\"summary\"][\"rows\"]\nmissing = col_report[\"missing\"]\nmissing_pct = (missing / rows) if rows else 0.0"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#solution-write_markdown-example-simple",
    "href": "W1_Python/D2_Functions_Files.html#solution-write_markdown-example-simple",
    "title": "Python & Tooling",
    "section": "Solution — write_markdown (example, simple)",
    "text": "Solution — write_markdown (example, simple)\nfrom pathlib import Path\n\ndef write_markdown(report: dict, path: str | Path) -&gt; None:\n    path = Path(path)\n    path.parent.mkdir(parents=True, exist_ok=True)\n    rows = report[\"summary\"][\"rows\"]\n\n    lines: list[str] = []\n    lines.extend(md_header(\"data/sample.csv\"))\n\n    lines.append(\"## Summary\")\n    lines.append(f\"- Rows: {rows:,}\")\n    lines.append(f\"- Columns: {report['summary']['columns']:,}\")\n    lines.append(\"\")\n\n    lines.append(\"## Columns (table)\")\n    lines.extend(md_table_header())\n\n    for name, col in report[\"columns\"].items():\n        missing_pct = (col[\"missing\"] / rows) if rows else 0.0\n        lines.append(md_col_row(name, col[\"type\"], col[\"missing\"], missing_pct, col[\"unique\"]))\n\n    lines.append(\"\")\n    ... # continue to the next slide\n\n\nThe implementation continues on the next slide."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#solution-write_markdown-example-simple-1",
    "href": "W1_Python/D2_Functions_Files.html#solution-write_markdown-example-simple-1",
    "title": "Python & Tooling",
    "section": "Solution — write_markdown (example, simple)",
    "text": "Solution — write_markdown (example, simple)\n    ... # write_markdown() continues here\n    lines.append(\"## Column details\")\n\n    for name, col in report[\"columns\"].items():\n        lines.append(f\"### `{name}` ({col['type']})\")\n\n        if col[\"type\"] == \"number\":\n            lines.append(f\"- min: {col['min']}\")\n            lines.append(f\"- max: {col['max']}\")\n            lines.append(f\"- mean: {col['mean']}\")\n        else:\n            top = col.get(\"top\", [])\n            if not top:\n                lines.append(\"- (no non-missing values)\")\n            else:\n                lines.append(\"- top values:\")\n                for item in top:\n                    lines.append(f\"  - `{item['value']}`: {item['count']}\")\n\n        lines.append(\"\")\n\n    path.write_text(\"\\n\".join(lines) + \"\\n\", encoding=\"utf-8\")\n\n\n\n\n\n\nTip\n\n\nKeep it “simple but correct” today. We’ll polish the report formatting later."
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#task-7-run-end-to-end-10-minutes",
    "href": "W1_Python/D2_Functions_Files.html#task-7-run-end-to-end-10-minutes",
    "title": "Python & Tooling",
    "section": "Task 7 — Run end-to-end (10 minutes)",
    "text": "Task 7 — Run end-to-end (10 minutes)\nRun:\n\nIf you have csv_profiler/ next to main.py:\n\nuv run python main.py\n\nIf you have a src/ folder:\n\nUnix/macOS:\n\n\nPYTHONPATH=src uv run python main.py\n\nWindows PowerShell:\n\n$env:PYTHONPATH=\"src\"\nuv run python main.py\nCheckpoint: - outputs/report.json has types and stats - outputs/report.md has a table and details"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#debug-playbook-when-it-fails",
    "href": "W1_Python/D2_Functions_Files.html#debug-playbook-when-it-fails",
    "title": "Python & Tooling",
    "section": "Debug playbook (when it fails)",
    "text": "Debug playbook (when it fails)\n\nRead the traceback top to bottom\nFind the first line that points to your code\nPrint intermediate values:\n\nprint(\"DEBUG values:\", values[:5])\n\nConfirm assumptions:\n\n\nare you reading the file you think you are?\nare there missing keys?\nare strings like \" \" being treated as missing?"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#stretch-if-you-finish-early",
    "href": "W1_Python/D2_Functions_Files.html#stretch-if-you-finish-early",
    "title": "Python & Tooling",
    "section": "Stretch (if you finish early)",
    "text": "Stretch (if you finish early)\nPick one:\n\nAdd median (hint: sort and pick middle)\nAdd a “mostly numeric” rule (e.g., ≥ 90% parse as float)\nAdd a --input / --output argument using argparse (Typer comes tomorrow)"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#exit-ticket",
    "href": "W1_Python/D2_Functions_Files.html#exit-ticket",
    "title": "Python & Tooling",
    "section": "Exit Ticket",
    "text": "Exit Ticket\nIn 1–2 sentences:\nWhat made your profiler “better” today compared to Day 1?"
  },
  {
    "objectID": "W1_Python/D2_Functions_Files.html#what-to-do-after-class-day-2-assignment",
    "href": "W1_Python/D2_Functions_Files.html#what-to-do-after-class-day-2-assignment",
    "title": "Python & Tooling",
    "section": "What to do after class (Day 2 assignment)",
    "text": "What to do after class (Day 2 assignment)\nDue: before Day 3 starts (Tue, 16 Dec 2025)\n\nAdd at least 2 new columns to data/sample.csv (one numeric, one text)\nRerun the profiler and check that:\n\ntypes are correct\nstats update correctly\n\nImprove your Markdown:\n\nformat numeric values with :.2f where relevant\nshow missing percentage in the table\n\n\nDeliverable: a zip or folder with your updated csv-profiler/."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#bootcamp-calendar",
    "href": "W1_Python/D1_Python_Tooling.html#bootcamp-calendar",
    "title": "Python & Tooling",
    "section": "Bootcamp calendar",
    "text": "Bootcamp calendar\n\nWeek 1: Python & Tooling\nWeek 2: Data Work (ETL + EDA)\nWeek 3: Machine Learning\nWeek 4: Deep Learning & Computer Vision\nWeek 5: LLM-based NLP\nWeek 6: Building AI Apps\nWeek 7: Agentic AI & Practical MLOps\nWeek 8: Capstone Sprint + Job Readiness"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#bootcamp-certificates",
    "href": "W1_Python/D1_Python_Tooling.html#bootcamp-certificates",
    "title": "Python & Tooling",
    "section": "Bootcamp Certificates",
    "text": "Bootcamp Certificates\n\nCertificate of Completion: final grade ≥ 70% by end of the bootcamp\nCertificate of Attendance: if not passing, but fewer than 4 excused absences"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#how-well-work-in-class",
    "href": "W1_Python/D1_Python_Tooling.html#how-well-work-in-class",
    "title": "Python & Tooling",
    "section": "How we’ll work in class",
    "text": "How we’ll work in class\n\nShort chunks of theory\nMicro-exercises (3–8 minutes)\nCheckpoints every ~15 minutes\n“Hands-on” block = build the project (with help)\n\n\n\n\n\n\n\nTip\n\n\nIf you get stuck: write down the exact error, the command you ran, and the file you edited."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#policy-genai-usage",
    "href": "W1_Python/D1_Python_Tooling.html#policy-genai-usage",
    "title": "Python & Tooling",
    "section": "Policy: GenAI usage",
    "text": "Policy: GenAI usage\n\n✅ Allowed: clarifying questions (definitions, error explanations)\n❌ Not allowed: generating code, writing solutions, or debugging by copy-paste\nIf unsure: ask the instructor first\n\n\n\n\n\n\n\nWarning\n\n\nThe point is skill-building. Using GenAI to do the work breaks the learning loop."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#todays-flow",
    "href": "W1_Python/D1_Python_Tooling.html#todays-flow",
    "title": "Python & Tooling",
    "section": "Today’s Flow",
    "text": "Today’s Flow\n\nSession 1 (60m): Setup + Shell essentials + uv\nAsr Prayer (20m)\nSession 2 (60m): Values, containers, operators\nMaghrib Prayer (20m)\nSession 3 (60m): Control flow + types + files\nIsha Prayer (20m)\nHands-on (120m): weekly project start (CSV Profiler)"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#learning-objectives",
    "href": "W1_Python/D1_Python_Tooling.html#learning-objectives",
    "title": "Python & Tooling",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of today, you can:\n\nNavigate and inspect files using basic shell commands\nCreate and use a Python environment with uv\nWrite Python scripts with variables, basic types, and control flow\nRead a CSV and compute a basic profiling summary\nWrite outputs to Markdown and JSON files"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#week-1-outcomes-ship-by-thu-1159pm",
    "href": "W1_Python/D1_Python_Tooling.html#week-1-outcomes-ship-by-thu-1159pm",
    "title": "Python & Tooling",
    "section": "Week 1 outcomes (ship by Thu 11:59pm)",
    "text": "Week 1 outcomes (ship by Thu 11:59pm)\nYou will build a small app called “CSV Profiler” with two interfaces:\n\nCLI (command line) → reads CSV → writes report.md and report.json\nGUI with Streamlit → uploads/reads CSV → shows profile → export files\n\nInput: a CSV file\nOutput:\n\nreport.json → machine-readable profiling stats\nreport.md → human-readable report\n\nYour code will handle:\n\nMissing values & Inferred column types (number / text / mixed)\nBasic stats (count, unique, min/max/mean when numeric)\n\n\n\nThis week is fundamentals: you’ll implement the profiling logic yourself."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#session-1-objectives",
    "href": "W1_Python/D1_Python_Tooling.html#session-1-objectives",
    "title": "Python & Tooling",
    "section": "Session 1 objectives",
    "text": "Session 1 objectives\n\nOpen a terminal and move around the filesystem\nUnderstand paths: absolute vs relative\nFind your Python and inspect environment variables\nCreate a Python env and run a script with uv"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#terminal-vocabulary",
    "href": "W1_Python/D1_Python_Tooling.html#terminal-vocabulary",
    "title": "Python & Tooling",
    "section": "Terminal vocabulary",
    "text": "Terminal vocabulary\n\nTerminal: the window\nShell: the program that reads your commands (bash, zsh, PowerShell)\nCommand: a program you run (ls, python, git)\nWorking directory: “where you are” right now"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#ides-you-can-use-pick-one",
    "href": "W1_Python/D1_Python_Tooling.html#ides-you-can-use-pick-one",
    "title": "Python & Tooling",
    "section": "IDEs you can use (pick one)",
    "text": "IDEs you can use (pick one)\n\nVS Code (recommended for this bootcamp)\nJupyterLab (great for exploration)\nGoogle Colab (only when local setup is blocked)\n\n\n\nToday we’ll work mostly with scripts in VS Code."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#navigation-where-am-i",
    "href": "W1_Python/D1_Python_Tooling.html#navigation-where-am-i",
    "title": "Python & Tooling",
    "section": "Navigation: where am I?",
    "text": "Navigation: where am I?\n\n\nCommand\n\npwd → print working directory\nls (mac/linux) or dir (Windows) → list files\n\n\nTry it\n\nRun pwd\nRun ls / dir\nFind your “Downloads” or “Desktop” folder\n\n\n\nDo: Live demo: pwd then ls, explain “working directory”.\nAsk: “What folder are you in right now?”\nTimebox: 4 minutes."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#navigation-moving-around",
    "href": "W1_Python/D1_Python_Tooling.html#navigation-moving-around",
    "title": "Python & Tooling",
    "section": "Navigation: moving around",
    "text": "Navigation: moving around\n\ncd &lt;path&gt; → change directory\ncd .. → go up one folder\ncd . → current folder (rarely useful)\ncd ~ → home folder\ncd - → previous folder (super useful)"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#creating-folders-and-files-quick-essentials",
    "href": "W1_Python/D1_Python_Tooling.html#creating-folders-and-files-quick-essentials",
    "title": "Python & Tooling",
    "section": "Creating folders and files (quick essentials)",
    "text": "Creating folders and files (quick essentials)\nYou’ll use these today to set up your project.\nmacOS/Linux\nmkdir my_folder  # creates a folder\nmkdir -p a/b/c  # creates nested folders\ntouch notes.txt  # creates empty file\nWindows PowerShell\nmkdir my_folder\nni notes.txt     # New-Item (creates empty file)\n\n\nIf you prefer, you can also create folders using the file explorer — just keep track of the paths."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#paths-absolute-vs-relative",
    "href": "W1_Python/D1_Python_Tooling.html#paths-absolute-vs-relative",
    "title": "Python & Tooling",
    "section": "Paths: absolute vs relative",
    "text": "Paths: absolute vs relative\nAbsolute path starts from the root.\n\nmac/linux: /Users/&lt;name&gt;/...\nWindows: C:\\Users\\&lt;name&gt;\\...\n\nRelative path starts from your current folder.\n\n./data/sample.csv (inside current folder)\n../data/sample.csv (one level up)"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#path-gotchas-avoid-20-minutes-of-pain",
    "href": "W1_Python/D1_Python_Tooling.html#path-gotchas-avoid-20-minutes-of-pain",
    "title": "Python & Tooling",
    "section": "Path gotchas (avoid 20 minutes of pain)",
    "text": "Path gotchas (avoid 20 minutes of pain)\n\nSpaces in folder names can confuse commands → use quotes\n\ncd \"My Files\"\n\nCase matters on mac/linux (Data ≠ data)\nPrefer putting your project in a simple path like ~/bootcamp/"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#micro-exercise-path-ninja-5-minutes",
    "href": "W1_Python/D1_Python_Tooling.html#micro-exercise-path-ninja-5-minutes",
    "title": "Python & Tooling",
    "section": "Micro-exercise: “Path ninja” (5 minutes)",
    "text": "Micro-exercise: “Path ninja” (5 minutes)\n\ncd ~\nCreate a new folder called bootcamp (use your file explorer if needed)\ncd bootcamp\nConfirm with pwd and ls / dir\n\nCheckpoint: your terminal shows you are inside bootcamp."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#environment-variables-why-you-care",
    "href": "W1_Python/D1_Python_Tooling.html#environment-variables-why-you-care",
    "title": "Python & Tooling",
    "section": "Environment variables (why you care)",
    "text": "Environment variables (why you care)\n\nThey are settings for programs\nMost common: PATH (where your shell looks for commands)\n\nTry:\n\necho $PATH (mac/linux)\necho $env:PATH (PowerShell)"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#finding-executables",
    "href": "W1_Python/D1_Python_Tooling.html#finding-executables",
    "title": "Python & Tooling",
    "section": "Finding executables",
    "text": "Finding executables\n\nwhich python (mac/linux)\nwhere python (Windows)\n\nInterpretation:\n\nIf you see a path inside .venv/ → you are in a virtual environment\nIf you see a system path → you are using system Python"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#why-virtual-environments",
    "href": "W1_Python/D1_Python_Tooling.html#why-virtual-environments",
    "title": "Python & Tooling",
    "section": "Why virtual environments?",
    "text": "Why virtual environments?\nDifferent projects need different packages.\n\n✅ reproducible installs\n✅ no “works on my machine”\n✅ you can safely delete and recreate"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#uv-our-tool-for-environments-installs",
    "href": "W1_Python/D1_Python_Tooling.html#uv-our-tool-for-environments-installs",
    "title": "Python & Tooling",
    "section": "uv: our tool for environments + installs",
    "text": "uv: our tool for environments + installs\nToday we’ll use:\nuv venv -p 3.11\nuv pip install &lt;package&gt;\nuv run &lt;script.py&gt;"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#activate-vs-uv-run",
    "href": "W1_Python/D1_Python_Tooling.html#activate-vs-uv-run",
    "title": "Python & Tooling",
    "section": "Activate vs uv run",
    "text": "Activate vs uv run\n\nIf you activate, python and pip point to the env\nIf you don’t activate, uv run ... still uses the env\n\nRecommended habit: use uv run for anything you want to be reproducible\n\n\nYou can activate the env, but uv run works even if you forget."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#create-a-new-env-demo-do",
    "href": "W1_Python/D1_Python_Tooling.html#create-a-new-env-demo-do",
    "title": "Python & Tooling",
    "section": "Create a new env (demo + do)",
    "text": "Create a new env (demo + do)\nFrom inside bootcamp/:\nuv venv -p 3.11\nExpected result: a folder named .venv/"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#activate-vs-dont-activate",
    "href": "W1_Python/D1_Python_Tooling.html#activate-vs-dont-activate",
    "title": "Python & Tooling",
    "section": "“Activate” vs “don’t activate”",
    "text": "“Activate” vs “don’t activate”\n\nIf you activate, python points to .venv automatically\nIf you don’t, use uv run ... to guarantee the env\n\n\n\n\n\n\n\nTip\n\n\nIf you ever wonder “which python am I using?”, run which python / where python."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#activate-optional-but-useful",
    "href": "W1_Python/D1_Python_Tooling.html#activate-optional-but-useful",
    "title": "Python & Tooling",
    "section": "Activate (optional but useful)",
    "text": "Activate (optional but useful)\nmac/linux:\n. .venv/bin/activate\nWindows:\n.venv\\Scripts\\activate\nCheck: your prompt usually changes."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#python-packages-libraries-what-are-we-installing",
    "href": "W1_Python/D1_Python_Tooling.html#python-packages-libraries-what-are-we-installing",
    "title": "Python & Tooling",
    "section": "Python packages (libraries): what are we installing?",
    "text": "Python packages (libraries): what are we installing?\n\nStandard library: ships with Python (e.g., csv, json)\nThird-party packages: extra features you install (e.g., typer, streamlit)\n\nuv pip install ... downloads third-party packages into your project’s env so you can import them later."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#install-a-package-well-use-later",
    "href": "W1_Python/D1_Python_Tooling.html#install-a-package-well-use-later",
    "title": "Python & Tooling",
    "section": "Install a package (we’ll use later)",
    "text": "Install a package (we’ll use later)\nuv pip install typer streamlit\n\n\n\n\n\n\nTip\n\n\nIf installation fails: copy the full error + your OS info and ask the instructor."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#run-a-python-script-with-uv-run",
    "href": "W1_Python/D1_Python_Tooling.html#run-a-python-script-with-uv-run",
    "title": "Python & Tooling",
    "section": "Run a Python script with uv run",
    "text": "Run a Python script with uv run\nCreate hello.py:\nprint(\"Hello from Week 1!\")\nRun:\nuv run hello.py"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#quick-check",
    "href": "W1_Python/D1_Python_Tooling.html#quick-check",
    "title": "Python & Tooling",
    "section": "Quick Check",
    "text": "Quick Check\nWhat is the main difference?\n\n\nuv run hello.py\n\n\npython hello.py\n\n\n\nAnswer: uv run ensures the command runs inside the project environment."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#mini-lab-run-break-fix-7-minutes",
    "href": "W1_Python/D1_Python_Tooling.html#mini-lab-run-break-fix-7-minutes",
    "title": "Python & Tooling",
    "section": "Mini-lab: “Run + break + fix” (7 minutes)",
    "text": "Mini-lab: “Run + break + fix” (7 minutes)\n\nChange hello.py to print your name\nIntroduce a syntax error (missing quote)\nRun it and read the error\nFix it\n\nCheckpoint: you can explain what line the error points to."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#session-1-recap",
    "href": "W1_Python/D1_Python_Tooling.html#session-1-recap",
    "title": "Python & Tooling",
    "section": "Session 1 recap",
    "text": "Session 1 recap\n\nTerminal basics: pwd, ls/dir, cd\nPaths and environment variables\nuv venv + uv run"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#session-2-objectives",
    "href": "W1_Python/D1_Python_Tooling.html#session-2-objectives",
    "title": "Python & Tooling",
    "section": "Session 2 objectives",
    "text": "Session 2 objectives\n\nRecognize Python’s core value types\nUse lists/tuples/sets/dicts\nUse arithmetic, comparison, and logical operators\nPredict the output of short expressions"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#a-python-program-is-just-values-steps",
    "href": "W1_Python/D1_Python_Tooling.html#a-python-program-is-just-values-steps",
    "title": "Python & Tooling",
    "section": "A Python program is just values + steps",
    "text": "A Python program is just values + steps\n\nCreate values (numbers, text, containers)\nCombine them (operators)\nMake decisions (if / loops)\nOrganize into functions and files"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#literals-quick-tour",
    "href": "W1_Python/D1_Python_Tooling.html#literals-quick-tour",
    "title": "Python & Tooling",
    "section": "Literals: quick tour",
    "text": "Literals: quick tour\n\nNone, True, False\nIntegers: 0, -2, 1_000_000, 0x1f\nFloats: 1.5, 1e6, -2.5e-3\nStrings: 'hi', \"hi\", \"\"\"multi\"\"\"\n\n\n\nUnderscores in numbers are allowed: 1_000_000."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#containers-youll-use-these-all-week",
    "href": "W1_Python/D1_Python_Tooling.html#containers-youll-use-these-all-week",
    "title": "Python & Tooling",
    "section": "Containers (you’ll use these all week)",
    "text": "Containers (you’ll use these all week)\n\n\n\nType\nExample\nMutable?\nTypical use\n\n\n\n\nlist\n[1, 2, 3]\n✅\nordered items\n\n\ntuple\n(1, 2)\n❌\nfixed group\n\n\nset\n{1, 2}\n✅\nunique items\n\n\ndict\n{ \"a\": 1 }\n✅\nkey → value"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#dot-notation-methods-quick-idea",
    "href": "W1_Python/D1_Python_Tooling.html#dot-notation-methods-quick-idea",
    "title": "Python & Tooling",
    "section": "Dot notation: methods (quick idea)",
    "text": "Dot notation: methods (quick idea)\nYou’ll often see something.do_this(...).\n\ndo_this is a method: a function that belongs to that value\nThe parentheses (...) mean “call the function”\n\nExample:\nnames = [\"Aisha\", \"Noor\"]\nnames.append(\"Salem\")  # add an item to the list"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#tuples-vs-lists-when-to-use-which",
    "href": "W1_Python/D1_Python_Tooling.html#tuples-vs-lists-when-to-use-which",
    "title": "Python & Tooling",
    "section": "Tuples vs lists (when to use which?)",
    "text": "Tuples vs lists (when to use which?)\n\n\nTuple (immutable)\npoint = (3, 5)\n\nFixed structure\nSafe to pass around\n\n\nList (mutable)\nnames = [\"Aisha\", \"Noor\"]\nnames.append(\"Salem\")\n\nGrows/shrinks\nGood for accumulation"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#tuples-vs-lists-quick-intuition",
    "href": "W1_Python/D1_Python_Tooling.html#tuples-vs-lists-quick-intuition",
    "title": "Python & Tooling",
    "section": "Tuples vs lists (quick intuition)",
    "text": "Tuples vs lists (quick intuition)\n\nUse a list when you plan to change it\nUse a tuple for a fixed “record” (like coordinates)\n\npoint = (24.7136, 46.6753)  # (lat, lon)\nnames = [\"Aisha\", \"Fahad\"]\nnames.append(\"Noor\")"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#sets-uniqueness-tool",
    "href": "W1_Python/D1_Python_Tooling.html#sets-uniqueness-tool",
    "title": "Python & Tooling",
    "section": "Sets: uniqueness tool",
    "text": "Sets: uniqueness tool\nitems = [\"a\", \"b\", \"b\", \"c\"]\nunique = set(items)\nprint(unique)  # {'a','b','c'} (order not guaranteed)\nUse cases:\n\nremove duplicates\nfast membership checks (x in my_set)"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#variables-are-labels-not-boxes",
    "href": "W1_Python/D1_Python_Tooling.html#variables-are-labels-not-boxes",
    "title": "Python & Tooling",
    "section": "Variables are labels, not boxes",
    "text": "Variables are labels, not boxes\nx = [1, 2, 3]\ny = x\ny.append(4)\nprint(x)  # ?\n\nx becomes [1, 2, 3, 4] because x and y point to the same list."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#operators-your-everyday-toolkit",
    "href": "W1_Python/D1_Python_Tooling.html#operators-your-everyday-toolkit",
    "title": "Python & Tooling",
    "section": "Operators: your everyday toolkit",
    "text": "Operators: your everyday toolkit\n\nArithmetic: + - * / // % **\nComparison: &lt; &lt;= == != &gt;= &gt;\nLogical: and or not\nMembership: in, not in\nIdentity: is, is not (usually with None)"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#in-vs-vs-is",
    "href": "W1_Python/D1_Python_Tooling.html#in-vs-vs-is",
    "title": "Python & Tooling",
    "section": "in vs == vs is",
    "text": "in vs == vs is\n\nx in container → membership (lists/strings/sets/dicts)\nx == y → value equality\nx is y → same object in memory (use for None)\n\nx = None\nif x is None:\n    print(\"missing\")"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#operator-precedence-dont-guess",
    "href": "W1_Python/D1_Python_Tooling.html#operator-precedence-dont-guess",
    "title": "Python & Tooling",
    "section": "Operator precedence (don’t guess)",
    "text": "Operator precedence (don’t guess)\nRule of thumb:\n\nParentheses (...)\nPower **\nMultiply/divide * / // %\nAdd/subtract + -\nComparisons == &lt; &gt; ...\nnot → and → or\n\nWhen in doubt: add parentheses."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#operator-precedence-mental-model",
    "href": "W1_Python/D1_Python_Tooling.html#operator-precedence-mental-model",
    "title": "Python & Tooling",
    "section": "Operator precedence (mental model)",
    "text": "Operator precedence (mental model)\n\nParentheses (...)\nExponents **\nMultiply/divide * / // %\nAdd/subtract + -\nComparisons &lt; == &gt;\nLogical not, and, or\n\nWhen in doubt: add parentheses."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#quick-check-predict-the-result",
    "href": "W1_Python/D1_Python_Tooling.html#quick-check-predict-the-result",
    "title": "Python & Tooling",
    "section": "Quick Check: predict the result",
    "text": "Quick Check: predict the result\nWhat do these evaluate to?\n\n5 // 2\n5 / 2\n5 % 2\n2 ** 3\n\n\nAnswers: 2, 2.5, 1, 8"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#truthiness-important-for-data-work",
    "href": "W1_Python/D1_Python_Tooling.html#truthiness-important-for-data-work",
    "title": "Python & Tooling",
    "section": "Truthiness (important for data work)",
    "text": "Truthiness (important for data work)\nThese are False:\n\nNone, 0, 0.0, \"\", [], {}, set()\n\nMost other things are True."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#casting-turning-text-into-numbers",
    "href": "W1_Python/D1_Python_Tooling.html#casting-turning-text-into-numbers",
    "title": "Python & Tooling",
    "section": "Casting: turning text into numbers",
    "text": "Casting: turning text into numbers\nint(\"32\")\nfloat(\"-2.5e-3\")\nlist(\"abc\")  # turn an iterable into a list\nbool(\"False\")  # careful!\n\n\n\n\n\n\nWarning\n\n\nbool(\"False\") is True because it’s a non-empty string."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#mini-quiz-pairs-casting",
    "href": "W1_Python/D1_Python_Tooling.html#mini-quiz-pairs-casting",
    "title": "Python & Tooling",
    "section": "Mini-quiz (pairs): casting",
    "text": "Mini-quiz (pairs): casting\nDecide without running:\n\nbool([])\nbool([0])\nint(1.9)\nfloat(3)\n\n\nAnswers: False, True, 1, 3.0"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#lists-indexing-and-slicing",
    "href": "W1_Python/D1_Python_Tooling.html#lists-indexing-and-slicing",
    "title": "Python & Tooling",
    "section": "Lists: indexing and slicing",
    "text": "Lists: indexing and slicing\nx = [4, 5, 6, 7, 8, 9]\nprint(x[1])     # 5\nprint(x[-2])    # 8\nprint(x[1:3])   # [5, 6]\nprint(x[::-1])  # reversed"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#dicts-the-data-row-type",
    "href": "W1_Python/D1_Python_Tooling.html#dicts-the-data-row-type",
    "title": "Python & Tooling",
    "section": "Dicts: the “data row” type",
    "text": "Dicts: the “data row” type\nrow = {\"name\": \"Aisha\", \"age\": 23}\nprint(row[\"name\"])\nrow[\"age\"] += 1\nWhy we care:\n\ncsv.DictReader gives you dicts (column → value)"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#dicts-keys-membership-and-safe-access",
    "href": "W1_Python/D1_Python_Tooling.html#dicts-keys-membership-and-safe-access",
    "title": "Python & Tooling",
    "section": "Dicts: keys, membership, and safe access",
    "text": "Dicts: keys, membership, and safe access\nYou’ll often need the column names and to check if a key exists.\nrow = {\"name\": \"Aisha\", \"age\": \"23\"}\n\nprint(row.keys())           # dict_keys(['name', 'age'])\nprint(\"age\" in row)        # True\nprint(row[\"age\"])          # '23'\n\n# If a key might be missing, use .get with a default:\nprint(row.get(\"salary\", \"\"))\n\n\nFor CSV data, keys usually exist for every column, but values may be empty strings."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#printing-values-and-why-it-matters",
    "href": "W1_Python/D1_Python_Tooling.html#printing-values-and-why-it-matters",
    "title": "Python & Tooling",
    "section": "Printing values (and why it matters)",
    "text": "Printing values (and why it matters)\nWhen you build reports, you’ll print and write lots of text.\nThree common ways:\ncity = \"Riyadh\"\ntemp = 19.5\n\nprint(\"City:\", city, \"Temp:\", temp)     # simplest\nprint(\"City: \" + city)                   # string concatenation"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#f-strings-readable-formatting-intro",
    "href": "W1_Python/D1_Python_Tooling.html#f-strings-readable-formatting-intro",
    "title": "Python & Tooling",
    "section": "f-strings: readable formatting (intro)",
    "text": "f-strings: readable formatting (intro)\nf-strings let you put values inside a string:\ncity = \"Riyadh\"\ntemp = 19.5\nis_weekend = True\n\nprint(f\"In {city}, temp is {temp}C. Weekend? {is_weekend}\")\nWe’ll use this style a lot in reports."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#micro-exercise-build-a-tiny-row-6-minutes",
    "href": "W1_Python/D1_Python_Tooling.html#micro-exercise-build-a-tiny-row-6-minutes",
    "title": "Python & Tooling",
    "section": "Micro-exercise: build a tiny “row” (6 minutes)",
    "text": "Micro-exercise: build a tiny “row” (6 minutes)\nCreate a dictionary with:\n\n\"city\"\n\"temp_c\"\n\"is_weekend\"\n\nThen print a sentence using an f-string.\nCheckpoint: Your output includes all three values."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#solution-example",
    "href": "W1_Python/D1_Python_Tooling.html#solution-example",
    "title": "Python & Tooling",
    "section": "Solution (example)",
    "text": "Solution (example)\nr = {\"city\": \"Riyadh\", \"temp_c\": 19.5, \"is_weekend\": True}\n\ncity = r[\"city\"]\ntemp_c = r[\"temp_c\"]\nis_weekend = r[\"is_weekend\"]\n\nprint(f\"In {city}, temp is {temp_c}C. Weekend? {is_weekend}\")"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#session-2-recap",
    "href": "W1_Python/D1_Python_Tooling.html#session-2-recap",
    "title": "Python & Tooling",
    "section": "Session 2 recap",
    "text": "Session 2 recap\n\nValues + containers\nOperators and truthiness\nLists/dicts basics"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#session-3-objectives",
    "href": "W1_Python/D1_Python_Tooling.html#session-3-objectives",
    "title": "Python & Tooling",
    "section": "Session 3 objectives",
    "text": "Session 3 objectives\n\nUse if/elif/else and conditional expressions\nLoop with for and while\nHandle errors with try/except\nRead and write text files with with open(...)\nUse strings + lists + dicts to build a report"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#python-syntax-101-indentation-blocks",
    "href": "W1_Python/D1_Python_Tooling.html#python-syntax-101-indentation-blocks",
    "title": "Python & Tooling",
    "section": "Python syntax 101: indentation + blocks",
    "text": "Python syntax 101: indentation + blocks\nIn Python, whitespace is part of the syntax.\n\nA : starts a block\nThe indented lines belong to that block\n\nif 5 &gt; 3:\n    print(\"Yes\")\n    print(\"Still inside\")\nprint(\"Back outside\")\nComments start with #."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#if-in-practice",
    "href": "W1_Python/D1_Python_Tooling.html#if-in-practice",
    "title": "Python & Tooling",
    "section": "if in practice",
    "text": "if in practice\ngrade = 83\nif grade &gt;= 90:\n    letter = \"A\"\nelif grade &gt;= 80:\n    letter = \"B\"\nelse:\n    letter = \"C or below\"\nprint(letter)"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#one-line-condition-ternary",
    "href": "W1_Python/D1_Python_Tooling.html#one-line-condition-ternary",
    "title": "Python & Tooling",
    "section": "One-line condition (ternary)",
    "text": "One-line condition (ternary)\nnumber = 7\nparity = \"even\" if number % 2 == 0 else \"odd\"\nprint(parity)"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#for-loops-your-default-loop",
    "href": "W1_Python/D1_Python_Tooling.html#for-loops-your-default-loop",
    "title": "Python & Tooling",
    "section": "for loops: your default loop",
    "text": "for loops: your default loop\nnames = [\"Aisha\", \"Fahad\", \"Noor\"]\nfor name in names:\n    print(name)\nPattern you’ll use for CSV: loop over rows, update counters."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#list-comprehensions-loop-list",
    "href": "W1_Python/D1_Python_Tooling.html#list-comprehensions-loop-list",
    "title": "Python & Tooling",
    "section": "List comprehensions (loop → list)",
    "text": "List comprehensions (loop → list)\nA compact way to build a new list from a loop.\nnums = [1, 2, 3, 4, 5]\nsquares = [n * n for n in nums]\nplus_one = [n + 1 for n in nums]\nUse when it’s short and clear. Otherwise, use a normal for loop."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#loop-helpers-range-enumerate-zip",
    "href": "W1_Python/D1_Python_Tooling.html#loop-helpers-range-enumerate-zip",
    "title": "Python & Tooling",
    "section": "Loop helpers: range, enumerate, zip",
    "text": "Loop helpers: range, enumerate, zip\nfor i in range(3):\n    print(i)\n\nnames = [\"Aisha\", \"Fahad\"]\nfor i, name in enumerate(names, start=1):\n    print(i, name)\n\nages = [23, 31]\nfor name, age in zip(names, ages):\n    print(name, age)"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#while-loops-when-you-dont-know-how-many",
    "href": "W1_Python/D1_Python_Tooling.html#while-loops-when-you-dont-know-how-many",
    "title": "Python & Tooling",
    "section": "while loops: when you don’t know “how many”",
    "text": "while loops: when you don’t know “how many”\ni = 0\nwhile i &lt; 3:\n    print(i)\n    i += 1"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#common-loop-controls",
    "href": "W1_Python/D1_Python_Tooling.html#common-loop-controls",
    "title": "Python & Tooling",
    "section": "Common loop controls",
    "text": "Common loop controls\n\ncontinue → skip to next iteration\nbreak → stop the loop\n\nfor x in \"abcdef\":\n    if x == \"b\":\n        continue\n    if x == \"e\":\n        break\n    print(x)"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#quick-check-1",
    "href": "W1_Python/D1_Python_Tooling.html#quick-check-1",
    "title": "Python & Tooling",
    "section": "Quick Check",
    "text": "Quick Check\nWhat prints?\nfor x in [1, 2, 3, 4]:\n    if x % 2 == 0:\n        continue\n    print(x)\n\nAnswer: 1 then 3"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#match-clean-branching-python-3.10",
    "href": "W1_Python/D1_Python_Tooling.html#match-clean-branching-python-3.10",
    "title": "Python & Tooling",
    "section": "match: clean branching (Python 3.10+)",
    "text": "match: clean branching (Python 3.10+)\ncmd = input(\"Command: \")\nmatch cmd:\n    case \"stats\":\n        print(\"Show stats\")\n    case \"help\":\n        print(\"Show help\")\n    case _:\n        print(\"Unknown command\")"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#assertions-enforce-assumptions",
    "href": "W1_Python/D1_Python_Tooling.html#assertions-enforce-assumptions",
    "title": "Python & Tooling",
    "section": "Assertions: enforce assumptions",
    "text": "Assertions: enforce assumptions\nage = 250\nassert 0 &lt;= age &lt;= 200, \"Age must be realistic\"\nUse this to catch “impossible states” early."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#errors-happen-handle-them",
    "href": "W1_Python/D1_Python_Tooling.html#errors-happen-handle-them",
    "title": "Python & Tooling",
    "section": "Errors happen — handle them",
    "text": "Errors happen — handle them\ntry:\n    x = int(input(\"Enter a number: \"))\n    print(1 / x)\nexcept ValueError:\n    print(\"That was not a number\")\nexcept ZeroDivisionError:\n    print(\"We cannot divide by zero\")"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#files-always-use-with-open...",
    "href": "W1_Python/D1_Python_Tooling.html#files-always-use-with-open...",
    "title": "Python & Tooling",
    "section": "Files: always use with open(...)",
    "text": "Files: always use with open(...)\nwith open(\"notes.txt\", mode=\"w\") as f:\n    f.write(\"Hello file!\\n\")\n\nwith open(\"notes.txt\", mode=\"r\") as f:\n    print(f.read())"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#strings-indexing-methods",
    "href": "W1_Python/D1_Python_Tooling.html#strings-indexing-methods",
    "title": "Python & Tooling",
    "section": "Strings: indexing + methods",
    "text": "Strings: indexing + methods\ns = \"  Data,Data,AI  \"\nprint(s.strip())\nprint(s.lower())\nprint(s.split(\",\"))\n\nlines = [\"one\", \"two\", \"three\"]\nprint(\"\\n\".join(lines))"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#f-strings-formatting-options-review",
    "href": "W1_Python/D1_Python_Tooling.html#f-strings-formatting-options-review",
    "title": "Python & Tooling",
    "section": "f-strings: formatting options (review)",
    "text": "f-strings: formatting options (review)\nname = \"Noor\"\nscore = 91.23456\nprint(f\"{name} scored {score:.2f}\")  # keep 2 decimals"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#functions-named-steps-you-can-reuse",
    "href": "W1_Python/D1_Python_Tooling.html#functions-named-steps-you-can-reuse",
    "title": "Python & Tooling",
    "section": "Functions: named steps you can reuse",
    "text": "Functions: named steps you can reuse\nWhen code gets longer, put pieces into functions.\ndef greet(name):\n    message = f\"Hello, {name}!\"\n    return message\n\nprint(greet(\"Aisha\"))\nTwo key ideas:\n\ndef starts a function\nreturn sends a value back to the caller\n\nWhile drafting, you might also see:\n\npass → “do nothing for now” (a placeholder)"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#modules-importing-code-from-another-file",
    "href": "W1_Python/D1_Python_Tooling.html#modules-importing-code-from-another-file",
    "title": "Python & Tooling",
    "section": "Modules: importing code from another file",
    "text": "Modules: importing code from another file\nIf you create a file math_tools.py:\n# math_tools.py\ndef double(x):\n    return 2 * x\nYou can use it from main.py in the same folder:\nfrom math_tools import double\n\nprint(double(5))\nA folder can also be a package if it contains an __init__.py file:\ncsv_profiler/\n  __init__.py\n  io.py\n  profile.py\nThen you can import from it like:\nfrom csv_profiler.io import read_csv_rows"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#the-main-guard-why-we-use-it",
    "href": "W1_Python/D1_Python_Tooling.html#the-main-guard-why-we-use-it",
    "title": "Python & Tooling",
    "section": "The “main guard” (why we use it)",
    "text": "The “main guard” (why we use it)\nIn many projects, main.py can be:\n\nrun directly (python main.py)\nimported by other code\n\nThis pattern makes sure code runs only when executed as a script:\ndef main():\n    print(\"Running!\")\n\nif __name__ == \"__main__\":\n    main()"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#built-ins-youll-use-in-profilers",
    "href": "W1_Python/D1_Python_Tooling.html#built-ins-youll-use-in-profilers",
    "title": "Python & Tooling",
    "section": "Built-ins you’ll use in profilers",
    "text": "Built-ins you’ll use in profilers\n\nlen(rows) → row count\nmin(numbers), max(numbers) → extremes\nsum(numbers) / len(numbers) → mean\nsorted(items) → ordering\nenumerate(items) → index + value\n\nnames = [\"Aisha\", \"Fahad\"]\nfor i, name in enumerate(names, start=1):\n    print(i, name)\n\n\nWe’ll add numeric stats tomorrow."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#lists-dicts-the-report-builder-pattern",
    "href": "W1_Python/D1_Python_Tooling.html#lists-dicts-the-report-builder-pattern",
    "title": "Python & Tooling",
    "section": "Lists + dicts: the report builder pattern",
    "text": "Lists + dicts: the report builder pattern\nYou will build a report like:\nreport = {\n  \"rows\": 120,\n  \"columns\": {\n     \"age\": {\"missing\": 2, \"type\": \"number\"},\n     \"city\": {\"missing\": 0, \"type\": \"text\"}\n  }\n}"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#micro-exercise-count-missing-values-8-minutes",
    "href": "W1_Python/D1_Python_Tooling.html#micro-exercise-count-missing-values-8-minutes",
    "title": "Python & Tooling",
    "section": "Micro-exercise: count missing values (8 minutes)",
    "text": "Micro-exercise: count missing values (8 minutes)\nGiven this list of rows:\nrows = [\n  {\"age\": \"19\", \"city\": \"Riyadh\"},\n  {\"age\": \"\",   \"city\": \"Jeddah\"},\n  {\"age\": \"20\", \"city\": \"\"},\n]\nWrite code that counts missing values per column.\nRule: treat empty string \"\" as missing."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#solution-one-good-approach",
    "href": "W1_Python/D1_Python_Tooling.html#solution-one-good-approach",
    "title": "Python & Tooling",
    "section": "Solution (one good approach)",
    "text": "Solution (one good approach)\nmissing = {\"age\": 0, \"city\": 0}\nfor row in rows:\n    for col in missing:\n        if row[col] == \"\":\n            missing[col] += 1\nprint(missing)"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#session-3-recap",
    "href": "W1_Python/D1_Python_Tooling.html#session-3-recap",
    "title": "Python & Tooling",
    "section": "Session 3 recap",
    "text": "Session 3 recap\n\nControl flow: if / loops / match\nFiles: with open(...)\nReport pattern: nested dicts"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#vibe-coding-safe-version",
    "href": "W1_Python/D1_Python_Tooling.html#vibe-coding-safe-version",
    "title": "Python & Tooling",
    "section": "Vibe coding (safe version)",
    "text": "Vibe coding (safe version)\n\nPlan first (write steps in English)\nImplement small increments\nRun → break → read error → fix\nCommit frequently\nRepeat\n\n\n\n\n\n\n\nWarning\n\n\nDo not ask GenAI to write your solution code. Ask it to explain concepts or errors."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#hands-on-success-criteria-today",
    "href": "W1_Python/D1_Python_Tooling.html#hands-on-success-criteria-today",
    "title": "Python & Tooling",
    "section": "Hands-on success criteria (today)",
    "text": "Hands-on success criteria (today)\nBy the end of the day, you should have:\n\nA project folder with .venv/\nA Python package csv_profiler/\nCode that:\n\nreads a CSV\ncomputes basic profile (rows/cols, missing counts)\nwrites report.json and report.md"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#todays-project-layout-minimal",
    "href": "W1_Python/D1_Python_Tooling.html#todays-project-layout-minimal",
    "title": "Python & Tooling",
    "section": "Today’s project layout (minimal)",
    "text": "Today’s project layout (minimal)\nFor Day 1, we’ll keep things simple so imports “just work”.\nbootcamp/\n  csv-profiler/\n    .venv/\n    main.py\n    csv_profiler/\n      __init__.py\n      io.py\n      profile.py\n      render.py\n    data/\n      sample.csv\n    outputs/\n      report.json\n      report.md\n\n\nLater this week, we’ll switch to a more “professional” layout with pyproject.toml and a src/ folder."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#by-thursday-target-layout-well-refactor-later",
    "href": "W1_Python/D1_Python_Tooling.html#by-thursday-target-layout-well-refactor-later",
    "title": "Python & Tooling",
    "section": "By Thursday: target layout (we’ll refactor later)",
    "text": "By Thursday: target layout (we’ll refactor later)\ncsv-profiler/\n  pyproject.toml\n  README.md\n  src/\n    csv_profiler/\n      ...\n  data/\n  outputs/"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#task-0-create-the-project-10-minutes",
    "href": "W1_Python/D1_Python_Tooling.html#task-0-create-the-project-10-minutes",
    "title": "Python & Tooling",
    "section": "Task 0 — Create the project (10 minutes)",
    "text": "Task 0 — Create the project (10 minutes)\n\nInside bootcamp/, create a folder csv-profiler/\ncd csv-profiler\nCreate an env: uv venv -p 3.11\n\nCheckpoint: you have .venv/ inside csv-profiler/."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#task-0-suggested-commands",
    "href": "W1_Python/D1_Python_Tooling.html#task-0-suggested-commands",
    "title": "Python & Tooling",
    "section": "Task 0 — Suggested commands",
    "text": "Task 0 — Suggested commands\ncd ~/bootcamp\nmkdir csv-profiler\ncd csv-profiler\nuv venv -p 3.11"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#task-1-add-a-sample-csv-8-minutes",
    "href": "W1_Python/D1_Python_Tooling.html#task-1-add-a-sample-csv-8-minutes",
    "title": "Python & Tooling",
    "section": "Task 1 — Add a sample CSV (8 minutes)",
    "text": "Task 1 — Add a sample CSV (8 minutes)\nCreate data/sample.csv with this content:\nname,age,city,salary\nAisha,23,Riyadh,12000\nFahad,,Jeddah,9000\nNoor,29,,\nSalem,31,Dammam,15000\nCheckpoint: you can open it in VS Code."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#task-2-create-package-skeleton-10-minutes",
    "href": "W1_Python/D1_Python_Tooling.html#task-2-create-package-skeleton-10-minutes",
    "title": "Python & Tooling",
    "section": "Task 2 — Create package skeleton (10 minutes)",
    "text": "Task 2 — Create package skeleton (10 minutes)\nCreate these files (match the minimal layout slide):\n\ncsv_profiler/__init__.py\ncsv_profiler/io.py\ncsv_profiler/profile.py\ncsv_profiler/render.py\nmain.py (entrypoint for today)\n\n\n\n__init__.py can be empty for now — it just marks the folder as a package."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#task-2-minimal-main.py",
    "href": "W1_Python/D1_Python_Tooling.html#task-2-minimal-main.py",
    "title": "Python & Tooling",
    "section": "Task 2 — Minimal main.py",
    "text": "Task 2 — Minimal main.py\nPaste this first:\nfrom csv_profiler.io import read_csv_rows\nfrom csv_profiler.profile import basic_profile\nfrom csv_profiler.render import write_json, write_markdown\n\ndef main():\n    rows = read_csv_rows(\"data/sample.csv\")\n    report = basic_profile(rows)\n    write_json(report, \"outputs/report.json\")\n    write_markdown(report, \"outputs/report.md\")\n    print(\"Wrote outputs/report.json and outputs/report.md\")\n\nif __name__ == \"__main__\":\n    main()"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#reading-csvs-in-python-csv.dictreader",
    "href": "W1_Python/D1_Python_Tooling.html#reading-csvs-in-python-csv.dictreader",
    "title": "Python & Tooling",
    "section": "Reading CSVs in Python: csv.DictReader",
    "text": "Reading CSVs in Python: csv.DictReader\nPython’s standard library has a csv module.\nimport csv\n\nwith open(\"data/sample.csv\", \"r\", encoding=\"utf-8\", newline=\"\") as f:\n    reader = csv.DictReader(f)\n    for row in reader:\n        print(row)          # a dict: column_name -&gt; cell_value (strings)\n        break\nNotes:\n\nCSV values come in as strings (even numbers)\nMissing cells usually come in as the empty string \"\""
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#task-3-implement-csv-reading-15-minutes",
    "href": "W1_Python/D1_Python_Tooling.html#task-3-implement-csv-reading-15-minutes",
    "title": "Python & Tooling",
    "section": "Task 3 — Implement CSV reading (15 minutes)",
    "text": "Task 3 — Implement CSV reading (15 minutes)\nIn csv_profiler/io.py implement:\nimport csv\n\n\ndef read_csv_rows(path):\n    \"\"\"Read a CSV as a list of rows (each row is a dict of strings).\"\"\"\n    # TODO: implement\n    pass\nRules:\n\nUse with open(..., newline=\"\")\nUse csv.DictReader to parse rows\nReturn a list of dictionaries (one dict per row)"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#solution-read_csv_rows-example",
    "href": "W1_Python/D1_Python_Tooling.html#solution-read_csv_rows-example",
    "title": "Python & Tooling",
    "section": "Solution — read_csv_rows (example)",
    "text": "Solution — read_csv_rows (example)\nimport csv\n\n\ndef read_csv_rows(path):\n    with open(path, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n        reader = csv.DictReader(f)\n        return list(reader)"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#task-4-compute-a-basic-profile-20-minutes",
    "href": "W1_Python/D1_Python_Tooling.html#task-4-compute-a-basic-profile-20-minutes",
    "title": "Python & Tooling",
    "section": "Task 4 — Compute a basic profile (20 minutes)",
    "text": "Task 4 — Compute a basic profile (20 minutes)\nIn csv_profiler/profile.py, implement:\ndef basic_profile(rows):\n    \"\"\"Compute row count, column names, and missing values per column.\"\"\"\n    # TODO: implement\n    pass\nDefinition of missing today:\n\nempty string after stripping whitespace"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#hint-how-to-get-columns",
    "href": "W1_Python/D1_Python_Tooling.html#hint-how-to-get-columns",
    "title": "Python & Tooling",
    "section": "Hint — how to get columns",
    "text": "Hint — how to get columns\nIf there is at least one row:\ncolumns = list(rows[0].keys())\nThen loop rows and update counts."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#solution-basic_profile-day-1-version",
    "href": "W1_Python/D1_Python_Tooling.html#solution-basic_profile-day-1-version",
    "title": "Python & Tooling",
    "section": "Solution — basic_profile (day-1 version)",
    "text": "Solution — basic_profile (day-1 version)\ndef basic_profile(rows):\n    if not rows:\n        return {\"rows\": 0, \"n_cols\": 0, \"columns\": [], \"missing\": {}, \"non_empty\": {}}\n\n    columns = list(rows[0].keys())\n    missing = {}\n    non_empty = {}\n    for c in columns:\n        missing[c] = 0\n        non_empty[c] = 0\n\n    for row in rows:\n        for c in columns:\n            v = row[c].strip()\n            if v == \"\":  # DictReader gives empty string for missing cells\n                missing[c] += 1\n            else:\n                non_empty[c] += 1\n\n    return {\n        \"rows\": len(rows), \"n_cols\": len(columns), \"columns\": columns,\n        \"missing\": missing, \"non_empty\": non_empty\n    }"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#optional-stretch-start-type-inference",
    "href": "W1_Python/D1_Python_Tooling.html#optional-stretch-start-type-inference",
    "title": "Python & Tooling",
    "section": "Optional (stretch): start type inference",
    "text": "Optional (stretch): start type inference\nGoal: infer a simple type label per column:\n\nnumber if all non-empty values can be parsed as float\ntext otherwise\n\nPseudo-steps:\n\nFor each column, collect its non-empty strings\nTry float(value) in a try/except ValueError\nIf any value fails → text\n\nExample helper:\ndef is_number(s):\n    try:\n        float(s)\n        return True\n    except ValueError:\n        return False"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#task-5-write-json-output-10-minutes",
    "href": "W1_Python/D1_Python_Tooling.html#task-5-write-json-output-10-minutes",
    "title": "Python & Tooling",
    "section": "Task 5 — Write JSON output (10 minutes)",
    "text": "Task 5 — Write JSON output (10 minutes)\nIn csv_profiler/render.py implement:\nimport json\nimport os\n\n\ndef write_json(report, path):\n    \"\"\"Write the report dict to a JSON file.\"\"\"\n    # TODO: implement\n    pass\nRequirements:\n\nCreate the parent folder if it doesn’t exist\nPretty-print with indentation"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#solution-write_json",
    "href": "W1_Python/D1_Python_Tooling.html#solution-write_json",
    "title": "Python & Tooling",
    "section": "Solution — write_json",
    "text": "Solution — write_json\nimport json\nimport os\n\n\ndef write_json(report, path):\n    folder = os.path.dirname(path)\n    if folder:\n        os.makedirs(folder, exist_ok=True)\n\n    with open(path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(report, f, indent=2, ensure_ascii=False)"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#task-6-write-markdown-output-15-minutes",
    "href": "W1_Python/D1_Python_Tooling.html#task-6-write-markdown-output-15-minutes",
    "title": "Python & Tooling",
    "section": "Task 6 — Write Markdown output (15 minutes)",
    "text": "Task 6 — Write Markdown output (15 minutes)\nImplement:\ndef write_markdown(report, path):\n    \"\"\"Write a human-readable Markdown report.\"\"\"\n    # TODO: implement\n    pass\nMarkdown should include:\n\nTitle\nRows + columns\nA small table: column name + missing count"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#solution-write_markdown-simple",
    "href": "W1_Python/D1_Python_Tooling.html#solution-write_markdown-simple",
    "title": "Python & Tooling",
    "section": "Solution — write_markdown (simple)",
    "text": "Solution — write_markdown (simple)\nimport os\n\n\ndef write_markdown(report, path):\n    folder = os.path.dirname(path)\n    if folder:\n        os.makedirs(folder, exist_ok=True)\n\n    cols = report.get(\"columns\", [])\n    missing = report.get(\"missing\", {})\n    lines = []\n    lines.append(\"# CSV Profiling Report\\n\")\n    lines.append(f\"- Rows: **{report.get('rows', 0)}**\")\n    lines.append(f\"- Columns: **{report.get('n_cols', 0)}**\\n\")\n\n    lines.append(\"## Missing Values\\n\")\n    lines.append(\"| column | missing |\")\n    lines.append(\"|---|---:|\")\n    for c in cols:\n        lines.append(f\"| {c} | {missing.get(c, 0)} |\")\n\n    with open(path, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"\\n\".join(lines) + \"\\n\")"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#task-7-run-it-end-to-end-10-minutes",
    "href": "W1_Python/D1_Python_Tooling.html#task-7-run-it-end-to-end-10-minutes",
    "title": "Python & Tooling",
    "section": "Task 7 — Run it end-to-end (10 minutes)",
    "text": "Task 7 — Run it end-to-end (10 minutes)\nFrom the project root:\nuv run main.py\nThen open:\n\noutputs/report.json\noutputs/report.md\n\nCheckpoint: both files exist and match the sample CSV."
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#debug-playbook-when-it-fails",
    "href": "W1_Python/D1_Python_Tooling.html#debug-playbook-when-it-fails",
    "title": "Python & Tooling",
    "section": "Debug playbook (when it fails)",
    "text": "Debug playbook (when it fails)\n\nRead the first error line (most important)\nConfirm the file path is correct\nPrint intermediate values (print(rows[0]))\nReduce the problem (try 1 row)"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#stretch-if-you-finish-early",
    "href": "W1_Python/D1_Python_Tooling.html#stretch-if-you-finish-early",
    "title": "Python & Tooling",
    "section": "Stretch (if you finish early)",
    "text": "Stretch (if you finish early)\nAdd one more section to the Markdown:\n\nNon-empty counts per column\n\nBonus:\n\nA top_values list for text columns (most common values)"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#exit-ticket",
    "href": "W1_Python/D1_Python_Tooling.html#exit-ticket",
    "title": "Python & Tooling",
    "section": "Exit Ticket",
    "text": "Exit Ticket\nIn 1–2 sentences:\nWhat was the most confusing part today: paths, environments, or Python control flow?"
  },
  {
    "objectID": "W1_Python/D1_Python_Tooling.html#what-to-do-after-class-day-1-assignment",
    "href": "W1_Python/D1_Python_Tooling.html#what-to-do-after-class-day-1-assignment",
    "title": "Python & Tooling",
    "section": "What to do after class (Day 1 assignment)",
    "text": "What to do after class (Day 1 assignment)\nDue: before Day 2 starts\n\nMake your code work on data/sample.csv\nChange the sample CSV (add 2 rows) and rerun\nUpdate report.md to include a short “Notes” section\n\nDeliverable: a zip or folder with your csv-profiler/ project.\n\n\n\n\n\n\nTip\n\n\nTomorrow we’ll refactor into functions + modules and add better type inference."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#todays-flow",
    "href": "W1_Python/D3_Modules_OOP.html#todays-flow",
    "title": "Python & Tooling",
    "section": "Today’s Flow",
    "text": "Today’s Flow\n\nSession 1 (60m): Modules + packages\nAsr Prayer (20m)\nSession 2 (60m): OOP essentials\nMaghrib Prayer (20m)\nSession 3 (60m): Typer: build a CLI from type hints\nIsha Prayer (20m)\nHands-on (120m): Project: package + CLI + errors"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#learning-objectives",
    "href": "W1_Python/D3_Modules_OOP.html#learning-objectives",
    "title": "Python & Tooling",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of today, you can:\n\nExplain the difference between a module and a package\nFix imports by understanding sys.path and PYTHONPATH\nUse core modules: os, sys, time, shutil\nWrite a small class using properties to enforce constraints\nExplain (and recognize) inheritance and polymorphism\nBuild a multi-command Typer CLI with --help\nShip a CLI that generates JSON + Markdown reports"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#warm-up-5-minutes",
    "href": "W1_Python/D3_Modules_OOP.html#warm-up-5-minutes",
    "title": "Python & Tooling",
    "section": "Warm-up (5 minutes)",
    "text": "Warm-up (5 minutes)\nRun your Day 2 project (whatever layout you have right now).\n\nGo to your project folder\n\ncd ~/bootcamp/csv-profiler\n\nRun it\n\nIf you already have a src/ folder (src-layout):\nPYTHONPATH=src uv run python main.py\nIf you do not have a src/ folder yet (flat-layout):\nuv run python main.py"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#warm-up-5-minutes-1",
    "href": "W1_Python/D3_Modules_OOP.html#warm-up-5-minutes-1",
    "title": "Python & Tooling",
    "section": "Warm-up (5 minutes)",
    "text": "Warm-up (5 minutes)\nRun your Day 2 project (whatever layout you have right now).\nWindows PowerShell (src-layout):\ncd $HOME\\bootcamp\\csv-profiler\n$env:PYTHONPATH=\"src\"\nuv run python main.py\nWindows PowerShell (flat-layout):\ncd $HOME\\bootcamp\\csv-profiler\nuv run python main.py\nCheckpoint: outputs/report.json and outputs/report.md are updated."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#week-project-progress",
    "href": "W1_Python/D3_Modules_OOP.html#week-project-progress",
    "title": "Python & Tooling",
    "section": "Week project progress",
    "text": "Week project progress\nYou already have:\n\nA working profiler\nType inference (number vs text)\nNumeric stats for numeric columns\nClean-ish Markdown and JSON exports\n\nToday you will add:\n\nPackage structure (src/csv_profiler/...)\nA CLI (Typer) that accepts input/output paths\nBetter error handling + helpful messages\nA tiny bit of timing (how long profiling takes)\n\n\n\nThis is what makes your work gradeable and reproducible."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#session-1-objectives",
    "href": "W1_Python/D3_Modules_OOP.html#session-1-objectives",
    "title": "Python & Tooling",
    "section": "Session 1 objectives",
    "text": "Session 1 objectives\n\nUnderstand how Python finds code to import\nCreate and import your own modules\nUse built-in modules to interact with the OS"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#vocabulary-module-vs-package",
    "href": "W1_Python/D3_Modules_OOP.html#vocabulary-module-vs-package",
    "title": "Python & Tooling",
    "section": "Vocabulary: module vs package",
    "text": "Vocabulary: module vs package\n\nModule: one .py file\n\nExample: profiling.py\n\nPackage: a folder of modules\n\nExample: csv_profiler/ with __init__.py\n\n\nWhy packages?\n\norganize code by responsibility\nreuse code across scripts\neasier testing and maintenance"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#what-happens-when-you-import-something",
    "href": "W1_Python/D3_Modules_OOP.html#what-happens-when-you-import-something",
    "title": "Python & Tooling",
    "section": "What happens when you import something?",
    "text": "What happens when you import something?\nPython searches for something in this order:\n\nBuilt-in modules\nInstalled packages (your environment)\nYour project paths (current folder + sys.path)\n\nDebug tool:\nimport sys\nprint(sys.path)\n\n\nIf you understand sys.path, you can debug most import problems."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#quick-demo-check-your-import-paths",
    "href": "W1_Python/D3_Modules_OOP.html#quick-demo-check-your-import-paths",
    "title": "Python & Tooling",
    "section": "Quick demo: check your import paths",
    "text": "Quick demo: check your import paths\nCreate debug_paths.py:\nimport sys\n\nprint(\"sys.path (where Python looks for imports):\")\nfor p in sys.path:\n    print(\" -\", p)\nRun:\nuv run python debug_paths.py\nQuestion: Do you see your project root? Do you see .../.venv/...?"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#environment-variables-quick-idea",
    "href": "W1_Python/D3_Modules_OOP.html#environment-variables-quick-idea",
    "title": "Python & Tooling",
    "section": "Environment variables (quick idea)",
    "text": "Environment variables (quick idea)\n\nEnvironment variables are key/value strings set in your terminal (outside Python).\nThey are inherited by programs you run from that terminal.\nWe’ll use one today: PYTHONPATH (adds folders to Python’s import search).\n\n\n\n\n\n\n\nTip\n\n\nYou don’t need to memorize many environment variables. Today we only care about PYTHONPATH."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#pythonpath-add-folders-to-import-search",
    "href": "W1_Python/D3_Modules_OOP.html#pythonpath-add-folders-to-import-search",
    "title": "Python & Tooling",
    "section": "PYTHONPATH: add folders to import search",
    "text": "PYTHONPATH: add folders to import search\nIf your code lives in src/, add it to the path:\n\nUnix/macOS:\n\nPYTHONPATH=src uv run python main.py\n\nWindows PowerShell:\n\n$env:PYTHONPATH=\"src\"\nuv run python main.py\n\n\n\n\n\n\nTip\n\n\nThis is the simplest way to use a src/ layout before we finalize packaging."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#import-styles-use-intentionally",
    "href": "W1_Python/D3_Modules_OOP.html#import-styles-use-intentionally",
    "title": "Python & Tooling",
    "section": "Import styles (use intentionally)",
    "text": "Import styles (use intentionally)\n\n\nGood defaults\n\nimport csv\nimport json\nfrom pathlib import Path\n\nWhy?\n\nkeeps namespace clean\navoids name collisions\n\n\nAlso okay (be explicit)\n\nimport numpy as np (common convention)\nimport utilities.arithmetic.units as convert\n\nAvoid:\n\nfrom module import * (hides names)"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#name__-__main__-run-vs-import",
    "href": "W1_Python/D3_Modules_OOP.html#name__-__main__-run-vs-import",
    "title": "Python & Tooling",
    "section": "__name__ == \"__main__\": run vs import",
    "text": "__name__ == \"__main__\": run vs import\nA file can be:\n\nimported (used as a library)\nexecuted (run as a program)\n\nPattern:\ndef main() -&gt; None:\n    ...\n\nif __name__ == \"__main__\":\n    main()"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#run-a-module-with--m",
    "href": "W1_Python/D3_Modules_OOP.html#run-a-module-with--m",
    "title": "Python & Tooling",
    "section": "Run a module with -m",
    "text": "Run a module with -m\nInstead of:\nuv run python src/csv_profiler/cli.py\nPrefer:\nPYTHONPATH=src uv run python -m csv_profiler.cli --help\nWhy?\n\nimports work more predictably\nyou run the module “as part of a package”"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#project-structure-we-want-by-end-of-today",
    "href": "W1_Python/D3_Modules_OOP.html#project-structure-we-want-by-end-of-today",
    "title": "Python & Tooling",
    "section": "Project structure we want (by end of today)",
    "text": "Project structure we want (by end of today)\ncsv-profiler/\n├── data/\n│   └── sample.csv\n├── outputs/\n├── src/\n│   └── csv_profiler/\n│       ├── __init__.py\n│       ├── io.py\n│       ├── profiling.py\n│       ├── render.py\n│       └── cli.py\n└── pyproject.toml\n\n\nEach file gets one job."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#one-job-per-module-recommended",
    "href": "W1_Python/D3_Modules_OOP.html#one-job-per-module-recommended",
    "title": "Python & Tooling",
    "section": "One job per module (recommended)",
    "text": "One job per module (recommended)\n\nio.py\n\nread CSV → list of rows (list[dict[str, str]])\n\nprofiling.py\n\ncompute column stats → Python dicts/classes\n\nrender.py\n\nconvert report → Markdown string\n\ncli.py\n\nparse args + call your library"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#built-in-modules-youll-use-today",
    "href": "W1_Python/D3_Modules_OOP.html#built-in-modules-youll-use-today",
    "title": "Python & Tooling",
    "section": "Built-in modules you’ll use today",
    "text": "Built-in modules you’ll use today\nSystem & OS\n\nos → environment variables, current directory\nsys → argv, stdin/out, import path\ntime → measure runtime, timestamps\nshutil → file operations + check if tools exist\n\n\n\n\n\n\n\nTip\n\n\nThese are “glue” modules that make your Python code behave like a real tool."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#os-environment-current-folder",
    "href": "W1_Python/D3_Modules_OOP.html#os-environment-current-folder",
    "title": "Python & Tooling",
    "section": "os: environment + current folder",
    "text": "os: environment + current folder\nimport os\n\nprint(\"PWD:\", os.getcwd())\nprint(\"HOME:\", os.environ.get(\"HOME\"))\nprint(\"CSV_PATH:\", os.environ.get(\"CSV_PATH\"))\nUse cases:\n\nread config like OUTPUT_DIR\ndebug “where am I running from?”"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#sys-argv-exit-codes",
    "href": "W1_Python/D3_Modules_OOP.html#sys-argv-exit-codes",
    "title": "Python & Tooling",
    "section": "sys: argv + exit codes",
    "text": "sys: argv + exit codes\nimport sys\n\nprint(sys.argv)   # list of strings\nsys.exit(0)       # success\nsys.exit(1)       # failure\n\n\nWith Typer you won’t use sys.argv directly, but you should understand it."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#time-measure-how-long-profiling-takes",
    "href": "W1_Python/D3_Modules_OOP.html#time-measure-how-long-profiling-takes",
    "title": "Python & Tooling",
    "section": "time: measure how long profiling takes",
    "text": "time: measure how long profiling takes\nimport time\n\nstart = time.perf_counter_ns()\n# do work\nend = time.perf_counter_ns()\n\nelapsed_ms = (end - start) / 1_000_000\nprint(f\"Elapsed: {elapsed_ms:.2f}ms\")\n\nWhy?\n\nit’s easy feedback on performance\nlater, you’ll profile bigger datasets\n\n\nIn an f-string, :.2f means “show 2 digits after the decimal point”."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#shutil-find-tools-move-files",
    "href": "W1_Python/D3_Modules_OOP.html#shutil-find-tools-move-files",
    "title": "Python & Tooling",
    "section": "shutil: find tools + move files",
    "text": "shutil: find tools + move files\nimport shutil\n\nprint(shutil.which(\"git\"))\nprint(shutil.which(\"python\"))\nUseful later:\n\ncheck that git is installed before Day 5 tasks"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#mini-exercise-create-your-first-module-8-minutes",
    "href": "W1_Python/D3_Modules_OOP.html#mini-exercise-create-your-first-module-8-minutes",
    "title": "Python & Tooling",
    "section": "Mini-exercise: create your first module (8 minutes)",
    "text": "Mini-exercise: create your first module (8 minutes)\nCreate src/csv_profiler/strings.py:\ndef slugify(text: str) -&gt; str:\n    \"\"\"Turn 'Report Name' → 'report-name'.\"\"\"\n    ...\nThen import it in main.py (or another file):\nfrom csv_profiler.strings import slugify\nprint(slugify(\"My Report 01\"))\nCheckpoint: prints my-report-01"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#solution-slugify",
    "href": "W1_Python/D3_Modules_OOP.html#solution-slugify",
    "title": "Python & Tooling",
    "section": "Solution — slugify",
    "text": "Solution — slugify\ndef slugify(text: str) -&gt; str:\n    cleaned = text.strip().casefold()\n    parts = cleaned.split()\n    return \"-\".join(parts)\n\n\nThis is intentionally simple. We can improve later (remove punctuation, etc.)."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#common-import-mistakes",
    "href": "W1_Python/D3_Modules_OOP.html#common-import-mistakes",
    "title": "Python & Tooling",
    "section": "Common import mistakes",
    "text": "Common import mistakes\n\nForgetting __init__.py in a package folder\nRunning from the wrong working directory\nImporting by file path instead of module path\nNaming your file csv.py or json.py (shadows built-ins!)\n\n\n\n\n\n\n\nWarning\n\n\nNever name your file the same as a standard library module. Example: don’t create time.py."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#recap-session-1",
    "href": "W1_Python/D3_Modules_OOP.html#recap-session-1",
    "title": "Python & Tooling",
    "section": "Recap (Session 1)",
    "text": "Recap (Session 1)\n\nA module is a .py file; a package is a folder of modules\nImports depend on sys.path → debug it!\nUse PYTHONPATH=src (for now) to support src/ layout\nCore system modules: os, sys, time, shutil"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#session-2-objectives",
    "href": "W1_Python/D3_Modules_OOP.html#session-2-objectives",
    "title": "Python & Tooling",
    "section": "Session 2 objectives",
    "text": "Session 2 objectives\n\nKnow what a class is (and how to create an object)\nUnderstand encapsulation (protect invariants)\nRecognize inheritance (reuse behavior)\nExplain polymorphism in Python (“duck typing”)\nApply OOP lightly to our profiler"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#when-should-you-use-oop",
    "href": "W1_Python/D3_Modules_OOP.html#when-should-you-use-oop",
    "title": "Python & Tooling",
    "section": "When should you use OOP?",
    "text": "When should you use OOP?\nUse classes when you want:\n\ndata + behavior together\nconstraints/invariants (e.g., “age must be between 0–200”)\na reusable abstraction with a clear interface\n\nDon’t force OOP when:\n\na dict is enough\nyou have only one function using the data\n\n\n\nWe use OOP as a tool — not as a goal."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#vocabulary-class-vs-object-instance",
    "href": "W1_Python/D3_Modules_OOP.html#vocabulary-class-vs-object-instance",
    "title": "Python & Tooling",
    "section": "Vocabulary: class vs object (instance)",
    "text": "Vocabulary: class vs object (instance)\n\nClass: a blueprint you write (class Person: ...)\nObject / instance: a value you create (p = Person(...))\n\nA class can contain:\n\ndata (attributes like name, age)\nbehavior (methods like greet())"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#a-minimal-class",
    "href": "W1_Python/D3_Modules_OOP.html#a-minimal-class",
    "title": "Python & Tooling",
    "section": "A minimal class",
    "text": "A minimal class\nclass Person:\n    def __init__(self, name: str, age: int) -&gt; None:\n        self.name = name\n        self.age = age\n\n    def greet(self) -&gt; str:\n        return f\"Hi, I'm {self.name}\"\nKey idea:\n\n__init__ runs when you create the object\nself is the object being created/used"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#using-a-class",
    "href": "W1_Python/D3_Modules_OOP.html#using-a-class",
    "title": "Python & Tooling",
    "section": "Using a class",
    "text": "Using a class\np = Person(\"Sara Ahmed\", 23)\n\nprint(p.name)        # attribute\nprint(p.age)\nprint(p.greet())     # method call\n\n\n\n\n\n\nTip\n\n\nA method is just a function that lives inside a class. It always receives self as the first parameter."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#printing-objects-nicely-with-__repr__",
    "href": "W1_Python/D3_Modules_OOP.html#printing-objects-nicely-with-__repr__",
    "title": "Python & Tooling",
    "section": "Printing objects nicely with __repr__",
    "text": "Printing objects nicely with __repr__\nIf you print an object without __repr__, you usually see something like:\n&lt;__main__.Person object at 0x...&gt;\nAdd this:\nclass Person:\n    ...\n    def __repr__(self) -&gt; str:\n        return f\"Person(name={self.name!r}, age={self.age})\"\nNow:\nprint(p)  # Person(name='Sara Ahmed', age=23)\n\n\n\n\n\n\nTip\n\n\nTo get the output of repr as a str value for any object, you can use the builtin function repr(). In addition, you can also print the output in f-strings if you use the !r format specifier as in the example above.\n\n\n\n\n\nThe convention of __repr__ is to show how the object was created. It should look like valid Python code."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#read-only-properties-computed-attributes",
    "href": "W1_Python/D3_Modules_OOP.html#read-only-properties-computed-attributes",
    "title": "Python & Tooling",
    "section": "Read-only properties: computed attributes",
    "text": "Read-only properties: computed attributes\nSometimes you want an attribute that is computed from other data.\nclass Person:\n    ...\n\n    @property\n    def first_name(self) -&gt; str:\n        parts = self.name.split()\n        if not parts:\n            return \"\"\n        return parts[0]\n\n    @property\n    def last_name(self) -&gt; str:\n        parts = self.name.split()\n        if not parts:\n            return \"\"\n        return parts[-1]\n\n\n@property lets you write p.first_name instead of p.first_name()."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#encapsulation-validate-changes-with-a-setter",
    "href": "W1_Python/D3_Modules_OOP.html#encapsulation-validate-changes-with-a-setter",
    "title": "Python & Tooling",
    "section": "Encapsulation: validate changes with a setter",
    "text": "Encapsulation: validate changes with a setter\nWe want: “age must be between 0 and 200”.\nclass Person:\n    def __init__(self, name: str, age: int) -&gt; None:\n        self.name = name\n        self.age = age  # calls the setter\n\n    @property\n    def age(self) -&gt; int:\n        return self._age\n\n    @age.setter\n    def age(self, value: int) -&gt; None:\n        if value &lt; 0 or value &gt; 200:\n            raise ValueError(\"age must be between 0 and 200\")\n        self._age = value\n\n\n\n\n\n\nTip\n\n\nWe store the real value in _age. By convention, a leading _ means “internal use”."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#mini-exercise-try-the-person-class-6-minutes",
    "href": "W1_Python/D3_Modules_OOP.html#mini-exercise-try-the-person-class-6-minutes",
    "title": "Python & Tooling",
    "section": "Mini-exercise: try the Person class (6 minutes)",
    "text": "Mini-exercise: try the Person class (6 minutes)\n\nCreate a person and print:\n\np = Person(\"Sara Ahmed\", 23)\nprint(p)\nprint(p.first_name)\nprint(p.last_name)\n\nTry an invalid update:\n\np.age = 300\nCheckpoint: you get a clear error (ValueError)."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#inheritance-reuse-behavior",
    "href": "W1_Python/D3_Modules_OOP.html#inheritance-reuse-behavior",
    "title": "Python & Tooling",
    "section": "Inheritance: reuse behavior",
    "text": "Inheritance: reuse behavior\nclass Employee(Person):\n    def __init__(self, name: str, age: int, salary: float) -&gt; None:\n        super().__init__(name, age)\n        self.salary = salary\n\nclass Student(Person):\n    def __init__(self, name: str, age: int, grades: list[float]) -&gt; None:\n        super().__init__(name, age)\n        self.grades = grades\n\n    @property\n    def average(self) -&gt; float:\n        if not self.grades:\n            return 0.0\n        return sum(self.grades) / len(self.grades)\n\n\nsuper().__init__(...) calls the parent class constructor."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#multiple-inheritance-use-carefully-optional",
    "href": "W1_Python/D3_Modules_OOP.html#multiple-inheritance-use-carefully-optional",
    "title": "Python & Tooling",
    "section": "Multiple inheritance (use carefully; optional)",
    "text": "Multiple inheritance (use carefully; optional)\nclass WorkingStudent(Employee, Student):\n    def __init__(self, name, age, salary, grades):\n        self.name = name\n        self.age = age\n        self.salary = salary\n        self.grades = grades\nWhy careful?\n\nthe method resolution order (MRO) can be confusing\nprefer composition (objects inside objects) for complex cases\n\n\n\nYou can ignore multiple inheritance but you should know it exists."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#polymorphism-same-method-name-different-types",
    "href": "W1_Python/D3_Modules_OOP.html#polymorphism-same-method-name-different-types",
    "title": "Python & Tooling",
    "section": "Polymorphism: “same method name, different types”",
    "text": "Polymorphism: “same method name, different types”\nvalues = [\"abc\", [\"c\", \"b\", \"b\"], (\"a\", \"b\", \"a\")]\n\nfor value in values:\n    print(value.count(\"a\"))\nKey idea:\n\nPython cares about behavior (“does it have .count()?”)\nnot the exact class name"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#oop-in-our-project-two-options",
    "href": "W1_Python/D3_Modules_OOP.html#oop-in-our-project-two-options",
    "title": "Python & Tooling",
    "section": "OOP in our project (two options)",
    "text": "OOP in our project (two options)\nOption A (fine): keep using dicts\n{\"name\": \"age\", \"type\": \"number\", \"missing\": 2, \"mean\": 24.3}\nOption B (cleaner): use a small class\nColumnProfile(name=\"age\", inferred_type=\"number\", missing=2, ...)\nToday: we’ll implement one small class to practice."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#mini-exercise-build-columnprofile-10-minutes",
    "href": "W1_Python/D3_Modules_OOP.html#mini-exercise-build-columnprofile-10-minutes",
    "title": "Python & Tooling",
    "section": "Mini-exercise: build ColumnProfile (10 minutes)",
    "text": "Mini-exercise: build ColumnProfile (10 minutes)\nCreate src/csv_profiler/models.py:\nclass ColumnProfile:\n    def __init__(self, name: str, inferred_type: str, total: int, missing: int, unique: int):\n        ...\n\n    @property\n    def missing_pct(self) -&gt; float:\n        ...\n\n    def to_dict(self) -&gt; dict[str, str | int | float]:\n        ...\nCheckpoint: missing_pct returns a number between 0 and 100."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#solution-columnprofile",
    "href": "W1_Python/D3_Modules_OOP.html#solution-columnprofile",
    "title": "Python & Tooling",
    "section": "Solution — ColumnProfile",
    "text": "Solution — ColumnProfile\nclass ColumnProfile:\n    def __init__(self, name: str, inferred_type: str, total: int, missing: int, unique: int):\n        self.name = name\n        self.inferred_type = inferred_type\n        self.total = total\n        self.missing = missing\n        self.unique = unique\n    @property\n    def missing_pct(self) -&gt; float:\n        return 0.0 if self.total == 0 else 100.0 * self.missing / self.total\n    def to_dict(self) -&gt; dict[str, str | int | float]:\n        return {\n            \"name\": self.name,\n            \"type\": self.inferred_type,\n            \"total\": self.total,\n            \"missing\": self.missing,\n            \"missing_pct\": self.missing_pct,\n            \"unique\": self.unique,\n        }\n    def __repr__(self) -&gt; str:\n        return (\n            f\"ColumnProfile(name={self.name!r}, type={self.inferred_type!r}, \"\n            f\"missing={self.missing}, total={self.total}, unique={self.unique})\"\n        )"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#how-to-use-this-in-profiling-code",
    "href": "W1_Python/D3_Modules_OOP.html#how-to-use-this-in-profiling-code",
    "title": "Python & Tooling",
    "section": "How to use this in profiling code",
    "text": "How to use this in profiling code\nInstead of building a dict per column:\ncol = ColumnProfile(\n    name=col_name,\n    inferred_type=col_type,\n    total=n_rows,\n    missing=missing,\n    unique=unique,\n)\nWhen exporting JSON:\ncolumns = []\nfor c in column_profiles:\n    columns.append(c.to_dict())"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#recap-session-2",
    "href": "W1_Python/D3_Modules_OOP.html#recap-session-2",
    "title": "Python & Tooling",
    "section": "Recap (Session 2)",
    "text": "Recap (Session 2)\n\nA class groups data + behavior (encapsulation)\nProperties can compute values (first_name) or validate updates (age)\nInheritance reuses behavior; polymorphism is “same interface, different types”\nA small model class can make your report easier to reason about"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#session-3-objectives",
    "href": "W1_Python/D3_Modules_OOP.html#session-3-objectives",
    "title": "Python & Tooling",
    "section": "Session 3 objectives",
    "text": "Session 3 objectives\n\nInstall and run Typer\nUnderstand commands, arguments, and options\nBuild profile command for your project\nHandle errors and exit codes nicely"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#why-a-cli",
    "href": "W1_Python/D3_Modules_OOP.html#why-a-cli",
    "title": "Python & Tooling",
    "section": "Why a CLI?",
    "text": "Why a CLI?\nA CLI makes your project:\n\nreproducible (same command, same output)\ngradeable (instructor can run it)\nautomatable (later: CI / workflows)\n\n\n\nStreamlit is for humans. CLI is for humans and machines."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#install-typer",
    "href": "W1_Python/D3_Modules_OOP.html#install-typer",
    "title": "Python & Tooling",
    "section": "Install Typer",
    "text": "Install Typer\nInside your project environment:\nuv pip install typer\nQuick check:\nuv run python -c \"import typer; print(typer.__version__)\""
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#a-tiny-detour-type-hints-just-labels",
    "href": "W1_Python/D3_Modules_OOP.html#a-tiny-detour-type-hints-just-labels",
    "title": "Python & Tooling",
    "section": "A tiny detour: type hints (just labels)",
    "text": "A tiny detour: type hints (just labels)\n\nname: str is a type hint (also called an annotation).\nPython does not magically enforce it at runtime.\nTools can use it (and Typer uses it to convert CLI text into the right type).\n\nExample:\ndef add_one(x: int):\n    return x + 1\nToday we’ll mostly use: str, int, float, and Path."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#a-tiny-detour-what-does-something-mean",
    "href": "W1_Python/D3_Modules_OOP.html#a-tiny-detour-what-does-something-mean",
    "title": "Python & Tooling",
    "section": "A tiny detour: what does @something mean?",
    "text": "A tiny detour: what does @something mean?\n\nA line starting with @ is a decorator.\nIt wraps a function or registers it somewhere.\n\nTwo decorators you’ll see today:\n\n@property (makes a method act like an attribute)\n@app.command() (registers a function as a CLI command)\n\n\n\nYou don’t need to write your own decorators today — just use them."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#a-minimal-typer-app",
    "href": "W1_Python/D3_Modules_OOP.html#a-minimal-typer-app",
    "title": "Python & Tooling",
    "section": "A minimal Typer app",
    "text": "A minimal Typer app\nimport typer\n\napp = typer.Typer()\n\n@app.command()\ndef hello(name: str) -&gt; None:\n    print(f\"Hello, {name}!\")\n\n@app.command()\ndef goodbye(name: str, formal: bool = False) -&gt; None:\n    print((\"Goodbye\" if formal else \"Bye\") + f\", {name}!\")\n\nif __name__ == \"__main__\":\n    app()\nRun:\nuv run python main.py --help\nuv run python main.py hello Sara"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#commands-vs-arguments-vs-options",
    "href": "W1_Python/D3_Modules_OOP.html#commands-vs-arguments-vs-options",
    "title": "Python & Tooling",
    "section": "Commands vs arguments vs options",
    "text": "Commands vs arguments vs options\n\nCommand: a verb (profile, validate, version)\nArgument: required positional input\n\nprofile data/sample.csv\n\nOption: named + optional\n\n--out-dir outputs\n\n\n\n\n\n\n\n\nTip\n\n\nIn Typer, Python type hints become CLI parsing."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#quick-refresher-path-objects-for-file-paths",
    "href": "W1_Python/D3_Modules_OOP.html#quick-refresher-path-objects-for-file-paths",
    "title": "Python & Tooling",
    "section": "Quick refresher: Path objects for file paths",
    "text": "Quick refresher: Path objects for file paths\nInstead of passing file paths as plain strings, we often use Path objects.\nfrom pathlib import Path\n\np = Path(\"data\") / \"sample.csv\"   # `/` joins paths safely (Windows/macOS/Linux)\nprint(p.exists())\n\nout_dir = Path(\"outputs\")\nout_dir.mkdir(exist_ok=True)\n\n(out_dir / \"hello.txt\").write_text(\"hi\", encoding=\"utf-8\")\nWhy use Path?\n\nfewer bugs with slashes (\\ vs /)\nnice helpers like .exists(), .mkdir(), .read_text(), .write_text()"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#use-pathlib.path-for-file-paths",
    "href": "W1_Python/D3_Modules_OOP.html#use-pathlib.path-for-file-paths",
    "title": "Python & Tooling",
    "section": "Use pathlib.Path for file paths",
    "text": "Use pathlib.Path for file paths\nfrom pathlib import Path\nimport typer\n\n@app.command()\ndef profile(input_path: Path, out_dir: Path = Path(\"outputs\")):\n    ...\nInside the function:\nif not input_path.exists():\n    raise typer.BadParameter(\"Input file does not exist\")"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#add-helpful---help-descriptions",
    "href": "W1_Python/D3_Modules_OOP.html#add-helpful---help-descriptions",
    "title": "Python & Tooling",
    "section": "Add helpful --help descriptions",
    "text": "Add helpful --help descriptions\n@app.command(help=\"Profile a CSV file and write JSON + Markdown reports\")\ndef profile(\n    input_path: Path = typer.Argument(..., help=\"Path to input CSV\"),\n    out_dir: Path = typer.Option(Path(\"outputs\"), \"--out-dir\", help=\"Output folder\"),\n):\n    ..."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#error-handling-pattern-cli-friendly",
    "href": "W1_Python/D3_Modules_OOP.html#error-handling-pattern-cli-friendly",
    "title": "Python & Tooling",
    "section": "Error handling pattern (CLI-friendly)",
    "text": "Error handling pattern (CLI-friendly)\n@app.command()\ndef profile(input_path: Path):\n    try:\n        # work\n        ...\n    except Exception as e:\n        typer.secho(f\"Error: {e}\", fg=typer.colors.RED)\n        raise typer.Exit(code=1)\nWhy?\n\nuser sees a clear message\nyour program returns a failure code"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#mini-quiz",
    "href": "W1_Python/D3_Modules_OOP.html#mini-quiz",
    "title": "Python & Tooling",
    "section": "Mini-quiz",
    "text": "Mini-quiz\nWhat should your CLI do if the input file doesn’t exist?\n\nsilently create it\ncrash with a long stack trace\nprint a clear message and exit with non-zero code\n\n\nPreferred: C"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#add-multiple-commands-optional-today",
    "href": "W1_Python/D3_Modules_OOP.html#add-multiple-commands-optional-today",
    "title": "Python & Tooling",
    "section": "Add multiple commands (optional today)",
    "text": "Add multiple commands (optional today)\n@app.command()\ndef version():\n    \"\"\"Print version info.\"\"\"\n    print(\"csv-profiler 0.1\")\n\n@app.command()\ndef profile(...):\n    ...\nRun:\n... version\n... profile data/sample.csv"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#mini-exercise-sketch-your-profile-command-10-minutes",
    "href": "W1_Python/D3_Modules_OOP.html#mini-exercise-sketch-your-profile-command-10-minutes",
    "title": "Python & Tooling",
    "section": "Mini-exercise: sketch your profile command (10 minutes)",
    "text": "Mini-exercise: sketch your profile command (10 minutes)\nCreate src/csv_profiler/cli.py with:\n\napp = typer.Typer()\nprofile command:\n\nargument: input_path\noption: --out-dir\noption: --report-name (default report)\n\n\nCheckpoint: --help shows your options."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#solution-cli-skeleton",
    "href": "W1_Python/D3_Modules_OOP.html#solution-cli-skeleton",
    "title": "Python & Tooling",
    "section": "Solution — CLI skeleton",
    "text": "Solution — CLI skeleton\nfrom pathlib import Path\nimport typer\n\napp = typer.Typer()\n\n@app.command(help=\"Profile a CSV file and write JSON + Markdown\")\ndef profile(\n    input_path: Path = typer.Argument(..., help=\"Input CSV file\"),\n    out_dir: Path = typer.Option(Path(\"outputs\"), \"--out-dir\", help=\"Output folder\"),\n    report_name: str = typer.Option(\"report\", \"--report-name\", help=\"Base name for outputs\"),\n):\n    # implementation comes in hands-on\n    typer.echo(f\"Input: {input_path}\")\n    typer.echo(f\"Out:   {out_dir}\")\n    typer.echo(f\"Name:  {report_name}\")\n\nif __name__ == \"__main__\":\n    app()"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#run-the-cli-with--m",
    "href": "W1_Python/D3_Modules_OOP.html#run-the-cli-with--m",
    "title": "Python & Tooling",
    "section": "Run the CLI (with -m)",
    "text": "Run the CLI (with -m)\nFrom your project root:\nPYTHONPATH=src uv run python -m csv_profiler.cli --help\nTry:\nPYTHONPATH=src uv run python -m csv_profiler.cli profile data/sample.csv"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#recap-session-3",
    "href": "W1_Python/D3_Modules_OOP.html#recap-session-3",
    "title": "Python & Tooling",
    "section": "Recap (Session 3)",
    "text": "Recap (Session 3)\n\nTyper turns type hints into a CLI\nGood CLIs have:\n\nhelpful --help\nclear error messages\nnon-zero exit codes on failure\n\nNext: wire your CLI to your profiler library"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#csv-profiler-part-3-package-cli",
    "href": "W1_Python/D3_Modules_OOP.html#csv-profiler-part-3-package-cli",
    "title": "Python & Tooling",
    "section": "CSV Profiler — Part 3 (Package + CLI)",
    "text": "CSV Profiler — Part 3 (Package + CLI)\nGoal: Run one command that generates:\n\noutputs/&lt;name&gt;.json\noutputs/&lt;name&gt;.md\n\nYou need:\n\nyour Day 2 profiler code\nTyper installed\n\nDeliverable: CLI works on data/sample.csv.\n\nSay: “We will do this in small tasks. Don’t jump ahead. Finish each checkpoint.”\nDo: Live-code Task 1 quickly, then let students repeat.\nTimebox: 2 hours total."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#hands-on-checklist",
    "href": "W1_Python/D3_Modules_OOP.html#hands-on-checklist",
    "title": "Python & Tooling",
    "section": "Hands-on checklist",
    "text": "Hands-on checklist\nBy the end, you can run:\nPYTHONPATH=src \\\n    uv run python -m csv_profiler.cli \\\n    profile data/sample.csv \\\n    --out-dir outputs \\\n    --report-name report\nAnd you get:\n\noutputs/report.json\noutputs/report.md"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#task-1-create-the-package-skeleton-10-minutes",
    "href": "W1_Python/D3_Modules_OOP.html#task-1-create-the-package-skeleton-10-minutes",
    "title": "Python & Tooling",
    "section": "Task 1 — Create the package skeleton (10 minutes)",
    "text": "Task 1 — Create the package skeleton (10 minutes)\n\nCreate folders:\n\nmkdir -p src/csv_profiler\n\nCreate empty init:\n\ntouch src/csv_profiler/__init__.py\n\nCreate empty modules:\n\nio.py\nprofiling.py\nrender.py\ncli.py\n\n\nCheckpoint: the folder tree matches the target structure."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#solution-expected-tree",
    "href": "W1_Python/D3_Modules_OOP.html#solution-expected-tree",
    "title": "Python & Tooling",
    "section": "Solution — expected tree",
    "text": "Solution — expected tree\nsrc/\n└── csv_profiler/\n    ├── __init__.py\n    ├── io.py\n    ├── profiling.py\n    ├── render.py\n    └── cli.py\n\n\n\n\n\n\nTip\n\n\nWindows users: if you don’t have touch, create files from VS Code."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#csv-reminder-csv.dictreader-2-minutes",
    "href": "W1_Python/D3_Modules_OOP.html#csv-reminder-csv.dictreader-2-minutes",
    "title": "Python & Tooling",
    "section": "CSV reminder: csv.DictReader (2 minutes)",
    "text": "CSV reminder: csv.DictReader (2 minutes)\n\ncsv.DictReader reads a CSV file and gives you one dictionary per row.\nThe dictionary keys come from the header row.\n\nExample (prints the first row dict):\nimport csv\nfrom pathlib import Path\n\npath = Path(\"data/sample.csv\")\nwith path.open(\"r\", encoding=\"utf-8\") as f:\n    reader = csv.DictReader(f)\n    for row in reader:\n        print(row)  # e.g. {'age': '23', 'name': 'Sara'}\n        break"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#task-2-move-csv-reading-into-io.py-15-minutes",
    "href": "W1_Python/D3_Modules_OOP.html#task-2-move-csv-reading-into-io.py-15-minutes",
    "title": "Python & Tooling",
    "section": "Task 2 — Move CSV reading into io.py (15 minutes)",
    "text": "Task 2 — Move CSV reading into io.py (15 minutes)\nCreate src/csv_profiler/io.py:\n\nfunction: read_csv_rows(path: Path) -&gt; list[dict[str, str]]\nreturns: a list of row dictionaries\nuse csv.DictReader\nraise a clear error if:\n\nfile not found\nCSV has no rows\n\n\nCheckpoint: you can import and call it from a scratch script."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#solution-read_csv_rows",
    "href": "W1_Python/D3_Modules_OOP.html#solution-read_csv_rows",
    "title": "Python & Tooling",
    "section": "Solution — read_csv_rows",
    "text": "Solution — read_csv_rows\nimport csv\nfrom pathlib import Path\n\n\ndef read_csv_rows(path: Path) -&gt; list[dict[str, str]]:\n    \"\"\"Read a CSV file and return a list of row dictionaries.\"\"\"\n    if not path.exists():\n        raise FileNotFoundError(f\"CSV not found: {path}\")\n\n    with path.open(\"r\", encoding=\"utf-8\") as f:\n        reader = csv.DictReader(f)\n        rows = list(reader)\n\n    if not rows:\n        raise ValueError(\"CSV has no data rows\")\n    return rows"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#task-3-move-profiling-logic-into-profiling.py-25-minutes",
    "href": "W1_Python/D3_Modules_OOP.html#task-3-move-profiling-logic-into-profiling.py-25-minutes",
    "title": "Python & Tooling",
    "section": "Task 3 — Move profiling logic into profiling.py (25 minutes)",
    "text": "Task 3 — Move profiling logic into profiling.py (25 minutes)\nIn src/csv_profiler/profiling.py:\n\nmove helpers: is_missing, try_float, infer_type\ncreate: profile_rows(rows: list[dict[str, str]]) -&gt; dict\nreturns: a report dictionary (JSON-serializable)\n\nReport keys (minimum):\n\nn_rows\nn_cols\ncolumns (list)\n\nCheckpoint: profile_rows(rows) returns a JSON-serializable dict."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#solution-profiling-skeleton",
    "href": "W1_Python/D3_Modules_OOP.html#solution-profiling-skeleton",
    "title": "Python & Tooling",
    "section": "Solution — profiling skeleton",
    "text": "Solution — profiling skeleton\ndef is_missing(value: str | None) -&gt; bool:\n    if value is None:\n        return True\n\n    cleaned = value.strip().casefold()\n    return cleaned in {\"\", \"na\", \"n/a\", \"null\", \"none\", \"nan\"}\n\ndef try_float(value: str) -&gt; float | None:\n    try:\n        return float(value)\n    except ValueError:\n        return None\n\ndef infer_type(values: list[str]) -&gt; str:\n    usable = [v for v in values if not is_missing(v)]\n    if not usable:\n        return \"text\"\n\n    for v in usable:\n        if try_float(v) is None:\n            return \"text\"\n\n    return \"number\""
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#tiny-tool-set-for-unique-values",
    "href": "W1_Python/D3_Modules_OOP.html#tiny-tool-set-for-unique-values",
    "title": "Python & Tooling",
    "section": "Tiny tool: set() for unique values",
    "text": "Tiny tool: set() for unique values\nA set keeps only unique items (duplicates are removed).\nvalues = [\"a\", \"b\", \"a\"]\nunique_values = set(values)\n\nprint(unique_values)       # {'a', 'b'} (order doesn't matter)\nprint(len(unique_values))  # 2\nWe’ll use len(set(...)) to count unique non-missing values in a column."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#solution-profile_rows-baseline",
    "href": "W1_Python/D3_Modules_OOP.html#solution-profile_rows-baseline",
    "title": "Python & Tooling",
    "section": "Solution — profile_rows (baseline)",
    "text": "Solution — profile_rows (baseline)\ndef profile_rows(rows: list[dict[str, str]]) -&gt; dict:\n    n_rows, columns = len(rows), list(rows[0].keys())\n    col_profiles = []\n    for col in columns:\n        values = [r.get(col, \"\") for r in rows]\n        usable = [v for v in values if not is_missing(v)]\n        missing = len(values) - len(usable)\n        inferred = infer_type(values)\n        unique = len(set(usable))\n        profile = {\n            \"name\": col,\n            \"type\": inferred,\n            \"missing\": missing,\n            \"missing_pct\": 100.0 * missing / n_rows if n_rows else 0.0,\n            \"unique\": unique,\n        }\n        if inferred == \"number\":\n            nums = [try_float(v) for v in usable]\n            nums = [x for x in nums if x is not None]\n            if nums:\n                profile.update({\"min\": min(nums), \"max\": max(nums), \"mean\": sum(nums) / len(nums)})\n        col_profiles.append(profile)\n    return {\"n_rows\": n_rows, \"n_cols\": len(columns), \"columns\": col_profiles}\n\n\nYou can later swap dicts for ColumnProfile objects."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#task-4-render-markdown-in-render.py-20-minutes",
    "href": "W1_Python/D3_Modules_OOP.html#task-4-render-markdown-in-render.py-20-minutes",
    "title": "Python & Tooling",
    "section": "Task 4 — Render Markdown in render.py (20 minutes)",
    "text": "Task 4 — Render Markdown in render.py (20 minutes)\nCreate src/csv_profiler/render.py:\n\nfunction: render_markdown(report: dict) -&gt; str\ninclude:\n\ntitle\ndataset summary\na table of columns\n\n\nCheckpoint: render_markdown(report) returns a multi-line Markdown string."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#solution-render_markdown-simple",
    "href": "W1_Python/D3_Modules_OOP.html#solution-render_markdown-simple",
    "title": "Python & Tooling",
    "section": "Solution — render_markdown (simple)",
    "text": "Solution — render_markdown (simple)\nfrom datetime import datetime\n\ndef render_markdown(report: dict) -&gt; str:\n    lines: list[str] = []\n\n    lines.append(f\"# CSV Profiling Report\\n\")\n    lines.append(f\"Generated: {datetime.now().isoformat(timespec='seconds')}\\n\")\n\n    lines.append(\"## Summary\\n\")\n    lines.append(f\"- Rows: **{report['n_rows']}**\")\n    lines.append(f\"- Columns: **{report['n_cols']}**\\n\")\n\n    lines.append(\"## Columns\\n\")\n    lines.append(\"| name | type | missing | missing_pct | unique |\")\n    lines.append(\"|---|---:|---:|---:|---:|\")\n    lines.extend([\n        f\"| {c['name']} | {c['type']} | {c['missing']} | {c['missing_pct']:.1f}% | {c['unique']} |\"\n        for c in report[\"columns\"]\n    ])\n\n    lines.append(\"\\n## Notes\\n\")\n    lines.append(\"- Missing values are: `''`, `na`, `n/a`, `null`, `none`, `nan` (case-insensitive)\")\n\n    return \"\\n\".join(lines)"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#task-5-wire-everything-in-cli.py-30-minutes",
    "href": "W1_Python/D3_Modules_OOP.html#task-5-wire-everything-in-cli.py-30-minutes",
    "title": "Python & Tooling",
    "section": "Task 5 — Wire everything in cli.py (30 minutes)",
    "text": "Task 5 — Wire everything in cli.py (30 minutes)\nIn src/csv_profiler/cli.py:\n\nimplement profile command\ncall:\n\nread_csv_rows()\nprofile_rows()\nrender_markdown()\n\nwrite outputs to out_dir:\n\n&lt;report_name&gt;.json\n&lt;report_name&gt;.md\n\n\nCheckpoint: running the command creates both files."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#solution-cli.py-working-version",
    "href": "W1_Python/D3_Modules_OOP.html#solution-cli.py-working-version",
    "title": "Python & Tooling",
    "section": "Solution — cli.py (working version)",
    "text": "Solution — cli.py (working version)\nimport json\nimport time\nimport typer\nfrom pathlib import Path\n\nfrom csv_profiler.io import read_csv_rows\nfrom csv_profiler.profiling import profile_rows\nfrom csv_profiler.render import render_markdown\n\napp = typer.Typer()\n\n@app.command(help=\"Profile a CSV file and write JSON + Markdown\")\ndef profile(\n    input_path: Path = typer.Argument(..., help=\"Input CSV file\"),\n    out_dir: Path = typer.Option(Path(\"outputs\"), \"--out-dir\", help=\"Output folder\"),\n    report_name: str = typer.Option(\"report\", \"--report-name\", help=\"Base name for outputs\"),\n    preview: bool = typer.Option(False, \"--preview\", help=\"Print a short summary\"),\n):\n    ...  # (see next slide for this implementation)\n\nif __name__ == \"__main__\":\n    app()\n\n\nThe actual implementation of this function is in the next slide."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#solution-cli.py-working-version-1",
    "href": "W1_Python/D3_Modules_OOP.html#solution-cli.py-working-version-1",
    "title": "Python & Tooling",
    "section": "Solution — cli.py (working version)",
    "text": "Solution — cli.py (working version)\ntry:\n    t0 = time.perf_counter_ns()\n    rows = read_csv_rows(input_path)\n    report = profile_rows(rows)\n    t1 = time.perf_counter_ns()\n    report[\"timing_ms\"] = (t1 - t0) / 1_000_000\n\n    out_dir.mkdir(parents=True, exist_ok=True)\n\n    json_path = out_dir / f\"{report_name}.json\"\n    json_path.write_text(json.dumps(report, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n    typer.secho(f\"Wrote {json_path}\", fg=typer.colors.GREEN)\n\n    md_path = out_dir / f\"{report_name}.md\"\n    md_path.write_text(render_markdown(report), encoding=\"utf-8\")\n    typer.secho(f\"Wrote {md_path}\", fg=typer.colors.GREEN)\n\n    if preview:\n        typer.echo(f\"Rows: {report['n_rows']} | Cols: {report['n_cols']} | {report['timing_ms']:.2f}ms\")\n\nexcept Exception as e:\n    typer.secho(f\"Error: {e}\", fg=typer.colors.RED)\n    raise typer.Exit(code=1)\n\n\nThis is the implementation of profile()."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#task-6-run-verify-10-minutes",
    "href": "W1_Python/D3_Modules_OOP.html#task-6-run-verify-10-minutes",
    "title": "Python & Tooling",
    "section": "Task 6 — Run + verify (10 minutes)",
    "text": "Task 6 — Run + verify (10 minutes)\nRun:\nPYTHONPATH=src uv run \\\n    python -m csv_profiler.cli \\\n    profile data/sample.csv --preview\nThen open:\n\noutputs/report.json\noutputs/report.md\n\nCheckpoint: timing_ms exists in JSON and Markdown table lists all columns\n\n\n\n\n\n\nTip\n\n\nThe backslash \\ at the end of each line means that the command didn’t end here and it will continue on the next line. The above command is the same as the following:\nPYTHONPATH=src uv run python -m csv_profiler.cli profile data/sample.csv --preview"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#troubleshooting-common-issues",
    "href": "W1_Python/D3_Modules_OOP.html#troubleshooting-common-issues",
    "title": "Python & Tooling",
    "section": "Troubleshooting: common issues",
    "text": "Troubleshooting: common issues\nIf you see ModuleNotFoundError: csv_profiler:\n\nmake sure you are in the project root\nensure PYTHONPATH=src\nensure src/csv_profiler/__init__.py exists\n\nIf you see encoding errors:\n\ntry encoding=\"utf-8-sig\" for reading\nor confirm the CSV is UTF-8"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#stretch-tasks-if-you-finish-early",
    "href": "W1_Python/D3_Modules_OOP.html#stretch-tasks-if-you-finish-early",
    "title": "Python & Tooling",
    "section": "Stretch tasks (if you finish early)",
    "text": "Stretch tasks (if you finish early)\n\nAdd --out-dir default to a new folder per run:\n\noutputs/2025-12-16_1930/\n\nAdd a --fail-on-missing-pct 30 option:\n\nexit with code 2 if any column exceeds threshold\n\nAdd version command"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#recap-hands-on",
    "href": "W1_Python/D3_Modules_OOP.html#recap-hands-on",
    "title": "Python & Tooling",
    "section": "Recap (Hands-on)",
    "text": "Recap (Hands-on)\nYou now have:\n\na real Python package layout\na CLI that reads CSV and writes JSON + Markdown\ntiming + better error handling\n\nTomorrow: Streamlit GUI will reuse the same library."
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#exit-ticket",
    "href": "W1_Python/D3_Modules_OOP.html#exit-ticket",
    "title": "Python & Tooling",
    "section": "Exit Ticket",
    "text": "Exit Ticket\nIn 1–2 sentences:\nWhat caused your biggest slowdown today: imports, refactoring, or CLI wiring?"
  },
  {
    "objectID": "W1_Python/D3_Modules_OOP.html#what-to-do-after-class-day-3-assignment",
    "href": "W1_Python/D3_Modules_OOP.html#what-to-do-after-class-day-3-assignment",
    "title": "Python & Tooling",
    "section": "What to do after class (Day 3 assignment)",
    "text": "What to do after class (Day 3 assignment)\nDue: before Day 4 starts (Wed, 17 Dec 2025)\n\nMake --help look professional:\n\nclear descriptions\nsensible defaults\n\nAdd one more CLI option:\n\n--delimiter (even if you keep , as default)\n\nAdd one more section to Markdown:\n\nshow the slowest/fastest column to process (your choice)\n\n\nDeliverable: updated project folder with working CLI.\n\n\n\n\n\n\nTip\n\n\nKeep your changes small and commit-worthy. Even before Day 5, practicing commits helps."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#todays-flow",
    "href": "W1_Python/D5_Git_Project.html#todays-flow",
    "title": "Python & Tooling",
    "section": "Today’s Flow",
    "text": "Today’s Flow\n\nSession 1 (60m): Git essentials (trusted commit history)\nAsr Prayer (20m)\nSession 2 (60m): GitHub (remote, push, README)\nMaghrib Prayer (20m)\nSession 3 (60m): Polish + submission readiness (runbook, checklist, pitfalls)\nIsha Prayer (20m)\nHands-on (120m): Week 1 Project (due 11:59pm Thu)"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#learning-objectives",
    "href": "W1_Python/D5_Git_Project.html#learning-objectives",
    "title": "Python & Tooling",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of today, you can:\n\nExplain Git’s mental model: working tree → staging → commits\nUse core commands:\n\nstatus, add, commit, log, diff\n\nUse “safe undo” tools:\n\nrestore, revert (and when to avoid reset)\n\nCreate a GitHub repo and:\n\nadd origin, push, pull\n\nWrite a README that lets anyone run:\n\nCLI profiling → JSON + Markdown\nStreamlit GUI → export JSON + Markdown\n\nSubmit your Week 1 project by tonight, 11:59pm"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#week-1-rules-reminder-assessment-week",
    "href": "W1_Python/D5_Git_Project.html#week-1-rules-reminder-assessment-week",
    "title": "Python & Tooling",
    "section": "Week 1 rules reminder (assessment week)",
    "text": "Week 1 rules reminder (assessment week)\n\n\n\n\n\n\nWarning\n\n\nNo Generative AI for coding this week.\nAllowed: - clarifying questions (concepts, error meaning, docs navigation) - official documentation - your notes + course slides\nNot allowed: - “write this code for me” - “fix my code” with pasted solutions - copying generated code into your repo\n\n\n\n\nSay: This is about learning the muscles (debugging, reading errors, using docs). Next weeks you can move faster — but Week 1 is foundational.\nAsk: “What is a clarifying question you could ask today?”"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#certification-policy-so-you-plan-ahead",
    "href": "W1_Python/D5_Git_Project.html#certification-policy-so-you-plan-ahead",
    "title": "Python & Tooling",
    "section": "Certification policy (so you plan ahead)",
    "text": "Certification policy (so you plan ahead)\n\nCertificate of completion: end-of-bootcamp grade ≥ 70%\nCertificate of attendance: not passing, but &lt; 4 excused absences\n\n\n\nWeek 1 submission quality helps a lot later (capstone + job readiness)."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#what-you-submit-tonight-week-1-deliverable",
    "href": "W1_Python/D5_Git_Project.html#what-you-submit-tonight-week-1-deliverable",
    "title": "Python & Tooling",
    "section": "What you submit tonight (Week 1 deliverable)",
    "text": "What you submit tonight (Week 1 deliverable)\nA public (or instructor-accessible) GitHub repository that contains:\n\nYour csv_profiler/ package (either src/csv_profiler/ or csv_profiler/ at repo root)\nA working CLI that outputs:\n\nreport.json\nreport.md\n\nA working Streamlit app that:\n\nloads a CSV\npreviews profiling results\nexports JSON + Markdown\n\nA README with “how to run” instructions\nClean Git hygiene:\n\n.gitignore\nreasonable commit history (not 1 giant commit)"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#quick-refresher-running-the-project-and-pythonpath",
    "href": "W1_Python/D5_Git_Project.html#quick-refresher-running-the-project-and-pythonpath",
    "title": "Python & Tooling",
    "section": "Quick refresher: running the project (and PYTHONPATH)",
    "text": "Quick refresher: running the project (and PYTHONPATH)\nToday you will run two entry points:\n\nCLI (command line): creates report.json + report.md\nStreamlit app (browser UI): upload CSV + export reports\n\nSetup commands you’ll see\n\nuv venv -p 3.11 creates a project virtual environment in .venv/\nuv pip install -r requirements.txt installs the packages listed in requirements.txt"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#quick-refresher-running-the-project-and-pythonpath-1",
    "href": "W1_Python/D5_Git_Project.html#quick-refresher-running-the-project-and-pythonpath-1",
    "title": "Python & Tooling",
    "section": "Quick refresher: running the project (and PYTHONPATH)",
    "text": "Quick refresher: running the project (and PYTHONPATH)\nToday you will run two entry points:\n\nCLI (command line): creates report.json + report.md\nStreamlit app (browser UI): upload CSV + export reports\n\nTwo tiny concepts\n\npython -m some_package.some_module means: run that module as a program\nIf your code lives in src/, Python won’t find it automatically → we temporarily set PYTHONPATH=src\n\n\n\n\n\n\n\nTip\n\n\nIf you do not have a src/ folder (your csv_profiler/ folder is at repo root), you can skip PYTHONPATH."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#quick-refresher-running-the-project-and-pythonpath-2",
    "href": "W1_Python/D5_Git_Project.html#quick-refresher-running-the-project-and-pythonpath-2",
    "title": "Python & Tooling",
    "section": "Quick refresher: running the project (and PYTHONPATH)",
    "text": "Quick refresher: running the project (and PYTHONPATH)\nToday you will run two entry points:\n\nCLI (command line): creates report.json + report.md\nStreamlit app (browser UI): upload CSV + export reports\n\nSet PYTHONPATH (only needed for src/ layout)\nMac/Linux (bash/zsh)\nexport PYTHONPATH=src\nWindows PowerShell\n$env:PYTHONPATH=\"src\"\n\n\nWith uv, you usually don’t need to “activate” the venv — uv run ... will use the project’s .venv automatically."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#what-done-looks-like-acceptance-test",
    "href": "W1_Python/D5_Git_Project.html#what-done-looks-like-acceptance-test",
    "title": "Python & Tooling",
    "section": "What “done” looks like (acceptance test)",
    "text": "What “done” looks like (acceptance test)\nFrom the repo root:\nMac/Linux (bash/zsh)\nuv venv -p 3.11\nuv pip install -r requirements.txt\n\nexport PYTHONPATH=src # Only if you have a src/ folder\n\nuv run python -m csv_profiler.cli profile data/sample.csv --out-dir outputs\nuv run streamlit run app.py\nWindows PowerShell\nuv venv -p 3.11\nuv pip install -r requirements.txt\n\n$env:PYTHONPATH=\"src\" # Only if you have a src/ folder\n\nuv run python -m csv_profiler.cli profile data/sample.csv --out-dir outputs\nuv run streamlit run app.py\n\n\n\n\n\n\nTip\n\n\nIf you do not have a src/ folder, skip the PYTHONPATH lines.\n\n\n\n\nSay: We grade with a “fresh clone” mindset. If your README works, you win."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#why-git-exists-in-one-slide",
    "href": "W1_Python/D5_Git_Project.html#why-git-exists-in-one-slide",
    "title": "Python & Tooling",
    "section": "Why Git exists (in one slide)",
    "text": "Why Git exists (in one slide)\nGit gives you:\n\nA timeline of your work (commits)\nA safe way to experiment (branches)\nA way to collaborate without overwriting (merges)\nA permanent record you can show employers (GitHub)\n\n\nAsk: “What’s worse: losing code, or losing why you wrote it?”"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#git-mental-model",
    "href": "W1_Python/D5_Git_Project.html#git-mental-model",
    "title": "Python & Tooling",
    "section": "Git mental model",
    "text": "Git mental model\n\n\nThree places\n\nWorking tree\n\nfiles on your disk\n\nStaging area\n\n“what will be included next”\n\nRepository\n\ncommits (history)\n\n\n\nMini-diagram\nedit files\n  ↓\ngit add (stage)\n  ↓\ngit commit (snapshot)\n  ↓\ngit log (history)\n\nOne rule: only committed work is “saved”."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#quick-check",
    "href": "W1_Python/D5_Git_Project.html#quick-check",
    "title": "Python & Tooling",
    "section": "Quick check",
    "text": "Quick check\nQuestion: If you edited app.py but didn’t commit it… is it “saved”?\n\nAnswer: It’s only on your machine. Git history doesn’t know it yet.\n\nSay: Git is not magic backup until you commit."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#before-you-start-identity-one-time-setup",
    "href": "W1_Python/D5_Git_Project.html#before-you-start-identity-one-time-setup",
    "title": "Python & Tooling",
    "section": "Before you start: identity (one-time setup)",
    "text": "Before you start: identity (one-time setup)\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"you@example.com\"\ngit config --global init.defaultBranch main\nCheck:\ngit config --list\n\nDo: Show where these settings live (global config). Warn: email should match GitHub email if possible."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#start-tracking-a-project",
    "href": "W1_Python/D5_Git_Project.html#start-tracking-a-project",
    "title": "Python & Tooling",
    "section": "Start tracking a project",
    "text": "Start tracking a project\nFrom your repo root:\ngit init\ngit status\nYou should see:\n\n“On branch main” (or “master” → we will rename to main)\n“No commits yet”\nuntracked files"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#file-states-the-words-youll-see",
    "href": "W1_Python/D5_Git_Project.html#file-states-the-words-youll-see",
    "title": "Python & Tooling",
    "section": "File states (the words you’ll see)",
    "text": "File states (the words you’ll see)\n\nUntracked → Git doesn’t know it exists\nModified → changed since last commit\nStaged → will be included in the next commit\nCommitted → safely in history"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#git-status-is-your-dashboard",
    "href": "W1_Python/D5_Git_Project.html#git-status-is-your-dashboard",
    "title": "Python & Tooling",
    "section": "git status is your “dashboard”",
    "text": "git status is your “dashboard”\nRun it constantly:\ngit status\nPractice reading:\n\nwhat branch you’re on\nwhat is staged\nwhat is modified\nwhat is untracked\n\n\nSay: If you’re confused, run git status first."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#staging-pick-what-goes-into-the-next-snapshot",
    "href": "W1_Python/D5_Git_Project.html#staging-pick-what-goes-into-the-next-snapshot",
    "title": "Python & Tooling",
    "section": "Staging: pick what goes into the next snapshot",
    "text": "Staging: pick what goes into the next snapshot\ngit add README.md\ngit add src/csv_profiler/cli.py\nOr stage everything:\ngit add .\n\n\nPrefer “small commits”: stage only what belongs together."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#view-changes-before-you-commit",
    "href": "W1_Python/D5_Git_Project.html#view-changes-before-you-commit",
    "title": "Python & Tooling",
    "section": "View changes before you commit",
    "text": "View changes before you commit\ngit diff\nView staged changes:\ngit diff --staged\n\nAsk: “Why is git diff a superpower?”"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#commit-messages-simple-rule",
    "href": "W1_Python/D5_Git_Project.html#commit-messages-simple-rule",
    "title": "Python & Tooling",
    "section": "Commit messages (simple rule)",
    "text": "Commit messages (simple rule)\nA good commit message:\n\nis short (≤ 50 chars)\nstarts with a verb\ndescribes the change\n\nExamples:\n\nAdd Typer CLI entrypoint\nRender Markdown report\nFix numeric parsing for empty strings"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#gitignore-protect-your-repo",
    "href": "W1_Python/D5_Git_Project.html#gitignore-protect-your-repo",
    "title": "Python & Tooling",
    "section": ".gitignore (protect your repo)",
    "text": ".gitignore (protect your repo)\nYou usually should NOT commit:\n\n.venv/ (virtual env)\n__pycache__/\noutputs/ (generated reports)\n.env (secrets)\n\nIf you commit these, your repo becomes: - huge - noisy - sometimes unsafe"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#example-.gitignore-for-this-project",
    "href": "W1_Python/D5_Git_Project.html#example-.gitignore-for-this-project",
    "title": "Python & Tooling",
    "section": "Example .gitignore for this project",
    "text": "Example .gitignore for this project\n# Python\n__pycache__/\n*.py[cod]\n\n# Virtual env\n.venv/\n\n# Local outputs\noutputs/\n*.log\n\n# OS junk\n.DS_Store\nThumbs.db\n\n# Secrets (later weeks)\n.env\n\n\n\n\n\n\nTip\n\n\nSometimes Python creates __pycache__/ and *.py[cod] in your local machine to help it run your code faster. These files are specific to your machine, so keep them local and don’t commit them.\n\n\n\n\n\n\n\n\n\nNote\n\n\n*.py[cod] meens any file that has the extension *.pyc, *.pyo, or *.pyd.\n\n\n\n\nSay: Generated files are okay locally — but keep Git history clean."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#task-create-.gitignore-8-minutes",
    "href": "W1_Python/D5_Git_Project.html#task-create-.gitignore-8-minutes",
    "title": "Python & Tooling",
    "section": "Task — Create .gitignore (8 minutes)",
    "text": "Task — Create .gitignore (8 minutes)\n\nCreate a .gitignore file in the repo root\nAdd rules for:\n\n.venv/\n__pycache__/\noutputs/\n\nVerify:\n\ngit status\nCheckpoint: git status no longer lists .venv/ contents."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#solution-.gitignore",
    "href": "W1_Python/D5_Git_Project.html#solution-.gitignore",
    "title": "Python & Tooling",
    "section": "Solution — .gitignore",
    "text": "Solution — .gitignore\nCreate .gitignore:\n__pycache__/\n.venv/\noutputs/\n.env\n.DS_Store\nThumbs.db\nThen:\ngit add .gitignore\ngit commit -m \"Add .gitignore\""
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#history-what-commits-look-like",
    "href": "W1_Python/D5_Git_Project.html#history-what-commits-look-like",
    "title": "Python & Tooling",
    "section": "History: what commits look like",
    "text": "History: what commits look like\ngit log\nA compact view:\ngit log --oneline --decorate --graph --all\n\nDo: Explain: each line is a snapshot."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#safe-undo-dont-panic",
    "href": "W1_Python/D5_Git_Project.html#safe-undo-dont-panic",
    "title": "Python & Tooling",
    "section": "Safe undo (don’t panic)",
    "text": "Safe undo (don’t panic)\nUndo unstaged changes (restore file from last commit):\ngit restore app.py\nUnstage a staged file:\ngit restore --staged app.py\n\n\n\n\n\n\nWarning\n\n\nAvoid git reset --hard unless you really know what you’re doing."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#undoing-commits-revert-vs-reset",
    "href": "W1_Python/D5_Git_Project.html#undoing-commits-revert-vs-reset",
    "title": "Python & Tooling",
    "section": "Undoing commits: revert vs reset",
    "text": "Undoing commits: revert vs reset\n\n\n\n\n\n\n\n\n\nTool\nWhat it does\nSafe after pushing?\nUse it when\n\n\n\n\ngit revert &lt;hash&gt;\nCreates a new commit that undoes changes\n✅\nYou already pushed a bad commit\n\n\ngit reset --hard &lt;hash&gt;\nMoves branch pointer + rewrites history\n❌\nYou have not pushed yet\n\n\n\n\n\nDefault choice on shared branches: revert."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#inspect-an-old-version-without-changing-your-files",
    "href": "W1_Python/D5_Git_Project.html#inspect-an-old-version-without-changing-your-files",
    "title": "Python & Tooling",
    "section": "Inspect an old version (without changing your files)",
    "text": "Inspect an old version (without changing your files)\nShow a file at a previous commit:\ngit show &lt;hash&gt;:src/csv_profiler/cli.py\nShow details of a commit:\ngit show &lt;hash&gt;"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#mini-quiz",
    "href": "W1_Python/D5_Git_Project.html#mini-quiz",
    "title": "Python & Tooling",
    "section": "Mini-quiz",
    "text": "Mini-quiz\nYou pushed a commit that breaks the CLI. You want to undo it safely.\nA. git reset --hard HEAD~1\nB. git revert HEAD\n\nAnswer: B (git revert) on shared branches."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#i-committed-the-wrong-thing-common-fixes",
    "href": "W1_Python/D5_Git_Project.html#i-committed-the-wrong-thing-common-fixes",
    "title": "Python & Tooling",
    "section": "“I committed the wrong thing” (common fixes)",
    "text": "“I committed the wrong thing” (common fixes)\nRename last commit message (no new content):\ngit commit --amend -m \"Better message\"\nAdd a missed file to the last commit:\ngit add missed_file.py\ngit commit --amend --no-edit\nStop tracking a file without deleting it (useful after fixing .gitignore):\ngit rm --cached path/to/file\n# folders need -r:\ngit rm -r --cached outputs/\ngit commit -m \"Stop tracking generated files\"\n\n\n\n\n\n\nWarning\n\n\nOnly amend commits that you have not pushed yet.\nBe careful: git rm without --cached deletes the file."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#branches-why-you-should-care",
    "href": "W1_Python/D5_Git_Project.html#branches-why-you-should-care",
    "title": "Python & Tooling",
    "section": "Branches (why you should care)",
    "text": "Branches (why you should care)\nA branch is:\n\na named pointer to a commit\na way to isolate work\n\nCommon workflow:\n\nmain: stable\nfeature/...: new work"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#branch-naming-make-it-readable",
    "href": "W1_Python/D5_Git_Project.html#branch-naming-make-it-readable",
    "title": "Python & Tooling",
    "section": "Branch naming (make it readable)",
    "text": "Branch naming (make it readable)\nGood patterns:\n\nfeature/&lt;short-name&gt;\nfix/&lt;short-name&gt;\ndocs/&lt;short-name&gt;\n\nAvoid:\n\ntest\nfinal_final2\nwip\n\n\n\nBranches are communication."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#create-switch-branches-git-switch",
    "href": "W1_Python/D5_Git_Project.html#create-switch-branches-git-switch",
    "title": "Python & Tooling",
    "section": "Create / switch branches: git switch",
    "text": "Create / switch branches: git switch\nYou will see two actions:\n\ncreate a new branch (for new work)\nswitch between branches (to see different versions of your files)\n\ngit switch -c feature/readme   # create + switch\ngit switch main                # switch back\n\n\n\n\n\n\nTip\n\n\nIf your Git is old and doesn’t support git switch, use:\ngit checkout -b feature/readme\ngit checkout main"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#optional-git-stash-park-work-temporarily",
    "href": "W1_Python/D5_Git_Project.html#optional-git-stash-park-work-temporarily",
    "title": "Python & Tooling",
    "section": "Optional: git stash (park work temporarily)",
    "text": "Optional: git stash (park work temporarily)\nWhen you must switch context but you’re not ready to commit:\ngit stash -u\ngit switch main\n# ...\ngit stash pop\n\n\n\n\n\n\nWarning\n\n\nUse stash short-term. Prefer commits for real progress."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#mini-task-make-a-feature-branch-7-minutes",
    "href": "W1_Python/D5_Git_Project.html#mini-task-make-a-feature-branch-7-minutes",
    "title": "Python & Tooling",
    "section": "Mini-task — Make a feature branch (7 minutes)",
    "text": "Mini-task — Make a feature branch (7 minutes)\n\nCreate a new branch:\n\nfeature/readme\n\nAdd 5 lines to your README\nCommit\nMerge back into main\n\nCheckpoint: git log --oneline --graph shows a merge."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#solution-branch-merge",
    "href": "W1_Python/D5_Git_Project.html#solution-branch-merge",
    "title": "Python & Tooling",
    "section": "Solution — Branch + merge",
    "text": "Solution — Branch + merge\ngit switch -c feature/readme\n# edit README.md\ngit add README.md\ngit commit -m \"Improve README quickstart\"\n\ngit switch main\ngit merge feature/readme"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#recap-session-1",
    "href": "W1_Python/D5_Git_Project.html#recap-session-1",
    "title": "Python & Tooling",
    "section": "Recap (Session 1)",
    "text": "Recap (Session 1)\n\nGit is a system of snapshots\nUse status + diff to stay oriented\nCommit small, meaningful units\n.gitignore keeps repos clean\nLearn safe undo before you need it"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#git-vs-github",
    "href": "W1_Python/D5_Git_Project.html#git-vs-github",
    "title": "Python & Tooling",
    "section": "Git vs GitHub",
    "text": "Git vs GitHub\n\nGit: version control tool on your machine\nGitHub: a hosted place to store Git repos + collaborate\n\nThink of GitHub as: “Google Drive for Git repos” (but with workflows)."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#clone-vs-download-zip",
    "href": "W1_Python/D5_Git_Project.html#clone-vs-download-zip",
    "title": "Python & Tooling",
    "section": "Clone vs “Download ZIP”",
    "text": "Clone vs “Download ZIP”\nPrefer clone because:\n\nyou keep Git history\nyou can commit + push easily\nyou can pull updates later\n\nClone:\ngit clone &lt;REPO_URL&gt;\ncd csv-profiler"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#forks-and-pull-requests-prs",
    "href": "W1_Python/D5_Git_Project.html#forks-and-pull-requests-prs",
    "title": "Python & Tooling",
    "section": "Forks and Pull Requests (PRs)",
    "text": "Forks and Pull Requests (PRs)\n\nFork: your copy of someone else’s repo\nPull Request (PR): request to merge changes into a branch\n\nEven solo, PRs can be useful for: - review before merging into main - discussion + feedback"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#mini-quiz-1",
    "href": "W1_Python/D5_Git_Project.html#mini-quiz-1",
    "title": "Python & Tooling",
    "section": "Mini-quiz",
    "text": "Mini-quiz\nWhat does origin mean?\nA. Your current branch\nB. The default remote name\nC. A GitHub feature\n\nAnswer: B — it’s the default remote name (just a label)."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#remote-basics-origin",
    "href": "W1_Python/D5_Git_Project.html#remote-basics-origin",
    "title": "Python & Tooling",
    "section": "Remote basics: origin",
    "text": "Remote basics: origin\nA “remote” is a named URL.\nYou usually have:\n\norigin → your GitHub repo\n\nCheck:\ngit remote -v"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#create-a-github-repository-checklist",
    "href": "W1_Python/D5_Git_Project.html#create-a-github-repository-checklist",
    "title": "Python & Tooling",
    "section": "Create a GitHub repository (checklist)",
    "text": "Create a GitHub repository (checklist)\nOn GitHub:\n\nNew repository\nName: csv-profiler (example)\nAdd description\nChoose Public/Private (based on instructions)\nDo not add a README if you already have one locally (either is fine, but avoid confusion)\n\n\nDo: Show the page where GitHub gives you the git remote add origin ... line."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#connect-local-github",
    "href": "W1_Python/D5_Git_Project.html#connect-local-github",
    "title": "Python & Tooling",
    "section": "Connect local → GitHub",
    "text": "Connect local → GitHub\nCopy the URL from GitHub, then:\ngit remote add origin &lt;YOUR_REPO_URL&gt;\ngit branch -M main\ngit push -u origin main\nNow your future pushes can be:\ngit push"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#quick-check-correct-order",
    "href": "W1_Python/D5_Git_Project.html#quick-check-correct-order",
    "title": "Python & Tooling",
    "section": "Quick check: correct order?",
    "text": "Quick check: correct order?\nWhich comes first?\nA. git push\nB. git remote add origin ...\n\nAnswer: Add remote first (git remote add origin ...), then push."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#authentication-what-usually-breaks",
    "href": "W1_Python/D5_Git_Project.html#authentication-what-usually-breaks",
    "title": "Python & Tooling",
    "section": "Authentication (what usually breaks)",
    "text": "Authentication (what usually breaks)\nIf you see authentication errors:\n\nHTTPS:\n\nyou may need a Personal Access Token (PAT) instead of a password\n\nSSH:\n\nyou need an SSH key added to GitHub\n\n\n\n\n\n\n\n\nTip\n\n\nAsk a clarifying question to the instructor if auth blocks you. Don’t spend 30 minutes stuck."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#pulling-updates-even-if-you-work-alone",
    "href": "W1_Python/D5_Git_Project.html#pulling-updates-even-if-you-work-alone",
    "title": "Python & Tooling",
    "section": "Pulling updates (even if you work alone)",
    "text": "Pulling updates (even if you work alone)\nBefore starting work each day:\ngit pull\nIf you are behind, Git updates your local branch."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#readme-your-repos-front-door",
    "href": "W1_Python/D5_Git_Project.html#readme-your-repos-front-door",
    "title": "Python & Tooling",
    "section": "README: your repo’s “front door”",
    "text": "README: your repo’s “front door”\nA good README answers:\n\nWhat is this?\nWhat can it do?\nHow do I install dependencies?\nHow do I run it?\nWhat does output look like?"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#readme-skeleton-copyable",
    "href": "W1_Python/D5_Git_Project.html#readme-skeleton-copyable",
    "title": "Python & Tooling",
    "section": "README skeleton (copyable)",
    "text": "README skeleton (copyable)\n# CSV Profiler\n\nGenerate a profiling report for a CSV file.\n\n## Features\n- CLI: JSON + Markdown report\n- Streamlit GUI: upload CSV + export reports\n\n## Setup\n    uv venv -p 3.11\n    uv pip install -r requirements.txt\n\n## Run CLI\n    # If you have a src/ folder:\n    #   Mac/Linux: export PYTHONPATH=src\n    #   Windows:   $env:PYTHONPATH=\"src\"\n    uv run python -m csv_profiler.cli profile data/sample.csv --out-dir outputs\n\n## Run GUI\n    # If you have a src/ folder:\n    #   Mac/Linux: export PYTHONPATH=src\n    #   Windows:   $env:PYTHONPATH=\"src\"\n    uv run streamlit run app.py\n\nSay: Make it runnable in 60 seconds. Minimal + clear beats “fancy”."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#task-improve-your-readme-10-minutes",
    "href": "W1_Python/D5_Git_Project.html#task-improve-your-readme-10-minutes",
    "title": "Python & Tooling",
    "section": "Task — Improve your README (10 minutes)",
    "text": "Task — Improve your README (10 minutes)\nAdd these sections:\n\n## Setup\n## Run CLI\n## Run GUI\n## Output Files\n\nCheckpoint: A new student can follow your README without asking you questions."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#solution-readme-output-files-section",
    "href": "W1_Python/D5_Git_Project.html#solution-readme-output-files-section",
    "title": "Python & Tooling",
    "section": "Solution — README “Output Files” section",
    "text": "Solution — README “Output Files” section\n## Output Files\n\nThe CLI writes:\n- `outputs/report.json`\n- `outputs/report.md`\n\nThe Streamlit app can:\n- preview the report\n- download JSON + Markdown\nThen commit:\ngit add README.md\ngit commit -m \"Document setup and usage\""
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#add-one-screenshot-optional-but-strong",
    "href": "W1_Python/D5_Git_Project.html#add-one-screenshot-optional-but-strong",
    "title": "Python & Tooling",
    "section": "Add one screenshot (optional but strong)",
    "text": "Add one screenshot (optional but strong)\n\nTake a screenshot of your Streamlit app (small)\nAdd it to assets/ or images/\nReference it in README:\n\n![Streamlit UI](images/ui.png)\n\n\nA screenshot makes your project feel “real” instantly."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#repo-hygiene-professional-signal",
    "href": "W1_Python/D5_Git_Project.html#repo-hygiene-professional-signal",
    "title": "Python & Tooling",
    "section": "Repo hygiene (professional signal)",
    "text": "Repo hygiene (professional signal)\n\nKeep secrets out (.env in .gitignore)\nKeep big data out (or use a tiny sample)\nKeep generated outputs out (outputs/ ignored)\nKeep instructions up to date"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#recap-session-2",
    "href": "W1_Python/D5_Git_Project.html#recap-session-2",
    "title": "Python & Tooling",
    "section": "Recap (Session 2)",
    "text": "Recap (Session 2)\n\nGitHub hosts your Git repo\norigin is the remote name you’ll use most\nYour README is part of the grade (and your portfolio)"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#definition-of-done-week-1",
    "href": "W1_Python/D5_Git_Project.html#definition-of-done-week-1",
    "title": "Python & Tooling",
    "section": "Definition of Done (Week 1)",
    "text": "Definition of Done (Week 1)\nYou’re “done” when:\n\nCLI works from a fresh terminal\nStreamlit app runs and exports reports\nRepo has:\n\n.gitignore\nrequirements.txt (or equivalent)\nREADME with run steps\n\nGitHub has your latest commit (push succeeded)"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#fresh-clone-runbook-what-graders-do",
    "href": "W1_Python/D5_Git_Project.html#fresh-clone-runbook-what-graders-do",
    "title": "Python & Tooling",
    "section": "“Fresh clone” runbook (what graders do)",
    "text": "“Fresh clone” runbook (what graders do)\nWe will roughly do:\n\ngit clone ...\ncreate env\ninstall deps\nrun CLI on data/sample.csv\nrun Streamlit\n\nIf any step is confusing → points lost."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#your-datasample.csv-should-prove-your-app-works",
    "href": "W1_Python/D5_Git_Project.html#your-datasample.csv-should-prove-your-app-works",
    "title": "Python & Tooling",
    "section": "Your data/sample.csv should prove your app works",
    "text": "Your data/sample.csv should prove your app works\nInclude a tiny CSV with:\n\na numeric column\na text column\nat least one missing value\nat least 5–10 rows\n\n\n\nSmall file = fast grading."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#add-a-troubleshooting-section-saves-you-messages",
    "href": "W1_Python/D5_Git_Project.html#add-a-troubleshooting-section-saves-you-messages",
    "title": "Python & Tooling",
    "section": "Add a “Troubleshooting” section (saves you messages)",
    "text": "Add a “Troubleshooting” section (saves you messages)\nExamples:\n\nIf imports fail:\n\nconfirm you are in the repo root\nif your code is under src/, set PYTHONPATH=src\n\nMac/Linux: export PYTHONPATH=src\nWindows PowerShell: $env:PYTHONPATH=\"src\"\n\n\nIf Streamlit can’t import your package:\n\nstop + restart Streamlit\nconfirm you launched it from the repo root\n\nIf uv commands fail:\n\nconfirm you ran uv venv in the repo\nconfirm .venv/ exists"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#task-add-a-5-step-manual-test-plan-6-minutes",
    "href": "W1_Python/D5_Git_Project.html#task-add-a-5-step-manual-test-plan-6-minutes",
    "title": "Python & Tooling",
    "section": "Task — Add a 5-step manual test plan (6 minutes)",
    "text": "Task — Add a 5-step manual test plan (6 minutes)\nIn README, add:\n\nsetup\nrun CLI\nverify output files\nrun Streamlit\nexport reports\n\nCheckpoint: Another student can run it in &lt; 2 minutes."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#solution-manual-test-plan-readme-snippet",
    "href": "W1_Python/D5_Git_Project.html#solution-manual-test-plan-readme-snippet",
    "title": "Python & Tooling",
    "section": "Solution — Manual test plan (README snippet)",
    "text": "Solution — Manual test plan (README snippet)\n## Manual Test Plan\n\n1. Setup:\n   - `uv venv -p 3.11`\n   - `uv pip install -r requirements.txt`\n\n2. CLI:\n   - (If you have a `src/` folder: set `PYTHONPATH=src` first)\n   - `uv run python -m csv_profiler.cli profile data/sample.csv --out-dir outputs`\n\n3. Verify:\n   - `outputs/report.json` and `outputs/report.md` exist\n\n4. GUI:\n   - (If you have a `src/` folder: set `PYTHONPATH=src` first)\n   - `uv run streamlit run app.py`\n\n5. Export:\n   - download JSON + Markdown from the UI"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#freeze-dependencies-simple-practical",
    "href": "W1_Python/D5_Git_Project.html#freeze-dependencies-simple-practical",
    "title": "Python & Tooling",
    "section": "Freeze dependencies (simple, practical)",
    "text": "Freeze dependencies (simple, practical)\nrequirements.txt is a plain text list of the packages (and versions) your project needs.\n\nuv pip freeze prints “what’s installed” in your project environment\n&gt; means “write this output into a file” (it will overwrite the file)\n\nFrom the repo root (where your .venv/ is):\nuv pip freeze &gt; requirements.txt\nThen commit:\ngit add requirements.txt\ngit commit -m \"Add requirements.txt\"\n\n\nThis makes your setup reproducible even if someone doesn’t know your install history."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#quick-check-1",
    "href": "W1_Python/D5_Git_Project.html#quick-check-1",
    "title": "Python & Tooling",
    "section": "Quick check",
    "text": "Quick check\nQuestion: Should requirements.txt include your .venv/?\n\nAnswer: No. requirements.txt is text. .venv/ stays untracked."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#add-a-tiny-smoke-test-section-in-readme",
    "href": "W1_Python/D5_Git_Project.html#add-a-tiny-smoke-test-section-in-readme",
    "title": "Python & Tooling",
    "section": "Add a tiny “smoke test” section in README",
    "text": "Add a tiny “smoke test” section in README\nExample:\n## Smoke Test\n\n1) Run the CLI:\n\n    # If you have a `src/` folder: set `PYTHONPATH=src` first\n    uv run python -m csv_profiler.cli profile data/sample.csv --out-dir outputs\n\n2) Check the output files exist:\n\n    # Mac/Linux\n    ls outputs\n\n    # Windows PowerShell\n    dir outputs\n\nYou should see `report.json` and `report.md`."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#dont-commit-secrets-future-you-will-thank-you",
    "href": "W1_Python/D5_Git_Project.html#dont-commit-secrets-future-you-will-thank-you",
    "title": "Python & Tooling",
    "section": "Don’t commit secrets (future-you will thank you)",
    "text": "Don’t commit secrets (future-you will thank you)\nBad:\n\nAPI keys in code\ntokens in README\n.env committed\n\nGood:\n\n.env in .gitignore\n.env.example committed (no secrets)\n\n\n\n\n\n\n\nWarning\n\n\nOnce a secret is in Git history, removing it is hard. Treat repos as public."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#common-week-1-submission-pitfalls",
    "href": "W1_Python/D5_Git_Project.html#common-week-1-submission-pitfalls",
    "title": "Python & Tooling",
    "section": "Common Week 1 submission pitfalls",
    "text": "Common Week 1 submission pitfalls\n\n“It works on my machine” (but README doesn’t)\nNo sample CSV (grader can’t run)\nPushed .venv/ or huge files\nCLI crashes on:\n\nempty strings\nmissing values\nweird headers\n\nStreamlit app only works after manual steps not documented"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#grading-rubric-transparent",
    "href": "W1_Python/D5_Git_Project.html#grading-rubric-transparent",
    "title": "Python & Tooling",
    "section": "Grading rubric (transparent)",
    "text": "Grading rubric (transparent)\n\n\n\nArea\nPoints\nWhat we look for\n\n\n\n\nCLI works\n30\nReads CSV, writes JSON + MD, helpful errors\n\n\nStreamlit works\n30\nUpload CSV, preview, export JSON + MD\n\n\nCode quality\n15\nClear functions/modules, reasonable naming\n\n\nReproducibility\n15\nREADME + requirements, fresh-clone runnable\n\n\nGit/GitHub hygiene\n10\ncommits, .gitignore, pushed on time\n\n\n\nPassing (Week 1): ≥ 70/100\n\nSay: Points are easiest to earn with a good README + clean runbook."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#merge-conflicts-you-will-see-this-eventually",
    "href": "W1_Python/D5_Git_Project.html#merge-conflicts-you-will-see-this-eventually",
    "title": "Python & Tooling",
    "section": "Merge conflicts (you will see this eventually)",
    "text": "Merge conflicts (you will see this eventually)\nConflict happens when:\n\nyou and Git both changed the same lines\nGit can’t automatically decide which is correct\n\nSigns:\n\nCONFLICT (content) message\nfile contains &lt;&lt;&lt;&lt;&lt;&lt;&lt;, =======, &gt;&gt;&gt;&gt;&gt;&gt;&gt;"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#how-to-resolve-a-conflict-safe-process",
    "href": "W1_Python/D5_Git_Project.html#how-to-resolve-a-conflict-safe-process",
    "title": "Python & Tooling",
    "section": "How to resolve a conflict (safe process)",
    "text": "How to resolve a conflict (safe process)\n\nRead git status\nOpen the conflicting file\nChoose the correct lines (remove markers)\nSave file\ngit add &lt;file&gt;\ngit commit"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#mini-exercise-simulate-a-conflict-10-minutes",
    "href": "W1_Python/D5_Git_Project.html#mini-exercise-simulate-a-conflict-10-minutes",
    "title": "Python & Tooling",
    "section": "Mini-exercise — Simulate a conflict (10 minutes)",
    "text": "Mini-exercise — Simulate a conflict (10 minutes)\n\nCreate a branch: feature/conflict\nChange the same line in README.md\nCommit on branch\nSwitch to main\nChange the same line differently\nCommit on main\nMerge branch into main → conflict appears\nResolve and commit"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#solution-conflict-simulation-commands",
    "href": "W1_Python/D5_Git_Project.html#solution-conflict-simulation-commands",
    "title": "Python & Tooling",
    "section": "Solution — Conflict simulation (commands)",
    "text": "Solution — Conflict simulation (commands)\ngit switch -c feature/conflict\n# edit README.md (change SAME line)\ngit add README.md\ngit commit -m \"Edit README on branch\"\n\ngit switch main\n# edit README.md (change SAME line differently)\ngit add README.md\ngit commit -m \"Edit README on main\"\n\ngit merge feature/conflict\n# resolve file\ngit add README.md\ngit commit -m \"Resolve merge conflict\""
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#recap-session-3",
    "href": "W1_Python/D5_Git_Project.html#recap-session-3",
    "title": "Python & Tooling",
    "section": "Recap (Session 3)",
    "text": "Recap (Session 3)\n\nThink like a grader: “fresh clone”\nFreeze deps (requirements.txt)\nProtect secrets\nKnow the conflict workflow"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#hands-on-kickoff",
    "href": "W1_Python/D5_Git_Project.html#hands-on-kickoff",
    "title": "Python & Tooling",
    "section": "Hands-on kickoff",
    "text": "Hands-on kickoff\nGoal: Push a polished Week 1 repo by tonight, 11:59pm.\nDeliverable: A Gib link that anyone can run.\nWork style: - work in pairs (review each other’s README + commands) - ask instructors clarifying questions quickly\n\nDo: Put a visible timer. Encourage small commits every ~15 minutes."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#task-0-ensure-a-runnable-sample-csv-exists-8-minutes",
    "href": "W1_Python/D5_Git_Project.html#task-0-ensure-a-runnable-sample-csv-exists-8-minutes",
    "title": "Python & Tooling",
    "section": "Task 0 — Ensure a runnable sample CSV exists (8 minutes)",
    "text": "Task 0 — Ensure a runnable sample CSV exists (8 minutes)\n\nConfirm data/sample.csv exists\nKeep it small (≤ ~20 rows)\nInclude:\n\na numeric column\na text column\nat least one missing value\n\n\nCheckpoint: Your repo can be tested without extra files."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#solution-commit-your-sample-csv",
    "href": "W1_Python/D5_Git_Project.html#solution-commit-your-sample-csv",
    "title": "Python & Tooling",
    "section": "Solution — Commit your sample CSV",
    "text": "Solution — Commit your sample CSV\ngit add data/sample.csv\ngit commit -m \"Add sample CSV for grading\"\n\n\nIf you can’t share real data, create a synthetic sample."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#task-1-final-local-smoke-test-10-minutes",
    "href": "W1_Python/D5_Git_Project.html#task-1-final-local-smoke-test-10-minutes",
    "title": "Python & Tooling",
    "section": "Task 1 — Final local smoke test (10 minutes)",
    "text": "Task 1 — Final local smoke test (10 minutes)\nRun both (from repo root):\nMac/Linux (bash/zsh)\n# Only if you have a src/ folder:\nexport PYTHONPATH=src\n\nuv run python -m csv_profiler.cli profile data/sample.csv --out-dir outputs\nuv run streamlit run app.py\nWindows PowerShell\n# Only if you have a src/ folder:\n$env:PYTHONPATH=\"src\"\n\nuv run python -m csv_profiler.cli profile data/sample.csv --out-dir outputs\nuv run streamlit run app.py\nCheckpoint: Both run without editing code."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#solution-task-1-checklist",
    "href": "W1_Python/D5_Git_Project.html#solution-task-1-checklist",
    "title": "Python & Tooling",
    "section": "Solution — Task 1 checklist",
    "text": "Solution — Task 1 checklist\n\nCLI produced:\n\noutputs/report.json\noutputs/report.md\n\nStreamlit:\n\nuploads sample.csv\nshows a preview\ndownload buttons work\n\n\nIf one fails: fix it before touching GitHub."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#task-2-create-requirements.txt-10-minutes",
    "href": "W1_Python/D5_Git_Project.html#task-2-create-requirements.txt-10-minutes",
    "title": "Python & Tooling",
    "section": "Task 2 — Create requirements.txt (10 minutes)",
    "text": "Task 2 — Create requirements.txt (10 minutes)\nuv pip freeze &gt; requirements.txt\nCheckpoint: file exists and is not empty."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#solution-task-2",
    "href": "W1_Python/D5_Git_Project.html#solution-task-2",
    "title": "Python & Tooling",
    "section": "Solution — Task 2",
    "text": "Solution — Task 2\nCommit:\ngit add requirements.txt\ngit commit -m \"Add requirements.txt\""
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#task-3-ensure-.gitignore-is-correct-10-minutes",
    "href": "W1_Python/D5_Git_Project.html#task-3-ensure-.gitignore-is-correct-10-minutes",
    "title": "Python & Tooling",
    "section": "Task 3 — Ensure .gitignore is correct (10 minutes)",
    "text": "Task 3 — Ensure .gitignore is correct (10 minutes)\nVerify these are NOT tracked:\n\n.venv/\noutputs/\n__pycache__/\n\nCheck:\ngit status\ngit ls-files | head"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#solution-task-3-fix-accidental-tracking",
    "href": "W1_Python/D5_Git_Project.html#solution-task-3-fix-accidental-tracking",
    "title": "Python & Tooling",
    "section": "Solution — Task 3 (fix accidental tracking)",
    "text": "Solution — Task 3 (fix accidental tracking)\nIf you already committed .venv/ or outputs/ by mistake:\ngit rm -r --cached .venv outputs __pycache__\ngit commit -m \"Stop tracking generated files\"\nThen ensure .gitignore contains those patterns."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#task-4-readme-fresh-clone-instructions-15-minutes",
    "href": "W1_Python/D5_Git_Project.html#task-4-readme-fresh-clone-instructions-15-minutes",
    "title": "Python & Tooling",
    "section": "Task 4 — README “fresh clone” instructions (15 minutes)",
    "text": "Task 4 — README “fresh clone” instructions (15 minutes)\nYour README must include:\n\nsetup steps\nCLI command\nStreamlit command\nexpected outputs\n\nCheckpoint: Your partner can follow it without help."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#solution-task-4-minimum-readme",
    "href": "W1_Python/D5_Git_Project.html#solution-task-4-minimum-readme",
    "title": "Python & Tooling",
    "section": "Solution — Task 4 (minimum README)",
    "text": "Solution — Task 4 (minimum README)\n## Setup\nuv venv -p 3.11\nuv pip install -r requirements.txt\n\n## Run CLI\n# If you have a src/ folder:\n#   Mac/Linux: export PYTHONPATH=src\n#   Windows:   $env:PYTHONPATH=\"src\"\nuv run python -m csv_profiler.cli profile data/sample.csv --out-dir outputs\n\n## Run GUI\n# If you have a src/ folder:\n#   Mac/Linux: export PYTHONPATH=src\n#   Windows:   $env:PYTHONPATH=\"src\"\nuv run streamlit run app.py\nCommit:\ngit add README.md\ngit commit -m \"Finalize README runbook\""
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#task-5-create-github-repo-push-15-minutes",
    "href": "W1_Python/D5_Git_Project.html#task-5-create-github-repo-push-15-minutes",
    "title": "Python & Tooling",
    "section": "Task 5 — Create GitHub repo + push (15 minutes)",
    "text": "Task 5 — Create GitHub repo + push (15 minutes)\n\nCreate repo on GitHub\nAdd remote\nPush\n\nCheckpoint: You can open GitHub and see your files."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#solution-task-5-push-commands",
    "href": "W1_Python/D5_Git_Project.html#solution-task-5-push-commands",
    "title": "Python & Tooling",
    "section": "Solution — Task 5 (push commands)",
    "text": "Solution — Task 5 (push commands)\ngit remote add origin &lt;YOUR_REPO_URL&gt;\ngit branch -M main\ngit push -u origin main\nIf you already had a remote but it’s wrong:\ngit remote set-url origin &lt;YOUR_REPO_URL&gt;\ngit push -u origin main"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#git-tags-bookmark-a-commit",
    "href": "W1_Python/D5_Git_Project.html#git-tags-bookmark-a-commit",
    "title": "Python & Tooling",
    "section": "Git tags (bookmark a commit)",
    "text": "Git tags (bookmark a commit)\nA tag is a human-friendly name for a specific commit.\n\nIt does not change your code\nIt makes grading / “submission versions” easy to find later\nYou can push a tag to GitHub just like a branch\n\nGeneric pattern:\ngit tag -a &lt;tag-name&gt; -m \"message\"\ngit push origin &lt;tag-name&gt;"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#task-6-tag-your-week-1-submission-optional-8-minutes",
    "href": "W1_Python/D5_Git_Project.html#task-6-tag-your-week-1-submission-optional-8-minutes",
    "title": "Python & Tooling",
    "section": "Task 6 — Tag your Week 1 submission (optional, 8 minutes)",
    "text": "Task 6 — Tag your Week 1 submission (optional, 8 minutes)\nCreate a “submission tag” so it’s easy to find:\ngit tag -a week1-submission -m \"Week 1 submission\"\ngit push origin week1-submission\nCheckpoint: GitHub shows the tag under Releases/Tags."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#solution-task-6-when-tags-fail",
    "href": "W1_Python/D5_Git_Project.html#solution-task-6-when-tags-fail",
    "title": "Python & Tooling",
    "section": "Solution — Task 6 (when tags fail)",
    "text": "Solution — Task 6 (when tags fail)\nIf push is rejected, first push commits:\ngit push\ngit push origin week1-submission"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#task-7-final-sanity-check-from-github-10-minutes",
    "href": "W1_Python/D5_Git_Project.html#task-7-final-sanity-check-from-github-10-minutes",
    "title": "Python & Tooling",
    "section": "Task 7 — Final sanity check from GitHub (10 minutes)",
    "text": "Task 7 — Final sanity check from GitHub (10 minutes)\nOn GitHub:\n\nopen README (renders correctly)\nverify file tree:\n\nsrc/csv_profiler/...\napp.py\nrequirements.txt\n.gitignore\ndata/sample.csv\n\n\nCheckpoint: Repo looks “professional”."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#solution-task-7-ideal-structure",
    "href": "W1_Python/D5_Git_Project.html#solution-task-7-ideal-structure",
    "title": "Python & Tooling",
    "section": "Solution — Task 7 (ideal structure)",
    "text": "Solution — Task 7 (ideal structure)\nOption A: src/ layout (common in bootcamps)\ncsv-profiler/\n├── README.md\n├── requirements.txt\n├── .gitignore\n├── app.py\n├── data/\n│   └── sample.csv\n├── outputs/          (ignored)\n└── src/\n    └── csv_profiler/\n        ├── __init__.py\n        ├── cli.py\n        ├── io.py\n        ├── profiling.py\n        └── render.py"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#solution-task-7-ideal-structure-1",
    "href": "W1_Python/D5_Git_Project.html#solution-task-7-ideal-structure-1",
    "title": "Python & Tooling",
    "section": "Solution — Task 7 (ideal structure)",
    "text": "Solution — Task 7 (ideal structure)\nOption B: “flat” layout (also acceptable for Week 1)\ncsv-profiler/\n├── README.md\n├── requirements.txt\n├── .gitignore\n├── app.py\n├── data/\n│   └── sample.csv\n├── outputs/          (ignored)\n└── csv_profiler/\n    ├── __init__.py\n    ├── cli.py\n    ├── io.py\n    ├── profiling.py\n    └── render.py\n\n\nIf you use Option B, your run commands usually don’t need PYTHONPATH."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#task-8-submission-message-5-minutes",
    "href": "W1_Python/D5_Git_Project.html#task-8-submission-message-5-minutes",
    "title": "Python & Tooling",
    "section": "Task 8 — Submission message (5 minutes)",
    "text": "Task 8 — Submission message (5 minutes)\nSend the following to the instructor/portal:\n\nGitHub repo link\nCommit hash of your final submission\nAny known limitations (1–2 bullets)\n\nCheckpoint: Submission sent before 11:59pm."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#solution-task-8-template",
    "href": "W1_Python/D5_Git_Project.html#solution-task-8-template",
    "title": "Python & Tooling",
    "section": "Solution — Task 8 template",
    "text": "Solution — Task 8 template\nRepo: https://github.com/&lt;user&gt;/csv-profiler\nFinal commit: &lt;hash&gt;\nLimitations:\n- Does not infer dates (treated as text)\n- Very large CSVs may be slow"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#if-you-finish-early-stretch-goals",
    "href": "W1_Python/D5_Git_Project.html#if-you-finish-early-stretch-goals",
    "title": "Python & Tooling",
    "section": "If you finish early (stretch goals)",
    "text": "If you finish early (stretch goals)\nPick ONE:\n\nAdd better type inference: int vs float\nAdd missing-value % per column\nAdd a “Top values” section for categorical columns\nAdd a --delimiter option in CLI\nImprove Streamlit UI (tabs, nicer layout)\n\n\nSay: Stretch only after the main rubric is satisfied."
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#week-1-wrap-up",
    "href": "W1_Python/D5_Git_Project.html#week-1-wrap-up",
    "title": "Python & Tooling",
    "section": "Week 1 wrap-up",
    "text": "Week 1 wrap-up\nYou can now:\n\nbuild and run Python projects with uv\nwrite a CLI (Typer) and a GUI (Streamlit)\nread CSV → generate JSON + Markdown reports\nship to GitHub with clean version control\n\nNext week: Data Work (ETL + EDA)"
  },
  {
    "objectID": "W1_Python/D5_Git_Project.html#exit-ticket",
    "href": "W1_Python/D5_Git_Project.html#exit-ticket",
    "title": "Python & Tooling",
    "section": "Exit Ticket",
    "text": "Exit Ticket\nIn 1–2 sentences:\n\nWhat is the difference between staging and committing?\nWhat is one thing you improved in your README today?"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#todays-flow",
    "href": "W2_Data/D2_Data_Integrity.html#todays-flow",
    "title": "Data Work (ETL + EDA)",
    "section": "Today’s Flow",
    "text": "Today’s Flow\n\nSession 1 (60m): Verify — turn assumptions into checks\nAsr Prayer (20m)\nSession 2 (60m): Clean — missingness + categories + duplicates\nMaghrib Prayer (20m)\nSession 3 (60m): Join + report — safe merges + first EDA summary\nIsha Prayer (20m)\nHands-on (120m): Build checks.py + run_day2_validate_and_report.py"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#learning-objectives",
    "href": "W2_Data/D2_Data_Integrity.html#learning-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of today, you can:\n\nwrite lightweight data quality checks (columns, non-empty, uniqueness, ranges)\nquantify missingness (counts + %) and choose drop vs flag vs careful impute (EDA-safe default)\nnormalize messy text categories into *_clean columns and dedupe using a business key rule\njoin tables safely with pd.merge(..., validate=...), detect join explosions with row-count checks, and measure match rate\nproduce reproducible artifacts: processed Parquet + quality artifacts (e.g. missingness CSV) + a Markdown summary in reports/"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#warm-up-5-minutes",
    "href": "W2_Data/D2_Data_Integrity.html#warm-up-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Warm-up (5 minutes)",
    "text": "Warm-up (5 minutes)\nRun Day 1 and confirm Parquet outputs still look typed.\nmacOS/Linux\nuv run python -m scripts.run_day1_load\nuv run python -c \"import pandas as pd; df=pd.read_parquet('data/processed/orders.parquet'); print(df.dtypes)\"\nWindows PowerShell\nuv run python -m scripts.run_day1_load\nuv run python -c \"import pandas as pd; df=pd.read_parquet('data/processed/orders.parquet'); print(df.dtypes)\"\nCheckpoint: data/processed/orders.parquet exists and user_id is string."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#quick-review-where-we-left-off-day-1",
    "href": "W2_Data/D2_Data_Integrity.html#quick-review-where-we-left-off-day-1",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick review: where we left off (Day 1)",
    "text": "Quick review: where we left off (Day 1)\n\nImport-safe project layout (packages + module execution)\nTyped processed outputs in data/processed/ (Parquet preserves dtypes)\nCanonical workflow:\n\nLoad → Verify → Clean → Transform → Analyze → Visualize → Conclude\n\n\n\n\n\n\n\n\nNote\n\n\nDay 1 mostly covered Load + “typed I/O”. Today we seriously start Verify + Clean."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#todays-deliverable-what-youll-commit",
    "href": "W2_Data/D2_Data_Integrity.html#todays-deliverable-what-youll-commit",
    "title": "Data Work (ETL + EDA)",
    "section": "Today’s deliverable (what you’ll commit)",
    "text": "Today’s deliverable (what you’ll commit)\nA Day 2 pipeline that runs end-to-end from repo root:\n\nbootcamp_data/checks.py (small, testable checks)\nextra helpers in bootcamp_data/transforms.py (flags, normalization, dedupe)\nscripts/run_day2_validate_and_report.py (wire it together)\nartifacts:\n\ndata/processed/orders_clean.parquet\ndata/processed/orders_enriched.parquet\nreports/day2_missingness_orders.csv\nreports/day2_summary.md (row counts + duplicates + join match rate + a missingness snapshot)"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#uv-quick-review-so-commands-are-consistent",
    "href": "W2_Data/D2_Data_Integrity.html#uv-quick-review-so-commands-are-consistent",
    "title": "Data Work (ETL + EDA)",
    "section": "uv quick review (so commands are consistent)",
    "text": "uv quick review (so commands are consistent)\n\nRun inside your project environment:\n\nuv run &lt;command&gt;\n\nInstall a dependency (if we decide we need one):\n\nuv add &lt;package&gt;\n\n\n\n\n\n\n\n\nTip\n\n\nWe’ll stick to uv run ... so we don’t depend on “did you activate your venv?”"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#if-imports-fail-fix-the-root-cause-no-hacks",
    "href": "W2_Data/D2_Data_Integrity.html#if-imports-fail-fix-the-root-cause-no-hacks",
    "title": "Data Work (ETL + EDA)",
    "section": "If imports fail: fix the root cause (no hacks)",
    "text": "If imports fail: fix the root cause (no hacks)\nIf you see:\nModuleNotFoundError: No module named 'bootcamp_data'\nDo this checklist (in order):\n\nAre you in repo root? (folder that contains bootcamp_data/ and scripts/)\nAre you running as a module?\n\n✅ uv run python -m scripts.run_day1_load\n✅ uv run python -m scripts.run_day2_validate_and_report\n\nDoes bootcamp_data/__init__.py exist?\nAre you using the right Python?\n\nmacOS/Linux\nuv run python -c \"import bootcamp_data; print('import ok')\"\nWindows PowerShell\nuv run python -c \"import bootcamp_data; print('import ok')\""
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#checkpoint",
    "href": "W2_Data/D2_Data_Integrity.html#checkpoint",
    "title": "Data Work (ETL + EDA)",
    "section": "Checkpoint",
    "text": "Checkpoint\nRaise your hand when:\n\nyou can run Day 1 using uv run python -m ...\nyou can explain (in 1 sentence) why we avoid “import hacks”\n\n\nWalk around. Fix 1 common issue: students running from the wrong folder."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#session-1-objectives",
    "href": "W2_Data/D2_Data_Integrity.html#session-1-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 1 objectives",
    "text": "Session 1 objectives\nBy the end of this session, you can:\n\nexplain “fail fast” and why it saves time\nwrite checks for:\n\nrequired columns\nnon-empty datasets\nduplicate keys\nbasic numeric ranges"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#why-data-bugs-are-usually-silent",
    "href": "W2_Data/D2_Data_Integrity.html#why-data-bugs-are-usually-silent",
    "title": "Data Work (ETL + EDA)",
    "section": "Why data bugs are usually silent",
    "text": "Why data bugs are usually silent\nBad data rarely crashes your code.\nInstead it produces:\n\nwrong totals\nwrong joins\nwrong charts\nconfident wrong conclusions"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#fail-fast-in-one-sentence",
    "href": "W2_Data/D2_Data_Integrity.html#fail-fast-in-one-sentence",
    "title": "Data Work (ETL + EDA)",
    "section": "“Fail fast” in one sentence",
    "text": "“Fail fast” in one sentence\nTurn assumptions into checks that stop the pipeline with a clear message.\n\n\n\n\n\n\nTip\n\n\nA pipeline that crashes early is annoying. A pipeline that silently lies is dangerous."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#where-checks-live-separation-of-concerns",
    "href": "W2_Data/D2_Data_Integrity.html#where-checks-live-separation-of-concerns",
    "title": "Data Work (ETL + EDA)",
    "section": "Where checks live (separation of concerns)",
    "text": "Where checks live (separation of concerns)\nKeep your pipeline debuggable:\n\nbootcamp_data/io.py → read/write\nbootcamp_data/transforms.py → transforms (df -&gt; df)\nbootcamp_data/checks.py → validations (fail fast)\nscripts/...py → thin entrypoints (wires everything together)"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#check-1-required-columns",
    "href": "W2_Data/D2_Data_Integrity.html#check-1-required-columns",
    "title": "Data Work (ETL + EDA)",
    "section": "Check 1 — required columns",
    "text": "Check 1 — required columns\nIf a required column is missing, nothing else matters.\ndef require_columns(df, cols, *, df_name=\"df\"):\n    missing = [c for c in cols if c not in df.columns]\n    if missing:\n        raise ValueError(f\"{df_name}: missing columns {missing}\")"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#micro-exercise-break-it-on-purpose-6-minutes",
    "href": "W2_Data/D2_Data_Integrity.html#micro-exercise-break-it-on-purpose-6-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: break it on purpose (6 minutes)",
    "text": "Micro-exercise: break it on purpose (6 minutes)\n\nLoad data/processed/orders.parquet\nRun require_columns with one fake column (\"NOT_A_COL\")\nConfirm the error message names the missing column\n\nCheckpoint: you get a clear ValueError that names NOT_A_COL."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution-example",
    "href": "W2_Data/D2_Data_Integrity.html#solution-example",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\nimport pandas as pd\n\norders = pd.read_parquet(\"data/processed/orders.parquet\")\n\ndef require_columns(df, cols, *, df_name=\"df\"):\n    missing = [c for c in cols if c not in df.columns]\n    if missing:\n        raise ValueError(f\"{df_name}: missing columns {missing}\")\n\nrequire_columns(orders, [\"order_id\", \"user_id\", \"NOT_A_COL\"], df_name=\"orders\")"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#check-2-non-empty-inputs",
    "href": "W2_Data/D2_Data_Integrity.html#check-2-non-empty-inputs",
    "title": "Data Work (ETL + EDA)",
    "section": "Check 2 — non-empty inputs",
    "text": "Check 2 — non-empty inputs\nA surprising number of pipelines produce 0 rows.\nCommon reasons:\n\nwrong file path\nwrong filter\nupstream extract returned nothing\n\ndef assert_non_empty(df, *, df_name=\"df\"):\n    if len(df) == 0:\n        raise ValueError(f\"{df_name}: 0 rows\")"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#micro-exercise-predict-the-failure-4-minutes",
    "href": "W2_Data/D2_Data_Integrity.html#micro-exercise-predict-the-failure-4-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: predict the failure (4 minutes)",
    "text": "Micro-exercise: predict the failure (4 minutes)\nYou wrote:\npaid = orders[orders[\"status\"] == \"paid\"]\nGive two reasons paid might be empty even if there are paid orders.\nCheckpoint: you can name 2 realistic reasons."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution-common-reasons",
    "href": "W2_Data/D2_Data_Integrity.html#solution-common-reasons",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution: common reasons",
    "text": "Solution: common reasons\n\ninconsistent casing (\"Paid\", \"PAID\", \"paid\")\nhidden whitespace (\"paid \")\n\n\nToday we’ll normalize categories and make joins + groupbys safer."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#check-3-key-integrity-duplicates",
    "href": "W2_Data/D2_Data_Integrity.html#check-3-key-integrity-duplicates",
    "title": "Data Work (ETL + EDA)",
    "section": "Check 3 — key integrity (duplicates)",
    "text": "Check 3 — key integrity (duplicates)\nKeys connect tables. If keys are wrong, joins lie.\nFast question:\n\n“How many duplicate key rows do we have?”\n\ndup_rows = df[\"order_id\"].duplicated(keep=False)\nn_dup_rows = int(dup_rows.sum())"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#micro-exercise-measure-duplicate-order-ids-6-minutes",
    "href": "W2_Data/D2_Data_Integrity.html#micro-exercise-measure-duplicate-order-ids-6-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: measure duplicate order IDs (6 minutes)",
    "text": "Micro-exercise: measure duplicate order IDs (6 minutes)\n\nLoad data/processed/orders.parquet\nCompute how many rows have a duplicate order_id\n\nCheckpoint: you can answer: “duplicates = 0” or “duplicates &gt; 0”."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution-example-1",
    "href": "W2_Data/D2_Data_Integrity.html#solution-example-1",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\nimport pandas as pd\n\norders = pd.read_parquet(\"data/processed/orders.parquet\")\ndup_rows = orders[\"order_id\"].duplicated(keep=False)\nprint(\"duplicate rows:\", int(dup_rows.sum()))"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#check-4-range-checks-practical",
    "href": "W2_Data/D2_Data_Integrity.html#check-4-range-checks-practical",
    "title": "Data Work (ETL + EDA)",
    "section": "Check 4 — range checks (practical)",
    "text": "Check 4 — range checks (practical)\nEven after parsing, numbers can be invalid.\nExamples:\n\namount &gt;= 0\nquantity &gt;= 0\n\ndef assert_in_range(s, lo=None, hi=None, name=\"value\"):\n    x = s.dropna()\n    if lo is not None and not (x &gt;= lo).all():\n        raise ValueError(f\"{name}: below {lo}\")\n    if hi is not None and not (x &lt;= hi).all():\n        raise ValueError(f\"{name}: above {hi}\")"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#micro-exercise-check-for-negative-amounts-5-minutes",
    "href": "W2_Data/D2_Data_Integrity.html#micro-exercise-check-for-negative-amounts-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: check for negative amounts (5 minutes)",
    "text": "Micro-exercise: check for negative amounts (5 minutes)\n\nLoad orders.parquet\nCount how many rows have amount &lt; 0 (ignore missing)\n\nCheckpoint: you can report n_negative."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution-example-2",
    "href": "W2_Data/D2_Data_Integrity.html#solution-example-2",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\nimport pandas as pd\n\norders = pd.read_parquet(\"data/processed/orders.parquet\")\nn_negative = int((orders[\"amount\"].dropna() &lt; 0).sum())\nprint(\"n_negative:\", n_negative)"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#session-1-recap",
    "href": "W2_Data/D2_Data_Integrity.html#session-1-recap",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 1 recap",
    "text": "Session 1 recap\n\nChecks turn assumptions into clear, early failures\nStart with high ROI:\n\nrequired columns\nnon-empty\nduplicates / key sanity\nnumeric ranges\n\nKeep checks separate from transforms and I/O"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#minutes",
    "href": "W2_Data/D2_Data_Integrity.html#minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: we’ll quantify missingness and clean without deleting the story."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#session-2-objectives",
    "href": "W2_Data/D2_Data_Integrity.html#session-2-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 2 objectives",
    "text": "Session 2 objectives\nBy the end of this session, you can:\n\nmeasure missingness (counts + %)\nexplain why blanket .dropna() is risky\ndefault to missingness flags for EDA\nnormalize messy categories into *_clean\napply an explicit dedupe rule (and record what you did)"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#missingness-is-a-signal-not-just-a-mess",
    "href": "W2_Data/D2_Data_Integrity.html#missingness-is-a-signal-not-just-a-mess",
    "title": "Data Work (ETL + EDA)",
    "section": "Missingness is a signal (not just a mess)",
    "text": "Missingness is a signal (not just a mess)\nMissing values can mean:\n\nunknown\nnot applicable\nupstream bug\nintentionally blank\n\nYour move: measure first, then decide."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#missingness-report-counts",
    "href": "W2_Data/D2_Data_Integrity.html#missingness-report-counts",
    "title": "Data Work (ETL + EDA)",
    "section": "Missingness report (counts + %)",
    "text": "Missingness report (counts + %)\ndef missingness_report(df):\n    n = len(df)\n    rep = df.isna().sum().rename(\"n_missing\").to_frame()\n    rep[\"p_missing\"] = rep[\"n_missing\"] / (n if n else 1)\n    return rep.sort_values(\"p_missing\", ascending=False)"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#micro-exercise-run-the-report-6-minutes",
    "href": "W2_Data/D2_Data_Integrity.html#micro-exercise-run-the-report-6-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: run the report (6 minutes)",
    "text": "Micro-exercise: run the report (6 minutes)\n\nLoad data/processed/orders.parquet\nRun missingness_report(orders)\nPrint the top 5 rows\n\nCheckpoint: you can name the most-missing column."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution-example-3",
    "href": "W2_Data/D2_Data_Integrity.html#solution-example-3",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\nimport pandas as pd\n\norders = pd.read_parquet(\"data/processed/orders.parquet\")\nrep = missingness_report(orders)\nprint(rep.head(5))"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#decide-drop-vs-impute-vs-flag",
    "href": "W2_Data/D2_Data_Integrity.html#decide-drop-vs-impute-vs-flag",
    "title": "Data Work (ETL + EDA)",
    "section": "Decide: drop vs impute vs flag",
    "text": "Decide: drop vs impute vs flag\nA simple rule for analytics/EDA:\n\nDrop: only when rows are unusable\nImpute: only with strong justification\nFlag: often the best default (*_isna)\n\n\n\n\n\n\n\nTip\n\n\nFlags let you analyze “missingness patterns” later."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#pattern-add-missingness-flags",
    "href": "W2_Data/D2_Data_Integrity.html#pattern-add-missingness-flags",
    "title": "Data Work (ETL + EDA)",
    "section": "Pattern: add missingness flags",
    "text": "Pattern: add missingness flags\ndef add_missing_flags(df, cols):\n    out = df.copy()\n    for c in cols:\n        out[f\"{c}__isna\"] = out[c].isna()\n    return out"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#micro-exercise-add-flags-5-minutes",
    "href": "W2_Data/D2_Data_Integrity.html#micro-exercise-add-flags-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: add flags (5 minutes)",
    "text": "Micro-exercise: add flags (5 minutes)\nAdd flags for:\n\namount\nquantity\n\nCheckpoint: your DataFrame has amount__isna and quantity__isna."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution-example-4",
    "href": "W2_Data/D2_Data_Integrity.html#solution-example-4",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\norders2 = orders.copy()\norders2[\"amount__isna\"] = orders2[\"amount\"].isna()\norders2[\"quantity__isna\"] = orders2[\"quantity\"].isna()\n\nprint(orders2[[\"amount\", \"amount__isna\", \"quantity\", \"quantity__isna\"]].head())"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#text-categories-normalize-map-so-eda-is-consistent",
    "href": "W2_Data/D2_Data_Integrity.html#text-categories-normalize-map-so-eda-is-consistent",
    "title": "Data Work (ETL + EDA)",
    "section": "Text categories: normalize + map (so EDA is consistent)",
    "text": "Text categories: normalize + map (so EDA is consistent)\nCategory columns (like status) can create fake groups:\n\n\"Paid\", \"PAID\", \" paid \" become 3 categories\ntypos/synonyms (\"refunded\" vs \"refund\") split the story\n\nBest practice:\n\nkeep the original column\ncreate a new *_clean column you use for analysis\n\nimport re\n\n_ws = re.compile(r\"\\s+\")\nstatus_norm = (\n    orders[\"status\"].astype(\"string\")\n    .str.strip()\n    .str.casefold()\n    .str.replace(_ws, \" \", regex=True)\n)\nmapping = {\"refunded\": \"refund\"}\nstatus_clean = status_norm.map(lambda x: mapping.get(x, x))\n\n\n\n\n\n\nNote\n\n\nre.compile(r\"\\s+\") matches one-or-more whitespace, so multiple spaces/tabs collapse to one."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#micro-exercise-normalize-map-status-6-minutes",
    "href": "W2_Data/D2_Data_Integrity.html#micro-exercise-normalize-map-status-6-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: normalize + map status (6 minutes)",
    "text": "Micro-exercise: normalize + map status (6 minutes)\n\nPrint orders[\"status\"].value_counts(dropna=False).head(10)\nCreate status_norm (trim + casefold + whitespace collapse)\nAdd a small mapping (at least one synonym)\nPrint counts for the clean version\n\nCheckpoint: your “clean” counts look more consistent than the raw counts."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution-example-5",
    "href": "W2_Data/D2_Data_Integrity.html#solution-example-5",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\nimport re\n\n_ws = re.compile(r\"\\s+\")\n\nprint(orders[\"status\"].value_counts(dropna=False).head(10))\n\nstatus_norm = (\n    orders[\"status\"].astype(\"string\").str.strip().str.casefold().str.replace(_ws, \" \", regex=True)\n)\nmapping = {\"refunded\": \"refund\"}\nstatus_clean = status_norm.map(lambda x: mapping.get(x, x))\n\nprint(status_clean.value_counts(dropna=False).head(10))"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#duplicates-decide-on-a-rule-dont-guess",
    "href": "W2_Data/D2_Data_Integrity.html#duplicates-decide-on-a-rule-dont-guess",
    "title": "Data Work (ETL + EDA)",
    "section": "Duplicates: decide on a rule (don’t guess)",
    "text": "Duplicates: decide on a rule (don’t guess)\nNot all duplicates are exact row duplicates.\nFirst choose a business key, then choose a keep rule.\nCommon keep rules:\n\nkeep the last record you saw (simple, explicit)\nkeep the latest by a reliable timestamp (better, but requires parsing)"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#pattern-dedupe-by-key-keep-last",
    "href": "W2_Data/D2_Data_Integrity.html#pattern-dedupe-by-key-keep-last",
    "title": "Data Work (ETL + EDA)",
    "section": "Pattern: dedupe by key (keep last)",
    "text": "Pattern: dedupe by key (keep last)\nimport pandas as pd\n\ndef dedupe_keep_last(df: pd.DataFrame, key_cols: list[str]) -&gt; pd.DataFrame:\n    return df.drop_duplicates(subset=key_cols, keep=\"last\").reset_index(drop=True)"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#micro-exercise-dedupe-and-check-uniqueness-6-minutes",
    "href": "W2_Data/D2_Data_Integrity.html#micro-exercise-dedupe-and-check-uniqueness-6-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: dedupe and check uniqueness (6 minutes)",
    "text": "Micro-exercise: dedupe and check uniqueness (6 minutes)\n\nIf order_id duplicates exist, create a deduped DataFrame\nVerify it has no duplicate order_id\n\nCheckpoint: deduped[\"order_id\"].duplicated().sum() == 0."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution-example-6",
    "href": "W2_Data/D2_Data_Integrity.html#solution-example-6",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\nimport pandas as pd\n\norders = pd.read_parquet(\"data/processed/orders.parquet\")\ndeduped = orders.drop_duplicates(subset=[\"order_id\"], keep=\"last\")\nprint(\"dup after:\", int(deduped[\"order_id\"].duplicated().sum()))"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#session-2-recap",
    "href": "W2_Data/D2_Data_Integrity.html#session-2-recap",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 2 recap",
    "text": "Session 2 recap\n\nMissingness: measure → decide (drop/impute/flag)\nFlags are a safe EDA default\nNormalize categories into *_clean before groupby\nDedupe requires a business key + an explicit keep rule"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#minutes-1",
    "href": "W2_Data/D2_Data_Integrity.html#minutes-1",
    "title": "Data Work (ETL + EDA)",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: we’ll join orders to users safely and write our first Day 2 report."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#session-3-objectives",
    "href": "W2_Data/D2_Data_Integrity.html#session-3-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 3 objectives",
    "text": "Session 3 objectives\nBy the end of this session, you can:\n\nexplain common join failures (dtype mismatch, missing keys, duplicate keys → join explosions)\njoin with pd.merge(..., validate=...) and add a simple row-count sanity check\nmeasure join coverage with indicator=True (match rate)\nwrite a minimal Markdown report you can trust (so EDA is reproducible)"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#joins-can-silently-lie",
    "href": "W2_Data/D2_Data_Integrity.html#joins-can-silently-lie",
    "title": "Data Work (ETL + EDA)",
    "section": "Joins can silently lie",
    "text": "Joins can silently lie\nA join usually doesn’t crash. It just changes your row count.\nWatch for:\n\nunexpected row increases\nlots of missing values after the join\ngroupbys that look “too good to be true”"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#join-pitfall-1-dtype-mismatch",
    "href": "W2_Data/D2_Data_Integrity.html#join-pitfall-1-dtype-mismatch",
    "title": "Data Work (ETL + EDA)",
    "section": "Join pitfall #1 — dtype mismatch",
    "text": "Join pitfall #1 — dtype mismatch\nIf orders.user_id is a string but users.user_id is an int, you can get:\n\na join that matches almost nothing\nlots of missing country (or other user fields)\n\n\n\n\n\n\n\nTip\n\n\nEnforce key dtypes early, then merge."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#pd.merge...-validate...-your-safety-belt",
    "href": "W2_Data/D2_Data_Integrity.html#pd.merge...-validate...-your-safety-belt",
    "title": "Data Work (ETL + EDA)",
    "section": "pd.merge(..., validate=...) (your safety belt)",
    "text": "pd.merge(..., validate=...) (your safety belt)\nvalidate= tells pandas what join cardinality you expect:\n\n\"one_to_one\"\n\"one_to_many\"\n\"many_to_one\"\n\"many_to_many\" (no protection)\n\nFor orders → users:\n\nmany orders per user\none user row per user\n\nSo we expect: validate=\"many_to_one\"."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#micro-exercise-choose-the-right-validate-4-minutes",
    "href": "W2_Data/D2_Data_Integrity.html#micro-exercise-choose-the-right-validate-4-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: choose the right validate (4 minutes)",
    "text": "Micro-exercise: choose the right validate (4 minutes)\nYou are joining:\n\norders (many rows per user_id)\nusers (one row per user_id)\n\nWhat should you use?\n\none_to_one\nmany_to_one\nmany_to_many\n\nCheckpoint: choose A/B/C and explain in 1 sentence."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution",
    "href": "W2_Data/D2_Data_Integrity.html#solution",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution",
    "text": "Solution\nB) many_to_one — many orders map to one user."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#measure-join-coverage-with-indicatortrue",
    "href": "W2_Data/D2_Data_Integrity.html#measure-join-coverage-with-indicatortrue",
    "title": "Data Work (ETL + EDA)",
    "section": "Measure join coverage with indicator=True",
    "text": "Measure join coverage with indicator=True\nUse indicator=True to see whether each row matched:\nout = orders.merge(users, on=\"user_id\", how=\"left\", validate=\"many_to_one\", indicator=True)\nprint(out[\"_merge\"].value_counts())"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#micro-exercise-compute-the-match-rate-7-minutes",
    "href": "W2_Data/D2_Data_Integrity.html#micro-exercise-compute-the-match-rate-7-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: compute the match rate (7 minutes)",
    "text": "Micro-exercise: compute the match rate (7 minutes)\n\nAfter the merge, compute:\n\nn_total\nn_matched (_merge == \"both\")\nmatch_rate = n_matched / n_total\n\n\nCheckpoint: you can print match_rate as a %."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution-example-7",
    "href": "W2_Data/D2_Data_Integrity.html#solution-example-7",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\nn_total = len(out)\nn_matched = int((out[\"_merge\"] == \"both\").sum())\nprint(f\"match_rate: {n_matched / n_total:.1%}\")"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#join-pitfall-2-duplicate-keys-on-the-one-side",
    "href": "W2_Data/D2_Data_Integrity.html#join-pitfall-2-duplicate-keys-on-the-one-side",
    "title": "Data Work (ETL + EDA)",
    "section": "Join pitfall #2 — duplicate keys on the “one” side",
    "text": "Join pitfall #2 — duplicate keys on the “one” side\nIf users.user_id is not unique, your merge can multiply rows.\nTwo ways to catch it:\n\npre-check uniqueness (assert_unique_key(users, \"user_id\"))\nmerge with validate=\"many_to_one\" (it will raise)"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#quick-check",
    "href": "W2_Data/D2_Data_Integrity.html#quick-check",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: If pd.merge(..., validate=\"many_to_one\") raises, what’s the most likely cause?\n\nAnswer: the right table (users) has duplicate user_id values."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#join-explosion-demo-how-totals-get-inflated",
    "href": "W2_Data/D2_Data_Integrity.html#join-explosion-demo-how-totals-get-inflated",
    "title": "Data Work (ETL + EDA)",
    "section": "Join explosion demo — how totals get inflated",
    "text": "Join explosion demo — how totals get inflated\nA join can change your row count without errors.\nBad outcome: your aggregates (revenue, counts) become wrong.\nimport pandas as pd\n\norders = pd.DataFrame(\n    {\"order_id\": [\"o1\", \"o2\"], \"user_id\": [\"u1\", \"u1\"], \"amount\": [10, 20]}\n)\n\n# BUG: users should be unique by user_id, but it's not\nusers = pd.DataFrame(\n    {\"user_id\": [\"u1\", \"u1\"], \"country\": [\"SA\", \"SA\"]}\n)\n\nout = orders.merge(users, on=\"user_id\", how=\"left\")  # no validate!\nprint(\"rows:\", len(orders), \"→\", len(out))\nprint(\"revenue before:\", orders[\"amount\"].sum())\nprint(\"revenue after :\", out[\"amount\"].sum())  # inflated\nFix: enforce uniqueness and use validate=... + row-count checks."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#join-safety-checklist-operational",
    "href": "W2_Data/D2_Data_Integrity.html#join-safety-checklist-operational",
    "title": "Data Work (ETL + EDA)",
    "section": "Join safety checklist (operational)",
    "text": "Join safety checklist (operational)\nBefore the merge:\n\njoin keys exist on both tables\nkeys have the same dtype (string vs int is a common bug)\nthe “one” side is unique (assert_unique_key)\nyou chose join type intentionally (left vs inner)\n\nDuring the merge:\n\nuse validate=..., suffixes=..., indicator=True\n\nAfter the merge:\n\nrow count matches expectation (left join: len(out) == len(left))\nmatch rate is reasonable (and you can explain low coverage)\nnew columns aren’t mysteriously mostly null"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#reporting-why-write-a-markdown-report",
    "href": "W2_Data/D2_Data_Integrity.html#reporting-why-write-a-markdown-report",
    "title": "Data Work (ETL + EDA)",
    "section": "Reporting: why write a Markdown report?",
    "text": "Reporting: why write a Markdown report?\nA report is an artifact you can:\n\nreview offline\ndiff in Git\nshare with a teammate\nrerun tomorrow and compare\n\n\n\n\n\n\n\nTip\n\n\nIf it matters, write it to reports/."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#pattern-build-small-markdown-tables-week-1-skill",
    "href": "W2_Data/D2_Data_Integrity.html#pattern-build-small-markdown-tables-week-1-skill",
    "title": "Data Work (ETL + EDA)",
    "section": "Pattern: build small Markdown tables (Week 1 skill)",
    "text": "Pattern: build small Markdown tables (Week 1 skill)\nUse Week 1 tools (f-strings + str.join) to render tables without extra libraries.\ndef md_table(headers, rows):\n    lines = []\n    lines.append(\"| \" + \" | \".join(headers) + \" |\")\n    lines.append(\"| \" + \" | \".join([\"---\"] * len(headers)) + \" |\")\n    for row in rows:\n        lines.append(\"| \" + \" | \".join(str(x) for x in row) + \" |\")\n    return \"\\n\".join(lines)"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#micro-exercise-one-table-for-the-report-8-minutes",
    "href": "W2_Data/D2_Data_Integrity.html#micro-exercise-one-table-for-the-report-8-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: one table for the report (8 minutes)",
    "text": "Micro-exercise: one table for the report (8 minutes)\nCreate a “Top 5 countries by revenue” table.\n\nGroup by country\nSum amount\nTake top 5\nRender with md_table(...)\n\nCheckpoint: you have a Markdown table string you can print."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution-example-8",
    "href": "W2_Data/D2_Data_Integrity.html#solution-example-8",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\nby_country = (\n    orders_enriched.groupby(\"country\", dropna=False)[\"amount\"]\n    .sum(min_count=1)\n    .sort_values(ascending=False)\n    .head(5)\n)\nrows = [(c, f\"{v:.2f}\" if v == v else \"NA\") for c, v in by_country.items()]\nprint(md_table([\"country\", \"revenue\"], rows))"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#session-3-recap",
    "href": "W2_Data/D2_Data_Integrity.html#session-3-recap",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 3 recap",
    "text": "Session 3 recap\n\nUse validate= so merges fail when cardinality assumptions break\nUse indicator=True to measure match coverage\nWrite a small report you can trust (and re-run)"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#minutes-2",
    "href": "W2_Data/D2_Data_Integrity.html#minutes-2",
    "title": "Data Work (ETL + EDA)",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: we’ll implement Day 2 as committed code + artifacts."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#hands-on-success-criteria-today",
    "href": "W2_Data/D2_Data_Integrity.html#hands-on-success-criteria-today",
    "title": "Data Work (ETL + EDA)",
    "section": "Hands-on success criteria (today)",
    "text": "Hands-on success criteria (today)\nBy the end, you should have:\n\nbootcamp_data/checks.py with reusable validations\nupdates to bootcamp_data/transforms.py (flags, normalization, dedupe)\na runnable entrypoint: uv run python -m scripts.run_day2_validate_and_report\nartifacts:\n\ndata/processed/orders_clean.parquet\ndata/processed/orders_enriched.parquet\nreports/day2_missingness_orders.csv\nreports/day2_summary.md\n\nat least one commit pushed to GitHub"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#project-layout-what-you-add-today",
    "href": "W2_Data/D2_Data_Integrity.html#project-layout-what-you-add-today",
    "title": "Data Work (ETL + EDA)",
    "section": "Project layout (what you add today)",
    "text": "Project layout (what you add today)\nbootcamp_data/\n  __init__.py\n  config.py\n  io.py\n  transforms.py            # add helpers\n  checks.py                # NEW\nscripts/\n  __init__.py\n  run_day1_load.py\n  run_day2_validate_and_report.py   # NEW\nreports/\n  day2_summary.md\ndata/\n  raw/\n  processed/"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#vibe-coding-safe-version",
    "href": "W2_Data/D2_Data_Integrity.html#vibe-coding-safe-version",
    "title": "Data Work (ETL + EDA)",
    "section": "Vibe coding (safe version)",
    "text": "Vibe coding (safe version)\n\nWrite the plan in 5 bullets (no code yet)\nImplement the smallest piece\nRun → break → read error → fix\nCommit\nRepeat\n\n\n\n\n\n\n\nWarning\n\n\nDo not ask GenAI to write your solution code. Ask it to explain concepts or errors."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#task-1-create-bootcamp_datachecks.py-20-minutes",
    "href": "W2_Data/D2_Data_Integrity.html#task-1-create-bootcamp_datachecks.py-20-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 1 — Create bootcamp_data/checks.py (20 minutes)",
    "text": "Task 1 — Create bootcamp_data/checks.py (20 minutes)\nCreate a new module with these functions:\n\nrequire_columns(df, cols, *, df_name=\"df\")\nassert_non_empty(df, *, df_name=\"df\")\nmissingness_report(df) -&gt; DataFrame (counts + %)\nassert_unique_key(df, key, *, allow_na=False, df_name=\"df\")\nassert_in_range(s, lo=None, hi=None, name=\"value\")\n\nCheckpoint: you can import everything.\nmacOS/Linux\nuv run python -c \"from bootcamp_data.checks import require_columns, assert_non_empty, missingness_report, assert_unique_key, assert_in_range; print('checks import: ok')\"\nWindows PowerShell\nuv run python -c \"from bootcamp_data.checks import require_columns, assert_non_empty, missingness_report, assert_unique_key, assert_in_range; print('checks import: ok')\""
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#hint-keep-checks-readable",
    "href": "W2_Data/D2_Data_Integrity.html#hint-keep-checks-readable",
    "title": "Data Work (ETL + EDA)",
    "section": "Hint — keep checks readable",
    "text": "Hint — keep checks readable\n\n\n\n\n\n\nTip\n\n\nPrefer small functions + clear error messages.\nIf you can’t explain the check in one sentence, it’s too complicated (for now)."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution-bootcamp_datachecks.py-part-1",
    "href": "W2_Data/D2_Data_Integrity.html#solution-bootcamp_datachecks.py-part-1",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — bootcamp_data/checks.py (part 1)",
    "text": "Solution — bootcamp_data/checks.py (part 1)\nimport pandas as pd\n\ndef require_columns(df: pd.DataFrame, cols: list[str], *, df_name: str = \"df\") -&gt; None:\n    missing = [c for c in cols if c not in df.columns]\n    if missing:\n        raise ValueError(f\"{df_name}: missing columns {missing}\")\n\ndef assert_non_empty(df: pd.DataFrame, *, df_name: str = \"df\") -&gt; None:\n    if len(df) == 0:\n        raise ValueError(f\"{df_name}: 0 rows\")\n\ndef missingness_report(df: pd.DataFrame) -&gt; pd.DataFrame:\n    n = len(df)\n    rep = df.isna().sum().rename(\"n_missing\").to_frame()\n    rep[\"p_missing\"] = rep[\"n_missing\"] / (n if n else 1)\n    return rep.sort_values(\"p_missing\", ascending=False)"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution-bootcamp_datachecks.py-part-2",
    "href": "W2_Data/D2_Data_Integrity.html#solution-bootcamp_datachecks.py-part-2",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — bootcamp_data/checks.py (part 2)",
    "text": "Solution — bootcamp_data/checks.py (part 2)\nimport pandas as pd\n\ndef assert_unique_key(\n    df: pd.DataFrame,\n    key: str,\n    *,\n    allow_na: bool = False,\n    df_name: str = \"df\",\n) -&gt; None:\n    s = df[key]\n    if (not allow_na) and (not s.notna().all()):\n        raise ValueError(f\"{df_name}.{key}: contains NA\")\n    dup = s.dropna().duplicated(keep=False)\n    if dup.any():\n        raise ValueError(f\"{df_name}.{key}: not unique\")\n\ndef assert_in_range(s: pd.Series, lo=None, hi=None, name: str = \"value\") -&gt; None:\n    x = s.dropna()\n    if lo is not None and not (x &gt;= lo).all():\n        raise ValueError(f\"{name}: below {lo}\")\n    if hi is not None and not (x &lt;= hi).all():\n        raise ValueError(f\"{name}: above {hi}\")"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#task-2-add-helpers-to-bootcamp_datatransforms.py-20-minutes",
    "href": "W2_Data/D2_Data_Integrity.html#task-2-add-helpers-to-bootcamp_datatransforms.py-20-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 2 — Add helpers to bootcamp_data/transforms.py (20 minutes)",
    "text": "Task 2 — Add helpers to bootcamp_data/transforms.py (20 minutes)\nAppend these helper functions below your existing enforce_schema:\n\nadd_missing_flags(df, cols) -&gt; df\nnormalize_text(series) -&gt; series\napply_mapping(series, mapping) -&gt; series\ndedupe_keep_last(df, key_cols) -&gt; df\n\nCheckpoint: you can import them.\nmacOS/Linux\nuv run python -c \"from bootcamp_data.transforms import add_missing_flags, normalize_text, apply_mapping, dedupe_keep_last; print('transforms helpers: ok')\"\nWindows PowerShell\nuv run python -c \"from bootcamp_data.transforms import add_missing_flags, normalize_text, apply_mapping, dedupe_keep_last; print('transforms helpers: ok')\""
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution-helpers-in-bootcamp_datatransforms.py",
    "href": "W2_Data/D2_Data_Integrity.html#solution-helpers-in-bootcamp_datatransforms.py",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — helpers in bootcamp_data/transforms.py",
    "text": "Solution — helpers in bootcamp_data/transforms.py\nimport re\nimport pandas as pd\n\n_ws = re.compile(r\"\\s+\")\n\ndef add_missing_flags(df: pd.DataFrame, cols: list[str]) -&gt; pd.DataFrame:\n    out = df.copy()\n    for c in cols:\n        out[f\"{c}__isna\"] = out[c].isna()\n    return out\n\ndef normalize_text(s: pd.Series) -&gt; pd.Series:\n    return s.astype(\"string\").str.strip().str.casefold().str.replace(_ws, \" \", regex=True)\n\ndef apply_mapping(s: pd.Series, mapping: dict[str, str]) -&gt; pd.Series:\n    return s.map(lambda x: mapping.get(x, x))\n\ndef dedupe_keep_last(df: pd.DataFrame, key_cols: list[str]) -&gt; pd.DataFrame:\n    return df.drop_duplicates(subset=key_cols, keep=\"last\").reset_index(drop=True)"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#task-3-create-scriptsrun_day2_validate_and_report.py-40-minutes",
    "href": "W2_Data/D2_Data_Integrity.html#task-3-create-scriptsrun_day2_validate_and_report.py-40-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 3 — Create scripts/run_day2_validate_and_report.py (40 minutes)",
    "text": "Task 3 — Create scripts/run_day2_validate_and_report.py (40 minutes)\nWrite a Day 2 entrypoint that:\n\nloads raw CSVs (orders + users)\nruns fast checks (required columns + non-empty)\nenforces schema for orders\nwrites a missingness CSV report in reports/\ncleans orders:\n\nstatus_clean (normalize + mapping)\nmissing flags (amount, quantity)\ndedupe by order_id (keep last)\n\nruns post-clean checks (unique order_id, non-negative amount/quantity)\njoins to users with validate=\"many_to_one\" + indicator=True\nwrites:\n\norders_clean.parquet\norders_enriched.parquet\nreports/day2_missingness_orders.csv\nreports/day2_summary.md\n\n\nCheckpoint: script runs from repo root:\nmacOS/Linux\nuv run python -m scripts.run_day2_validate_and_report\nWindows PowerShell\nuv run python -m scripts.run_day2_validate_and_report"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#hint-a-good-order-of-operations",
    "href": "W2_Data/D2_Data_Integrity.html#hint-a-good-order-of-operations",
    "title": "Data Work (ETL + EDA)",
    "section": "Hint — a good order of operations",
    "text": "Hint — a good order of operations\n\nValidate fast things first (columns + non-empty)\nEnforce types early (so joins don’t fail on dtype mismatch)\nClean + dedupe\nValidate invariants (uniqueness, ranges)\nJoin with validate= + indicator=\nWrite artifacts (Parquet + report)\n\n\n\n\n\n\n\nWarning\n\n\nDo not “fix” data by deleting everything. Measure first. Keep your actions explicit."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution-scriptsrun_day2_validate_and_report.py-18-imports-setup",
    "href": "W2_Data/D2_Data_Integrity.html#solution-scriptsrun_day2_validate_and_report.py-18-imports-setup",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — scripts/run_day2_validate_and_report.py (1/8): imports + setup",
    "text": "Solution — scripts/run_day2_validate_and_report.py (1/8): imports + setup\nimport logging\nfrom pathlib import Path\n\nfrom bootcamp_data.config import make_paths\nfrom bootcamp_data.io import read_orders_csv, read_users_csv, write_parquet\nfrom bootcamp_data.checks import (\n    require_columns,\n    assert_non_empty,\n    missingness_report,\n    assert_unique_key,\n    assert_in_range,\n)\nfrom bootcamp_data.transforms import (\n    enforce_schema,\n    add_missing_flags,\n    normalize_text,\n    apply_mapping,\n    dedupe_keep_last,\n)\n\nlog = logging.getLogger(__name__)\nROOT = Path(__file__).resolve().parents[1]"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution-scriptsrun_day2_validate_and_report.py-28-helpers-main",
    "href": "W2_Data/D2_Data_Integrity.html#solution-scriptsrun_day2_validate_and_report.py-28-helpers-main",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — scripts/run_day2_validate_and_report.py (2/8): helpers + main()",
    "text": "Solution — scripts/run_day2_validate_and_report.py (2/8): helpers + main()\ndef md_table(headers, rows) -&gt; str:\n    lines = []\n    lines.append(\"| \" + \" | \".join(headers) + \" |\")\n    lines.append(\"| \" + \" | \".join([\"---\"] * len(headers)) + \" |\")\n    for row in rows:\n        lines.append(\"| \" + \" | \".join(str(x) for x in row) + \" |\")\n    return \"\\n\".join(lines)\n\ndef main() -&gt; None:\n    logging.basicConfig(level=logging.INFO, format=\"%(levelname)s %(name)s: %(message)s\")\n    p = make_paths(ROOT)\n    reports_dir = ROOT / \"reports\"\n    reports_dir.mkdir(parents=True, exist_ok=True)\n    # (See the next slides for the body of `main()`.)\n\nif __name__ == \"__main__\":\n    main()"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution-scriptsrun_day2_validate_and_report.py-38-load-fast-checks",
    "href": "W2_Data/D2_Data_Integrity.html#solution-scriptsrun_day2_validate_and_report.py-38-load-fast-checks",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — scripts/run_day2_validate_and_report.py (3/8): load + fast checks",
    "text": "Solution — scripts/run_day2_validate_and_report.py (3/8): load + fast checks\n    log.info(\"Load raw inputs\")\n    orders_raw = read_orders_csv(p.raw / \"orders.csv\")\n    users = read_users_csv(p.raw / \"users.csv\")\n\n    require_columns(\n        orders_raw,\n        [\"order_id\", \"user_id\", \"amount\", \"quantity\", \"created_at\", \"status\"],\n        df_name=\"orders_raw\",\n    )\n    require_columns(users, [\"user_id\", \"country\", \"signup_date\"], df_name=\"users\")\n    assert_non_empty(orders_raw, df_name=\"orders_raw\")\n    assert_non_empty(users, df_name=\"users\")"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution-scriptsrun_day2_validate_and_report.py-48-schema-missingness-artifact",
    "href": "W2_Data/D2_Data_Integrity.html#solution-scriptsrun_day2_validate_and_report.py-48-schema-missingness-artifact",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — scripts/run_day2_validate_and_report.py (4/8): schema + missingness artifact",
    "text": "Solution — scripts/run_day2_validate_and_report.py (4/8): schema + missingness artifact\n    orders = enforce_schema(orders_raw)\n    users[\"user_id\"] = users[\"user_id\"].astype(\"string\")\n\n    rep = missingness_report(orders)\n    rep_path = reports_dir / \"day2_missingness_orders.csv\"\n    rep.to_csv(rep_path, index=True)\n    log.info(\"Wrote missingness report: %s\", rep_path)"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution-scriptsrun_day2_validate_and_report.py-58-clean-post-checks",
    "href": "W2_Data/D2_Data_Integrity.html#solution-scriptsrun_day2_validate_and_report.py-58-clean-post-checks",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — scripts/run_day2_validate_and_report.py (5/8): clean + post-checks",
    "text": "Solution — scripts/run_day2_validate_and_report.py (5/8): clean + post-checks\n    status_norm = normalize_text(orders[\"status\"])\n    mapping = {\"paid\": \"paid\", \"refund\": \"refund\", \"refunded\": \"refund\"}\n\n    orders_clean = (\n        orders.assign(status_clean=apply_mapping(status_norm, mapping))\n        .pipe(add_missing_flags, cols=[\"amount\", \"quantity\"])\n        .pipe(dedupe_keep_last, key_cols=[\"order_id\"])\n    )\n\n    assert_unique_key(orders_clean, \"order_id\", df_name=\"orders_clean\")\n    assert_in_range(orders_clean[\"amount\"], lo=0, name=\"amount\")\n    assert_in_range(orders_clean[\"quantity\"], lo=0, name=\"quantity\")"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution-scriptsrun_day2_validate_and_report.py-68-safe-join-metrics",
    "href": "W2_Data/D2_Data_Integrity.html#solution-scriptsrun_day2_validate_and_report.py-68-safe-join-metrics",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — scripts/run_day2_validate_and_report.py (6/8): safe join + metrics",
    "text": "Solution — scripts/run_day2_validate_and_report.py (6/8): safe join + metrics\n    assert_unique_key(users, \"user_id\", df_name=\"users\")\n\n    orders_enriched = orders_clean.merge(\n        users[[\"user_id\", \"country\"]],\n        on=\"user_id\",\n        how=\"left\",\n        validate=\"many_to_one\",\n        indicator=True,\n    )\n    orders_enriched[\"user_found\"] = orders_enriched[\"_merge\"] == \"both\"\n    orders_enriched = orders_enriched.drop(columns=[\"_merge\"])\n\n    n_total = len(orders_enriched)\n    n_matched = int(orders_enriched[\"user_found\"].sum())\n    total_revenue = orders_clean[\"amount\"].sum(min_count=1)"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution-scriptsrun_day2_validate_and_report.py-78-build-the-report",
    "href": "W2_Data/D2_Data_Integrity.html#solution-scriptsrun_day2_validate_and_report.py-78-build-the-report",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — scripts/run_day2_validate_and_report.py (7/8): build the report",
    "text": "Solution — scripts/run_day2_validate_and_report.py (7/8): build the report\n    # quick missingness snapshot (top 10 columns)\n    top_missing = (\n        rep.head(10)\n          .reset_index()\n          .rename(columns={\"index\": \"column\"})\n    )\n    missing_rows = [\n        (r[\"column\"], int(r[\"n_missing\"]), f\"{r['p_missing']:.1%}\")\n        for _, r in top_missing.iterrows()\n    ]\n\n    # duplicates snapshot (before dedupe)\n    n_dup_rows = int(orders[\"order_id\"].duplicated(keep=False).sum())\n    n_removed_by_dedupe = len(orders) - len(orders_clean)\n\n    # revenue by country (matched users only)\n    by_country = (\n        orders_enriched.loc[orders_enriched[\"user_found\"]]\n        .groupby(\"country\", dropna=False)[\"amount\"]\n        .sum(min_count=1)\n        .sort_values(ascending=False)\n        .head(10)\n    )\n    country_rows = [\n        (c if c == c else \"(missing)\", f\"{v:.2f}\" if v == v else \"NA\")\n        for c, v in by_country.items()\n    ]\n\n    out_path = reports_dir / \"day2_summary.md\"\n    report = []\n    report.append(\"# Day 2 summary\")\n    report.append(\"\")\n    report.append(\"## Data checks\")\n    report.append(f\"- orders_raw rows: **{len(orders_raw)}**\")\n    report.append(f\"- orders (typed) rows: **{len(orders)}**\")\n    report.append(f\"- orders_clean rows: **{len(orders_clean)}**\")\n    report.append(f\"- orders_enriched rows: **{len(orders_enriched)}**\")\n    report.append(f\"- duplicate `order_id` rows (pre-dedupe): **{n_dup_rows}**\")\n    report.append(f\"- rows removed by dedupe: **{n_removed_by_dedupe}**\")\n    report.append(f\"- join match rate: **{n_matched / n_total:.1%}** ({n_matched}/{n_total})\")\n    report.append(f\"- missingness report: `{rep_path}`\")\n\n    if total_revenue == total_revenue:\n        report.append(f\"- total revenue (clean): **{float(total_revenue):.2f}**\")\n    else:\n        report.append(\"- total revenue (clean): **NA**\")\n\n    report.append(\"\")\n    report.append(\"## Missingness snapshot (top 10 columns)\")\n    report.append(md_table([\"column\", \"n_missing\", \"p_missing\"], missing_rows))\n    report.append(\"\")\n    report.append(\"## Top countries by revenue (matched users only)\")\n    report.append(md_table([\"country\", \"revenue\"], country_rows))\n    report.append(\"\")\n    out_path.write_text(\"\\n\".join(report), encoding=\"utf-8\")"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution-scriptsrun_day2_validate_and_report.py-88-write-outputs",
    "href": "W2_Data/D2_Data_Integrity.html#solution-scriptsrun_day2_validate_and_report.py-88-write-outputs",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — scripts/run_day2_validate_and_report.py (8/8): write outputs",
    "text": "Solution — scripts/run_day2_validate_and_report.py (8/8): write outputs\n    write_parquet(orders_clean, p.processed / \"orders_clean.parquet\")\n    write_parquet(orders_enriched, p.processed / \"orders_enriched.parquet\")\n    write_parquet(users, p.processed / \"users.parquet\")\n\n    log.info(\"Wrote processed outputs: %s\", p.processed)\n    log.info(\"Wrote report: %s\", out_path)"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#task-4-run-verify-artifacts-15-minutes",
    "href": "W2_Data/D2_Data_Integrity.html#task-4-run-verify-artifacts-15-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 4 — Run + verify artifacts (15 minutes)",
    "text": "Task 4 — Run + verify artifacts (15 minutes)\nRun Day 2 and verify outputs exist.\nmacOS/Linux\nuv run python -m scripts.run_day2_validate_and_report\nuv run python -c \"import pandas as pd; df=pd.read_parquet('data/processed/orders_enriched.parquet'); print(df[['status_clean','amount__isna','quantity__isna','user_found']].head())\"\nuv run python -c \"import pandas as pd; print(pd.read_csv('reports/day2_missingness_orders.csv').head())\"\nWindows PowerShell\nuv run python -m scripts.run_day2_validate_and_report\nuv run python -c \"import pandas as pd; df=pd.read_parquet('data/processed/orders_enriched.parquet'); print(df[['status_clean','amount__isna','quantity__isna','user_found']].head())\"\nuv run python -c \"import pandas as pd; print(pd.read_csv('reports/day2_missingness_orders.csv').head())\"\nCheckpoint: you have:\n\ndata/processed/orders_clean.parquet\ndata/processed/orders_enriched.parquet\nreports/day2_missingness_orders.csv\nreports/day2_summary.md"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#git-checkpoint-5-minutes",
    "href": "W2_Data/D2_Data_Integrity.html#git-checkpoint-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Git checkpoint (5 minutes)",
    "text": "Git checkpoint (5 minutes)\n\ngit status\ncommit with message: \"w2d2: validate + clean + join + report\"\npush to GitHub\n\nCheckpoint: repo shows your new commit online."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#solution-git-commands",
    "href": "W2_Data/D2_Data_Integrity.html#solution-git-commands",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — git commands",
    "text": "Solution — git commands\nmacOS/Linux\ngit add -A\ngit commit -m \"w2d2: validate + clean + join + report\"\ngit push\nWindows PowerShell\ngit add -A\ngit commit -m \"w2d2: validate + clean + join + report\"\ngit push"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#debug-playbook-day-2",
    "href": "W2_Data/D2_Data_Integrity.html#debug-playbook-day-2",
    "title": "Data Work (ETL + EDA)",
    "section": "Debug playbook (Day 2)",
    "text": "Debug playbook (Day 2)\nWhen something fails:\n\nConfirm you’re in repo root (ls should show bootcamp_data/ and scripts/)\nRe-run the exact command: uv run python -m scripts.run_day2_validate_and_report\nPrint key facts:\n\ndf.shape, df.dtypes, df.head()\n\nIf merge fails:\n\ncheck key dtypes match\ncheck uniqueness on the “one” side (users.user_id)\n\nIf a check fails:\n\ndon’t delete data; inspect the failing rows and decide a rule\n\n\n\n\n\n\n\n\nTip\n\n\nMost bugs are “my assumption about format was wrong.” Make the assumption explicit, then measure."
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#stretch-goals-optional",
    "href": "W2_Data/D2_Data_Integrity.html#stretch-goals-optional",
    "title": "Data Work (ETL + EDA)",
    "section": "Stretch goals (optional)",
    "text": "Stretch goals (optional)\nIf you finish early:\n\nAdd a “Top 10 statuses” table to the report (status_clean counts)\nAdd a “Top 5 missing columns” table to the report (from missingness_report)\nAdd user_found == False count to the report (unmatched users)\nAdd a second report file: reports/day2_checks.md (what checks ran + what they asserted)"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#exit-ticket",
    "href": "W2_Data/D2_Data_Integrity.html#exit-ticket",
    "title": "Data Work (ETL + EDA)",
    "section": "Exit Ticket",
    "text": "Exit Ticket\nIn 1–2 sentences:\nWhat does validate=\"many_to_one\" protect you from, and what problem does indicator=True help you measure?"
  },
  {
    "objectID": "W2_Data/D2_Data_Integrity.html#what-to-do-after-class-day-2-assignment",
    "href": "W2_Data/D2_Data_Integrity.html#what-to-do-after-class-day-2-assignment",
    "title": "Data Work (ETL + EDA)",
    "section": "What to do after class (Day 2 assignment)",
    "text": "What to do after class (Day 2 assignment)\nDue: before Day 3 starts\n\nMake sure these commands work from a fresh terminal (repo root):\n\nuv run python -m scripts.run_day1_load\nuv run python -m scripts.run_day2_validate_and_report\n\nPush your changes to GitHub\nConfirm these artifacts exist in your repo:\n\nbootcamp_data/checks.py\ndata/processed/orders_clean.parquet\ndata/processed/orders_enriched.parquet\nreports/day2_missingness_orders.csv\nreports/day2_summary.md (row counts + duplicates + missingness snapshot + join match rate)\n\nAdd one dataset-specific check (an invariant you believe should always hold) and include the result in reports/day2_summary.md.\n\nExample ideas: status_clean is in an allowed set; a high-percentile cap is reasonable; key columns aren’t missing above X%; etc. Deliverable: GitHub repo link + screenshot of reports/day2_summary.md opened.\n\n\n\n\n\n\n\n\nTip\n\n\nAdd 1–2 commits with clear messages. Don’t wait until the end of the week."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#todays-flow",
    "href": "W2_Data/D3_Feature_Engineering.html#todays-flow",
    "title": "Data Work (ETL + EDA)",
    "section": "Today’s Flow",
    "text": "Today’s Flow\n\nSession 1 (60m): Datetimes that don’t lie (parse → measure → time parts)\nAsr Prayer (20m)\nSession 2 (60m): Outliers + robust summaries (flag, cap for viz, don’t delete)\nMaghrib Prayer (20m)\nSession 3 (60m): Tidy data + reshape (wide ↔︎ long with melt / pivot_table)\nIsha Prayer (20m)\nHands-on (120m): Build data/processed/orders_features.parquet + reports/day3_eda_tables.md (+ long/wide samples for tomorrow)"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#learning-objectives",
    "href": "W2_Data/D3_Feature_Engineering.html#learning-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of today, you can:\n\nrun Day 2 and verify inputs before analysis\nparse a datetime safely with pd.to_datetime(..., errors=\"coerce\", utc=True) and measure invalids\nderive time parts (month, dow, hour) for grouping\ndetect outliers with percentiles / IQR and choose a safe policy (flag + optional cap for viz)\nproduce robust numeric summaries (mean vs median, quantiles) and interpret skew\nreshape tables safely: wide ↔︎ long with melt() / pivot_table()\nwrite data/processed/orders_features.parquet + reports/day3_eda_tables.md from a script you can rerun"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#bridge-week-1-habits-that-make-week-2-work",
    "href": "W2_Data/D3_Feature_Engineering.html#bridge-week-1-habits-that-make-week-2-work",
    "title": "Data Work (ETL + EDA)",
    "section": "Bridge: Week 1 habits that make Week 2 work",
    "text": "Bridge: Week 1 habits that make Week 2 work\n\nUse uv to stay reproducible: uv add ... and uv run ...\nRun entrypoints as modules from repo root (imports stay stable)\nWrite artifacts you can commit/review:\n\nParquet in data/processed/\nMarkdown in reports/"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#quick-review-what-you-already-built-day-12",
    "href": "W2_Data/D3_Feature_Engineering.html#quick-review-what-you-already-built-day-12",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick review: what you already built (Day 1–2)",
    "text": "Quick review: what you already built (Day 1–2)\nToday we build on these artifacts:\n\ndata/processed/orders_clean.parquet\ndata/processed/orders_enriched.parquet\nreports/day2_summary.md\n\n\n\n\n\n\n\nNote\n\n\nWeek 2 is offline-first: we do not fetch anything from the internet today."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#warm-up-5-minutes",
    "href": "W2_Data/D3_Feature_Engineering.html#warm-up-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Warm-up (5 minutes)",
    "text": "Warm-up (5 minutes)\nRun Day 2 and confirm the outputs exist.\nmacOS/Linux\nuv run python -m scripts.run_day2_validate_and_report\nls -la data/processed | sed -n '1,40p'\nls -la reports | sed -n '1,40p'\nWindows PowerShell\nuv run python -m scripts.run_day2_validate_and_report\nGet-ChildItem data\\processed | Select-Object -First 20\nGet-ChildItem reports | Select-Object -First 20\nCheckpoint: these files exist:\n\ndata/processed/orders_clean.parquet\ndata/processed/orders_enriched.parquet\nreports/day2_summary.md"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#if-warm-up-fails-3-fast-fixes",
    "href": "W2_Data/D3_Feature_Engineering.html#if-warm-up-fails-3-fast-fixes",
    "title": "Data Work (ETL + EDA)",
    "section": "If warm-up fails: 3 fast fixes",
    "text": "If warm-up fails: 3 fast fixes\n\nYou’re not in repo root\n\nYou should see folders like bootcamp_data/, scripts/, data/, reports/\n\nYou ran by file path instead of as a module\n\n✅ uv run python -m scripts.run_day2_validate_and_report\n❌ python scripts/run_day2_validate_and_report.py\n\nYour environment is missing deps\n\n✅ uv add pandas pyarrow httpx\n\n\n\n\n\n\n\n\nWarning\n\n\nDo not “fix imports” by editing sys.path or setting PYTHONPATH."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#session-1-objectives",
    "href": "W2_Data/D3_Feature_Engineering.html#session-1-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 1 objectives",
    "text": "Session 1 objectives\nBy the end of this session, you can:\n\nexplain why datetime parsing is a correctness problem\nparse timestamps safely with errors=\"coerce\" and utc=True\nmeasure invalid timestamps (after parsing)\nadd time parts for grouping (month / day-of-week / hour)"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#why-datetimes-break-analytics-silently",
    "href": "W2_Data/D3_Feature_Engineering.html#why-datetimes-break-analytics-silently",
    "title": "Data Work (ETL + EDA)",
    "section": "Why datetimes break analytics (silently)",
    "text": "Why datetimes break analytics (silently)\nIf time is wrong, you get wrong:\n\ntrends and seasonality\n“before vs after” comparisons\n“most recent” sorting\ncohorts and retention\n\nDatetime bugs often don’t crash. They quietly lie."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#new-habit-parse-measure-proceed",
    "href": "W2_Data/D3_Feature_Engineering.html#new-habit-parse-measure-proceed",
    "title": "Data Work (ETL + EDA)",
    "section": "New habit: parse → measure → proceed",
    "text": "New habit: parse → measure → proceed\nWhen you parse time:\n\nParse with a safe rule\nCount how many values became missing\nDecide what to do (fix, drop, flag)\n\n\n\n\n\n\n\nTip\n\n\n“I parsed it” is not enough. You need the missing-after-parse count."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#pd.to_datetime-safe-defaults",
    "href": "W2_Data/D3_Feature_Engineering.html#pd.to_datetime-safe-defaults",
    "title": "Data Work (ETL + EDA)",
    "section": "pd.to_datetime safe defaults",
    "text": "pd.to_datetime safe defaults\nGood Week 2 default:\n\nerrors=\"coerce\" → invalid strings become missing values (measurable)\nutc=True → timestamps become UTC-aware (avoids mixing time zones)\n\n\n\n\n\n\n\nWarning\n\n\nIf your raw timestamps have mixed formats (e.g., 03/04/2025), you need a plan. Don’t guess."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#micro-exercise-parse-created_at-and-count-invalids-6-minutes",
    "href": "W2_Data/D3_Feature_Engineering.html#micro-exercise-parse-created_at-and-count-invalids-6-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: parse created_at and count invalids (6 minutes)",
    "text": "Micro-exercise: parse created_at and count invalids (6 minutes)\n\nLoad data/processed/orders_enriched.parquet\nParse created_at with errors=\"coerce\" and utc=True\nPrint:\n\ndtype of created_at\nnumber of missing timestamps after parsing\n\n\nCheckpoint: dtype is datetime-like and you can print n_missing_created_at."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#solution-example",
    "href": "W2_Data/D3_Feature_Engineering.html#solution-example",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\nimport pandas as pd\n\ndf = pd.read_parquet(\"data/processed/orders_enriched.parquet\")\ndt = pd.to_datetime(df[\"created_at\"], errors=\"coerce\", utc=True)\ndf = df.assign(created_at=dt)\n\nprint(\"dtype:\", df[\"created_at\"].dtype)\nprint(\"n_missing_created_at:\", int(df[\"created_at\"].isna().sum()))"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#time-parts-youll-actually-use",
    "href": "W2_Data/D3_Feature_Engineering.html#time-parts-youll-actually-use",
    "title": "Data Work (ETL + EDA)",
    "section": "Time parts you’ll actually use",
    "text": "Time parts you’ll actually use\nTime parts turn a timestamp into group keys:\n\nmonth (trend)\ndow (day-of-week)\nhour (hour-of-day)\n\n\n\n\n\n\n\nNote\n\n\n.dt only works after parsing to a datetime type."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#micro-exercise-add-time-parts-group-7-minutes",
    "href": "W2_Data/D3_Feature_Engineering.html#micro-exercise-add-time-parts-group-7-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: add time parts + group (7 minutes)",
    "text": "Micro-exercise: add time parts + group (7 minutes)\n\nStart from the parsed created_at\nAdd:\n\nmonth = created_at.dt.to_period(\"M\").astype(\"string\")\ndow = created_at.dt.day_name()\nhour = created_at.dt.hour\n\nCompute orders_per_month (count of rows per month)\n\nCheckpoint: you can print a small month table sorted by month."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#solution-example-1",
    "href": "W2_Data/D3_Feature_Engineering.html#solution-example-1",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\norders = (\n    df\n    .assign(\n        month=df[\"created_at\"].dt.to_period(\"M\").astype(\"string\"),\n        dow=df[\"created_at\"].dt.day_name(),\n        hour=df[\"created_at\"].dt.hour,\n    )\n)\n\norders_per_month = (\n    orders.groupby(\"month\", dropna=False)\n          .size()\n          .reset_index(name=\"n_orders\")\n          .sort_values(\"month\")\n)\nprint(orders_per_month)"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#new-pattern-.pipe-makes-transforms-readable",
    "href": "W2_Data/D3_Feature_Engineering.html#new-pattern-.pipe-makes-transforms-readable",
    "title": "Data Work (ETL + EDA)",
    "section": "New pattern: .pipe() makes transforms readable",
    "text": "New pattern: .pipe() makes transforms readable\n.pipe(fn, ...) lets you apply a function in a clean top-to-bottom flow.\norders = (\n    df\n    .pipe(parse_created_at)\n    .pipe(add_time_parts)\n)\n\nWe’ll use this in hands-on when we move parsing logic into bootcamp_data/transforms.py."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#micro-exercise-narrate-a-pipeline-3-minutes",
    "href": "W2_Data/D3_Feature_Engineering.html#micro-exercise-narrate-a-pipeline-3-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: narrate a pipeline (3 minutes)",
    "text": "Micro-exercise: narrate a pipeline (3 minutes)\nIn one sentence each, explain what these steps do:\n\nparse\nadd time parts\ngroup and summarize\n\nCheckpoint: you can explain the pipeline without reading code line-by-line."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#solution-a-good-narration",
    "href": "W2_Data/D3_Feature_Engineering.html#solution-a-good-narration",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution: a good narration",
    "text": "Solution: a good narration\n\nParse: convert time-like strings into real timestamps and measure invalids\nTime parts: create group keys like month/day/hour\nSummarize: aggregate counts/totals by those group keys"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#session-1-recap",
    "href": "W2_Data/D3_Feature_Engineering.html#session-1-recap",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 1 recap",
    "text": "Session 1 recap\n\nDatetimes are a correctness problem, not a formatting problem\nDefault: errors=\"coerce\" + measure missing-after-parse\nAdd time parts to create useful group keys\nUse .pipe() to keep transforms readable (df → df)"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#minutes",
    "href": "W2_Data/D3_Feature_Engineering.html#minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: we’ll handle outliers without corrupting the story."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#session-2-objectives",
    "href": "W2_Data/D3_Feature_Engineering.html#session-2-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 2 objectives",
    "text": "Session 2 objectives\nBy the end of this session, you can:\n\nexplain why outliers distort averages and charts\ncompute percentile summaries (p50/p90/p99)\ncompute IQR bounds and flag outliers\npick a safe policy: flag + (optional) cap for viz"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#outliers-not-delete-but-decide",
    "href": "W2_Data/D3_Feature_Engineering.html#outliers-not-delete-but-decide",
    "title": "Data Work (ETL + EDA)",
    "section": "Outliers: not “delete”, but “decide”",
    "text": "Outliers: not “delete”, but “decide”\nOutliers might be:\n\ndata entry mistakes\ngenuine rare events (VIP purchase)\nfraud / abuse\n\nRule for Week 2: don’t delete silently. Flag first."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#percentiles-quick-reality-check",
    "href": "W2_Data/D3_Feature_Engineering.html#percentiles-quick-reality-check",
    "title": "Data Work (ETL + EDA)",
    "section": "Percentiles = quick reality check",
    "text": "Percentiles = quick reality check\nUseful first look for a numeric column:\n\np50 (median) = “typical”\np90 = high but not extreme\np99 = top 1% threshold\n\nIf p99 is wildly bigger than p50, you may have a heavy tail or errors."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#micro-exercise-compute-p50p90p99-for-amount-6-minutes",
    "href": "W2_Data/D3_Feature_Engineering.html#micro-exercise-compute-p50p90p99-for-amount-6-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: compute p50/p90/p99 for amount (6 minutes)",
    "text": "Micro-exercise: compute p50/p90/p99 for amount (6 minutes)\n\nLoad orders_enriched.parquet\nDrop missing amount\nPrint p50/p90/p99\n\nCheckpoint: you can explain what p99 means in one sentence."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#solution-example-2",
    "href": "W2_Data/D3_Feature_Engineering.html#solution-example-2",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\nimport pandas as pd\n\ndf = pd.read_parquet(\"data/processed/orders_enriched.parquet\")\ns = df[\"amount\"].dropna()\nprint(s.quantile([0.5, 0.9, 0.99]))"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#robust-summary-single-average",
    "href": "W2_Data/D3_Feature_Engineering.html#robust-summary-single-average",
    "title": "Data Work (ETL + EDA)",
    "section": "Robust summary > single average",
    "text": "Robust summary &gt; single average\nIf data is skewed (common in money), the mean can be misleading.\nFor numeric EDA, always include:\n\nn (non-missing)\nmean and median\np25 / p75 (IQR) and a “tail” percentile (p90 or p95)\nmin / max (sanity)\n\n\n\n\n\n\n\nTip\n\n\nIf mean ≫ median, your “average” is being pulled by a small number of large values."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#micro-exercise-build-a-numeric-summary-table-for-amount-7-minutes",
    "href": "W2_Data/D3_Feature_Engineering.html#micro-exercise-build-a-numeric-summary-table-for-amount-7-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: build a numeric summary table for amount (7 minutes)",
    "text": "Micro-exercise: build a numeric summary table for amount (7 minutes)\nCreate a small summary table with rows:\nn, mean, median, p25, p75, p90, min, max\nCheckpoint: you can explain “median vs mean” in one sentence."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#solution-example-3",
    "href": "W2_Data/D3_Feature_Engineering.html#solution-example-3",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\nimport pandas as pd\n\ndf = pd.read_parquet(\"data/processed/orders_enriched.parquet\")\ns = pd.to_numeric(df[\"amount\"], errors=\"coerce\")\n\nsummary = pd.DataFrame(\n    {\n        \"metric\": [\"n\", \"mean\", \"median\", \"p25\", \"p75\", \"p90\", \"min\", \"max\"],\n        \"value\": [\n            int(s.notna().sum()),\n            float(s.mean()),\n            float(s.median()),\n            float(s.quantile(0.25)),\n            float(s.quantile(0.75)),\n            float(s.quantile(0.90)),\n            float(s.min()),\n            float(s.max()),\n        ],\n    }\n)\nprint(summary)"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#iqr-bounds-simple-outlier-flagging",
    "href": "W2_Data/D3_Feature_Engineering.html#iqr-bounds-simple-outlier-flagging",
    "title": "Data Work (ETL + EDA)",
    "section": "IQR bounds = simple outlier flagging",
    "text": "IQR bounds = simple outlier flagging\nIQR method:\n\nQ1 = 25th percentile\nQ3 = 75th percentile\nIQR = Q3 − Q1\nbounds = [Q1 − 1.5×IQR, Q3 + 1.5×IQR]\n\nWe use bounds to flag unusual values."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#micro-exercise-add-an-outlier-flag-compute-the-rate-7-minutes",
    "href": "W2_Data/D3_Feature_Engineering.html#micro-exercise-add-an-outlier-flag-compute-the-rate-7-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: add an outlier flag + compute the rate (7 minutes)",
    "text": "Micro-exercise: add an outlier flag + compute the rate (7 minutes)\n\nCompute IQR bounds for amount\nCreate amount__is_outlier\nPrint outlier rate (mean of the boolean)\n\nCheckpoint: you can print outlier_rate as a number between 0 and 1."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#solution-example-4",
    "href": "W2_Data/D3_Feature_Engineering.html#solution-example-4",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\nimport pandas as pd\n\ndf = pd.read_parquet(\"data/processed/orders_enriched.parquet\")\nx = df[\"amount\"].dropna()\nq1, q3 = x.quantile(0.25), x.quantile(0.75)\niqr = q3 - q1\nlo, hi = float(q1 - 1.5 * iqr), float(q3 + 1.5 * iqr)\n\ndf = df.assign(amount__is_outlier=(df[\"amount\"] &lt; lo) | (df[\"amount\"] &gt; hi))\nprint(\"bounds:\", lo, hi)\nprint(\"outlier_rate:\", float(df[\"amount__is_outlier\"].mean()))"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#capping-for-charts-winsorized-values",
    "href": "W2_Data/D3_Feature_Engineering.html#capping-for-charts-winsorized-values",
    "title": "Data Work (ETL + EDA)",
    "section": "Capping for charts: winsorized values",
    "text": "Capping for charts: winsorized values\nSometimes you want readable charts without deleting rows.\nWinsorization (simple version):\n\ncap values to [p1, p99]\nkeep all rows\n\n\n\n\n\n\n\nWarning\n\n\nUse capped values for visualization. Use raw values for final totals unless you have a business rule."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#micro-exercise-compare-top-countries-raw-vs-winsor-8-minutes",
    "href": "W2_Data/D3_Feature_Engineering.html#micro-exercise-compare-top-countries-raw-vs-winsor-8-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: compare top countries (raw vs winsor) (8 minutes)",
    "text": "Micro-exercise: compare top countries (raw vs winsor) (8 minutes)\n\nCreate amount_winsor by capping to p1/p99\nCompute top 5 countries by revenue using:\n\nraw amount\namount_winsor\n\nCompare: do the top 5 change?\n\nCheckpoint: you can answer: “Does capping change the story?”"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#solution-example-5",
    "href": "W2_Data/D3_Feature_Engineering.html#solution-example-5",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\nimport pandas as pd\n\ndf = pd.read_parquet(\"data/processed/orders_enriched.parquet\")\na, b = df[\"amount\"].dropna().quantile(0.01), df[\"amount\"].dropna().quantile(0.99)\ndf = df.assign(amount_winsor=df[\"amount\"].clip(lower=a, upper=b))\n\nraw = (\n    df.groupby(\"country\", dropna=False)[\"amount\"]\n      .sum()\n      .sort_values(ascending=False)\n      .head(5)\n)\ncap = (\n    df.groupby(\"country\", dropna=False)[\"amount_winsor\"]\n      .sum()\n      .sort_values(ascending=False)\n      .head(5)\n)\n\nprint(\"raw top 5:\\n\", raw)\nprint(\"\\ncapped top 5:\\n\", cap)"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#session-2-recap",
    "href": "W2_Data/D3_Feature_Engineering.html#session-2-recap",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 2 recap",
    "text": "Session 2 recap\n\nOutliers are a decision: flag first\nPercentiles tell you “typical vs extreme”\nIQR gives a simple outlier rule\nWinsorization helps charts without deleting rows"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#minutes-1",
    "href": "W2_Data/D3_Feature_Engineering.html#minutes-1",
    "title": "Data Work (ETL + EDA)",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: we’ll turn these ideas into a rerunnable report (and optional figures)."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#session-3-objectives",
    "href": "W2_Data/D3_Feature_Engineering.html#session-3-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 3 objectives",
    "text": "Session 3 objectives\nBy the end of this session, you can:\n\nexplain “tidy data” in one minute (variables / observations / units)\nbuild a monthly summary table with multiple metrics (n_orders, revenue, AOV)\nreshape wide → long with melt() (plotting-friendly)\nreshape long → wide with pivot_table() (report-friendly)\navoid accidental aggregation when reshaping"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#tidy-data-mental-model-the-10-second-version",
    "href": "W2_Data/D3_Feature_Engineering.html#tidy-data-mental-model-the-10-second-version",
    "title": "Data Work (ETL + EDA)",
    "section": "Tidy data mental model (the 10-second version)",
    "text": "Tidy data mental model (the 10-second version)\nA dataset is “tidy” when:\n\neach variable is a column\neach observation is a row\neach observational unit is its own table\n\nWhy you care: groupby + Plotly become much easier."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#long-vs-wide-when-to-use-which",
    "href": "W2_Data/D3_Feature_Engineering.html#long-vs-wide-when-to-use-which",
    "title": "Data Work (ETL + EDA)",
    "section": "Long vs wide: when to use which",
    "text": "Long vs wide: when to use which\nLong (tidy):\n\nbest for plotting (Plotly) and flexible grouping\ncolumns like: month, metric, value\n\nWide:\n\nbest for human-readable tables / CSV exports\ncolumns like: month, n_orders, revenue, aov\n\nRule of thumb: store features as normal tables; reshape for viz/reporting."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#example-monthly-metrics-table-wide",
    "href": "W2_Data/D3_Feature_Engineering.html#example-monthly-metrics-table-wide",
    "title": "Data Work (ETL + EDA)",
    "section": "Example: monthly metrics table (wide)",
    "text": "Example: monthly metrics table (wide)\nWe want one row per month:\n\nn_orders\nrevenue\naov (mean order amount)\n\nThis is perfect for a Markdown report."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#micro-exercise-build-a-monthly-metrics-table-7-minutes",
    "href": "W2_Data/D3_Feature_Engineering.html#micro-exercise-build-a-monthly-metrics-table-7-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: build a monthly metrics table (7 minutes)",
    "text": "Micro-exercise: build a monthly metrics table (7 minutes)\n\nStart from your transformed DataFrame with a month column\nGroup by month\nCompute:\n\nn_orders\nrevenue\naov (mean amount)\n\n\nCheckpoint: you can print a month table sorted by month."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#solution-example-6",
    "href": "W2_Data/D3_Feature_Engineering.html#solution-example-6",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\nmonthly = (\n    df.groupby(\"month\", dropna=False)\n      .agg(\n          n_orders=(\"order_id\", \"size\"),\n          revenue=(\"amount\", \"sum\"),\n          aov=(\"amount\", \"mean\"),\n      )\n      .reset_index()\n      .sort_values(\"month\")\n)\nprint(monthly.head(12))"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#melt-wide-long-plotting-friendly",
    "href": "W2_Data/D3_Feature_Engineering.html#melt-wide-long-plotting-friendly",
    "title": "Data Work (ETL + EDA)",
    "section": "melt() = wide → long (plotting-friendly)",
    "text": "melt() = wide → long (plotting-friendly)\nmelt turns metric columns into two columns:\n\nmetric (a category)\nvalue (a numeric value)\n\nThis is the format Plotly loves: x = month, y = value, color = metric."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#micro-exercise-melt-monthly-metrics-to-long-6-minutes",
    "href": "W2_Data/D3_Feature_Engineering.html#micro-exercise-melt-monthly-metrics-to-long-6-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: melt monthly metrics to long (6 minutes)",
    "text": "Micro-exercise: melt monthly metrics to long (6 minutes)\n\nStart from monthly (wide)\nConvert to long with:\n\nid_vars=[\"month\"]\nvalue_vars=[\"n_orders\",\"revenue\",\"aov\"]\n\n\nCheckpoint: your long table has columns: month, metric, value."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#solution-example-7",
    "href": "W2_Data/D3_Feature_Engineering.html#solution-example-7",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\nmonthly_long = monthly.melt(\n    id_vars=[\"month\"],\n    value_vars=[\"n_orders\", \"revenue\", \"aov\"],\n    var_name=\"metric\",\n    value_name=\"value\",\n)\nprint(monthly_long.head(10))"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#pivot_table-long-wide-report-friendly",
    "href": "W2_Data/D3_Feature_Engineering.html#pivot_table-long-wide-report-friendly",
    "title": "Data Work (ETL + EDA)",
    "section": "pivot_table() = long → wide (report-friendly)",
    "text": "pivot_table() = long → wide (report-friendly)\npivot_table is how you go back to wide.\nUse it when:\n\nyou want a “spreadsheet-like” table\nyou are sure the pivot keys uniquely identify rows (or you choose an explicit aggregation)"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#micro-exercise-pivot-long-wide-5-minutes",
    "href": "W2_Data/D3_Feature_Engineering.html#micro-exercise-pivot-long-wide-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro-exercise: pivot long → wide (5 minutes)",
    "text": "Micro-exercise: pivot long → wide (5 minutes)\n\nStart from monthly_long\nCreate a wide version again\nConfirm it has one row per month\n\nCheckpoint: row count equals number of distinct months."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#solution-example-8",
    "href": "W2_Data/D3_Feature_Engineering.html#solution-example-8",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\nmonthly_wide = (\n    monthly_long.pivot_table(\n        index=[\"month\"],\n        columns=\"metric\",\n        values=\"value\",\n        aggfunc=\"first\",  # safe because (month, metric) is unique here\n    )\n    .reset_index()\n)\nprint(monthly_wide.head(12))"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#pitfall-pivot-can-hide-accidental-aggregation",
    "href": "W2_Data/D3_Feature_Engineering.html#pitfall-pivot-can-hide-accidental-aggregation",
    "title": "Data Work (ETL + EDA)",
    "section": "Pitfall: “pivot” can hide accidental aggregation",
    "text": "Pitfall: “pivot” can hide accidental aggregation\nIf your keys are not unique, pivot_table will aggregate without yelling.\nSafer habits:\n\naggregate first (groupby → tidy summary), then pivot\nverify uniqueness (or expected row counts)\nchoose aggfunc intentionally (never rely on defaults)"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#end-of-day-artifacts-to-use-tomorrow",
    "href": "W2_Data/D3_Feature_Engineering.html#end-of-day-artifacts-to-use-tomorrow",
    "title": "Data Work (ETL + EDA)",
    "section": "End-of-day artifacts (to use tomorrow)",
    "text": "End-of-day artifacts (to use tomorrow)\nToday we will write:\n\ndata/processed/orders_features.parquet (analysis-ready features)\nreports/day3_eda_tables.md (tables + caveats)\nreports/day3_monthly_metrics_long.csv (plot-ready long form)\noptional: reports/day3_monthly_metrics_wide.csv (wide form for review)"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#session-3-recap",
    "href": "W2_Data/D3_Feature_Engineering.html#session-3-recap",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 3 recap",
    "text": "Session 3 recap\n\nLong = plotting-friendly, wide = report-friendly\nmelt() and pivot_table() are the bridge\nTomorrow’s charts become easy when today’s tables are tidy"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#minutes-2",
    "href": "W2_Data/D3_Feature_Engineering.html#minutes-2",
    "title": "Data Work (ETL + EDA)",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: we’ll build orders_features.parquet + day3_eda_tables.md + tidy reshape artifacts end-to-end."
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#hands-on-success-criteria-today",
    "href": "W2_Data/D3_Feature_Engineering.html#hands-on-success-criteria-today",
    "title": "Data Work (ETL + EDA)",
    "section": "Hands-on success criteria (today)",
    "text": "Hands-on success criteria (today)\nBy the end, you should have:\n\ndata/processed/orders_features.parquet (NEW)\nbootcamp_data/eda.py (updated helpers)\nupdated bootcamp_data/transforms.py with datetime + outlier helpers\nscripts/run_day3_features_and_tables.py (NEW runner)\nreports/day3_eda_tables.md\nreports/day3_monthly_metrics_long.csv (plot-ready long form)\noptional: reports/day3_monthly_metrics_wide.csv (wide form for review)"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#project-layout-after-today",
    "href": "W2_Data/D3_Feature_Engineering.html#project-layout-after-today",
    "title": "Data Work (ETL + EDA)",
    "section": "Project layout (after today)",
    "text": "Project layout (after today)\nbootcamp_data/\n  config.py\n  checks.py\n  transforms.py\n  eda.py\nscripts/\n  run_day1_load.py\n  run_day2_validate_and_report.py\n  run_day3_features_and_tables.py     # NEW today\ndata/processed/\n  orders_enriched.parquet\n  orders_features.parquet            # NEW today\nreports/\n  day2_summary.md\n  day3_eda_tables.md                 # NEW today\n  day3_monthly_metrics_long.csv      # NEW today\n  day3_monthly_metrics_wide.csv      # optional"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#task-0-confirm-day-2-artifacts-5-minutes",
    "href": "W2_Data/D3_Feature_Engineering.html#task-0-confirm-day-2-artifacts-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 0 — Confirm Day 2 artifacts (5 minutes)",
    "text": "Task 0 — Confirm Day 2 artifacts (5 minutes)\nFrom repo root, confirm these exist:\n\ndata/processed/orders_enriched.parquet\nreports/day2_summary.md\n\nmacOS/Linux\nls -la data/processed | sed -n '1,40p'\nls -la reports | sed -n '1,40p'\nWindows PowerShell\nGet-ChildItem data\\processed | Select-Object -First 20\nGet-ChildItem reports | Select-Object -First 20"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#task-1-upgrade-bootcamp_dataeda.py-25-minutes",
    "href": "W2_Data/D3_Feature_Engineering.html#task-1-upgrade-bootcamp_dataeda.py-25-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 1 — Upgrade bootcamp_data/eda.py (25 minutes)",
    "text": "Task 1 — Upgrade bootcamp_data/eda.py (25 minutes)\nIn bootcamp_data/eda.py, implement:\n\nmd_table(df, max_rows=10) → DataFrame → Markdown table string\ntop_k_table(df, group_col, value_col, k=10) → grouped totals table\ndescribe_numeric(df, col) → robust numeric summary (mean/median/quantiles)\nsummary_metrics(df) → top-line metrics (rows, revenue, missing timestamps, match rate, outlier rate)\nwrite_markdown_report(path, title, sections) → write a Markdown report from sections\n\nCheckpoint:\nuv run python -c \"from bootcamp_data.eda import describe_numeric, top_k_table; print('eda ok')\""
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#solution-bootcamp_dataeda.py-complete",
    "href": "W2_Data/D3_Feature_Engineering.html#solution-bootcamp_dataeda.py-complete",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — bootcamp_data/eda.py (complete)",
    "text": "Solution — bootcamp_data/eda.py (complete)\nfrom __future__ import annotations\n\nfrom pathlib import Path\n\nimport pandas as pd\n\n\ndef md_table(df: pd.DataFrame, max_rows: int = 10) -&gt; str:\n    view = df.head(max_rows).copy().astype(\"string\").fillna(\"\")\n    cols = list(view.columns)\n    header = \"| \" + \" | \".join(cols) + \" |\"\n    sep = \"| \" + \" | \".join([\"---\"] * len(cols)) + \" |\"\n    rows = [\"| \" + \" | \".join(row) + \" |\" for row in view.itertuples(index=False, name=None)]\n    tail = \"\" if len(df) &lt;= max_rows else f\"\\n\\n::: {{.muted}}Showing first {max_rows} of {len(df)} rows.:::\\n\"\n    return \"\\n\".join([header, sep, *rows]) + tail\n\n\ndef top_k_table(df: pd.DataFrame, group_col: str, value_col: str, k: int = 10) -&gt; pd.DataFrame:\n    return (\n        df.groupby(group_col, dropna=False)[value_col]\n          .agg(n=\"size\", total=\"sum\")\n          .reset_index()\n          .sort_values(\"total\", ascending=False)\n          .head(k)\n    )\n\n\ndef describe_numeric(df: pd.DataFrame, col: str) -&gt; pd.DataFrame:\n    s = pd.to_numeric(df[col], errors=\"coerce\")\n    return pd.DataFrame(\n        {\n            \"metric\": [\"n\", \"mean\", \"median\", \"p25\", \"p75\", \"p90\", \"min\", \"max\"],\n            \"value\": [\n                int(s.notna().sum()),\n                float(s.mean()),\n                float(s.median()),\n                float(s.quantile(0.25)),\n                float(s.quantile(0.75)),\n                float(s.quantile(0.90)),\n                float(s.min()),\n                float(s.max()),\n            ],\n        }\n    )\n\n\ndef summary_metrics(df: pd.DataFrame) -&gt; pd.DataFrame:\n    rows = len(df)\n    revenue = df[\"amount\"].sum(min_count=1) if \"amount\" in df.columns else None\n    missing_ts = df[\"created_at\"].isna().sum() if \"created_at\" in df.columns else None\n\n    match_rate = None\n    if \"user_found\" in df.columns:\n        match_rate = float(df[\"user_found\"].mean())\n    elif \"country\" in df.columns:\n        match_rate = 1.0 - float(df[\"country\"].isna().mean())\n\n    outlier_rate = float(df[\"amount__is_outlier\"].mean()) if \"amount__is_outlier\" in df.columns else None\n\n    out = pd.DataFrame(\n        {\n            \"metric\": [\"rows\", \"revenue_sum\", \"missing_created_at\", \"user_match_rate\", \"outlier_rate\"],\n            \"value\": [rows, revenue, missing_ts, match_rate, outlier_rate],\n        }\n    )\n    return out.dropna(subset=[\"value\"])\n\n\ndef write_markdown_report(path: Path, title: str, sections: list[tuple[str, str]]) -&gt; None:\n    path.parent.mkdir(parents=True, exist_ok=True)\n    parts = [f\"# {title}\\n\"]\n    for h, body in sections:\n        parts.append(f\"## {h}\\n\\n{body}\\n\")\n    path.write_text(\"\\n\".join(parts), encoding=\"utf-8\")"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#task-2-add-datetime-outlier-transforms-20-minutes",
    "href": "W2_Data/D3_Feature_Engineering.html#task-2-add-datetime-outlier-transforms-20-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 2 — Add datetime + outlier transforms (20 minutes)",
    "text": "Task 2 — Add datetime + outlier transforms (20 minutes)\nIn bootcamp_data/transforms.py, add:\n\nparse_datetime(df, col, utc=True)\nadd_time_parts(df, ts_col) → month/dow/hour\niqr_bounds(s, k=1.5)\nwinsorize(s, lo=0.01, hi=0.99)\nadd_outlier_flag(df, col, k=1.5)\n\nCheckpoint:\nuv run python -c \"from bootcamp_data.transforms import add_time_parts, winsorize; print('transforms ok')\""
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#solution-transforms-datetime-outliers",
    "href": "W2_Data/D3_Feature_Engineering.html#solution-transforms-datetime-outliers",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — transforms (datetime + outliers)",
    "text": "Solution — transforms (datetime + outliers)\nimport pandas as pd\n\n\ndef parse_datetime(df: pd.DataFrame, col: str, *, utc: bool = True) -&gt; pd.DataFrame:\n    dt = pd.to_datetime(df[col], errors=\"coerce\", utc=utc)\n    return df.assign(**{col: dt})\n\n\ndef add_time_parts(df: pd.DataFrame, ts_col: str) -&gt; pd.DataFrame:\n    ts = df[ts_col]\n    return df.assign(\n        month=ts.dt.to_period(\"M\").astype(\"string\"),\n        dow=ts.dt.day_name(),\n        hour=ts.dt.hour,\n    )\n\n\ndef iqr_bounds(s: pd.Series, k: float = 1.5) -&gt; tuple[float, float]:\n    x = s.dropna()\n    q1, q3 = x.quantile(0.25), x.quantile(0.75)\n    iqr = q3 - q1\n    return float(q1 - k * iqr), float(q3 + k * iqr)\n\n\ndef winsorize(s: pd.Series, lo: float = 0.01, hi: float = 0.99) -&gt; pd.Series:\n    x = s.dropna()\n    a, b = x.quantile(lo), x.quantile(hi)\n    return s.clip(lower=a, upper=b)\n\n\ndef add_outlier_flag(df: pd.DataFrame, col: str, *, k: float = 1.5) -&gt; pd.DataFrame:\n    lo, hi = iqr_bounds(df[col], k=k)\n    return df.assign(**{f\"{col}__is_outlier\": (df[col] &lt; lo) | (df[col] &gt; hi)})"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#task-3-create-scriptsrun_day3_features_and_tables.py-40-minutes",
    "href": "W2_Data/D3_Feature_Engineering.html#task-3-create-scriptsrun_day3_features_and_tables.py-40-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 3 — Create scripts/run_day3_features_and_tables.py (40 minutes)",
    "text": "Task 3 — Create scripts/run_day3_features_and_tables.py (40 minutes)\nCreate a new runner that:\n\nreads data/processed/orders_enriched.parquet\nverifies required columns\nparses created_at and adds time parts\nadds amount_winsor + amount__is_outlier\nwrites data/processed/orders_features.parquet\nbuilds a monthly metrics table (wide) and a melted long form table\nwrites:\n\nreports/day3_eda_tables.md\nreports/day3_monthly_metrics_long.csv\noptional: reports/day3_monthly_metrics_wide.csv"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#hint-run-your-runner-as-a-module",
    "href": "W2_Data/D3_Feature_Engineering.html#hint-run-your-runner-as-a-module",
    "title": "Data Work (ETL + EDA)",
    "section": "Hint — run your runner as a module",
    "text": "Hint — run your runner as a module\nThis keeps imports stable (no sys.path hacks).\nmacOS/Linux\nuv run python -m scripts.run_day3_features_and_tables\nWindows PowerShell\nuv run python -m scripts.run_day3_features_and_tables"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#solution-runner-step-1-load-verify",
    "href": "W2_Data/D3_Feature_Engineering.html#solution-runner-step-1-load-verify",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — runner (step 1: load + verify)",
    "text": "Solution — runner (step 1: load + verify)\nPut this in scripts/run_day3_features_and_tables.py:\nfrom __future__ import annotations\n\nimport logging\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom bootcamp_data.checks import assert_non_empty, require_columns\nfrom bootcamp_data.eda import describe_numeric, md_table, summary_metrics, top_k_table, write_markdown_report\nfrom bootcamp_data.transforms import add_outlier_flag, add_time_parts, parse_datetime, winsorize\n\nlog = logging.getLogger(__name__)\n\n\ndef main() -&gt; None:\n    logging.basicConfig(level=logging.INFO, format=\"%(levelname)s %(name)s: %(message)s\")\n    root = Path(__file__).resolve().parents[1]\n\n    in_path = root / \"data\" / \"processed\" / \"orders_enriched.parquet\"\n    df = pd.read_parquet(in_path)\n\n    require_columns(\n        df,\n        [\"order_id\", \"user_id\", \"amount\", \"status_clean\", \"created_at\", \"country\"],\n        df_name=\"orders_enriched\",\n    )\n    assert_non_empty(df, df_name=\"orders_enriched\")"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#solution-runner-step-2-build-features-save",
    "href": "W2_Data/D3_Feature_Engineering.html#solution-runner-step-2-build-features-save",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — runner (step 2: build features + save)",
    "text": "Solution — runner (step 2: build features + save)\nContinue inside main():\n    features = (\n        df.pipe(parse_datetime, col=\"created_at\", utc=True)\n          .pipe(add_time_parts, ts_col=\"created_at\")\n          .assign(amount_winsor=lambda d: winsorize(d[\"amount\"]))\n          .pipe(add_outlier_flag, col=\"amount\", k=1.5)\n    )\n\n    out_features = root / \"data\" / \"processed\" / \"orders_features.parquet\"\n    out_features.parent.mkdir(parents=True, exist_ok=True)\n    features.to_parquet(out_features, index=False)\n    log.info(\"wrote: %s (%s rows)\", out_features, len(features))"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#solution-runner-step-3-monthly-tables-reshape-samples",
    "href": "W2_Data/D3_Feature_Engineering.html#solution-runner-step-3-monthly-tables-reshape-samples",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — runner (step 3: monthly tables + reshape samples)",
    "text": "Solution — runner (step 3: monthly tables + reshape samples)\nContinue inside main():\n    monthly = (\n        features.groupby(\"month\", dropna=False)\n                .agg(\n                    n_orders=(\"order_id\", \"size\"),\n                    revenue=(\"amount\", \"sum\"),\n                    aov=(\"amount\", \"mean\"),\n                )\n                .reset_index()\n                .sort_values(\"month\")\n    )\n\n    monthly_long = monthly.melt(\n        id_vars=[\"month\"],\n        value_vars=[\"n_orders\", \"revenue\", \"aov\"],\n        var_name=\"metric\",\n        value_name=\"value\",\n    )\n\n    monthly_wide = (\n        monthly_long.pivot_table(index=[\"month\"], columns=\"metric\", values=\"value\", aggfunc=\"first\")\n                   .reset_index()\n    )\n\n    reports = root / \"reports\"\n    reports.mkdir(parents=True, exist_ok=True)\n    monthly_long.to_csv(reports / \"day3_monthly_metrics_long.csv\", index=False)\n    monthly_wide.to_csv(reports / \"day3_monthly_metrics_wide.csv\", index=False)"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#solution-runner-step-4-write-the-markdown-tables-report",
    "href": "W2_Data/D3_Feature_Engineering.html#solution-runner-step-4-write-the-markdown-tables-report",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — runner (step 4: write the Markdown tables report)",
    "text": "Solution — runner (step 4: write the Markdown tables report)\nContinue inside main():\n    metrics = summary_metrics(features)\n    amount_desc = describe_numeric(features, \"amount\")\n    by_month = monthly.head(24)  # show first ~2 years if present\n    by_country = top_k_table(features, \"country\", \"amount\", k=10)\n    by_status = top_k_table(features, \"status_clean\", \"amount\", k=10)\n\n    caveats = (\n        \"- `created_at` was parsed with `errors='coerce'`; invalid timestamps become missing.\\n\"\n        \"- Outliers are **flagged** (`amount__is_outlier`). For charts we may cap values (`amount_winsor`).\\n\"\n        \"- Join coverage may be &lt; 100% (see match rate).\"\n    )\n\n    out_report = reports / \"day3_eda_tables.md\"\n    sections = [\n        (\"Top-line metrics\", md_table(metrics)),\n        (\"Amount summary (robust stats)\", md_table(amount_desc)),\n        (\"Monthly metrics (wide)\", md_table(by_month, max_rows=24)),\n        (\"Revenue by country (top 10)\", md_table(by_country)),\n        (\"Revenue by status_clean (top 10)\", md_table(by_status)),\n        (\"Data caveats\", caveats),\n        (\"Files written\", \"- `data/processed/orders_features.parquet`\\n- `reports/day3_monthly_metrics_long.csv`\"),\n    ]\n    write_markdown_report(out_report, title=\"Day 3 — Feature table + EDA tables\", sections=sections)\n    log.info(\"wrote: %s\", out_report)\n\n\nif __name__ == \"__main__\":\n    main()"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#task-4-run-verify-artifacts-10-minutes",
    "href": "W2_Data/D3_Feature_Engineering.html#task-4-run-verify-artifacts-10-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 4 — Run + verify artifacts (10 minutes)",
    "text": "Task 4 — Run + verify artifacts (10 minutes)\nmacOS/Linux\nuv run python -m scripts.run_day3_features_and_tables\nls -la data/processed | sed -n '1,60p'\nls -la reports | sed -n '1,60p'\nWindows PowerShell\nuv run python -m scripts.run_day3_features_and_tables\nGet-ChildItem data\\processed | Select-Object -First 30\nGet-ChildItem reports | Select-Object -First 30\nCheckpoint: these files exist:\n\ndata/processed/orders_features.parquet\nreports/day3_eda_tables.md\nreports/day3_monthly_metrics_long.csv"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#git-checkpoint-5-minutes",
    "href": "W2_Data/D3_Feature_Engineering.html#git-checkpoint-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Git checkpoint (5 minutes)",
    "text": "Git checkpoint (5 minutes)\n\ngit status\ncommit with message: \"w2d3: features + tidy tables\"\npush"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#solution-git-commands",
    "href": "W2_Data/D3_Feature_Engineering.html#solution-git-commands",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution — git commands",
    "text": "Solution — git commands\ngit add -A\ngit commit -m \"w2d3: features + tidy tables\"\ngit push"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#debug-playbook-day-3",
    "href": "W2_Data/D3_Feature_Engineering.html#debug-playbook-day-3",
    "title": "Data Work (ETL + EDA)",
    "section": "Debug playbook (Day 3)",
    "text": "Debug playbook (Day 3)\nWhen results look wrong:\n\nDatetimes: created_at dtype + missing-after-parse count\nTime parts: check month/dow/hour exist and look reasonable\nOutliers: print p50/p99 + outlier rate\nJoin coverage: check user_found (if present) or % missing country\nReshape sanity: monthly_long should have n_months × 3 rows\nReproducibility: rerun the script from a fresh terminal"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#stretch-goals-optional",
    "href": "W2_Data/D3_Feature_Engineering.html#stretch-goals-optional",
    "title": "Data Work (ETL + EDA)",
    "section": "Stretch goals (optional)",
    "text": "Stretch goals (optional)\nIf you finish early:\n\nAdd a second grouped table:\n\norders by dow (day-of-week)\nrevenue by hour\n\nSave a second long-form table for tomorrow:\n\nreports/day3_by_dow_long.csv\n\nAdd a small run metadata JSON:\n\nreports/day3_run_meta.json (rows, missing timestamps, match rate, outlier rate)"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#exit-ticket",
    "href": "W2_Data/D3_Feature_Engineering.html#exit-ticket",
    "title": "Data Work (ETL + EDA)",
    "section": "Exit Ticket",
    "text": "Exit Ticket\nIn 1–2 sentences:\nWhen would you use melt() vs pivot_table()?"
  },
  {
    "objectID": "W2_Data/D3_Feature_Engineering.html#what-to-do-after-class-day-3-assignment",
    "href": "W2_Data/D3_Feature_Engineering.html#what-to-do-after-class-day-3-assignment",
    "title": "Data Work (ETL + EDA)",
    "section": "What to do after class (Day 3 assignment)",
    "text": "What to do after class (Day 3 assignment)\nDue: before Day 4 starts\n\nEnsure this runs from repo root:\n\nuv run python -m scripts.run_day3_features_and_tables\n\nCommit + push your changes\nConfirm these artifacts exist:\n\ndata/processed/orders_features.parquet\nreports/day3_eda_tables.md\nreports/day3_monthly_metrics_long.csv\n\n\nDeliverable: GitHub repo link + screenshot of reports/day3_eda_tables.md preview.\n\n\n\n\n\n\nTip\n\n\nTomorrow (Day 4) you should only need to read orders_features.parquet and plot."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#todays-flow",
    "href": "W2_Data/D5_Data_Product.html#todays-flow",
    "title": "Data Work (ETL + EDA)",
    "section": "Today’s Flow",
    "text": "Today’s Flow\n\nSession 1 (60m): Quality gates + “what does trustworthy mean?”\nAsr Prayer (20m)\nSession 2 (60m): One‑command rebuild + run metadata (Typer CLI)\nMaghrib Prayer (20m)\nSession 3 (60m): DuckDB SQL lens + handoff docs + ship checklist\nIsha Prayer (20m)\nHands‑on (120m): Implement contract + rebuild CLI + run meta + DuckDB queries + handoff"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#learning-objectives",
    "href": "W2_Data/D5_Data_Product.html#learning-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of today, you can:\n\nadd a quality gate that fails fast with actionable messages\ndefine a lightweight data contract for orders_features.parquet\nbuild a one‑command rebuild using Typer (builds on Week 1)\nwrite run metadata (data/processed/_run_meta.json) and a schema summary\nuse DuckDB to query local Parquet (SQL as an analytics lens)\nwrite a clear handoff: how to run, what files matter, what caveats exist"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#warmup-5-minutes",
    "href": "W2_Data/D5_Data_Product.html#warmup-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Warm‑up (5 minutes)",
    "text": "Warm‑up (5 minutes)\nRerun Day 4 and confirm outputs exist.\nmacOS/Linux\nuv run python -m scripts.run_day4_publish --top-k 5 --figures\nls -la reports\nls -la data/processed\nls -la reports/figures\nWindows PowerShell\nuv run python -m scripts.run_day4_publish --top-k 5 --figures\ndir reports\ndir data\\processed\ndir reports\\figures\nCheckpoint: these exist:\n\nreports/day4_publishable_report.md\nreports/day4_data_dictionary.md\ndata/processed/orders_features.parquet\n\n\n\n\n\n\n\nNote\n\n\nIf reports/figures/ is empty, that’s okay. Figures are optional and offline‑friendly."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#quick-review-week-2-pipeline-so-far",
    "href": "W2_Data/D5_Data_Product.html#quick-review-week-2-pipeline-so-far",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick review: Week 2 pipeline so far",
    "text": "Quick review: Week 2 pipeline so far\n\nDay 2: verify + clean + join → orders_enriched.parquet + reports/day2_summary.md\nDay 3: trusted EDA tables → reports/day3_eda.md (+ optional figures)\nDay 4: publishable report + feature table + data dictionary\n\nToday: add guardrails + audit trail so a teammate can rebuild and trust the artifacts.\n\nOffline‑first: everything runs locally from data/raw/ + data/processed/."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#session-1-objectives",
    "href": "W2_Data/D5_Data_Product.html#session-1-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 1 objectives",
    "text": "Session 1 objectives\nBy the end of this session, you can:\n\nexplain a “quality gate” in one sentence\ndefine a practical data contract for a table\nadd dtype + range checks without being brittle\ndecide where the contract runs (pipeline + rebuild)"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#trustworthy-data-product-3-things",
    "href": "W2_Data/D5_Data_Product.html#trustworthy-data-product-3-things",
    "title": "Data Work (ETL + EDA)",
    "section": "Trustworthy data product = 3 things",
    "text": "Trustworthy data product = 3 things\n\nRepeatable: rerun produces the same outputs (idempotent)\nChecked: assumptions are enforced (quality gates)\nAuditable: you can answer “what ran?” (run metadata)\n\nToday we implement (2) + (3)."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#why-a-quality-gate",
    "href": "W2_Data/D5_Data_Product.html#why-a-quality-gate",
    "title": "Data Work (ETL + EDA)",
    "section": "Why a “quality gate”?",
    "text": "Why a “quality gate”?\nWithout a gate:\n\nyour report can silently change when data changes\njoins can quietly drop coverage (or explode rows)\ndtypes can drift (IDs become numbers, leading zeros disappear)\n\nWith a gate:\n\nthe pipeline fails fast with a message that tells you what to fix"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#data-contract-practical-definition",
    "href": "W2_Data/D5_Data_Product.html#data-contract-practical-definition",
    "title": "Data Work (ETL + EDA)",
    "section": "Data contract (practical definition)",
    "text": "Data contract (practical definition)\nA data contract is a small, explicit list of promises about a table:\n\nrequired columns exist\nkey rules hold (e.g., unique order_id)\ndtypes are safe (IDs are strings)\nbasic ranges make sense (non‑negative amounts, hour in 0–23)\n\n\n\n\n\n\n\nTip\n\n\nContracts are just composed checks. No new framework."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#contract-in-code-one-function",
    "href": "W2_Data/D5_Data_Product.html#contract-in-code-one-function",
    "title": "Data Work (ETL + EDA)",
    "section": "Contract in code (one function)",
    "text": "Contract in code (one function)\n\n\nMental model\n\nOne function per “important table”\nUses bootcamp_data.checks inside\nRaises clear errors\nReturns nothing on success\n\nToday we contract‑check orders_features.parquet.\n\nShape\ndef validate_orders_features(df):\n    # 1) columns + non-empty\n    # 2) keys\n    # 3) dtypes\n    # 4) ranges\n    return None  # success"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#microexercise-design-the-contract-6-minutes",
    "href": "W2_Data/D5_Data_Product.html#microexercise-design-the-contract-6-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro‑exercise: design the contract (6 minutes)",
    "text": "Micro‑exercise: design the contract (6 minutes)\nIn pairs, write a minimal contract for orders_features:\n\n5 required columns you will enforce\n1 key rule you will enforce\n2 range rules you will enforce\n\nCheckpoint: every rule can be checked automatically in code."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#solution-a-minimal-contract-example",
    "href": "W2_Data/D5_Data_Product.html#solution-a-minimal-contract-example",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution: a minimal contract (example)",
    "text": "Solution: a minimal contract (example)\nA reasonable minimum set:\n\nRequired columns: order_id, user_id, amount, created_at, hour\nKey rule: order_id is unique and non‑missing\nRange rules:\n\namount &gt;= 0\nhour is in [0, 23] (after parsing)\n\n\n\n\n\n\n\n\nNote\n\n\nYour contract can be stricter later. Start minimal, then tighten."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#dtype-checks-that-wont-fight-you",
    "href": "W2_Data/D5_Data_Product.html#dtype-checks-that-wont-fight-you",
    "title": "Data Work (ETL + EDA)",
    "section": "Dtype checks that won’t fight you",
    "text": "Dtype checks that won’t fight you\nUse pandas.api.types instead of comparing dtype strings.\nfrom pandas.api.types import is_numeric_dtype, is_string_dtype\n\nis_string_dtype(df[\"order_id\"])  # True when IDs are safe\nis_numeric_dtype(df[\"amount\"])   # True for Float64 / Int64 / etc.\n\n\n\n\n\n\nWarning\n\n\nIf order_id becomes an int, you may permanently lose leading zeros."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#quick-check",
    "href": "W2_Data/D5_Data_Product.html#quick-check",
    "title": "Data Work (ETL + EDA)",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: Where should the contract run?\n\nAnswer: at least before publishing/handoff, and again in the one‑command rebuild."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#session-1-recap",
    "href": "W2_Data/D5_Data_Product.html#session-1-recap",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 1 recap",
    "text": "Session 1 recap\n\nA quality gate makes your pipeline trustworthy\nA contract is a small set of explicit promises about a table\nUse pandas.api.types for dtype checks\nStart minimal → tighten over time"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#minutes",
    "href": "W2_Data/D5_Data_Product.html#minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: we’ll build a one‑command rebuild and write run metadata."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#session-2-objectives",
    "href": "W2_Data/D5_Data_Product.html#session-2-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 2 objectives",
    "text": "Session 2 objectives\nBy the end of this session, you can:\n\nexplain why “one command” matters for teams\nbuild a small Typer CLI that orchestrates Day 2 → Day 4\nverify output files (exists + non‑empty)\nwrite run metadata and a schema summary"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#why-one-command",
    "href": "W2_Data/D5_Data_Product.html#why-one-command",
    "title": "Data Work (ETL + EDA)",
    "section": "Why “one command”?",
    "text": "Why “one command”?\nA teammate should not have to remember 6 steps.\nOne command gives you:\n\nreproducibility (same steps, same order)\nless “it works on my laptop”\na natural place to run the contract gate\na natural place to write run metadata"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#why-typer-today",
    "href": "W2_Data/D5_Data_Product.html#why-typer-today",
    "title": "Data Work (ETL + EDA)",
    "section": "Why Typer (today)?",
    "text": "Why Typer (today)?\nWeek 1 already taught you Typer CLIs.\nWe use Typer today because:\n\n--help is automatic and pleasant\noptions are typed (int, bool, optional strings)\nit’s the same mental model as Week 1: commands call reusable functions\n\n\n\n\n\n\n\nTip\n\n\nWe are not building a fancy CLI. Just one command: rebuild."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#cli-shape-minimal",
    "href": "W2_Data/D5_Data_Product.html#cli-shape-minimal",
    "title": "Data Work (ETL + EDA)",
    "section": "CLI shape (minimal)",
    "text": "CLI shape (minimal)\nimport typer\n\napp = typer.Typer(add_completion=False)\n\n@app.command()\ndef rebuild(top_k: int = 10, figures: bool = False):\n    ...\n\nif __name__ == \"__main__\":\n    app()\nRun it like:\nuv run python -m bootcamp_data.cli rebuild --top-k 10 --figures"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#orchestration-pattern-simple-crossplatform",
    "href": "W2_Data/D5_Data_Product.html#orchestration-pattern-simple-crossplatform",
    "title": "Data Work (ETL + EDA)",
    "section": "Orchestration pattern (simple + cross‑platform)",
    "text": "Orchestration pattern (simple + cross‑platform)\nWe will call your existing scripts using subprocess.run.\nKey habits:\n\nuse sys.executable (works inside uv run)\nrun modules with -m scripts... (import‑safe)\nset cwd=ROOT (paths are correct)"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#verification-files-exist-nonempty",
    "href": "W2_Data/D5_Data_Product.html#verification-files-exist-nonempty",
    "title": "Data Work (ETL + EDA)",
    "section": "Verification: files exist + non‑empty",
    "text": "Verification: files exist + non‑empty\nAfter running scripts, verify the artifacts.\nfrom pathlib import Path\n\ndef require_file(path: Path) -&gt; None:\n    if not path.exists():\n        raise FileNotFoundError(f\"Missing: {path}\")\n    if path.stat().st_size == 0:\n        raise ValueError(f\"Empty file: {path}\")"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#new-concept-run-metadata-audit-trail",
    "href": "W2_Data/D5_Data_Product.html#new-concept-run-metadata-audit-trail",
    "title": "Data Work (ETL + EDA)",
    "section": "New concept: run metadata (audit trail)",
    "text": "New concept: run metadata (audit trail)\nRun metadata answers:\n\nwhat inputs were used?\nwhat outputs were written?\nhow many rows were produced?\nwhen did it run?\n(optional) what git commit produced these results?\n\nWhy it matters: when numbers change, you can debug what changed."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#minimal-run-metadata-json-template",
    "href": "W2_Data/D5_Data_Product.html#minimal-run-metadata-json-template",
    "title": "Data Work (ETL + EDA)",
    "section": "Minimal run metadata JSON (template)",
    "text": "Minimal run metadata JSON (template)\nWrite to: data/processed/_run_meta.json\n{\n  \"timestamp_utc\": \"2025-12-25T09:15:00Z\",\n  \"git_commit\": \"abc123...\",\n  \"args\": {\"top_k\": 10, \"figures\": false},\n  \"rows\": {\"orders_enriched\": 12034, \"orders_features\": 12034},\n  \"outputs\": [\n    \"data/processed/orders_features.parquet\",\n    \"reports/day4_publishable_report.md\"\n  ]\n}\n\n\n\n\n\n\nTip\n\n\nKeep it small and truthful. You can always add fields later."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#schema-summary-quick-useful",
    "href": "W2_Data/D5_Data_Product.html#schema-summary-quick-useful",
    "title": "Data Work (ETL + EDA)",
    "section": "Schema summary (quick, useful)",
    "text": "Schema summary (quick, useful)\nWrite a small schema/missingness table for the handoff.\nTarget path: reports/schema_summary.csv\nColumns:\n\ncolumn\ndtype\nn_missing"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#session-2-recap",
    "href": "W2_Data/D5_Data_Product.html#session-2-recap",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 2 recap",
    "text": "Session 2 recap\n\nOne‑command rebuild = team‑friendly reproducibility\nTyper gives you a clean, typed CLI interface\nVerify key artifacts (exists + non‑empty)\nWrite run metadata + schema summary so runs are auditable"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#minutes-1",
    "href": "W2_Data/D5_Data_Product.html#minutes-1",
    "title": "Data Work (ETL + EDA)",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: we’ll use DuckDB to query your Parquet and then finish the handoff."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#session-3-objectives",
    "href": "W2_Data/D5_Data_Product.html#session-3-objectives",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 3 objectives",
    "text": "Session 3 objectives\nBy the end of this session, you can:\n\nrun 2–3 useful analytics queries using DuckDB on Parquet\nexplain when SQL is simpler than pandas\nwrite a handoff doc that enables “clone → run → trust”\nfinish a ship checklist (rebuild + artifacts + caveats)"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#why-duckdb",
    "href": "W2_Data/D5_Data_Product.html#why-duckdb",
    "title": "Data Work (ETL + EDA)",
    "section": "Why DuckDB?",
    "text": "Why DuckDB?\nDuckDB is:\n\nzero‑setup SQL analytics on local files (CSV/Parquet)\nfast and convenient for groupby/join style questions\na bridge to “real” SQL environments later\n\n\n\n\n\n\n\nNote\n\n\nWe use DuckDB as an analytics lens, not as the source of truth for transforms."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#duckdb-pattern-query-parquet-directly",
    "href": "W2_Data/D5_Data_Product.html#duckdb-pattern-query-parquet-directly",
    "title": "Data Work (ETL + EDA)",
    "section": "DuckDB pattern: query Parquet directly",
    "text": "DuckDB pattern: query Parquet directly\nimport duckdb\n\nsql = '''\nSELECT\n  country,\n  COUNT(*) AS n,\n  SUM(amount) AS revenue\nFROM read_parquet('data/processed/orders_features.parquet')\nGROUP BY 1\nORDER BY revenue DESC\nLIMIT 10\n'''\ndf = duckdb.query(sql).df()\nprint(df.head())"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#microexercise-write-a-time-trend-query-6-minutes",
    "href": "W2_Data/D5_Data_Product.html#microexercise-write-a-time-trend-query-6-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Micro‑exercise: write a time trend query (6 minutes)",
    "text": "Micro‑exercise: write a time trend query (6 minutes)\nWrite a SQL query that returns:\n\nmonth\nn_orders\nrevenue\n\nSorted by month ascending.\nCheckpoint: your query uses GROUP BY."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#solution-example",
    "href": "W2_Data/D5_Data_Product.html#solution-example",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (example)",
    "text": "Solution (example)\nSELECT\n  month,\n  COUNT(*) AS n_orders,\n  SUM(amount) AS revenue\nFROM read_parquet('data/processed/orders_features.parquet')\nGROUP BY 1\nORDER BY month ASC"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#what-should-duckdb-output",
    "href": "W2_Data/D5_Data_Product.html#what-should-duckdb-output",
    "title": "Data Work (ETL + EDA)",
    "section": "What should DuckDB output?",
    "text": "What should DuckDB output?\nKeep it simple:\n\nwrite query results to reports/ as CSV\nlink the CSV in your handoff\n\nExample:\n\nreports/day5_duckdb_top_countries.csv\nreports/day5_duckdb_monthly_revenue.csv"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#handoff-doc-template-reportshandoff.md",
    "href": "W2_Data/D5_Data_Product.html#handoff-doc-template-reportshandoff.md",
    "title": "Data Work (ETL + EDA)",
    "section": "Handoff doc template: reports/handoff.md",
    "text": "Handoff doc template: reports/handoff.md\n# Week 2 Handoff (Data Work)\n\n## Quick start (5 minutes)\n1) uv run python -m bootcamp_data.cli rebuild --top-k 10 --figures\n2) Open reports/day4_publishable_report.md\n\n## Key artifacts\n- data/processed/orders_features.parquet\n- reports/day4_publishable_report.md\n- reports/day4_data_dictionary.md\n- data/processed/_run_meta.json\n- reports/schema_summary.csv\n\n## Optional SQL artifacts (DuckDB)\n- reports/day5_duckdb_top_countries.csv\n- reports/day5_duckdb_monthly_revenue.csv\n\n## Data quality caveats\n- Missingness: ...\n- Join coverage: ...\n- Outliers/winsorization: ...\n\n## Troubleshooting\n- Run from repo root\n- Rerun rebuild\n- If date filters empty the data, adjust --start-date/--end-date"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#week-2-ship-checklist",
    "href": "W2_Data/D5_Data_Product.html#week-2-ship-checklist",
    "title": "Data Work (ETL + EDA)",
    "section": "Week 2 ship checklist",
    "text": "Week 2 ship checklist\nBefore you call it “done”:\n\n✅ uv run python -m bootcamp_data.cli rebuild succeeds from repo root\n✅ orders_features.parquet exists and contract check passes\n✅ run metadata exists: data/processed/_run_meta.json\n✅ schema summary exists: reports/schema_summary.csv\n✅ Day 4 report is readable (metrics + tables + caveats)\n✅ data dictionary exists and matches the feature table\n✅ reports/handoff.md tells a teammate exactly what to do"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#session-3-recap",
    "href": "W2_Data/D5_Data_Product.html#session-3-recap",
    "title": "Data Work (ETL + EDA)",
    "section": "Session 3 recap",
    "text": "Session 3 recap\n\nDuckDB is a useful SQL lens on local Parquet\nHandoff docs make your work usable by others\nCaveats are not embarrassment — they are professionalism"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#minutes-2",
    "href": "W2_Data/D5_Data_Product.html#minutes-2",
    "title": "Data Work (ETL + EDA)",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: we’ll implement the contract + CLI rebuild + run metadata + DuckDB outputs and commit."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#handson-success-criteria-today",
    "href": "W2_Data/D5_Data_Product.html#handson-success-criteria-today",
    "title": "Data Work (ETL + EDA)",
    "section": "Hands‑on success criteria (today)",
    "text": "Hands‑on success criteria (today)\nBy the end, you should have:\n\nbootcamp_data/contract.py (contract for orders_features)\nbootcamp_data/cli.py (Typer command: rebuild)\ndata/processed/_run_meta.json (run metadata written by rebuild)\nreports/schema_summary.csv (schema + missingness summary)\nscripts/run_day5_duckdb_queries.py (writes SQL outputs to reports/)\nreports/handoff.md (quick start + artifacts + caveats)\nat least 1 commit pushed to GitHub"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#project-layout-what-youll-have",
    "href": "W2_Data/D5_Data_Product.html#project-layout-what-youll-have",
    "title": "Data Work (ETL + EDA)",
    "section": "Project layout (what you’ll have)",
    "text": "Project layout (what you’ll have)\nbootcamp_data/\n  __init__.py\n  checks.py\n  contract.py          # NEW\n  cli.py               # NEW (Typer)\n  io.py\n  transforms.py\nscripts/\n  __init__.py\n  run_day2_validate_and_report.py\n  run_day3_eda_and_figures.py\n  run_day4_publish.py\n  run_day5_duckdb_queries.py   # NEW\nreports/\n  day4_publishable_report.md\n  day4_data_dictionary.md\n  schema_summary.csv           # NEW\n  handoff.md                   # NEW\n  day5_duckdb_top_countries.csv        # NEW (from DuckDB)\n  day5_duckdb_monthly_revenue.csv      # NEW (from DuckDB)\n  figures/\ndata/\n  raw/\n  processed/\n    orders_features.parquet\n    _run_meta.json             # NEW"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#task-0-confirm-starting-point-10-minutes",
    "href": "W2_Data/D5_Data_Product.html#task-0-confirm-starting-point-10-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 0 — Confirm starting point (10 minutes)",
    "text": "Task 0 — Confirm starting point (10 minutes)\n\nRerun Day 4 once\nMake sure you are in the repo root\n\nCheckpoint: Day 4 outputs exist (Warm‑up checkpoint)."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#task-1-add-bootcamp_datacontract.py-25-minutes",
    "href": "W2_Data/D5_Data_Product.html#task-1-add-bootcamp_datacontract.py-25-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 1 — Add bootcamp_data/contract.py (25 minutes)",
    "text": "Task 1 — Add bootcamp_data/contract.py (25 minutes)\n\nCreate bootcamp_data/contract.py\nImplement validate_orders_features(df)\nUse existing checks: columns, non‑empty, unique key, ranges\nAdd 2 dtype checks (IDs string‑like, amount numeric)\n\nCheckpoint: calling the function raises no error for your current orders_features.parquet."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#solution-task-1-bootcamp_datacontract.py",
    "href": "W2_Data/D5_Data_Product.html#solution-task-1-bootcamp_datacontract.py",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (Task 1): bootcamp_data/contract.py",
    "text": "Solution (Task 1): bootcamp_data/contract.py\nfrom __future__ import annotations\n\nimport pandas as pd\nfrom pandas.api.types import is_numeric_dtype, is_string_dtype\n\nfrom .checks import assert_in_range, assert_non_empty, assert_unique_key, require_columns\n\nREQUIRED = [\n    \"order_id\", \"user_id\", \"amount\", \"quantity\", \"created_at\",\n    \"status_clean\", \"month\", \"dow\", \"hour\",\n]\n\ndef validate_orders_features(df: pd.DataFrame, *, df_name: str = \"orders_features\") -&gt; None:\n    require_columns(df, REQUIRED, df_name=df_name)\n    assert_non_empty(df, df_name=df_name)\n    assert_unique_key(df, \"order_id\", allow_na=False, df_name=df_name)\n\n    if not is_string_dtype(df[\"order_id\"]):\n        raise ValueError(f\"{df_name}: order_id must be string-like (got {df['order_id'].dtype})\")\n    if not is_string_dtype(df[\"user_id\"]):\n        raise ValueError(f\"{df_name}: user_id must be string-like (got {df['user_id'].dtype})\")\n    if not is_numeric_dtype(df[\"amount\"]):\n        raise ValueError(f\"{df_name}: amount must be numeric (got {df['amount'].dtype})\")\n\n    assert_in_range(df[\"amount\"].dropna(), lo=0, name=f\"{df_name}.amount\")\n    assert_in_range(df[\"quantity\"].dropna(), lo=0, name=f\"{df_name}.quantity\")\n    assert_in_range(df[\"hour\"].dropna(), lo=0, hi=23, name=f\"{df_name}.hour\")"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#task-1-checkpoint-run-it-5-minutes",
    "href": "W2_Data/D5_Data_Product.html#task-1-checkpoint-run-it-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 1 checkpoint (run it) (5 minutes)",
    "text": "Task 1 checkpoint (run it) (5 minutes)\nmacOS/Linux\nuv run python -c \"import pandas as pd; from bootcamp_data.contract import validate_orders_features; df=pd.read_parquet('data/processed/orders_features.parquet'); validate_orders_features(df); print('contract OK')\"\nWindows PowerShell\nuv run python -c \"import pandas as pd; from bootcamp_data.contract import validate_orders_features; df=pd.read_parquet('data/processed/orders_features.parquet'); validate_orders_features(df); print('contract OK')\"\nCheckpoint: you see contract OK."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#task-2-create-bootcamp_datacli.py-typer-40-minutes",
    "href": "W2_Data/D5_Data_Product.html#task-2-create-bootcamp_datacli.py-typer-40-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 2 — Create bootcamp_data/cli.py (Typer) (40 minutes)",
    "text": "Task 2 — Create bootcamp_data/cli.py (Typer) (40 minutes)\n\n\n\n\n\n\nNote\n\n\nIf you see ModuleNotFoundError: typer, install it once with: uv add typer.\n\n\n\n\nCreate bootcamp_data/cli.py\nAdd a rebuild command that runs Day 2 → Day 4 using subprocess.run\nVerify key artifacts exist and are non‑empty\nLoad orders_features.parquet and run validate_orders_features(df)\nWrite:\n\ndata/processed/_run_meta.json\nreports/schema_summary.csv\n\n\nCheckpoint: uv run python -m bootcamp_data.cli rebuild completes successfully."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#solution-task-2-bootcamp_datacli.py-12",
    "href": "W2_Data/D5_Data_Product.html#solution-task-2-bootcamp_datacli.py-12",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (Task 2): bootcamp_data/cli.py (1/2)",
    "text": "Solution (Task 2): bootcamp_data/cli.py (1/2)\nfrom __future__ import annotations\n\nimport json\nimport subprocess\nimport sys\nimport time\nfrom datetime import datetime, timezone\nfrom pathlib import Path\n\nimport pandas as pd\nimport typer\n\nfrom .contract import validate_orders_features\n\napp = typer.Typer(add_completion=False)\nROOT = Path(__file__).resolve().parents[1]\n\ndef run_mod(mod: str, args: list[str] | None = None) -&gt; None:\n    cmd = [sys.executable, \"-m\", mod] + (args or [])\n    subprocess.run(cmd, cwd=ROOT, check=True)\n\ndef require_file(path: Path) -&gt; None:\n    if not path.exists():\n        raise FileNotFoundError(f\"Missing: {path}\")\n    if path.stat().st_size == 0:\n        raise ValueError(f\"Empty file: {path}\")\n\ndef safe_git_commit() -&gt; str | None:\n    try:\n        return subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], cwd=ROOT, text=True).strip()\n    except Exception:\n        return None"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#solution-task-2-bootcamp_datacli.py-22",
    "href": "W2_Data/D5_Data_Product.html#solution-task-2-bootcamp_datacli.py-22",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (Task 2): bootcamp_data/cli.py (2/2)",
    "text": "Solution (Task 2): bootcamp_data/cli.py (2/2)\n@app.command()\ndef rebuild(\n    top_k: int = typer.Option(10, help=\"Top-k categories to show in Day 4 report.\"),\n    figures: bool = typer.Option(False, help=\"Attempt to export figures (optional).\"),\n    start_date: str | None = typer.Option(None, help=\"Optional YYYY-MM-DD filter for Day 4.\"),\n    end_date: str | None = typer.Option(None, help=\"Optional YYYY-MM-DD filter for Day 4.\"),\n) -&gt; None:\n    t0 = time.time()\n    started = datetime.now(timezone.utc).isoformat()\n\n    run_mod(\"scripts.run_day2_validate_and_report\")\n    run_mod(\"scripts.run_day3_eda_and_figures\")\n\n    day4_args = [\"--top-k\", str(top_k)]\n    if start_date: day4_args += [\"--start-date\", start_date]\n    if end_date: day4_args += [\"--end-date\", end_date]\n    if figures: day4_args += [\"--figures\"]\n    run_mod(\"scripts.run_day4_publish\", day4_args)\n\n    features_path = ROOT / \"data/processed/orders_features.parquet\"\n    report_path = ROOT / \"reports/day4_publishable_report.md\"\n    dict_path = ROOT / \"reports/day4_data_dictionary.md\"\n\n    require_file(features_path)\n    require_file(report_path)\n    require_file(dict_path)\n\n    df = pd.read_parquet(features_path)\n    validate_orders_features(df)\n\n    # schema summary\n    schema = pd.DataFrame({\n        \"column\": df.columns,\n        \"dtype\": [str(t) for t in df.dtypes],\n        \"n_missing\": [int(df[c].isna().sum()) for c in df.columns],\n    }).sort_values(\"n_missing\", ascending=False)\n    schema_path = ROOT / \"reports/schema_summary.csv\"\n    schema_path.parent.mkdir(parents=True, exist_ok=True)\n    schema.to_csv(schema_path, index=False)\n\n    meta = {\n        \"started_utc\": started,\n        \"finished_utc\": datetime.now(timezone.utc).isoformat(),\n        \"duration_s\": round(time.time() - t0, 2),\n        \"git_commit\": safe_git_commit(),\n        \"args\": {\"top_k\": top_k, \"figures\": figures, \"start_date\": start_date, \"end_date\": end_date},\n        \"rows\": {\"orders_features\": int(len(df))},\n        \"outputs\": [str(features_path), str(report_path), str(dict_path), str(schema_path)],\n    }\n    meta_path = ROOT / \"data/processed/_run_meta.json\"\n    meta_path.parent.mkdir(parents=True, exist_ok=True)\n    meta_path.write_text(json.dumps(meta, indent=2), encoding=\"utf-8\")\n\n    typer.echo(\"✅ rebuild OK\")"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#task-2-checkpoint-run-it-5-minutes",
    "href": "W2_Data/D5_Data_Product.html#task-2-checkpoint-run-it-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 2 checkpoint (run it) (5 minutes)",
    "text": "Task 2 checkpoint (run it) (5 minutes)\nmacOS/Linux\nuv run python -m bootcamp_data.cli rebuild --top-k 10 --figures\nWindows PowerShell\nuv run python -m bootcamp_data.cli rebuild --top-k 10 --figures\nCheckpoint: you see ✅ rebuild OK."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#task-3-add-duckdb-queries-25-minutes",
    "href": "W2_Data/D5_Data_Product.html#task-3-add-duckdb-queries-25-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 3 — Add DuckDB queries (25 minutes)",
    "text": "Task 3 — Add DuckDB queries (25 minutes)\n\nAdd DuckDB dependency (if needed): uv add duckdb\nCreate scripts/run_day5_duckdb_queries.py\nRun 2 queries on orders_features.parquet and write CSV outputs to reports/\n\nCheckpoint: the CSVs exist in reports/.\n\n\n\n\n\n\nNote\n\n\nIf you can’t install DuckDB due to connectivity, keep the script and run it later. The SQL practice is still valuable."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#solution-task-3-scriptsrun_day5_duckdb_queries.py",
    "href": "W2_Data/D5_Data_Product.html#solution-task-3-scriptsrun_day5_duckdb_queries.py",
    "title": "Data Work (ETL + EDA)",
    "section": "Solution (Task 3): scripts/run_day5_duckdb_queries.py",
    "text": "Solution (Task 3): scripts/run_day5_duckdb_queries.py\nfrom __future__ import annotations\n\nfrom pathlib import Path\nimport duckdb\n\nROOT = Path(__file__).resolve().parents[1]\n\nFEATURES = ROOT / \"data/processed/orders_features.parquet\"\nOUT1 = ROOT / \"reports/day5_duckdb_top_countries.csv\"\nOUT2 = ROOT / \"reports/day5_duckdb_monthly_revenue.csv\"\n\ndef main() -&gt; None:\n    OUT1.parent.mkdir(parents=True, exist_ok=True)\n\n    q1 = '''\n    SELECT country, COUNT(*) AS n, SUM(amount) AS revenue\n    FROM read_parquet(?)\n    GROUP BY 1\n    ORDER BY revenue DESC\n    LIMIT 10\n    '''\n    df1 = duckdb.query(q1, [str(FEATURES)]).df()\n    df1.to_csv(OUT1, index=False)\n\n    q2 = '''\n    SELECT month, COUNT(*) AS n_orders, SUM(amount) AS revenue\n    FROM read_parquet(?)\n    GROUP BY 1\n    ORDER BY month ASC\n    '''\n    df2 = duckdb.query(q2, [str(FEATURES)]).df()\n    df2.to_csv(OUT2, index=False)\n\n    print(\"wrote:\", OUT1)\n    print(\"wrote:\", OUT2)\n\nif __name__ == \"__main__\":\n    main()"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#task-3-checkpoint-run-it-5-minutes",
    "href": "W2_Data/D5_Data_Product.html#task-3-checkpoint-run-it-5-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 3 checkpoint (run it) (5 minutes)",
    "text": "Task 3 checkpoint (run it) (5 minutes)\nmacOS/Linux\nuv run python -m scripts.run_day5_duckdb_queries\nls -la reports/day5_duckdb_*.csv\nWindows PowerShell\nuv run python -m scripts.run_day5_duckdb_queries\ndir reports\\day5_duckdb_*.csv"
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#task-4-write-reportshandoff.md-20-minutes",
    "href": "W2_Data/D5_Data_Product.html#task-4-write-reportshandoff.md-20-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Task 4 — Write reports/handoff.md (20 minutes)",
    "text": "Task 4 — Write reports/handoff.md (20 minutes)\n\nCreate reports/handoff.md\nAdd: quick start, key artifacts, optional SQL artifacts, caveats, troubleshooting\n\nCheckpoint: a teammate can follow it without asking you questions."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#git-checkpoint-2-minutes",
    "href": "W2_Data/D5_Data_Product.html#git-checkpoint-2-minutes",
    "title": "Data Work (ETL + EDA)",
    "section": "Git checkpoint (2 minutes)",
    "text": "Git checkpoint (2 minutes)\n\ngit status\nCommit with message: \"day5: contract + cli rebuild + run meta + duckdb + handoff\"\ngit push\n\nCheckpoint: your GitHub repo shows the new commit."
  },
  {
    "objectID": "W2_Data/D5_Data_Product.html#debug-playbook",
    "href": "W2_Data/D5_Data_Product.html#debug-playbook",
    "title": "Data Work (ETL + EDA)",
    "section": "Debug playbook",
    "text": "Debug playbook\nWhen something breaks:\n\nConfirm repo root (run from the folder with data/ + scripts/ + bootcamp_data/)\nRe-run: uv run python -m bootcamp_data.cli rebuild\nRead the error message: which check failed? which column?\nVerify inputs:\n\ndata/raw/ files exist\nprocessed artifacts are not stale (rebuild overwrites)\n\nIf using date filters: make sure they don’t filter everything out"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#setup",
    "href": "W2_Data/pandas_quick_intro.html#setup",
    "title": "Data Work (ETL + EDA)",
    "section": "1. Setup",
    "text": "1. Setup\nFirst, we need to import the necessary libraries.\nimport pandas as pd\nimport numpy as np"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#pandas-objects",
    "href": "W2_Data/pandas_quick_intro.html#pandas-objects",
    "title": "Data Work (ETL + EDA)",
    "section": "2. Pandas Objects",
    "text": "2. Pandas Objects\nPandas primarily works with two data structures:\n\nSeries: A one-dimensional labeled array.\nDataFrame: A two-dimensional tabular structure (like a spreadsheet)."
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#series-example-code",
    "href": "W2_Data/pandas_quick_intro.html#series-example-code",
    "title": "Data Work (ETL + EDA)",
    "section": "Series Example: Code",
    "text": "Series Example: Code\nA Series is essentially a single column of data with an index.\ns = pd.Series([10, 20, 30, 40], index=['a', 'b', 'c', 'd'])\ns"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#series-example-output",
    "href": "W2_Data/pandas_quick_intro.html#series-example-output",
    "title": "Data Work (ETL + EDA)",
    "section": "Series Example: Output",
    "text": "Series Example: Output\nOutput:\na    10\nb    20\nc    30\nd    40\ndtype: int64"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#creating-a-dataframe-code",
    "href": "W2_Data/pandas_quick_intro.html#creating-a-dataframe-code",
    "title": "Data Work (ETL + EDA)",
    "section": "Creating a DataFrame: Code",
    "text": "Creating a DataFrame: Code\nDataFrames are usually built using dictionaries where keys are column names.\ndata = {\n    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n    'Age': [25, 30, 35, 40, np.nan],\n    'Score': [85, 90, 75, 80, 95],\n    'City': ['New York', 'London', 'Paris', 'London', 'Tokyo']\n}\n\ndf = pd.DataFrame(data)\ndf"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#the-resulting-dataframe-output",
    "href": "W2_Data/pandas_quick_intro.html#the-resulting-dataframe-output",
    "title": "Data Work (ETL + EDA)",
    "section": "The Resulting DataFrame: Output",
    "text": "The Resulting DataFrame: Output\nThe df object now looks like this:\n\n\n\n\nName\nAge\nScore\nCity\n\n\n\n\n0\nAlice\n25.0\n85\nNew York\n\n\n1\nBob\n30.0\n90\nLondon\n\n\n2\nCharlie\n35.0\n75\nParis\n\n\n3\nDavid\n40.0\n80\nLondon\n\n\n4\nEva\nNaN\n95\nTokyo"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#accessing-elements-columns-code",
    "href": "W2_Data/pandas_quick_intro.html#accessing-elements-columns-code",
    "title": "Data Work (ETL + EDA)",
    "section": "3. Accessing Elements (Columns): Code",
    "text": "3. Accessing Elements (Columns): Code\nYou can extract a single column as a Series.\ndf['Age']"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#accessing-elements-columns-output",
    "href": "W2_Data/pandas_quick_intro.html#accessing-elements-columns-output",
    "title": "Data Work (ETL + EDA)",
    "section": "Accessing Elements (Columns): Output",
    "text": "Accessing Elements (Columns): Output\nOutput:\n0    25.0\n1    30.0\n2    35.0\n3    40.0\n4     NaN\nName: Age, dtype: float64"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#accessing-elements-rows-code",
    "href": "W2_Data/pandas_quick_intro.html#accessing-elements-rows-code",
    "title": "Data Work (ETL + EDA)",
    "section": "Accessing Elements (Rows): Code",
    "text": "Accessing Elements (Rows): Code\nAccess a row by its integer position using .iloc.\n# Access the first row (index 0)\ndf.iloc[0]"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#accessing-elements-rows-output",
    "href": "W2_Data/pandas_quick_intro.html#accessing-elements-rows-output",
    "title": "Data Work (ETL + EDA)",
    "section": "Accessing Elements (Rows): Output",
    "text": "Accessing Elements (Rows): Output\nOutput:\nName        Alice\nAge          25.0\nScore          85\nCity     New York\nName: 0, dtype: object"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#accessing-scalars-code",
    "href": "W2_Data/pandas_quick_intro.html#accessing-scalars-code",
    "title": "Data Work (ETL + EDA)",
    "section": "Accessing Scalars: Code",
    "text": "Accessing Scalars: Code\nAccess a specific cell value using .at.\n# Access the Name at index 0\ndf.at[0, 'Name']"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#accessing-scalars-output",
    "href": "W2_Data/pandas_quick_intro.html#accessing-scalars-output",
    "title": "Data Work (ETL + EDA)",
    "section": "Accessing Scalars: Output",
    "text": "Accessing Scalars: Output\nOutput:\n'Alice'"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#filtering-part-1-code",
    "href": "W2_Data/pandas_quick_intro.html#filtering-part-1-code",
    "title": "Data Work (ETL + EDA)",
    "section": "4. Filtering (Part 1): Code",
    "text": "4. Filtering (Part 1): Code\nBefore filtering, pandas creates a boolean mask. This is a Series of True and False values indicating which rows meet the condition.\n# This returns a Series of True/False values\ndf['Score'] &gt; 80"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#filtering-part-1-boolean-mask-output",
    "href": "W2_Data/pandas_quick_intro.html#filtering-part-1-boolean-mask-output",
    "title": "Data Work (ETL + EDA)",
    "section": "4. Filtering (Part 1): Boolean Mask Output",
    "text": "4. Filtering (Part 1): Boolean Mask Output\nOutput:\n\n\n\nIndex\nResult\n\n\n\n\n0\nTrue\n\n\n1\nTrue\n\n\n2\nFalse\n\n\n3\nFalse\n\n\n4\nTrue"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#filtering-part-2-code",
    "href": "W2_Data/pandas_quick_intro.html#filtering-part-2-code",
    "title": "Data Work (ETL + EDA)",
    "section": "4. Filtering (Part 2): Code",
    "text": "4. Filtering (Part 2): Code\nBy passing that boolean mask into the DataFrame using [], pandas returns only the rows where the value is True.\n# Pass the condition into the DataFrame\nhigh_scorers = df[df['Score'] &gt; 80]\nhigh_scorers"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#filtering-part-2-filtered-output",
    "href": "W2_Data/pandas_quick_intro.html#filtering-part-2-filtered-output",
    "title": "Data Work (ETL + EDA)",
    "section": "4. Filtering (Part 2): Filtered Output",
    "text": "4. Filtering (Part 2): Filtered Output\nOutput:\n\n\n\n\nName\nAge\nScore\nCity\n\n\n\n\n0\nAlice\n25.0\n85\nNew York\n\n\n1\nBob\n30.0\n90\nLondon\n\n\n4\nEva\nNaN\n95\nTokyo"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#multiple-conditions-code",
    "href": "W2_Data/pandas_quick_intro.html#multiple-conditions-code",
    "title": "Data Work (ETL + EDA)",
    "section": "Multiple Conditions: Code",
    "text": "Multiple Conditions: Code\nCombine filters using & (and) or | (or).\n# Score &gt; 80 AND City is London\nlondon_stars = df[(df['Score'] &gt; 80) & (df['City'] == 'London')]\nlondon_stars"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#multiple-conditions-output",
    "href": "W2_Data/pandas_quick_intro.html#multiple-conditions-output",
    "title": "Data Work (ETL + EDA)",
    "section": "Multiple Conditions: Output",
    "text": "Multiple Conditions: Output\nOutput:\n\n\n\n\nName\nAge\nScore\nCity\n\n\n\n\n1\nBob\n30.0\n90\nLondon"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#modifying-values-code",
    "href": "W2_Data/pandas_quick_intro.html#modifying-values-code",
    "title": "Data Work (ETL + EDA)",
    "section": "5. Modifying Values: Code",
    "text": "5. Modifying Values: Code\nYou can update specific values directly.\n# Update Bob's score\ndf.at[1, 'Score'] = 92\ndf.iloc[1:2] # Show only Bob's row"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#modifying-values-output",
    "href": "W2_Data/pandas_quick_intro.html#modifying-values-output",
    "title": "Data Work (ETL + EDA)",
    "section": "Modifying Values: Output",
    "text": "Modifying Values: Output\nOutput:\n\n\n\n\nName\nAge\nScore\nCity\n\n\n\n\n1\nBob\n30.0\n92\nLondon"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#creating-new-columns-code",
    "href": "W2_Data/pandas_quick_intro.html#creating-new-columns-code",
    "title": "Data Work (ETL + EDA)",
    "section": "Creating New Columns: Code",
    "text": "Creating New Columns: Code\nAdding a column based on existing data.\n# Create a 'Passed' flag\ndf['Passed'] = df['Score'] &gt;= 80\ndf"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#creating-new-columns-output",
    "href": "W2_Data/pandas_quick_intro.html#creating-new-columns-output",
    "title": "Data Work (ETL + EDA)",
    "section": "Creating New Columns: Output",
    "text": "Creating New Columns: Output\nOutput:\n\n\n\n\nName\nAge\nScore\nCity\nPassed\n\n\n\n\n0\nAlice\n25.0\n85\nNew York\nTrue\n\n\n1\nBob\n30.0\n92\nLondon\nTrue\n\n\n…\n…\n…\n…\n…\n…"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#aggregation-code",
    "href": "W2_Data/pandas_quick_intro.html#aggregation-code",
    "title": "Data Work (ETL + EDA)",
    "section": "6. Aggregation: Code",
    "text": "6. Aggregation: Code\nQuickly calculate statistics across your dataset.\ntotal_score = df['Score'].sum()\nmean_age = df['Age'].mean()\n\nprint(f\"Total Score: {total_score}\")\nprint(f\"Average Age: {mean_age}\")"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#aggregation-output",
    "href": "W2_Data/pandas_quick_intro.html#aggregation-output",
    "title": "Data Work (ETL + EDA)",
    "section": "Aggregation: Output",
    "text": "Aggregation: Output\nOutput:\nTotal Score: 427\nAverage Age: 32.5"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#handling-missing-data-12-code",
    "href": "W2_Data/pandas_quick_intro.html#handling-missing-data-12-code",
    "title": "Data Work (ETL + EDA)",
    "section": "Handling Missing Data (1/2): Code",
    "text": "Handling Missing Data (1/2): Code\nIdentify how many null values (NaN) exist in each column.\ndf.isna().sum()"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#handling-missing-data-12-output",
    "href": "W2_Data/pandas_quick_intro.html#handling-missing-data-12-output",
    "title": "Data Work (ETL + EDA)",
    "section": "Handling Missing Data (1/2): Output",
    "text": "Handling Missing Data (1/2): Output\nOutput:\nName      0\nAge       1\nScore     0\nCity      0\nPassed    0\ndtype: int64"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#handling-missing-data-22-code",
    "href": "W2_Data/pandas_quick_intro.html#handling-missing-data-22-code",
    "title": "Data Work (ETL + EDA)",
    "section": "Handling Missing Data (2/2): Code",
    "text": "Handling Missing Data (2/2): Code\nFill the missing values using the mean.\ndf['Age'] = df['Age'].fillna(df['Age'].mean())\ndf"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#handling-missing-data-22-updated-table-output",
    "href": "W2_Data/pandas_quick_intro.html#handling-missing-data-22-updated-table-output",
    "title": "Data Work (ETL + EDA)",
    "section": "Handling Missing Data (2/2): Updated Table Output",
    "text": "Handling Missing Data (2/2): Updated Table Output\nOutput (Row 4 is now filled):\n\n\n\n\nName\nAge\nScore\nCity\n\n\n\n\n4\nEva\n32.5\n95\nTokyo"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#read-write-operations-code",
    "href": "W2_Data/pandas_quick_intro.html#read-write-operations-code",
    "title": "Data Work (ETL + EDA)",
    "section": "7. Read / Write Operations: Code",
    "text": "7. Read / Write Operations: Code\nSave your processed data for later use.\n# Save to disk\ndf.to_csv('students_data.csv', index=False)\n\n# Load it back\ndf_loaded = pd.read_csv('students_data.csv')\ndf_loaded.head(2)"
  },
  {
    "objectID": "W2_Data/pandas_quick_intro.html#read-write-operations-output",
    "href": "W2_Data/pandas_quick_intro.html#read-write-operations-output",
    "title": "Data Work (ETL + EDA)",
    "section": "Read / Write Operations: Output",
    "text": "Read / Write Operations: Output\nOutput:\n\n\n\n\nName\nAge\nScore\nCity\n\n\n\n\n0\nAlice\n25.0\n85\nNew York\n\n\n1\nBob\n30.0\n92\nLondon"
  },
  {
    "objectID": "W3_ML/D2.html#announcements-admin",
    "href": "W3_ML/D2.html#announcements-admin",
    "title": "Machine Learning",
    "section": "Announcements / admin",
    "text": "Announcements / admin\n\nToday you create your first reproducible training run (baseline + saved model)\nDon’t commit generated artifacts:\n\nmodels/runs/, data/processed/, outputs/ are gitignored on purpose\n\nKeep your reports/model_card.md open (we will update the evaluation plan section)\n\n\n\n\n\n\n\nNote\n\n\nIf you get stuck: read the error, then ask for clarification — not code."
  },
  {
    "objectID": "W3_ML/D2.html#todays-flow",
    "href": "W3_ML/D2.html#todays-flow",
    "title": "Machine Learning",
    "section": "Today’s Flow",
    "text": "Today’s Flow\n\nSession 1 (60m): Splits that don’t lie (holdout + stratify)\nAsr Prayer (20m)\nSession 2 (60m): Baselines + metrics (beat the dummy)\nMaghrib Prayer (20m)\nSession 3 (60m): train command anatomy (run_id + artifacts)\nIsha Prayer (20m)\nHands-on (120m): Run training, inspect artifacts, update model card, push a commit"
  },
  {
    "objectID": "W3_ML/D2.html#learning-objectives",
    "href": "W3_ML/D2.html#learning-objectives",
    "title": "Machine Learning",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of today, you can:\n\nExplain what a holdout split is (and why it exists)\nChoose a split strategy at a high level: random / time / group\nExplain why a Dummy baseline is mandatory\nIdentify an evaluation metric that matches a decision (precision/recall vs accuracy)\nRun uv run ml-baseline train --target ... and find saved artifacts\nUpdate your model card with a clear evaluation plan"
  },
  {
    "objectID": "W3_ML/D2.html#warm-up-5-minutes",
    "href": "W3_ML/D2.html#warm-up-5-minutes",
    "title": "Machine Learning",
    "section": "Warm-up (5 minutes)",
    "text": "Warm-up (5 minutes)\nRun yesterday’s work and confirm it still works.\nuv run ml-baseline --help\nuv run ml-baseline make-sample-data\nls data/processed\nuv run pytest\nCheckpoint: you see features.csv or features.parquet, and tests pass."
  },
  {
    "objectID": "W3_ML/D2.html#from-your-model-card-your-training-config",
    "href": "W3_ML/D2.html#from-your-model-card-your-training-config",
    "title": "Machine Learning",
    "section": "From your model card → your training config",
    "text": "From your model card → your training config\nYesterday you wrote a dataset contract:\n\nTarget (y): what you predict\nUnit of analysis: what one row represents\nID passthrough: how you join predictions back\nForbidden columns: target + obvious leakage\n\n\n\n\n\n\n\nTip\n\n\nToday you will use those decisions to split and train consistently."
  },
  {
    "objectID": "W3_ML/D2.html#where-today-fits-in-the-week-3-loop",
    "href": "W3_ML/D2.html#where-today-fits-in-the-week-3-loop",
    "title": "Machine Learning",
    "section": "Where today fits in the Week 3 loop",
    "text": "Where today fits in the Week 3 loop\nDefine → Split → Baseline → Train → Save → Predict → Report\n\nToday: Split + Baseline + Train (your first run folder). Tomorrow: we’ll go deeper on evaluation artifacts and the input schema."
  },
  {
    "objectID": "W3_ML/D2.html#end-of-day-demo-what-should-work",
    "href": "W3_ML/D2.html#end-of-day-demo-what-should-work",
    "title": "Machine Learning",
    "section": "End-of-day demo (what should work)",
    "text": "End-of-day demo (what should work)\nTrain\nuv run ml-baseline train --target is_high_value\nWhat should happen - a new folder appears in models/runs/&lt;run_id&gt;/ - models/registry/latest.txt updates to the newest run - baseline metrics are saved to the run folder"
  },
  {
    "objectID": "W3_ML/D2.html#session-1-objectives",
    "href": "W3_ML/D2.html#session-1-objectives",
    "title": "Machine Learning",
    "section": "Session 1 objectives",
    "text": "Session 1 objectives\n\nUnderstand splitting as a simulation of production\nKnow when random split is acceptable (minimum requirement)\nUnderstand stratification for binary classification"
  },
  {
    "objectID": "W3_ML/D2.html#why-do-we-split",
    "href": "W3_ML/D2.html#why-do-we-split",
    "title": "Machine Learning",
    "section": "Why do we split?",
    "text": "Why do we split?\nA split answers:\n\n“If we train on some rows, how well do we do on new rows?”\n\nWithout a split, you only know:\n\n“how well do we predict what we already saw?” (not useful)"
  },
  {
    "objectID": "W3_ML/D2.html#train-vs-holdout-final-exam",
    "href": "W3_ML/D2.html#train-vs-holdout-final-exam",
    "title": "Machine Learning",
    "section": "Train vs holdout (final exam)",
    "text": "Train vs holdout (final exam)\n\nTrain split: the model learns patterns\nHoldout split: the model takes a “final exam” on unseen data\n\n\n\n\n\n\n\nTip\n\n\nTreat the holdout set like production: don’t “study” it."
  },
  {
    "objectID": "W3_ML/D2.html#random-split-minimum-requirement",
    "href": "W3_ML/D2.html#random-split-minimum-requirement",
    "title": "Machine Learning",
    "section": "Random split (minimum requirement)",
    "text": "Random split (minimum requirement)\nRandom split is OK when:\n\neach row is mostly independent\nyou are not forecasting over time\nyou do not have repeated entities (or you already have 1 row per entity)\n\n\nOur sample dataset has 1 row per user_id, so random split is fine."
  },
  {
    "objectID": "W3_ML/D2.html#stratification-keep-class-balance",
    "href": "W3_ML/D2.html#stratification-keep-class-balance",
    "title": "Machine Learning",
    "section": "Stratification (keep class balance)",
    "text": "Stratification (keep class balance)\nIf your target is imbalanced (example: 5% positives):\n\nplain random split can create weird class balance by accident\nstratification keeps train/holdout positive rates similar\n\n\n\n\n\n\n\nNote\n\n\nStratify only makes sense for classification (not regression)."
  },
  {
    "objectID": "W3_ML/D2.html#micro-exercise-choose-the-split-6-minutes",
    "href": "W3_ML/D2.html#micro-exercise-choose-the-split-6-minutes",
    "title": "Machine Learning",
    "section": "Micro-exercise: choose the split (6 minutes)",
    "text": "Micro-exercise: choose the split (6 minutes)\nPick the best split strategy:\n\nPredict next month demand using last 24 months of data\n\nPredict fraud on transactions (each user has many rows)\n\nPredict churn where each user appears once (one row per user)\n\nCheckpoint: you can justify each choice in 1 sentence."
  },
  {
    "objectID": "W3_ML/D2.html#solution-choose-the-split",
    "href": "W3_ML/D2.html#solution-choose-the-split",
    "title": "Machine Learning",
    "section": "Solution: choose the split",
    "text": "Solution: choose the split\n\nTime split (future demand = time matters)\n\nGroup split (avoid user leakage across splits)\n\nRandom split (likely i.i.d. and one row per user)"
  },
  {
    "objectID": "W3_ML/D2.html#group-leakage-common-accidental-cheating",
    "href": "W3_ML/D2.html#group-leakage-common-accidental-cheating",
    "title": "Machine Learning",
    "section": "Group leakage (common “accidental cheating”)",
    "text": "Group leakage (common “accidental cheating”)\nIf the same entity appears in train and holdout:\n\nthe model can “recognize” the entity\nmetrics inflate without real learning\n\nTypical group columns: - user_id, customer_id, device_id, patient_id"
  },
  {
    "objectID": "W3_ML/D2.html#code-pattern-random-stratified-split",
    "href": "W3_ML/D2.html#code-pattern-random-stratified-split",
    "title": "Machine Learning",
    "section": "Code pattern: random stratified split",
    "text": "Code pattern: random stratified split\nfrom sklearn.model_selection import train_test_split\n\ndef random_split(df, *, target, test_size, seed, stratify):\n    y = df[target]\n    strat = y if stratify else None\n    train, test = train_test_split(\n        df, test_size=test_size, random_state=seed, stratify=strat\n    )\n    return train.reset_index(drop=True), test.reset_index(drop=True)\n\nMinimum requirement: stratify for binary classification when possible."
  },
  {
    "objectID": "W3_ML/D2.html#quick-check",
    "href": "W3_ML/D2.html#quick-check",
    "title": "Machine Learning",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: What problem does stratification prevent?\n\nAnswer: train and holdout accidentally having very different class balance."
  },
  {
    "objectID": "W3_ML/D2.html#session-1-recap",
    "href": "W3_ML/D2.html#session-1-recap",
    "title": "Machine Learning",
    "section": "Session 1 recap",
    "text": "Session 1 recap\n\nSplitting simulates “new data”\nHoldout is a final exam\nRandom stratified split is the minimum for binary classification"
  },
  {
    "objectID": "W3_ML/D2.html#minutes",
    "href": "W3_ML/D2.html#minutes",
    "title": "Machine Learning",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: be ready to explain why “beat the dummy” is required."
  },
  {
    "objectID": "W3_ML/D2.html#session-2-objectives",
    "href": "W3_ML/D2.html#session-2-objectives",
    "title": "Machine Learning",
    "section": "Session 2 objectives",
    "text": "Session 2 objectives\n\nDefine a baseline as a floor\nSee why accuracy can lie (imbalanced targets)\nPick a primary metric that matches a decision"
  },
  {
    "objectID": "W3_ML/D2.html#what-is-a-baseline",
    "href": "W3_ML/D2.html#what-is-a-baseline",
    "title": "Machine Learning",
    "section": "What is a baseline?",
    "text": "What is a baseline?\nA baseline is the simplest thing that could work:\n\nclassification: predict the most common class\nregression: predict the average target value\n\n\n\n\n\n\n\nTip\n\n\nIf your model can’t beat the baseline, something is wrong (or there is no signal)."
  },
  {
    "objectID": "W3_ML/D2.html#if-you-cant-beat-the-dummy",
    "href": "W3_ML/D2.html#if-you-cant-beat-the-dummy",
    "title": "Machine Learning",
    "section": "If you can’t beat the dummy…",
    "text": "If you can’t beat the dummy…\nThat usually means one of these:\n\nyour features don’t contain signal\nyour target is noisy or poorly defined\nyour split is unrealistic (leakage or mismatch)\n\n\nA baseline result is a diagnostic, not an insult."
  },
  {
    "objectID": "W3_ML/D2.html#metrics-are-about-the-decision",
    "href": "W3_ML/D2.html#metrics-are-about-the-decision",
    "title": "Machine Learning",
    "section": "Metrics are about the decision",
    "text": "Metrics are about the decision\nBefore you choose a metric, ask:\n\nwhich mistake is worse?\n\nfalse positives (predict “yes” when it’s “no”)\nfalse negatives (miss a real “yes”)\n\ndo you need a ranking score or a hard decision?\n\n\n\n\n\n\n\nNote\n\n\nToday we focus on decision metrics: accuracy / precision / recall / F1."
  },
  {
    "objectID": "W3_ML/D2.html#accuracy-trap-imbalanced-data",
    "href": "W3_ML/D2.html#accuracy-trap-imbalanced-data",
    "title": "Machine Learning",
    "section": "Accuracy trap (imbalanced data)",
    "text": "Accuracy trap (imbalanced data)\nSuppose:\n\n1000 samples\n50 positives (5%)\na model predicts “negative” for everyone\n\nWhat is accuracy?"
  },
  {
    "objectID": "W3_ML/D2.html#micro-exercise-compute-the-accuracy-3-minutes",
    "href": "W3_ML/D2.html#micro-exercise-compute-the-accuracy-3-minutes",
    "title": "Machine Learning",
    "section": "Micro-exercise: compute the accuracy (3 minutes)",
    "text": "Micro-exercise: compute the accuracy (3 minutes)\n\nCorrect negatives = ?\nTotal samples = ?\nAccuracy = ?\n\nCheckpoint: you have a number between 0 and 1."
  },
  {
    "objectID": "W3_ML/D2.html#solution-why-accuracy-can-lie",
    "href": "W3_ML/D2.html#solution-why-accuracy-can-lie",
    "title": "Machine Learning",
    "section": "Solution: why accuracy can lie",
    "text": "Solution: why accuracy can lie\n\nCorrect negatives = 950\n\nTotal = 1000\n\nAccuracy = 950 / 1000 = 0.95\n\n\n\n\n\n\n\nWarning\n\n\n95% accuracy can still mean “your model never finds positives.”"
  },
  {
    "objectID": "W3_ML/D2.html#minimum-metrics-what-we-report-this-week",
    "href": "W3_ML/D2.html#minimum-metrics-what-we-report-this-week",
    "title": "Machine Learning",
    "section": "Minimum metrics (what we report this week)",
    "text": "Minimum metrics (what we report this week)\nClassification (binary) - accuracy - precision - recall - F1\nRegression - MAE (Mean Absolute Error)\n\n\n\n\n\n\nTip\n\n\nPick one primary metric and write it in your model card today."
  },
  {
    "objectID": "W3_ML/D2.html#optional-metrics-if-you-finish-early",
    "href": "W3_ML/D2.html#optional-metrics-if-you-finish-early",
    "title": "Machine Learning",
    "section": "Optional metrics (if you finish early)",
    "text": "Optional metrics (if you finish early)\n\nROC AUC / PR AUC: useful when you care about ranking quality\nRMSE: penalizes large errors more than MAE\nR²: “how much variance explained” (often confusing for beginners)\n\n\nOptional ≠ unimportant. It’s just not required to ship a baseline this week."
  },
  {
    "objectID": "W3_ML/D2.html#dummy-baseline-in-scikit-learn-pattern",
    "href": "W3_ML/D2.html#dummy-baseline-in-scikit-learn-pattern",
    "title": "Machine Learning",
    "section": "Dummy baseline in scikit-learn (pattern)",
    "text": "Dummy baseline in scikit-learn (pattern)\nfrom sklearn.dummy import DummyClassifier\n\ndummy = DummyClassifier(strategy=\"most_frequent\")\ndummy.fit(X_train, y_train)\n\nproba = dummy.predict_proba(X_test)\ny_score = proba[:, 1] if proba.shape[1] &gt; 1 else proba[:, 0]\nbaseline = classification_metrics(y_true, y_score, threshold=0.5)\n\nFit on the train split, evaluate on the holdout split."
  },
  {
    "objectID": "W3_ML/D2.html#micro-exercise-interpret-a-baseline-5-minutes",
    "href": "W3_ML/D2.html#micro-exercise-interpret-a-baseline-5-minutes",
    "title": "Machine Learning",
    "section": "Micro-exercise: interpret a baseline (5 minutes)",
    "text": "Micro-exercise: interpret a baseline (5 minutes)\nYou see:\n\nbaseline accuracy = 0.95\nbaseline recall = 0.00\n\n\nWhat is the baseline doing?\nWhy is this baseline “good” and “bad” at the same time?\nWhich metric should you focus on next?\n\nCheckpoint: you can answer in 3 short sentences."
  },
  {
    "objectID": "W3_ML/D2.html#solution-interpret-the-baseline",
    "href": "W3_ML/D2.html#solution-interpret-the-baseline",
    "title": "Machine Learning",
    "section": "Solution: interpret the baseline",
    "text": "Solution: interpret the baseline\n\nIt predicts the majority class (“negative”) almost always.\nAccuracy looks great because positives are rare, but it never finds positives.\nFocus on recall/precision/F1 (or change the problem/threshold)."
  },
  {
    "objectID": "W3_ML/D2.html#session-2-recap",
    "href": "W3_ML/D2.html#session-2-recap",
    "title": "Machine Learning",
    "section": "Session 2 recap",
    "text": "Session 2 recap\n\nBaselines create a performance floor\nAccuracy can be misleading on imbalanced targets\nChoose a metric that matches your decision"
  },
  {
    "objectID": "W3_ML/D2.html#minutes-1",
    "href": "W3_ML/D2.html#minutes-1",
    "title": "Machine Learning",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: we will connect the concepts to the train command + artifacts."
  },
  {
    "objectID": "W3_ML/D2.html#session-3-objectives",
    "href": "W3_ML/D2.html#session-3-objectives",
    "title": "Machine Learning",
    "section": "Session 3 objectives",
    "text": "Session 3 objectives\n\nUnderstand what ml-baseline train does at a high level\nKnow what a run folder is and why it exists\nIdentify the minimum artifacts you need today"
  },
  {
    "objectID": "W3_ML/D2.html#what-ml-baseline-train-does-in-8-steps",
    "href": "W3_ML/D2.html#what-ml-baseline-train-does-in-8-steps",
    "title": "Machine Learning",
    "section": "What ml-baseline train does (in 8 steps)",
    "text": "What ml-baseline train does (in 8 steps)\n\nLoad data/processed/features.*\nSeparate X and y (drop target + IDs from X)\nSplit into train + holdout\nFit a dummy baseline and record metrics\nFit a simple scikit-learn Pipeline (baseline model)\nSave a run folder under models/runs/&lt;run_id&gt;/\nWrite models/registry/latest.txt\nPrint where things were saved"
  },
  {
    "objectID": "W3_ML/D2.html#run-folder-mental-model",
    "href": "W3_ML/D2.html#run-folder-mental-model",
    "title": "Machine Learning",
    "section": "Run folder mental model",
    "text": "Run folder mental model\nEach run folder is a snapshot:\n\nthe model you trained\nthe data contract you assumed\nthe metrics you got\nthe config you used (seed, split, target, …)\n\n\n\n\n\n\n\nTip\n\n\nA run folder is how you make training reproducible and reviewable."
  },
  {
    "objectID": "W3_ML/D2.html#minimum-artifacts-to-understand-today",
    "href": "W3_ML/D2.html#minimum-artifacts-to-understand-today",
    "title": "Machine Learning",
    "section": "Minimum artifacts to understand today",
    "text": "Minimum artifacts to understand today\nInside models/runs/&lt;run_id&gt;/ focus on:\n\nmetrics/baseline_holdout.json ✅ (your floor)\nmodel/model.joblib ✅ (your saved model)\n\n\nYou may see extra files (schema, tables, holdout metrics). We’ll explain them more on Day 3."
  },
  {
    "objectID": "W3_ML/D2.html#micro-exercise-find-the-artifacts-4-minutes",
    "href": "W3_ML/D2.html#micro-exercise-find-the-artifacts-4-minutes",
    "title": "Machine Learning",
    "section": "Micro-exercise: find the artifacts (4 minutes)",
    "text": "Micro-exercise: find the artifacts (4 minutes)\nMatch the question → the file:\n\n“What is the baseline score?”\n\n“Which run is the newest?”\n\n“Where is the saved model object?”\n\nCheckpoint: you can name the file path for each."
  },
  {
    "objectID": "W3_ML/D2.html#solution-artifact-locations",
    "href": "W3_ML/D2.html#solution-artifact-locations",
    "title": "Machine Learning",
    "section": "Solution: artifact locations",
    "text": "Solution: artifact locations\n\nmodels/runs/&lt;run_id&gt;/metrics/baseline_holdout.json\n\nmodels/registry/latest.txt\n\nmodels/runs/&lt;run_id&gt;/model/model.joblib"
  },
  {
    "objectID": "W3_ML/D2.html#determinism-why-we-care-about-seeds",
    "href": "W3_ML/D2.html#determinism-why-we-care-about-seeds",
    "title": "Machine Learning",
    "section": "Determinism (why we care about seeds)",
    "text": "Determinism (why we care about seeds)\n\nSame seed → same split → fair comparisons across runs\nDifferent seed → different split → metrics can change a little\n\n\n\n\n\n\n\nNote\n\n\nWe don’t need “perfect” metrics today — we need repeatable training."
  },
  {
    "objectID": "W3_ML/D2.html#session-3-recap",
    "href": "W3_ML/D2.html#session-3-recap",
    "title": "Machine Learning",
    "section": "Session 3 recap",
    "text": "Session 3 recap\n\ntrain turns your feature table into a versioned run\nBaseline metrics + saved model are the minimum outcomes today\nSeeds make comparisons meaningful"
  },
  {
    "objectID": "W3_ML/D2.html#minutes-2",
    "href": "W3_ML/D2.html#minutes-2",
    "title": "Machine Learning",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: start Hands-on Task 1 immediately."
  },
  {
    "objectID": "W3_ML/D2.html#hands-on-success-criteria-today",
    "href": "W3_ML/D2.html#hands-on-success-criteria-today",
    "title": "Machine Learning",
    "section": "Hands-on success criteria (today)",
    "text": "Hands-on success criteria (today)\nMinimum ✅ - uv run ml-baseline train --target ... runs successfully - a new run folder exists under models/runs/&lt;run_id&gt;/ - metrics/baseline_holdout.json exists - model/model.joblib exists - you updated reports/model_card.md (evaluation plan section) - 1+ commit pushed to GitHub\nOptional ⭐ - run training with a different seed and compare metrics - try --split-strategy time or --split-strategy group on your own dataset (if you have one)"
  },
  {
    "objectID": "W3_ML/D2.html#project-touch-points-day-2",
    "href": "W3_ML/D2.html#project-touch-points-day-2",
    "title": "Machine Learning",
    "section": "Project touch points (Day 2)",
    "text": "Project touch points (Day 2)\nsrc/ml_baseline/\n  train.py       # orchestration: load → split → baseline → fit → save\n  splits.py      # random/time/group split helpers\n  metrics.py     # metric helpers\n  pipeline.py    # preprocessing + model (baseline pipeline)\nmodels/\n  runs/&lt;run_id&gt;/\n  registry/latest.txt\nreports/\n  model_card.md"
  },
  {
    "objectID": "W3_ML/D2.html#task-1-run-training-once-15-minutes",
    "href": "W3_ML/D2.html#task-1-run-training-once-15-minutes",
    "title": "Machine Learning",
    "section": "Task 1 — Run training once (15 minutes)",
    "text": "Task 1 — Run training once (15 minutes)\n\nEnsure sample data exists\nRun training for the sample target\nCopy the printed run folder path\n\nuv run ml-baseline make-sample-data\nuv run ml-baseline train --target is_high_value\nCheckpoint: terminal prints Saved run: .../models/runs/&lt;run_id&gt;."
  },
  {
    "objectID": "W3_ML/D2.html#solution-expected-output-shape",
    "href": "W3_ML/D2.html#solution-expected-output-shape",
    "title": "Machine Learning",
    "section": "Solution — expected output shape",
    "text": "Solution — expected output shape\nYou should see something like:\n\nSaved run: .../models/runs/2025-12-29T...Z__classification__seed42\n\n\n\n\n\n\n\nNote\n\n\nYour run_id will be different. That’s good: each run is versioned."
  },
  {
    "objectID": "W3_ML/D2.html#task-2-inspect-the-run-folder-15-minutes",
    "href": "W3_ML/D2.html#task-2-inspect-the-run-folder-15-minutes",
    "title": "Machine Learning",
    "section": "Task 2 — Inspect the run folder (15 minutes)",
    "text": "Task 2 — Inspect the run folder (15 minutes)\nList the run folders, open latest.txt, and confirm the minimum artifacts exist\nmacOS/Linux\nls models/runs\ncat models/registry/latest.txt\nls models/runs/$(cat models/registry/latest.txt)\nWindows PowerShell\nls models/runs\ntype models/registry/latest.txt\nls models/runs/$(Get-Content models/registry/latest.txt)\nCheckpoint: you can see metrics/ and model/ inside the run."
  },
  {
    "objectID": "W3_ML/D2.html#solution-run-folder-checklist",
    "href": "W3_ML/D2.html#solution-run-folder-checklist",
    "title": "Machine Learning",
    "section": "Solution — run folder checklist",
    "text": "Solution — run folder checklist\nmodels/runs/&lt;run_id&gt;/\n  metrics/baseline_holdout.json   ✅\n  model/model.joblib              ✅\n  ...\n\nIgnore the “…” for now. We’ll use more artifacts tomorrow."
  },
  {
    "objectID": "W3_ML/D2.html#task-3-read-baseline-metrics-15-minutes",
    "href": "W3_ML/D2.html#task-3-read-baseline-metrics-15-minutes",
    "title": "Machine Learning",
    "section": "Task 3 — Read baseline metrics (15 minutes)",
    "text": "Task 3 — Read baseline metrics (15 minutes)\n\nOpen the baseline JSON file\nAnswer:\n\nwhat is the baseline’s accuracy?\nwhat is the baseline’s recall?\nwhat does that imply about your class balance?\n\n\n\n\nThe commands are in the next slide."
  },
  {
    "objectID": "W3_ML/D2.html#task-3-read-baseline-metrics-15-minutes-1",
    "href": "W3_ML/D2.html#task-3-read-baseline-metrics-15-minutes-1",
    "title": "Machine Learning",
    "section": "Task 3 — Read baseline metrics (15 minutes)",
    "text": "Task 3 — Read baseline metrics (15 minutes)\nmacOS/Linux\nLATEST_ID=$(cat models/registry/latest.txt)\n\npython -m json.tool \\\n    models/runs/$LATEST_ID/metrics/baseline_holdout.json\nWindows PowerShell\n$LatestID = Get-Content models/registry/latest.txt\n\npython -m json.tool `\n    models/runs/$LatestID/metrics/baseline_holdout.json\nCheckpoint: you can explain the baseline in 1–2 sentences."
  },
  {
    "objectID": "W3_ML/D2.html#solution-what-to-look-for",
    "href": "W3_ML/D2.html#solution-what-to-look-for",
    "title": "Machine Learning",
    "section": "Solution — what to look for",
    "text": "Solution — what to look for\n\nIf accuracy is high and recall is low, the target might be imbalanced.\nYour next job is to beat this baseline on the holdout (not on training).\n\n\n\n\n\n\n\nTip\n\n\nWrite your baseline result (1–2 numbers) into your eval_summary.md later this week."
  },
  {
    "objectID": "W3_ML/D2.html#task-4-update-your-model-card-10-minutes",
    "href": "W3_ML/D2.html#task-4-update-your-model-card-10-minutes",
    "title": "Machine Learning",
    "section": "Task 4 — Update your model card (10 minutes)",
    "text": "Task 4 — Update your model card (10 minutes)\nOpen reports/model_card.md and update:\n\nSplit strategy: random holdout\nTest size + seed (whatever you used)\nPrimary metric (pick one)\n\nCheckpoint: your model card evaluation plan has no blanks."
  },
  {
    "objectID": "W3_ML/D2.html#task-5-quality-gates-10-minutes",
    "href": "W3_ML/D2.html#task-5-quality-gates-10-minutes",
    "title": "Machine Learning",
    "section": "Task 5 — Quality gates (10 minutes)",
    "text": "Task 5 — Quality gates (10 minutes)\nuv run pytest\nuv run ruff check .\nuv run ruff format --check .\nCheckpoint: all commands exit with code 0."
  },
  {
    "objectID": "W3_ML/D2.html#git-checkpoint-2-minutes",
    "href": "W3_ML/D2.html#git-checkpoint-2-minutes",
    "title": "Machine Learning",
    "section": "Git checkpoint (2 minutes)",
    "text": "Git checkpoint (2 minutes)\n\ngit status\ncommit message: \"w3d2: train + baseline\"\npush to GitHub\n\nCheckpoint: your commit appears on GitHub."
  },
  {
    "objectID": "W3_ML/D2.html#solution-git-commands",
    "href": "W3_ML/D2.html#solution-git-commands",
    "title": "Machine Learning",
    "section": "Solution — Git commands",
    "text": "Solution — Git commands\ngit status\ngit add reports/model_card.md\ngit add -A\ngit commit -m \"w3d2: train + baseline\"\ngit push"
  },
  {
    "objectID": "W3_ML/D2.html#debug-playbook-common-day-2-errors",
    "href": "W3_ML/D2.html#debug-playbook-common-day-2-errors",
    "title": "Machine Learning",
    "section": "Debug playbook (common Day 2 errors)",
    "text": "Debug playbook (common Day 2 errors)\n\nMissing target column → check --target matches your file’s column name\n“file not found” → confirm data/processed/features.* exists\n“could not convert string to float” → you forgot categorical handling (pipeline issue)\nParquet errors → install optional dependency: uv sync --extra parquet\n\n\n\n\n\n\n\nWarning\n\n\nMake one change at a time. Re-run train. Don’t “randomly tweak”."
  },
  {
    "objectID": "W3_ML/D2.html#stretch-goals-optional",
    "href": "W3_ML/D2.html#stretch-goals-optional",
    "title": "Machine Learning",
    "section": "Stretch goals (optional)",
    "text": "Stretch goals (optional)\n⭐ If you finish early:\n\nRun with a different seed: --seed 7 and compare baseline metrics\nIf your own dataset has a time column, try --split-strategy time\n(Strong students) add cross-validation on the training split (don’t remove holdout)"
  },
  {
    "objectID": "W3_ML/D2.html#exit-ticket",
    "href": "W3_ML/D2.html#exit-ticket",
    "title": "Machine Learning",
    "section": "Exit Ticket",
    "text": "Exit Ticket\nIn 1–2 sentences each:\n\nWhy do we need a holdout split?\nWhat is the purpose of a Dummy baseline?\nWhich metric did you pick as your primary metric, and why?"
  },
  {
    "objectID": "W3_ML/D2.html#what-to-do-after-class-day-2-assignment",
    "href": "W3_ML/D2.html#what-to-do-after-class-day-2-assignment",
    "title": "Machine Learning",
    "section": "What to do after class (Day 2 assignment)",
    "text": "What to do after class (Day 2 assignment)\nDue: before Day 3 (Dec 30, 2025)\n\nMake sure this command runs:\n\nuv run ml-baseline train --target &lt;your_target&gt;\n\nConfirm you can find:\n\nmetrics/baseline_holdout.json\nmodel/model.joblib\n\nUpdate reports/model_card.md evaluation plan section\nCommit + push\n\nDeliverable: GitHub repo link + the run_id from your latest run.\n\n\n\n\n\n\nTip\n\n\nDo not commit models/runs/. Commit code + reports."
  },
  {
    "objectID": "W3_ML/D4.html#announcements-admin",
    "href": "W3_ML/D4.html#announcements-admin",
    "title": "Machine Learning",
    "section": "Announcements / admin",
    "text": "Announcements / admin\n\nToday’s theme: training is not done until prediction works\nWe will use yesterday’s artifacts:\n\nschema/input_schema.json\ntables/holdout_input.*\n\nGoal: ml-baseline predict works on new files with guardrails\n\n\n\n\n\n\n\nNote\n\n\nDon’t commit generated artifacts: models/runs/, outputs/, data/processed/."
  },
  {
    "objectID": "W3_ML/D4.html#todays-flow",
    "href": "W3_ML/D4.html#todays-flow",
    "title": "Machine Learning",
    "section": "Today’s Flow",
    "text": "Today’s Flow\n\nSession 1 (60m): Inference mental model (inputs, outputs, thresholds)\nAsr Prayer (20m)\nSession 2 (60m): Schema validation + alignment (fail fast)\nMaghrib Prayer (20m)\nSession 3 (60m): Predict command end-to-end (run registry + sanity checks)\nIsha Prayer (20m)\nHands-on (120m): Implement/verify predict and test on holdout + “new” files"
  },
  {
    "objectID": "W3_ML/D4.html#learning-objectives",
    "href": "W3_ML/D4.html#learning-objectives",
    "title": "Machine Learning",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of today, you can:\n\nExplain the inference contract (what goes in, what comes out)\nRun ml-baseline predict on holdout_input.* successfully\nEnforce input_schema.json (missing required columns → error; forbidden columns → error)\nPreserve optional ID columns in prediction outputs\nDo 3 sanity checks on prediction outputs (rows, columns, ranges)\nAdd 1–2 helpful failure messages that save debugging time"
  },
  {
    "objectID": "W3_ML/D4.html#warm-up-5-minutes",
    "href": "W3_ML/D4.html#warm-up-5-minutes",
    "title": "Machine Learning",
    "section": "Warm-up (5 minutes)",
    "text": "Warm-up (5 minutes)\nRun prediction on your saved holdout input.\nmacOS/Linux\nrun_id=$(cat models/registry/latest.txt)\nholdout=$(ls models/runs/$run_id/tables/holdout_input.* | head -n 1)\nuv run ml-baseline predict --run latest --input \"$holdout\" --output outputs/preds.csv\nhead -n 6 outputs/preds.csv\nWindows PowerShell\n$run_id = Get-Content models/registry/latest.txt\n$holdout = (Get-ChildItem \"models/runs/$run_id/tables\" -Filter \"holdout_input.*\" | Select-Object -First 1).FullName\nuv run ml-baseline predict --run latest --input $holdout --output outputs/preds.csv\nGet-Content outputs/preds.csv -TotalCount 6\nCheckpoint: you produced outputs/preds.csv and it has prediction (and maybe score)."
  },
  {
    "objectID": "W3_ML/D4.html#where-today-fits-in-the-week-3-loop",
    "href": "W3_ML/D4.html#where-today-fits-in-the-week-3-loop",
    "title": "Machine Learning",
    "section": "Where today fits in the Week 3 loop",
    "text": "Where today fits in the Week 3 loop\nDefine → Split → Baseline → Train → Evaluate → Save → Predict → Report\n\nToday: Predict uses yesterday’s schema + holdout_input."
  },
  {
    "objectID": "W3_ML/D4.html#session-1-objectives",
    "href": "W3_ML/D4.html#session-1-objectives",
    "title": "Machine Learning",
    "section": "Session 1 objectives",
    "text": "Session 1 objectives\n\nDefine “inference” in 1 sentence\nDescribe the input contract (no target; required features must exist)\nDescribe the output contract (predictions file)\nUnderstand what a threshold does (classification)"
  },
  {
    "objectID": "W3_ML/D4.html#training-vs-inference-the-only-difference-that-matters",
    "href": "W3_ML/D4.html#training-vs-inference-the-only-difference-that-matters",
    "title": "Machine Learning",
    "section": "Training vs inference (the only difference that matters)",
    "text": "Training vs inference (the only difference that matters)\n\n\nTraining - input: features + target (y) - output: a saved model (pipeline) - you compute metrics (holdout)\n\nInference - input: features only - output: predictions file - you must handle missing/extra columns safely\n\n\n\n\n\n\n\nWarning\n\n\nIf the target leaks into inference input, your system becomes “cheat mode” and metrics become meaningless."
  },
  {
    "objectID": "W3_ML/D4.html#inference-contract-what-goes-in-what-comes-out",
    "href": "W3_ML/D4.html#inference-contract-what-goes-in-what-comes-out",
    "title": "Machine Learning",
    "section": "Inference contract (what goes in / what comes out)",
    "text": "Inference contract (what goes in / what comes out)\nInput file (--input) - must include: schema.required_feature_columns - may include: schema.optional_id_columns (pass-through) - must NOT include: schema.forbidden_columns (usually the target)\nOutput file (--output) - always includes: prediction - classification also includes: score - includes ID columns if they were provided in the input"
  },
  {
    "objectID": "W3_ML/D4.html#classification-outputs-score-vs-prediction",
    "href": "W3_ML/D4.html#classification-outputs-score-vs-prediction",
    "title": "Machine Learning",
    "section": "Classification outputs: score vs prediction",
    "text": "Classification outputs: score vs prediction\n\n\nScore - a probability-like number - used to rank cases\nPrediction - a 0/1 decision - made by score &gt;= threshold\n\nExample\n\n\n\nscore\nthreshold\nprediction\n\n\n\n\n0.82\n0.50\n1\n\n\n0.49\n0.50\n0\n\n\n0.82\n0.90\n0\n\n\n\n\n\nThe same score can become a different decision if you change the threshold."
  },
  {
    "objectID": "W3_ML/D4.html#thresholds-keep-it-simple-today",
    "href": "W3_ML/D4.html#thresholds-keep-it-simple-today",
    "title": "Machine Learning",
    "section": "Thresholds: keep it simple today",
    "text": "Thresholds: keep it simple today\nMinimum ✅ - use a fixed threshold (0.50) for classification\nOptional ⭐ - choose threshold to maximize F1 (max_f1) - choose threshold to meet a business rule (e.g., precision ≥ 0.80)\n\n\n\n\n\n\nTip\n\n\nPick one decision policy and document it in your model card."
  },
  {
    "objectID": "W3_ML/D4.html#quick-check",
    "href": "W3_ML/D4.html#quick-check",
    "title": "Machine Learning",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: If we increase the threshold from 0.50 to 0.80, what usually happens?\n\nMore predicted positives, higher recall\nFewer predicted positives, higher precision (often)\nNothing changes\n\n\nAnswer: B (fewer positives; precision often increases; recall often decreases)."
  },
  {
    "objectID": "W3_ML/D4.html#micro-exercise-design-your-prediction-output-6-minutes",
    "href": "W3_ML/D4.html#micro-exercise-design-your-prediction-output-6-minutes",
    "title": "Machine Learning",
    "section": "Micro-exercise: design your prediction output (6 minutes)",
    "text": "Micro-exercise: design your prediction output (6 minutes)\nIn pairs:\n\nDecide which columns your outputs/preds.csv must contain\nDecide which columns should be “pass-through” IDs\nWrite one sentence: “A teammate can use this output to ___.”\n\nCheckpoint: you can explain score vs prediction in one sentence."
  },
  {
    "objectID": "W3_ML/D4.html#solution-example",
    "href": "W3_ML/D4.html#solution-example",
    "title": "Machine Learning",
    "section": "Solution (example)",
    "text": "Solution (example)\n\nClassification output columns: user_id (optional), score, prediction\nPass-through IDs: columns like user_id, customer_id, transaction_id\nSentence: “A teammate can use this file to rank customers by score and take action on predicted positives.”"
  },
  {
    "objectID": "W3_ML/D4.html#session-1-recap",
    "href": "W3_ML/D4.html#session-1-recap",
    "title": "Machine Learning",
    "section": "Session 1 recap",
    "text": "Session 1 recap\n\nInference = run a saved model on features-only input\nOutput = predictions (and score for classification)\nThreshold converts score → decision"
  },
  {
    "objectID": "W3_ML/D4.html#minutes",
    "href": "W3_ML/D4.html#minutes",
    "title": "Machine Learning",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: open schema/input_schema.json in your latest run."
  },
  {
    "objectID": "W3_ML/D4.html#session-2-objectives",
    "href": "W3_ML/D4.html#session-2-objectives",
    "title": "Machine Learning",
    "section": "Session 2 objectives",
    "text": "Session 2 objectives\n\nExplain why we validate inference inputs\nImplement/verify validate_and_align(df, schema)\nFail fast on:\n\nforbidden columns\nmissing required features\n\nPreserve optional IDs in the output"
  },
  {
    "objectID": "W3_ML/D4.html#real-world-csv-problems-that-break-models",
    "href": "W3_ML/D4.html#real-world-csv-problems-that-break-models",
    "title": "Machine Learning",
    "section": "Real-world CSV problems (that break models)",
    "text": "Real-world CSV problems (that break models)\n\nA required column is missing\nA column name changed (typo / rename)\nThe target column was accidentally included\nA numeric column arrives as text (\"12\", \"N/A\")\n\n\n\n\n\n\n\nTip\n\n\nYour schema turns “mysterious errors” into clear messages."
  },
  {
    "objectID": "W3_ML/D4.html#what-validate_and_align...-must-do",
    "href": "W3_ML/D4.html#what-validate_and_align...-must-do",
    "title": "Machine Learning",
    "section": "What validate_and_align(...) must do",
    "text": "What validate_and_align(...) must do\ninput df\n  → check forbidden (fail)\n  → check missing required (fail)\n  → select optional IDs (passthrough)\n  → coerce dtypes (simple)\n  → return (X, ids)\n\nThis function is the “seatbelt” for your predict command."
  },
  {
    "objectID": "W3_ML/D4.html#example-validation-rules",
    "href": "W3_ML/D4.html#example-validation-rules",
    "title": "Machine Learning",
    "section": "Example: validation rules",
    "text": "Example: validation rules\nIf inference input contains:\n\nis_high_value (target) → error: forbidden column\nmissing avg_spend_30d → error: missing required feature\nextra column notes → ignore (unless you choose to fail) ⭐ optional\n\n\n\n\n\n\n\nWarning\n\n\nDo not silently fill missing required features. Fail fast."
  },
  {
    "objectID": "W3_ML/D4.html#friendly-failures-prefer-valueerror-over-assert",
    "href": "W3_ML/D4.html#friendly-failures-prefer-valueerror-over-assert",
    "title": "Machine Learning",
    "section": "Friendly failures: prefer ValueError over assert",
    "text": "Friendly failures: prefer ValueError over assert\n\n\nHard to read - assert not missing - can be skipped with Python optimizations - message might be unclear\n\nBetter - raise ValueError(\"Missing required columns: ...\") - always runs - clear for teammates\n\n\nAsserts are okay for learning — but clear errors are better for shipping."
  },
  {
    "objectID": "W3_ML/D4.html#micro-exercise-what-should-the-error-say-6-minutes",
    "href": "W3_ML/D4.html#micro-exercise-what-should-the-error-say-6-minutes",
    "title": "Machine Learning",
    "section": "Micro-exercise: what should the error say? (6 minutes)",
    "text": "Micro-exercise: what should the error say? (6 minutes)\nYou receive this inference file columns:\n[\"user_id\", \"country\", \"avg_spend_30d\", \"is_high_value\"]\n\nWhat is the problem?\nWrite the error message you want a teammate to see.\n\nCheckpoint: your message includes the exact bad column name."
  },
  {
    "objectID": "W3_ML/D4.html#solution-example-1",
    "href": "W3_ML/D4.html#solution-example-1",
    "title": "Machine Learning",
    "section": "Solution (example)",
    "text": "Solution (example)\n\nProblem: target column is_high_value is present (forbidden)\nExample error message:\n\nForbidden columns present in inference input: ['is_high_value']"
  },
  {
    "objectID": "W3_ML/D4.html#quick-check-1",
    "href": "W3_ML/D4.html#quick-check-1",
    "title": "Machine Learning",
    "section": "Quick Check",
    "text": "Quick Check\nQuestion: Should we automatically add a missing required feature column as zeros?\n\nAnswer: Usually no. That hides data problems and can silently degrade predictions."
  },
  {
    "objectID": "W3_ML/D4.html#session-2-recap",
    "href": "W3_ML/D4.html#session-2-recap",
    "title": "Machine Learning",
    "section": "Session 2 recap",
    "text": "Session 2 recap\n\nSchema validation prevents silent bugs\nFail fast on forbidden/missing columns\nReturn (X, ids) so IDs can be preserved in outputs"
  },
  {
    "objectID": "W3_ML/D4.html#minutes-1",
    "href": "W3_ML/D4.html#minutes-1",
    "title": "Machine Learning",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: be ready to run predict on a file with an intentional mistake."
  },
  {
    "objectID": "W3_ML/D4.html#session-3-objectives",
    "href": "W3_ML/D4.html#session-3-objectives",
    "title": "Machine Learning",
    "section": "Session 3 objectives",
    "text": "Session 3 objectives\n\nExplain what a run folder is and why we load from it\nUse --run latest to predict without guessing paths\nDo sanity checks on prediction outputs"
  },
  {
    "objectID": "W3_ML/D4.html#run-folders-prediction-must-be-reproducible",
    "href": "W3_ML/D4.html#run-folders-prediction-must-be-reproducible",
    "title": "Machine Learning",
    "section": "Run folders: prediction must be reproducible",
    "text": "Run folders: prediction must be reproducible\nA trained run lives at:\nmodels/runs/&lt;run_id&gt;/\n  model/model.joblib\n  schema/input_schema.json\n  run_meta.json\nAnd the “pointer” lives at:\nmodels/registry/latest.txt\n\n\n\n\n\n\nTip\n\n\nlatest.txt lets you predict without copy/pasting long paths."
  },
  {
    "objectID": "W3_ML/D4.html#predict-command-anatomy",
    "href": "W3_ML/D4.html#predict-command-anatomy",
    "title": "Machine Learning",
    "section": "Predict command anatomy",
    "text": "Predict command anatomy\nExample\nuv run ml-baseline predict \\\n  --run latest \\\n  --input data/processed/features.csv \\\n  --output outputs/preds.csv\nUnder the hood:\n\nresolve run dir (latest → models/runs/&lt;run_id&gt;)\nload schema + model\nread input table\nvalidate + align columns\npredict + write output"
  },
  {
    "objectID": "W3_ML/D4.html#sanity-checks-after-predict",
    "href": "W3_ML/D4.html#sanity-checks-after-predict",
    "title": "Machine Learning",
    "section": "Sanity checks after predict",
    "text": "Sanity checks after predict\nMinimum checks you should do every time:\n\nRow count: output rows == input rows\nColumns: output contains expected columns\nRanges:\n\nclassification: 0 ≤ score ≤ 1\nregression: predictions are finite (no all-NaN)\n\n\n\n\n\n\n\n\nTip\n\n\nIf row counts don’t match, stop. Something is wrong."
  },
  {
    "objectID": "W3_ML/D4.html#optional-a-tiny-skew-check-idea",
    "href": "W3_ML/D4.html#optional-a-tiny-skew-check-idea",
    "title": "Machine Learning",
    "section": "Optional ⭐: a tiny “skew check” idea",
    "text": "Optional ⭐: a tiny “skew check” idea\nNot required today, but good to know:\n\nCompare today’s inference input to yesterday’s holdout_input:\n\nmissingness rates\nnumeric ranges (min/max)\nnew/unseen categories\n\n\n\nWe’ll do richer checks in Week 7 (MLOps). Today we just ship predict."
  },
  {
    "objectID": "W3_ML/D4.html#session-3-recap",
    "href": "W3_ML/D4.html#session-3-recap",
    "title": "Machine Learning",
    "section": "Session 3 recap",
    "text": "Session 3 recap\n\nA run folder contains everything needed for inference\n--run latest uses models/registry/latest.txt\nAlways do sanity checks after prediction"
  },
  {
    "objectID": "W3_ML/D4.html#minutes-2",
    "href": "W3_ML/D4.html#minutes-2",
    "title": "Machine Learning",
    "section": "20 minutes",
    "text": "20 minutes\nWhen you return: start Hands-on Task 1 immediately."
  },
  {
    "objectID": "W3_ML/D4.html#hands-on-success-criteria-today",
    "href": "W3_ML/D4.html#hands-on-success-criteria-today",
    "title": "Machine Learning",
    "section": "Hands-on success criteria (today)",
    "text": "Hands-on success criteria (today)\nMinimum ✅ - uv run ml-baseline predict --run latest ... writes an output file - Input schema is enforced: - forbidden target column → clear error - missing required feature → clear error - Output includes optional IDs if they exist in the input - uv run pytest passes - 1+ commit pushed to GitHub\nOptional ⭐ - Improve error messages (ValueError + actionable hint) - Add --threshold override behavior (classification) - Add a tiny skew-check script (missingness + ranges)"
  },
  {
    "objectID": "W3_ML/D4.html#project-touch-points-day-4",
    "href": "W3_ML/D4.html#project-touch-points-day-4",
    "title": "Machine Learning",
    "section": "Project touch points (Day 4)",
    "text": "Project touch points (Day 4)\nsrc/ml_baseline/\n  predict.py     # run_predict + resolve_run_dir\n  schema.py      # InputSchema + validate_and_align\n  io.py          # read_tabular / write_tabular\nmodels/runs/&lt;run_id&gt;/\n  model/\n  schema/\noutputs/\n  preds.csv"
  },
  {
    "objectID": "W3_ML/D4.html#task-1-predict-on-holdout_input-15-minutes",
    "href": "W3_ML/D4.html#task-1-predict-on-holdout_input-15-minutes",
    "title": "Machine Learning",
    "section": "Task 1 — Predict on holdout_input (15 minutes)",
    "text": "Task 1 — Predict on holdout_input (15 minutes)\n\nFind holdout_input.* inside your latest run\nRun predict on it\nInspect the output file\n\nmacOS/Linux\nrun_id=$(cat models/registry/latest.txt)\nholdout=$(ls models/runs/$run_id/tables/holdout_input.* | head -n 1)\nuv run ml-baseline predict --run latest --input \"$holdout\" --output outputs/preds.csv\nhead -n 6 outputs/preds.csv\nWindows PowerShell\n$run_id = Get-Content models/registry/latest.txt\n$holdout = (Get-ChildItem \"models/runs/$run_id/tables\" -Filter \"holdout_input.*\" | Select-Object -First 1).FullName\nuv run ml-baseline predict --run latest --input $holdout --output outputs/preds.csv\nGet-Content outputs/preds.csv -TotalCount 6\nCheckpoint: output file exists and includes prediction."
  },
  {
    "objectID": "W3_ML/D4.html#task-2-create-an-intentional-failure-10-minutes",
    "href": "W3_ML/D4.html#task-2-create-an-intentional-failure-10-minutes",
    "title": "Machine Learning",
    "section": "Task 2 — Create an intentional failure (10 minutes)",
    "text": "Task 2 — Create an intentional failure (10 minutes)\nGoal: prove your guardrails work.\n\nCopy holdout_input.* to outputs/bad_input.csv\nAdd the target column name (or delete one required feature)\nRun predict again\n\nCheckpoint: predict fails with a clear message."
  },
  {
    "objectID": "W3_ML/D4.html#hint-easiest-way-to-create-a-bad-file",
    "href": "W3_ML/D4.html#hint-easiest-way-to-create-a-bad-file",
    "title": "Machine Learning",
    "section": "Hint: easiest way to create a bad file",
    "text": "Hint: easiest way to create a bad file\n\nIf you have holdout_input.csv, open it and add a column header:\n\nis_high_value\n\nOr delete one required feature header\n\n\n\n\n\n\n\nTip\n\n\nYou’re testing the contract, not the model."
  },
  {
    "objectID": "W3_ML/D4.html#task-3-verifyimplement-resolve_run_dir-10-minutes",
    "href": "W3_ML/D4.html#task-3-verifyimplement-resolve_run_dir-10-minutes",
    "title": "Machine Learning",
    "section": "Task 3 — Verify/implement resolve_run_dir (10 minutes)",
    "text": "Task 3 — Verify/implement resolve_run_dir (10 minutes)\nOpen: src/ml_baseline/predict.py\nEnsure:\n\n--run latest loads models/registry/latest.txt\nit returns models/runs/&lt;run_id&gt;\nit errors clearly when latest doesn’t exist\n\nCheckpoint: ml-baseline show-run latest prints run_meta.json."
  },
  {
    "objectID": "W3_ML/D4.html#solution-example-logic",
    "href": "W3_ML/D4.html#solution-example-logic",
    "title": "Machine Learning",
    "section": "Solution (example logic)",
    "text": "Solution (example logic)\nif run == \"latest\":\n    p = models_dir / \"registry\" / \"latest.txt\"\n    if not p.exists():\n        raise FileNotFoundError(\"No latest.txt found. Train a model first.\")\n    run_id = p.read_text(encoding=\"utf-8\").strip()\n    return models_dir / \"runs\" / run_id\nreturn Path(run).resolve()"
  },
  {
    "objectID": "W3_ML/D4.html#task-4-verifyimplement-validate_and_align-25-minutes",
    "href": "W3_ML/D4.html#task-4-verifyimplement-validate_and_align-25-minutes",
    "title": "Machine Learning",
    "section": "Task 4 — Verify/implement validate_and_align (25 minutes)",
    "text": "Task 4 — Verify/implement validate_and_align (25 minutes)\nOpen: src/ml_baseline/schema.py\nMinimum behavior:\n\nFail if forbidden columns exist\nFail if required columns are missing\nReturn:\n\nX with required features in schema order\nids with optional ID columns (if present)\n\n\nCheckpoint: predict works on good input and fails on bad input."
  },
  {
    "objectID": "W3_ML/D4.html#solution-pattern-high-level",
    "href": "W3_ML/D4.html#solution-pattern-high-level",
    "title": "Machine Learning",
    "section": "Solution pattern (high level)",
    "text": "Solution pattern (high level)\n- forbidden = ...\n- missing = ...\n- ids = df[optional_ids]\n- coerce dtypes (optional)\n- X = df[required_features]\n- return X, ids\n\nKeep it boring. Reliability beats cleverness."
  },
  {
    "objectID": "W3_ML/D4.html#task-5-output-contract-10-minutes",
    "href": "W3_ML/D4.html#task-5-output-contract-10-minutes",
    "title": "Machine Learning",
    "section": "Task 5 — Output contract (10 minutes)",
    "text": "Task 5 — Output contract (10 minutes)\nAfter prediction, check:\n\noutput row count equals input row count\ncolumns are correct:\n\nclassification: score, prediction (+ IDs)\nregression: prediction (+ IDs)\n\n\nCheckpoint: you can point to one row and explain it."
  },
  {
    "objectID": "W3_ML/D4.html#task-6-tests-small-doc-update-15-minutes",
    "href": "W3_ML/D4.html#task-6-tests-small-doc-update-15-minutes",
    "title": "Machine Learning",
    "section": "Task 6 — Tests + small doc update (15 minutes)",
    "text": "Task 6 — Tests + small doc update (15 minutes)\n\nRun tests:\n\nuv run pytest\n\nUpdate reports/model_card.md:\n\n\nadd a short “How to predict” section (1–3 commands)\nlist what inference input must contain\n\nCheckpoint: tests pass and model card explains prediction."
  },
  {
    "objectID": "W3_ML/D4.html#vibe-coding-safe-version",
    "href": "W3_ML/D4.html#vibe-coding-safe-version",
    "title": "Machine Learning",
    "section": "Vibe coding (safe version)",
    "text": "Vibe coding (safe version)\n\nWrite the plan in 5 bullets (no code yet)\nImplement the smallest piece\nRun → break → read error → fix\nCommit\nRepeat\n\n\n\n\n\n\n\nWarning\n\n\nDo not ask GenAI to write your solution code. Ask it to explain concepts or errors."
  },
  {
    "objectID": "W3_ML/D4.html#git-checkpoint-2-minutes",
    "href": "W3_ML/D4.html#git-checkpoint-2-minutes",
    "title": "Machine Learning",
    "section": "Git checkpoint (2 minutes)",
    "text": "Git checkpoint (2 minutes)\n\ngit status\ncommit with message: \"w3d4: predict cli + schema guardrails\"\npush to GitHub\n\nCheckpoint: repo shows the new commit online."
  },
  {
    "objectID": "W3_ML/D4.html#debug-playbook-predict-edition",
    "href": "W3_ML/D4.html#debug-playbook-predict-edition",
    "title": "Machine Learning",
    "section": "Debug playbook (predict edition)",
    "text": "Debug playbook (predict edition)\n\nConfirm files exist:\n\nmodels/registry/latest.txt\nmodels/runs/&lt;run_id&gt;/model/model.joblib\nmodels/runs/&lt;run_id&gt;/schema/input_schema.json\n\nPrint columns of your input file\nCompare with schema required list\nIf it fails, fix schema validation first\n\n\n\n\n\n\n\nTip\n\n\nMost predict bugs are column contract bugs, not model bugs."
  },
  {
    "objectID": "W3_ML/D4.html#stretch-goals-optional",
    "href": "W3_ML/D4.html#stretch-goals-optional",
    "title": "Machine Learning",
    "section": "Stretch goals (optional ⭐)",
    "text": "Stretch goals (optional ⭐)\n\nAdd --threshold override in predict (classification)\nAdd a “strict mode” (--strict) to fail on extra columns\nAdd a tiny skew-check script that prints:\n\nmissingness rate per column\nnumeric min/max"
  },
  {
    "objectID": "W3_ML/D4.html#exit-ticket",
    "href": "W3_ML/D4.html#exit-ticket",
    "title": "Machine Learning",
    "section": "Exit Ticket",
    "text": "Exit Ticket\nIn 1–2 sentences each:\n\nWhat is the difference between a score and a prediction?\nName 2 ways inference input can break a model.\nWhat file makes --run latest possible?"
  },
  {
    "objectID": "W3_ML/D4.html#what-to-do-after-class-day-4-assignment",
    "href": "W3_ML/D4.html#what-to-do-after-class-day-4-assignment",
    "title": "Machine Learning",
    "section": "What to do after class (Day 4 assignment)",
    "text": "What to do after class (Day 4 assignment)\nDue: before Day 5 (Jan 1, 2026)\n\nRun predict on 2 inputs:\n\nyour holdout_input.*\none “new” file you create (copy + edit 5 rows)\n\nWrite 3 bullet points in reports/model_card.md:\n\nrequired columns\nforbidden columns\nhow to run predict\n\nCommit + push\n\nDeliverable: GitHub repo link + screenshot of outputs/preds.csv (first 5 rows).\n\n\n\n\n\n\nTip\n\n\nTomorrow you’ll polish reporting + submission. Today is about reliable inference."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session1.html#module-1-overview",
    "href": "W4_DL/C1_M1_Getting_Started/session1.html#module-1-overview",
    "title": "Module 1 - Session 1: Introduction to PyTorch and Neural Networks",
    "section": "Module 1 Overview",
    "text": "Module 1 Overview\nWhat will we learn?\n\nDistinguish Deep Learning from Machine Learning\nWhat are neurons and how do they learn?\nWhy learn the PyTorch framework?\nThe ML Pipeline\nActivation Functions\nTensors (PyTorch’s data structures)\n\n\nWelcome to Module 1 of PyTorch Fundamentals. This module will take you from understanding why PyTorch exists to building and training your first neural network. We’ll start with the motivation behind PyTorch, then dive into the fundamental building blocks, and end with hands-on implementation.\nThe question chain shows how each session builds on the previous one: understanding PyTorch’s philosophy leads to understanding neural networks, which leads to understanding the pipeline, which leads to implementation."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session1.html#machine-learning-vs-traditional-programming",
    "href": "W4_DL/C1_M1_Getting_Started/session1.html#machine-learning-vs-traditional-programming",
    "title": "Module 1 - Session 1: Introduction to PyTorch and Neural Networks",
    "section": "Machine Learning vs Traditional Programming",
    "text": "Machine Learning vs Traditional Programming\n\nML vs Traditional Programming\nTo understand why we need PyTorch and neural networks, we need to understand how machine learning differs from traditional programming.\nIn traditional programming, you write rules that transform inputs to outputs. If the customer buys a camera, recommend lenses. But what if it was a gift? What if they already have five lenses? You’d need thousands of rules for every exception.\nIn machine learning, you give the system examples of inputs and outputs, and it learns the rules for you. Deep learning takes this further using neural networks - they can learn complex patterns from data that would be impossible to encode as rules."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session1.html#the-challenge-unstructured-data",
    "href": "W4_DL/C1_M1_Getting_Started/session1.html#the-challenge-unstructured-data",
    "title": "Module 1 - Session 1: Introduction to PyTorch and Neural Networks",
    "section": "The Challenge: Unstructured Data",
    "text": "The Challenge: Unstructured Data\n\nHigh-Dimensional Data\n224 × 224 image = 50,176 pixels\n1080p image = 2,073,600 pixels\n\n\nHere’s why we need deep learning. Traditional machine learning works well with structured data - clean tables with columns and rows. But much of the world’s data is unstructured: images, videos, audio, text.\nA single image can have millions of pixels. You can’t represent this as columns in a DataFrame and use classical ML models - it would be completely impractical. Neural networks can learn to recognize patterns in this high-dimensional data directly from the raw pixels."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session1.html#neural-networks-universal-approximators",
    "href": "W4_DL/C1_M1_Getting_Started/session1.html#neural-networks-universal-approximators",
    "title": "Module 1 - Session 1: Introduction to PyTorch and Neural Networks",
    "section": "Neural Networks: Universal Approximators",
    "text": "Neural Networks: Universal Approximators\n\nNeural Network ProcessingRepresentation Learning from raw data\n\nNeural networks are known as universal approximators because they can approximate any function given enough data and computational power. They solve the problem of representation learning - automatically discovering meaningful features from raw data.\nInstead of manually engineering features (like “does this image have edges?” or “are there circular shapes?”), neural networks learn to spot patterns formed by pixels and represent them as progressively more abstract and meaningful features. The final layer uses these learned features to make predictions."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session1.html#deep-learning-vs-machine-learning",
    "href": "W4_DL/C1_M1_Getting_Started/session1.html#deep-learning-vs-machine-learning",
    "title": "Module 1 - Session 1: Introduction to PyTorch and Neural Networks",
    "section": "Deep Learning vs Machine Learning",
    "text": "Deep Learning vs Machine Learning\n\nAI, ML, DL Venn DiagramDeep Learning = Neural Networks with multiple layers\n\nDeep learning is a subset of machine learning based on artificial neural networks with multiple layers - hence “deep.” While a basic neural network might have one or two hidden layers, deep learning models often contain dozens or even hundreds of layers.\nThe key difference: deep learning excels at unstructured data (images, speech, text) and learns hierarchical representations directly from raw data, while traditional ML often requires manual feature engineering and works well on structured/tabular data."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session1.html#ml-vs-dl",
    "href": "W4_DL/C1_M1_Getting_Started/session1.html#ml-vs-dl",
    "title": "Module 1 - Session 1: Introduction to PyTorch and Neural Networks",
    "section": "ML vs DL",
    "text": "ML vs DL\n\n\n\n\n\n\n\n\nCharacteristic\nMachine Learning (ML)\nDeep Learning (DL)\n\n\n\n\nPerformance Envelope\nCompetitive on structured/tabular data\nDominant in unstructured domains (vision, speech, NLP)\n\n\nData Regime\nPerforms well with small to medium datasets\nTypically requires large-scale datasets to generalize well\n\n\nComputational Cost\nOften CPU-friendly; faster training\nGPU/TPU-dependent; computationally expensive\n\n\nModel Class\nLinear models, Decision Trees, Random Forests, Gradient Boosting\nMulti-layer Neural Networks, CNNs, RNNs, Transformers\n\n\nFeature Engineering\nRelies heavily on manual feature design informed by domain knowledge\nLearns hierarchical representations directly from raw data\n\n\nInterpretability\nMany models are interpretable (linear models, trees)\nLargely opaque; “black box” nature requiring post-hoc explainability\n\n\n\n\nDeep learning isn’t always the right solution. It’s great when traditional rule-based approaches fail, when environments change continuously, or when you need to discover patterns in massive datasets.\nBut it’s not good when you need to explain decisions, when simple rules work fine, when errors can’t be tolerated, or when you have limited data. The key is choosing the right tool for the job."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session1.html#many-deep-learning-applications",
    "href": "W4_DL/C1_M1_Getting_Started/session1.html#many-deep-learning-applications",
    "title": "Module 1 - Session 1: Introduction to PyTorch and Neural Networks",
    "section": "Many Deep Learning Applications",
    "text": "Many Deep Learning Applications\nVision:\n\nLandingAI\nUltralytics\n\nLanguage:\n\nOpenAI\nGemini"
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session1.html#data-annotation",
    "href": "W4_DL/C1_M1_Getting_Started/session1.html#data-annotation",
    "title": "Module 1 - Session 1: Introduction to PyTorch and Neural Networks",
    "section": "Data Annotation",
    "text": "Data Annotation\n\nModels must be fine-tuned on annotated data"
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session1.html#start-simple-the-delivery-problem",
    "href": "W4_DL/C1_M1_Getting_Started/session1.html#start-simple-the-delivery-problem",
    "title": "Module 1 - Session 1: Introduction to PyTorch and Neural Networks",
    "section": "Start Simple: The Delivery Problem",
    "text": "Start Simple: The Delivery Problem\nScenario: Local delivery company, 30-minute promise\nNew order: 7 miles away\nQuestion: Can you get there in under 30 minutes?\n\nNow let’s ground these concepts with a concrete problem. You work for a local delivery company that promises 30-minute delivery. You’ve been late three times, and one more late delivery could cost you your job. A new order comes in - 7 miles away. Do you take it?\nThis is a perfect problem for a neural network to solve, if we have historical data. And we’ll use the simplest possible neural network - just one neuron - to tackle it."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session1.html#historical-delivery-data",
    "href": "W4_DL/C1_M1_Getting_Started/session1.html#historical-delivery-data",
    "title": "Module 1 - Session 1: Introduction to PyTorch and Neural Networks",
    "section": "Historical Delivery Data",
    "text": "Historical Delivery Data\n\n\n\nDistance (miles)\nTime (minutes)\n\n\n\n\n5.0\n22.2\n\n\n6.0\n25.6\n\n\n7.0\n?\n\n\n\nCan you see the pattern?\n\nHere’s some historical delivery data. Can you see the pattern? 5 miles took 22.2 minutes, 6 miles took 25.6 minutes. If we plot this data, we’d see the points follow a straight line. A good predictive model would be… a line!\nIf we know the equation for that line, we can predict new values. And here’s the key insight: a single neuron is just a linear equation with two parameters - the weight and the bias."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session1.html#a-single-neuron-a-linear-equation",
    "href": "W4_DL/C1_M1_Getting_Started/session1.html#a-single-neuron-a-linear-equation",
    "title": "Module 1 - Session 1: Introduction to PyTorch and Neural Networks",
    "section": "A Single Neuron = A Linear Equation",
    "text": "A Single Neuron = A Linear Equation\n\nSingle Neuron\\(y = Wx + b\\)\n\nW = weight (slope)\nb = bias (y-intercept)\nx = input (distance)\ny = output (predicted time)\n\n\nA single neuron is just a linear equation. That’s the equation for a straight line. The neuron needs to find the right values for W (weight) and b (bias) to create the best-fitting line through all the data points.\nThat search for the best values - that’s the learning in machine learning. The neuron starts with random values, measures how wrong its predictions are, and gradually adjusts W and b to improve."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session1.html#how-does-a-neuron-learn",
    "href": "W4_DL/C1_M1_Getting_Started/session1.html#how-does-a-neuron-learn",
    "title": "Module 1 - Session 1: Introduction to PyTorch and Neural Networks",
    "section": "How Does a Neuron Learn?",
    "text": "How Does a Neuron Learn?\n\nStart with random weight and bias\nMake predictions\nMeasure error (how far off?)\nUse calculus to find adjustment direction\nTake small step toward better values\nRepeat hundreds/thousands of times\n\n\nHere’s how the learning process works. The neuron starts with random values for weight and bias. It makes predictions and measures how far off each prediction is from the actual data. The further off, the bigger the total error.\nThen it uses calculus (specifically, gradient descent) to figure out which direction to adjust the weight and bias. It’s essentially asking: “If I increase the weight just a little, does the error go up or down?” Once it figures that out, it takes a small step in the right direction, measures the error again, and repeats.\nThis process happens hundreds or thousands of times until the neuron finds values close to the best possible ones."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session1.html#multiple-inputs",
    "href": "W4_DL/C1_M1_Getting_Started/session1.html#multiple-inputs",
    "title": "Module 1 - Session 1: Introduction to PyTorch and Neural Networks",
    "section": "Multiple Inputs",
    "text": "Multiple Inputs\nSingle input: distance → delivery_time\nMultiple inputs: distance + time_of_day + weather → delivery_time\n\\[\ny = w_1 x_1 + w_2 x_2 + w_3 x_3 + b\n\\]\n\nSo far we’ve seen a neuron with one input (distance). But what if you want to consider multiple factors - distance, time of day, and weather?\nA neuron with multiple inputs just extends the same pattern. It’s still a linear equation, just with more terms. Each input gets its own unique weight, they all add up, plus the single bias value. That’s really all a neural network is - neurons connected to neurons."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session1.html#layers-and-networks",
    "href": "W4_DL/C1_M1_Getting_Started/session1.html#layers-and-networks",
    "title": "Module 1 - Session 1: Introduction to PyTorch and Neural Networks",
    "section": "Layers and Networks",
    "text": "Layers and Networks\n\nNeural Network Structure\nLayer: group of neurons with same inputs\nHidden layers: layers between input and output\nNetwork: connected layers\n\n\nWhen you connect neurons together, you get layers. A layer is simply a group of neurons that all take the same inputs. When you connect one layer’s outputs to the next layer’s inputs, you’ve built a network.\nThe first layer takes in your raw data (distance, time of day, weather). The last layer gives your prediction (delivery time). All those layers in between are called hidden layers because you never directly set or see their values.\nSoon, you’ll see how easy it is to stack these layers together in PyTorch. But for now, we’ll continue with just one neuron to build the foundation."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session1.html#analogy-visual-cortex",
    "href": "W4_DL/C1_M1_Getting_Started/session1.html#analogy-visual-cortex",
    "title": "Module 1 - Session 1: Introduction to PyTorch and Neural Networks",
    "section": "Analogy: Visual Cortex",
    "text": "Analogy: Visual Cortex\nHierarchical Feature Extraction: From Retinal Input to Complex Object Recognition in the Ventral Stream.\n\nVisual Cortex High-Level Features\nDeep neural networks are like the visual cortex of the brain. They start with simple features like edges and shapes, and build up to more complex features like objects and scenes."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session1.html#pytorch",
    "href": "W4_DL/C1_M1_Getting_Started/session1.html#pytorch",
    "title": "Module 1 - Session 1: Introduction to PyTorch and Neural Networks",
    "section": "PyTorch",
    "text": "PyTorch\n\nPyTorch is an open-source deep learning framework designed to accelerate the path from research prototyping to production deployment. Originally developed by Meta’s AI Research lab (FAIR) and released in 2016, it is now governed by the PyTorch Foundation under the Linux Foundation.\n\n\nPyTorch Logo"
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session1.html#why-pytorch",
    "href": "W4_DL/C1_M1_Getting_Started/session1.html#why-pytorch",
    "title": "Module 1 - Session 1: Introduction to PyTorch and Neural Networks",
    "section": "Why PyTorch?",
    "text": "Why PyTorch?\nimport torch\na = torch.tensor([2.0])\nb = torch.tensor([3.0])\nresult = a + b\nprint(result)  # tensor([5.])\nSimple. Pythonic. Powerful.\n\nLet me show you what makes PyTorch special with a simple example. Adding two numbers in PyTorch looks just like regular Python code. This simplicity wasn’t always the case in deep learning frameworks.\nThe key insight here is that PyTorch makes deep learning feel like writing normal Python. This wasn’t true of early frameworks, which required complex setup and compilation steps just to do simple operations."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session1.html#the-problem-with-early-frameworks",
    "href": "W4_DL/C1_M1_Getting_Started/session1.html#the-problem-with-early-frameworks",
    "title": "Module 1 - Session 1: Introduction to PyTorch and Neural Networks",
    "section": "The Problem with Early Frameworks",
    "text": "The Problem with Early Frameworks\nStatic Computational Graphs\n\nDefine everything upfront\nCompile before running\nNo flexibility to change\nCryptic error messages\nNo standard Python debugging\n\n\nEarly deep learning frameworks used something called static computational graphs. Think of it like a factory assembly line - you had to design the entire production process before you could run anything. If you made a mistake or wanted to experiment, you had to stop everything, tear it down, and rebuild from scratch.\nThis made even simple operations complex. You couldn’t use normal Python if statements or loops. Error messages pointed to internal system code, not your actual mistakes. People spent more time fighting their tools than doing actual work."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session1.html#pytorchs-solution",
    "href": "W4_DL/C1_M1_Getting_Started/session1.html#pytorchs-solution",
    "title": "Module 1 - Session 1: Introduction to PyTorch and Neural Networks",
    "section": "PyTorch’s Solution",
    "text": "PyTorch’s Solution\nDynamic Computation\n\nWrite clean Pythonic code\nUse normal loops and if statements\nChange anything, anytime\nError messages point to your code\nStandard Python debugging\n\n\nPyTorch emerged from researchers’ frustration with these limitations. The core principle: deep learning should feel like normal Python. You write clean code, and PyTorch handles the computational complexity behind the scenes.\nThis approach made PyTorch incredibly popular, especially in research where experimentation and flexibility are crucial. Today, it’s backed by a massive community and has become the go-to choice for everyone from students to cutting-edge AI researchers."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session1.html#whats-next",
    "href": "W4_DL/C1_M1_Getting_Started/session1.html#whats-next",
    "title": "Module 1 - Session 1: Introduction to PyTorch and Neural Networks",
    "section": "What’s Next?",
    "text": "What’s Next?\n\nThe 6-stage ML pipeline\nBuilding a neural network in PyTorch\nTraining your first model\n\nClick here to go to Session 2: The ML Pipeline and Building Your First Model\n\nIn the next session, we’ll see the complete machine learning pipeline - the systematic process that every PyTorch project follows. Then you’ll build your first neural network and train it on this exact delivery problem. Just a few lines of PyTorch code will bring all these concepts to life."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session3.html#the-problem-linear-models-fail",
    "href": "W4_DL/C1_M1_Getting_Started/session3.html#the-problem-linear-models-fail",
    "title": "Module 1 - Session 3: Activation Functions",
    "section": "The Problem: Linear Models Fail",
    "text": "The Problem: Linear Models Fail\nDelivery company expanded: bike-only → city-wide with cars\nDiscovery: Delivery times stopped following a straight line\n\n\nWelcome back! In the previous lab, your delivery company expanded from bike-only service to city-wide operations using cars for longer routes. But you discovered something important: as distances increased, delivery times stopped following a straight line.\nSo what happened? Why did your model start to fail when you added cars? It all came down to your model’s assumption. A linear model treats every mile as needing the same amount of time, but in reality, it’s much more complicated."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session3.html#why-linear-models-fail",
    "href": "W4_DL/C1_M1_Getting_Started/session3.html#why-linear-models-fail",
    "title": "Module 1 - Session 3: Activation Functions",
    "section": "Why Linear Models Fail",
    "text": "Why Linear Models Fail\nReality:\n\nFirst few miles: dense city traffic (slow)\nFurther out: highways (faster)\nThe relationship curves\n\nLinear assumption: every mile needs the same time\n\nThese first few miles beyond bike range hit dense city traffic. Further out, cars reach highways and move faster. The relationship curves - it’s not a straight line anymore.\nYour linear model assumed every mile needed the same amount of time, but that’s not how transportation works in the real world. So what’s the solution?"
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session3.html#adding-more-neurons",
    "href": "W4_DL/C1_M1_Getting_Started/session3.html#adding-more-neurons",
    "title": "Module 1 - Session 3: Activation Functions",
    "section": "Adding More Neurons?",
    "text": "Adding More Neurons?\nOne neuron → one output\nTwo neurons → two outputs\nNeed: combine outputs into one prediction\nProblem: Still just a linear equation!\n\n\nYou might think: let’s just add more neurons. If one neuron learns one relationship, maybe multiple neurons can capture more complexity.\nBut when you have just one neuron, it produces your final prediction, so it is the output layer. When you add a second neuron, now you have two outputs from your single input, and you need a single prediction. So you add another neuron to combine these two outputs into one final output.\nBut here’s the problem: that’s still just a linear equation, no matter how many neurons you stack like this. If all operations are linear - simply multiplying by weights and adding biases - you’ll always end up with a straight line."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session3.html#the-solution-activation-functions",
    "href": "W4_DL/C1_M1_Getting_Started/session3.html#the-solution-activation-functions",
    "title": "Module 1 - Session 3: Activation Functions",
    "section": "The Solution: Activation Functions",
    "text": "The Solution: Activation Functions\nNon-linear transformations applied to each neuron\nEnables learning curves, not just straight lines\n\n\nTo learn curves and not just straight lines, your model needs something more than a linear transformation. It needs non-linear activation functions. These functions add just enough complexity to help the model learn more interesting patterns.\nIn PyTorch, we usually apply them element-wise to each neuron in a layer, one by one. A neuron starts by computing a linear transformation of its input. But instead of sending that raw number straight out, we pass it through an activation function. This small change - adding a non-linear transformation - is what lets your model learn much richer patterns."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session3.html#relu-rectified-linear-unit",
    "href": "W4_DL/C1_M1_Getting_Started/session3.html#relu-rectified-linear-unit",
    "title": "Module 1 - Session 3: Activation Functions",
    "section": "ReLU: Rectified Linear Unit",
    "text": "ReLU: Rectified Linear Unit\nSimple rule:\n\nIf input &lt; 0 → output = 0\nIf input ≥ 0 → output = input\n\nMost popular activation function in deep learning\n\n\nLet me introduce you to a really important activation function: ReLU. It’s incredibly simple and surprisingly powerful.\nHere’s what ReLU does: if the input is negative, output 0. If the input is positive, just pass it through unchanged. It’s as simple as that.\nIn PyTorch, it takes just one line to add ReLU to your model. Remember the Sequential layer type? That’s your assembly line where data flows through all layers in order. Now it goes through the linear layer first, and then through ReLU, which transforms the output."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session3.html#how-relu-creates-non-linearity",
    "href": "W4_DL/C1_M1_Getting_Started/session3.html#how-relu-creates-non-linearity",
    "title": "Module 1 - Session 3: Activation Functions",
    "section": "How ReLU Creates Non-Linearity",
    "text": "How ReLU Creates Non-Linearity\n\nWithout ReLU: straight line\nWith ReLU:\n\nWhen wx + b &lt; 0 → flat line at 0\nWhen wx + b ≥ 0 → follows the line\n\nResult: A bend, a corner where behavior changes\n\nHow can something this simple help us model curves? Let’s look at what happens when you add ReLU to your single neuron.\nYour neuron starts by computing w × distance + b. Without ReLU, this gives you a straight line. But with ReLU, when w × distance + b is negative, the output is 0, which is a flat line. When it’s positive, the output follows the line normally.\nLook at that - you’ve just escaped the world of straight lines. You now have a bend, a corner where the behavior changes. But here’s something crucial: where does the bend happen? When ReLU is applied to a neuron’s output, the bend occurs where wx + b = 0, which effectively gives us x = -b/w. That’s where it stops outputting 0 and starts responding to the input."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session3.html#multiple-neurons-multiple-bends",
    "href": "W4_DL/C1_M1_Getting_Started/session3.html#multiple-neurons-multiple-bends",
    "title": "Module 1 - Session 3: Activation Functions",
    "section": "Multiple Neurons, Multiple Bends",
    "text": "Multiple Neurons, Multiple Bends\nOne neuron → one bend\nMultiple neurons → multiple bends → smooth curve\n\n\nThink about your city transportation data. The pattern doesn’t just bend once - it curves, shifting gradually across different distances as traffic conditions change.\nSo if one neuron gives us one bend, then maybe multiple neurons will give us multiple bends. Each neuron has its own weight and bias, and that means each neuron activates at a different distance.\nPicture three neurons all receiving the same distance input. Neuron 1 activates right around 3 miles where traffic starts. Neuron 2 activates around 8 miles as we’re entering highways. Neuron 3 activates at around 15 miles when we’re at full highway speeds.\nNow here’s what happens: add their outputs together, and their combined output approximates your complex curve."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session3.html#building-the-model-in-pytorch",
    "href": "W4_DL/C1_M1_Getting_Started/session3.html#building-the-model-in-pytorch",
    "title": "Module 1 - Session 3: Activation Functions",
    "section": "Building the Model in PyTorch",
    "text": "Building the Model in PyTorch\nmodel = nn.Sequential(\n    nn.Linear(1, 3),  # 1 input, 3 neurons\n    nn.ReLU(),         # activation function\n    nn.Linear(3, 1)   # 3 inputs, 1 output\n)\nOnly two linear layers (ReLU is not a layer)\n\n\nIn PyTorch, this entire model takes just a few lines of Python. Let’s break that down.\nNotice we only define two linear layers. In PyTorch, you only code the layers that compute. The input is just your data. And ReLU - well, that’s an activation function that transforms values, not a separate layer in this count.\nYour first linear layer is your group of neurons. The 1 means one input feature (distance). The 3 means three neurons, so this layer outputs three values. Each of those outputs passes through a ReLU. Then the second linear layer takes those three transformed values and combines them with a single neuron, producing one final prediction - your delivery time."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session3.html#more-neurons-smoother-curves",
    "href": "W4_DL/C1_M1_Getting_Started/session3.html#more-neurons-smoother-curves",
    "title": "Module 1 - Session 3: Activation Functions",
    "section": "More Neurons = Smoother Curves",
    "text": "More Neurons = Smoother Curves\n\nEach neuron learns: Where to activate and how strongly to contribute\n\nIf you want a smoother curve, just increase the number of neurons in your first layer. With enough neurons, each learning where to activate and how strongly to contribute, you can approximate any smooth curve.\nYour city transportation patterns, with all their complexity, can finally be modeled. This is the power of non-linear activation functions combined with multiple neurons."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session3.html#other-activation-functions",
    "href": "W4_DL/C1_M1_Getting_Started/session3.html#other-activation-functions",
    "title": "Module 1 - Session 3: Activation Functions",
    "section": "Other Activation Functions",
    "text": "Other Activation Functions\nSigmoid: outputs 0-1 (great for probabilities)\nTanh: outputs -1 to +1 (useful for many tasks)\n\nReLU: most common choice for hidden layers\n\nWe’ve been using ReLU because it’s the workhorse of modern deep learning. It’s fast, effective, and widely used. But it’s not the only activation function out there.\nSigmoid will squash your outputs into a range between 0 and 1 and is great for probabilities. Tanh maps your values to a range between -1 and +1, which is really useful for many tasks. There are lots of others too.\nIf you want to dive deeper, there are great resources like PyTorch.org’s documentation. But honestly, for most situations, ReLU is all you need."
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session3.html#lab-2-modeling-non-linear-patterns-with-activation-functions",
    "href": "W4_DL/C1_M1_Getting_Started/session3.html#lab-2-modeling-non-linear-patterns-with-activation-functions",
    "title": "Module 1 - Session 3: Activation Functions",
    "section": "Lab 2: Modeling Non-Linear Patterns with Activation Functions",
    "text": "Lab 2: Modeling Non-Linear Patterns with Activation Functions\n\n“In theory, there is no difference between theory and practice. In practice, there is.”\n\n\nSTART WITH LAB 2"
  },
  {
    "objectID": "W4_DL/C1_M1_Getting_Started/session3.html#whats-next",
    "href": "W4_DL/C1_M1_Getting_Started/session3.html#whats-next",
    "title": "Module 1 - Session 3: Activation Functions",
    "section": "What’s Next?",
    "text": "What’s Next?\nIn Session 4: Working with Tensors we learn:\n\nUnderstanding tensor shapes\nData types in PyTorch\nReshaping and indexing\nElement-wise operations and broadcasting\n\n\nSpeaking of what you need, remember that curve city data that stumped your linear model? In the lab, you’ll add ReLU to your model and finally capture those complex traffic patterns.\nBut before we move on, there’s one more fundamental topic we need to cover: tensors. You’ve been using them, but understanding them deeply will help you avoid many common PyTorch errors. That’s what we’ll cover in the next session."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/from_equations_to_vectors(optional).html#why-are-we-here",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/from_equations_to_vectors(optional).html#why-are-we-here",
    "title": "Module 2 - Session 1.5: From Equations to Networks",
    "section": "Why are we here?",
    "text": "Why are we here?\nYou know this: \\(y = mx + b\\) (Line)\nYou need to know this: \\(\\mathbf{y} = \\mathbf{W}\\mathbf{x} + \\mathbf{b}\\) (Network Layer)\nThe Gap: How do we go from “Slope & Intercept” to “Weights & Biases”?\n\nWe often jump straight into “tensors” and “matrix multiplication” in deep learning. But let’s pause and build the bridge from high school math to deep learning math. If you understand this transition, the rest of the course is just implementation details."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/from_equations_to_vectors(optional).html#the-neuron-the-linear-equation",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/from_equations_to_vectors(optional).html#the-neuron-the-linear-equation",
    "title": "Module 2 - Session 1.5: From Equations to Networks",
    "section": "The Neuron = The Linear Equation",
    "text": "The Neuron = The Linear Equation\nRecall our delivery problem:\n\\[\n\\text{Time} = \\text{Weight} \\cdot \\text{Distance} + \\text{Bias}\n\\]\n\\[\ny = w \\cdot x + b\n\\]\n\nOne input (\\(x\\))\nOne output (\\(y\\))\nOne weight (\\(w\\))\nOne bias (\\(b\\))\n\n\nThis is the building block. A single neuron is literally just a linear equation. It takes an input, scales it by a weight, adds a bias, and gives an output."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/from_equations_to_vectors(optional).html#problem-real-world-is-complex",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/from_equations_to_vectors(optional).html#problem-real-world-is-complex",
    "title": "Module 2 - Session 1.5: From Equations to Networks",
    "section": "Problem: Real World is Complex",
    "text": "Problem: Real World is Complex\nPredicting delivery time needs more than just distance.\nWe need: 1. Distance (\\(x_1\\)) 2. Number of Packages (\\(x_2\\))\nThe Equation Expands: \\[\ny = w_1 x_1 + w_2 x_2 + b\n\\]\n\nAs soon as we add more inputs, our simple equation gets longer. We have a weight for every input. \\(w_1\\) handles distance, \\(w_2\\) handles traffic, etc. This is still just ONE equation producing ONE output."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/from_equations_to_vectors(optional).html#packing-inputs-into-vectors",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/from_equations_to_vectors(optional).html#packing-inputs-into-vectors",
    "title": "Module 2 - Session 1.5: From Equations to Networks",
    "section": "Packing Inputs into Vectors",
    "text": "Packing Inputs into Vectors\nWriting \\(w_1 x_1 + w_2 x_2 + \\dots\\) gets tired fast.\nLet’s pack our inputs into a Vector: \\[\n\\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}\n\\]\nAnd our weights into a Vector: \\[\n\\mathbf{w} = \\begin{bmatrix} w_1 & w_2 \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/from_equations_to_vectors(optional).html#the-dot-product",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/from_equations_to_vectors(optional).html#the-dot-product",
    "title": "Module 2 - Session 1.5: From Equations to Networks",
    "section": "The Dot Product:",
    "text": "The Dot Product:\n\\[\n\\mathbf{w} \\cdot \\mathbf{x} =\n\\begin{bmatrix} w_1 & w_2 \\end{bmatrix} \\cdot\n\\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}\n\\] \\[\n      = (w_1 \\cdot x_1) + (w_2 \\cdot x_2)\n\\]"
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/from_equations_to_vectors(optional).html#from-one-output-to-many",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/from_equations_to_vectors(optional).html#from-one-output-to-many",
    "title": "Module 2 - Session 1.5: From Equations to Networks",
    "section": "From One Output to Many",
    "text": "From One Output to Many\nWhat if we want to predict Time AND Fuel Consumption?\nWe need TWO equations:\n\n\\(\\text{Time} = w_{1,1}x_1 + w_{1,2}x_2 + b_1\\)\n\\(\\text{Fuel} = w_{2,1}x_1 + w_{2,2}x_2 + b_2\\)\n\nThis is a System of Equations.\n\nNow we have two outputs. Each output needs its own set of weights for the inputs. The Time prediction processes distance differently than Fuel prediction does."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/from_equations_to_vectors(optional).html#the-matrix-packing-equations",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/from_equations_to_vectors(optional).html#the-matrix-packing-equations",
    "title": "Module 2 - Session 1.5: From Equations to Networks",
    "section": "The Matrix: Packing Equations",
    "text": "The Matrix: Packing Equations\nLook at the weights. They form a grid.\n\\[\n\\mathbf{W} = \\begin{bmatrix}\nw_{1,1} & w_{1,2} \\\\\nw_{2,1} & w_{2,2}\n\\end{bmatrix}\n\\]\n\nTop Row: Weights for “Time” equation.\nBottom Row: Weights for “Fuel” equation.\n\nA Matrix is just a stack of weight vectors!\n\nThis is the key insight. A Matrix isn’t some scary new mathematical object. It is literally just a way to stack multiple linear equations on top of each other. Row 1 is Equation 1. Row 2 is Equation 2."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/from_equations_to_vectors(optional).html#matrix-multiplication-visualized",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/from_equations_to_vectors(optional).html#matrix-multiplication-visualized",
    "title": "Module 2 - Session 1.5: From Equations to Networks",
    "section": "Matrix Multiplication Visualized",
    "text": "Matrix Multiplication Visualized\n\\[\n\\begin{bmatrix} y_1 \\\\ y_2 \\end{bmatrix} =\n\\begin{bmatrix}\n\\text{--- } \\mathbf{w}_{\\text{time}} \\text{ ---} \\\\\n\\text{--- } \\mathbf{w}_{\\text{fuel}} \\text{ ---}\n\\end{bmatrix}\n\\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}\n+\n\\begin{bmatrix} b_1 \\\\ b_2 \\end{bmatrix}\n\\]\n\\[\n\\mathbf{y} = \\mathbf{W}\\mathbf{x} + \\mathbf{b}\n\\]\n\nTake Row 1, Dot with \\(\\mathbf{x}\\) \\(\\rightarrow\\) \\(y_1\\)\nTake Row 2, Dot with \\(\\mathbf{x}\\) \\(\\rightarrow\\) \\(y_2\\)\n\n\nWhen you multiply a matrix by a vector, you are just running those linear equations in parallel."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/from_equations_to_vectors(optional).html#in-pytorch-terms",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/from_equations_to_vectors(optional).html#in-pytorch-terms",
    "title": "Module 2 - Session 1.5: From Equations to Networks",
    "section": "In PyTorch Terms",
    "text": "In PyTorch Terms\n\\[\n\\mathbf{y} = \\mathbf{W}\\mathbf{x} + \\mathbf{b}\n\\]\nMatches this code exactly:\nlayer = nn.Linear(in_features=2, out_features=2)\ny = layer(x)\n\nin_features=2: Size of input vector \\(\\mathbf{x}\\) (columns of W)\nout_features=2: Size of output vector \\(\\mathbf{y}\\) (rows of W)\n\n\nWhen you define nn.Linear(2, 2), PyTorch creates a \\(2 \\times 2\\) matrix of random weights. When you pass data through it, it performs that matrix multiplication."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/from_equations_to_vectors(optional).html#why-this-matters",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/from_equations_to_vectors(optional).html#why-this-matters",
    "title": "Module 2 - Session 1.5: From Equations to Networks",
    "section": "Why This Matters",
    "text": "Why This Matters\nDeep Learning is just:\n\nHierarchy: Stacking these layers.\nDimension Transformation: Changing the vector size step-by-step.\n\nInput (Pixels): Vector of 784\nHidden Layer 1: Vector of 128 (Features)\nOutput Layer: Vector of 10 (Classes)\n\n\nThe Network transforms data shape to answer questions."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#the-training-sequence",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#the-training-sequence",
    "title": "Module 2 - Session 2: Loss Functions and Optimizers",
    "section": "The Training Sequence",
    "text": "The Training Sequence\nThree lines that make learning happen:\n\nMeasure - How wrong are we?\nDiagnose - What caused the error?\nUpdate - How do we fix it?\n\n\nAs you move through this professional certificate, you’ll see these three lines come up again and again and again during training. They’re simple to write, but a lot happens behind the scenes. PyTorch will take care of the complex math for you, but in this session, you’ll take a quick look under the hood to understand what each line really does and why the order matters.\nThese three lines will work together in this sequence: Measure, Diagnose, Update. First, you’ll measure how wrong your predictions are, and that’s your loss - this one number that sums up all of your mistakes. Then, backward diagnoses the problem. It examines how each weight in your model contributed to the error, which weights made things worse, and by how much. Finally, optimizer.step updates the weights. It uses those diagnostic scores to adjust each parameter. The weights with the bigger problems will get bigger corrections."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#step-1-measuring-loss",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#step-1-measuring-loss",
    "title": "Module 2 - Session 2: Loss Functions and Optimizers",
    "section": "Step 1: Measuring Loss",
    "text": "Step 1: Measuring Loss\nLoss function: compares predictions to true answers\nHigher number = more wrong\nGoal: minimize loss\n\n\nIn this session, you’re going to focus on the first step, and that’s measuring loss. You’ve already seen one kind of loss function called mean squared error, which works really well for tasks like we had when we were predicting delivery time. You’ll also meet a new loss function, cross-entropy loss, and this is used for classification problems.\nI’ll break down how these loss functions work and how to choose the correct one for your task. Every loss function does the same basic job: it compares your model’s predictions to the true answers and then gives you a number. The higher the number, the more wrong you are."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#measuring-error-for-regression-tasks",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#measuring-error-for-regression-tasks",
    "title": "Module 2 - Session 2: Loss Functions and Optimizers",
    "section": "Measuring Error for Regression Tasks",
    "text": "Measuring Error for Regression Tasks\nFor regression tasks (predicting numbers): temperature, price, distance\nAverage error = \\(\\frac{1}{n} \\sum_{i=1}^n (\\hat{y}_i - y_i)\\)\n\n\n\nPrediction (minutes)\nActual (minutes)\nError\n\n\n\n\n6\n4\n\\(6 - 4 = 2\\)\n\n\n3\n5\n\\(3 - 5 = -2\\)\n\n\n\nProblem: Average error = 0 (mistakes cancel out!)\n\nBack in the delivery company example, you used the model to predict delivery time based on distance. Now, let’s say your model makes two predictions. The first prediction: the model predicted 6 minutes, but the actual time was 4. For the second prediction, say it predicted 3 minutes, but the actual time was 5.\nTo figure out how far off you were, you subtract the target from the prediction, and that gives you the error. It’s like measuring the distance between your guess and reality. So how wrong was your model overall? Well, loss here is the average error across all of those predictions. Think of it like a report card for your model. The lower the score, the closer your predictions are to reality on average.\nBut if you average out the raw errors - in this case it was +2 and -2, and you divide that by two because there’s two of them - you get zero. It looks like perfect performance, even though both predictions were actually wrong."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#mean-squared-error-loss",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#mean-squared-error-loss",
    "title": "Module 2 - Session 2: Loss Functions and Optimizers",
    "section": "Mean Squared Error Loss",
    "text": "Mean Squared Error Loss\nSquaring:\n\nGets rid of minus signs (all mistakes count)\nMakes bigger mistakes matter more\n\n\\[\n\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n (\\hat{y}_i - y_i)^2\n\\]\n\nAnd this is why you use mean squared error and you square the differences. It gets rid of the minus signs. So now both mistakes count and they don’t cancel each other out. And that’s where that name comes from: mean squared error.\nAnd there’s one more benefit: squaring makes bigger mistakes matter more. Being off by 10 minutes is much worse than being off by one. So MSE loss, mean squared error loss, helps in these two ways: (1) it makes sure that all mistakes count, and (2) it punishes bigger errors more than it punishes smaller ones.\nMean squared error is perfect when you’re predicting continuous values, things like distances, temperatures, or prices."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#cross-entropy-loss",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#cross-entropy-loss",
    "title": "Module 2 - Session 2: Loss Functions and Optimizers",
    "section": "Cross-Entropy Loss",
    "text": "Cross-Entropy Loss\nFor classification tasks (predicting categories): digit, animal, word\nModel outputs: confidence scores (probabilities) for each class\nAll scores sum to 100%\n\\[\n\\text{BCE} = -\\sum_{i=1}^n y_i \\log(\\hat{y}_i)\n\\]\n\nBut in this module, you’re tackling classification. What digit is this? And here you’re going to need a different loss function. We’ll use one called cross-entropy loss.\nWith cross-entropy loss, your model isn’t just picking an answer - it outputs a confidence score for all possible answers or classes. Take MNIST: your model must choose between digits zero through nine. So for each image, it outputs 10 numbers, a probability for each digit. This means “I’m 70% sure it’s a three, maybe 8% sure it’s a two, but it could be a zero.” And all of those scores should add up to 100%."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#how-cross-entropy-works",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#how-cross-entropy-works",
    "title": "Module 2 - Session 2: Loss Functions and Optimizers",
    "section": "How Cross-Entropy Works",
    "text": "How Cross-Entropy Works\nPunishes overconfident wrong answers\n\n95% sure it’s a 7, but it’s actually a 3 → very high loss\n55% sure it’s a 7, but it’s actually a 3 → smaller loss\n\nGoal: Confident about right answers, unsure about wrong ones\n\nNow here’s the key idea: cross-entropy loss punishes overconfident wrong answers. If your model says it’s 95% sure that this is a seven, but it’s actually a three, that’s a big mistake and the loss will be very high. But if it’s only 55% sure it’s a seven, it’s still wrong, but not as confident, so the loss will be smaller.\nYou want your model to be confident about the right answers and unsure about the wrong ones. Cross-entropy loss helps shape that behavior."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#step-2-diagnosing-the-problem",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#step-2-diagnosing-the-problem",
    "title": "Module 2 - Session 2: Loss Functions and Optimizers",
    "section": "Step 2: Diagnosing the Problem",
    "text": "Step 2: Diagnosing the Problem\nBackward calculates gradients\nGradients = diagnostic scores for each parameter\n\nPositive gradient → increasing weight makes loss worse\nNegative gradient → increasing weight helps\nLarge gradient → big influence\nSmall gradient → barely mattered\n\n\nIn the last video, you saw how loss functions measure how right or how wrong your predictions are, and this is the first critical step in every training loop. Now let’s take a look at the next two steps.\nAfter measuring how wrong your predictions are with the loss function, the next step is to figure out what caused that loss, and that’s what Backward does. Think back to how neural networks work. Each neuron takes inputs, multiplies each by a weight, adds them up with a bias, and then passes that through an activation function.\nEven in a small neural network, you’re dealing potentially with thousands of weights and biases. So if we look at a simple example: this network has 784 inputs, 128 hidden neurons, and 10 output classes. And it has over 100,000 weights between inputs and the hidden layers. There are 128 biases for the hidden layer, and there are 1,280 weights between the hidden layer and the output. And of course there are those 10 biases for the final output layer. And that’s a total of 101,770 trainable parameters.\nSo Backward acts a little bit like a detective. It looks at every single weight and bias and asks: “How much did you contribute to the loss?” These diagnostic scores are called gradients. They tell you not just who contributed to the error, but how much and in what direction."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#what-backward-does-not-do",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#what-backward-does-not-do",
    "title": "Module 2 - Session 2: Loss Functions and Optimizers",
    "section": "What Backward Does NOT Do",
    "text": "What Backward Does NOT Do\nBackward does NOT update weights\nIt only calculates gradients\nUpdates happen later with optimizer.step()\n\nBut here’s a common misconception: people often think that Backward updates these weights. It doesn’t. Backward only calculates gradients. It figures out how much each weight contributed to the overall loss. The actual updates will happen later when you call optimizer.step().\nYou can find course resources if you want to learn more, but this course is focused on PyTorch and not Calculus. And the beauty of PyTorch is that it handles all of that complexity for you."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#the-gradient-descent-analogy",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#the-gradient-descent-analogy",
    "title": "Module 2 - Session 2: Loss Functions and Optimizers",
    "section": "The Gradient Descent Analogy",
    "text": "The Gradient Descent Analogy\n\nPlos: x-axis: weight, y-axis: lossGoal: minimize loss (reach bottom of valley)\nGradient: tells you the slope (which way is downhill?)\nGo downhill → lower loss\n\nBut what’s really happening here? Your goal is to try to minimize loss. Think of it as like standing on a hillside trying to reach the bottom of a valley. The gradient tells you the slope at your position, which way is uphill or which way is downhill.\nSo to get to the bottom, you go in the downhill direction, and that’s going towards lower loss. And that’s why we call it gradient descent."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#zooming-in-on-a-single-parameter-taking-a-step-against-the-gradient",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#zooming-in-on-a-single-parameter-taking-a-step-against-the-gradient",
    "title": "Module 2 - Session 2: Loss Functions and Optimizers",
    "section": "Zooming in on a single parameter taking a step against the gradient",
    "text": "Zooming in on a single parameter taking a step against the gradient\n\n\nThe stickman figure emphasizes two points:\n\nThe blind-fold on the eyes of the parameter emphasizes the fact that they can only feel the incline (slope / derivative), but cannot see further.\nThe parameter, being a stickman, moves relative to its current position by stepping. A step may be small or big, depending on the learning rate (step-size) we choose."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#multiple-parameters",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#multiple-parameters",
    "title": "Module 2 - Session 2: Loss Functions and Optimizers",
    "section": "Multiple parameters",
    "text": "Multiple parameters\nIf we have two parameters (\\(\\theta_0\\) and \\(\\theta_1\\)):"
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#stochastic-gradient-descent-sgd",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#stochastic-gradient-descent-sgd",
    "title": "Module 2 - Session 2: Loss Functions and Optimizers",
    "section": "Stochastic Gradient Descent (SGD)",
    "text": "Stochastic Gradient Descent (SGD)\nStrategy:\n\nNegative gradient (\\(\\frac{\\partial \\text{loss}}{\\partial w_0}\\)) → increase weight (\\(w_0\\))\nPositive gradient (\\(\\frac{\\partial \\text{loss}}{\\partial w_1}\\)) → decrease weight (\\(w_1\\))\nBig gradient (\\(\\frac{\\partial \\text{loss}}{\\partial w_0}\\)) → big change (\\(w_0\\))\nSmall gradient (\\(\\frac{\\partial \\text{loss}}{\\partial w_1}\\)) → small change (\\(w_1\\))\n\nScales updates with learning rate: \\(\\text{step size} = \\text{learning rate} \\times \\text{gradient}\\)\n\nThe simplest approach is what we’ve been using: stochastic gradient descent. SGD’s strategy is straightforward. If your weight has a negative gradient, then let’s increase it. If your weight has a positive gradient, then we can just decrease by going in the opposite direction. If it has a big gradient, we’ll make a big change. If it has a small gradient, we’ll make a small change.\nBut it doesn’t just subtract the gradient directly - it scales it first using the learning rate."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#learning-rate-matters",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#learning-rate-matters",
    "title": "Module 2 - Session 2: Loss Functions and Optimizers",
    "section": "Learning Rate Matters",
    "text": "Learning Rate Matters\n\n\n\nTiny learning rate: tiny steps, takes forever\nGood learning rate: steady progress to the bottom\nHuge learning rate: giant leaps, overshoots minima\n\nSo if your gradient, for example, is 0.5 and the learning rate is 0.01, the learning rate will scale down any updates. And here’s why this matters: in this case, a tiny learning rate has tiny steps. It will take forever to reach the bottom. A good learning rate has steady progress all the way to the bottom. A huge learning rate has these giant leaps that can bounce back and forth, overshooting the minima."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#adam-optimizer",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#adam-optimizer",
    "title": "Module 2 - Session 2: Loss Functions and Optimizers",
    "section": "Adam Optimizer",
    "text": "Adam Optimizer\nAdapts learning rate for each weight individually\nLike having an assistant:\n\nKnows which weights need big adjustments\nKnows which need fine-tuning\n\nPopular first choice: reliable, flexible, often faster\n\nOptimizers’ loss curves\nSo SGD can work great, but there are smarter optimizers that can adapt to each weight individually. And one of those is Adam. It’s kind of like having an assistant that knows which weights need big adjustments and which ones need fine-tuning.\nAdam has become a popular first choice optimizer because it’s reliable, flexible, and often faster than the alternatives. But a word of caution: don’t copy the learning rate from SGD when using Adam because your loss might explode. It’s tuned completely differently.\nThere are other optimizers in PyTorch like RMSprop, AdaGrad, and a whole lot more. And if you’re curious, check out the resources. But for most projects, SGD and Adam have you covered."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#why-zero_grad",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#why-zero_grad",
    "title": "Module 2 - Session 2: Loss Functions and Optimizers",
    "section": "Why zero_grad()?",
    "text": "Why zero_grad()?\nEvery backward() call adds to existing gradients\nWithout zero_grad(): gradients accumulate incorrectly\nResult: training breaks\n\nNow that you understand gradients as diagnostic scores for each parameter, zero_grad begins to make a lot more sense. Every time you call backward, PyTorch adds new gradients to whatever is already there. So if you don’t call zero_grad, you’re not just diagnosing parameters for this batch - you’re actually accumulating the diagnoses from every batch. And the gradients will keep accumulating incorrectly until your training breaks.\nSo that’s why you call optimizer.zero_grad() at the start of every training loop. Now you might wonder: well, why does PyTorch accumulate the gradients in the first place? It turns out that this behavior is really useful for advanced use cases like gradient accumulation or certain custom training schedules. But for most projects, including everything you’ll do in this course, you’re going to want to clear those gradients every time."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#complete-training-loop",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#complete-training-loop",
    "title": "Module 2 - Session 2: Loss Functions and Optimizers",
    "section": "Complete Training Loop",
    "text": "Complete Training Loop\nfor batch in dataloader:\n    optimizer.zero_grad()      # Clear gradients\n    outputs = model(inputs)     # Forward pass\n    loss = loss_fn(outputs, targets)  # Measure\n    loss.backward()            # Diagnose\n    optimizer.step()           # Update\nMeasure → Diagnose → Update\n\nYou can now understand the complete training loop. Loss functions measure how wrong or how right the model is. Backward diagnoses how each parameter contributes to the errors. Optimizers then use those diagnostic scores to update the weights.\nNow before you start building your first classifier, I have one final PyTorch-specific topic to discuss, and that’s device management. And that means making your code run on GPUs for faster training. And I’ll see you there."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#whats-next",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session2.html#whats-next",
    "title": "Module 2 - Session 2: Loss Functions and Optimizers",
    "section": "What’s Next?",
    "text": "What’s Next?\nIn Session 3: Device Management and Image Classification Setup, you learn:\n\nRunning on GPUs vs CPUs\nMoving models and data to devices\nSetting up MNIST data pipeline\nBuilding your first image classifier architecture\n\n\nIn the next session, we’ll learn about device management - how to make your code run on GPUs for much faster training. Then we’ll set up the complete data pipeline for MNIST and build the architecture for your first image classifier."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#setting-up-training",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#setting-up-training",
    "title": "Module 2 - Session 4: Training and Evaluating Your Classifier",
    "section": "Setting Up Training",
    "text": "Setting Up Training\nEverything you need:\n\nModel (on device)\nLoss function\nOptimizer\nData loaders\n\n\nWelcome back. In the last session, you saw how to build the two key components: a data pipeline that loads MNIST images, and a neural network architecture that can process them. But if you run the model right now, you’ll just be guessing.\nIn this session, you’re going to walk through the code that actually trains that model step by step. Let’s start by setting up everything that you need for training."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#device-and-model-setup",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#device-and-model-setup",
    "title": "Module 2 - Session 4: Training and Evaluating Your Classifier",
    "section": "Device and Model Setup",
    "text": "Device and Model Setup\ndevice = torch.device('cuda' if torch.cuda.is_available() \n                      else 'cpu')\nmodel = MNISTClassifier().to(device)\nBoth model and data must be on the same device\n\nFirst, device selection. If CUDA is available, you’ll use the GPU. Otherwise, PyTorch is going to fall back to the CPU. Then, let’s create the model and move it to the device using .to(device). Remember, both your model and your data need to be on the same device. Otherwise, you’ll get an error during training."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#loss-function",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#loss-function",
    "title": "Module 2 - Session 4: Training and Evaluating Your Classifier",
    "section": "Loss Function",
    "text": "Loss Function\nloss_function = nn.CrossEntropyLoss()\nDesigned for classification tasks\nPerfect for choosing a digit from 0-9\n\nYou’re going to be using cross-entropy loss as your loss function. And as you saw earlier, it’s designed for classification tasks, where the model will pick one class out of many. And that’s perfect for choosing a digit from 0 through 9."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#optimizer",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#optimizer",
    "title": "Module 2 - Session 4: Training and Evaluating Your Classifier",
    "section": "Optimizer",
    "text": "Optimizer\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nAdam: adapts learning rate as it trains\n\nLarger adjustments early (noisy gradients)\nSmaller corrections later (training stabilizes)\n\n\nAnd you’re using the Adam optimizer with a learning rate of 0.001. You’ve already seen how Adam adapts its learning rate as it trains by making larger adjustments early when gradients are noisy, and then smaller corrections later as your training stabilizes."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#training-function",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#training-function",
    "title": "Module 2 - Session 4: Training and Evaluating Your Classifier",
    "section": "Training Function",
    "text": "Training Function\ndef train_one_epoch(model, dataloader, loss_fn, optimizer, device):\n    model.train()  # Set to training mode\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for batch_idx, (data, targets) in enumerate(dataloader):\n        # Move to device\n        data, targets = data.to(device), targets.to(device)\n        \n        # Training steps\n        optimizer.zero_grad()\n        outputs = model(data)\n        loss = loss_fn(outputs, targets)\n        loss.backward()\n        optimizer.step()\n        \n        # Track progress\n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n        \n        if batch_idx % 100 == 0:\n            print(f'Loss: {loss.item():.4f}, '\n                  f'Accuracy: {100.*correct/total:.2f}%')\n\nSo now, let’s create a function to train our model for one epoch. The function takes in five inputs: your model, the data loader, the loss function, the optimizer, and the device that everything should run on.\nYou’ll start with model.train(), and this puts the model into training mode. You’ll set up three tracking variables: running_loss accumulates the loss values, correct counts predictions that match the true labels, and total counts all of the samples that you’ve seen so far.\nNext, we’re going to loop over all of the batches. And in each batch, we’re going to move the data and the target to the right device, clear any leftover gradients with optimizer.zero_grad(). We’ll then run a forward pass by calling the model and passing it the data to get output. We’ll compute the loss by calling the loss function. We’ll back propagate with loss.backward(), and then we’ll update the weights with optimizer.step().\nAnd then you track your progress. loss.item() gives us the label value, and output.max tells us which digit class got the highest score and lets you compare that to that label value. Every 100 batches, you’re going to print out the current loss and accuracy."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#understanding-the-training-progress",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#understanding-the-training-progress",
    "title": "Module 2 - Session 4: Training and Evaluating Your Classifier",
    "section": "Understanding the Training Progress",
    "text": "Understanding the Training Progress\nWith 60,000 training images and batch size 64:\n\nAbout 938 batches per epoch\nAround 9 progress updates\n\nWatch the numbers:\n\nLoss: dropping (0.64 → 0.17)\nAccuracy: climbing (81% → 95%)\n\n\nWith 60,000 training images and batch size 64, that’s about 938 batches per epoch. So you’re going to see around 9 updates.\nNotice what’s happening here. Look at the loss number: it’s dropping from 0.64 to about 0.17, while your accuracy climbs from about 81 percent to about 95 percent. And that’s just in a single pass through the training set. And look how little code it took to make all of that happen."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#evaluation-function",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#evaluation-function",
    "title": "Module 2 - Session 4: Training and Evaluating Your Classifier",
    "section": "Evaluation Function",
    "text": "Evaluation Function\ndef evaluate(model, dataloader, device):\n    model.eval()  # Set to evaluation mode\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():  # Disable gradient tracking\n        for data, targets in dataloader:\n            data, targets = data.to(device), targets.to(device)\n            outputs = model(data)\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n    \n    return 100. * correct / total\n\nBut training is only half of the story. You need to test your model on new, unseen data. There are two key differences from training. First, model.eval() will switch you into evaluation mode. Second, you’re going to wrap everything in a with torch.no_grad(). During evaluation, you’re not training, so you don’t need gradients. This will save memory and speed everything up.\nThe evaluation itself is pretty straightforward. You’re going to run each batch through the model. You’re going to find which class got the highest score with output.max. You’re going to count how many predictions match the true labels, and then you can return the accuracy percentage. No optimizer, no loss tracking, no weight updates - just how many did you get right."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#putting-it-all-together",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#putting-it-all-together",
    "title": "Module 2 - Session 4: Training and Evaluating Your Classifier",
    "section": "Putting It All Together",
    "text": "Putting It All Together\nnum_epochs = 10\n\nfor epoch in range(num_epochs):\n    print(f'Epoch {epoch+1}/{num_epochs}')\n    \n    # Train\n    train_one_epoch(model, train_loader, loss_function, \n                    optimizer, device)\n    \n    # Evaluate\n    accuracy = evaluate(model, test_loader, device)\n    print(f'Test Accuracy: {accuracy:.2f}%')\n    print('-' * 50)\n10 epochs = 10 full passes through training data\nAfter each epoch: evaluate on test set\n\nNow you have your training function and your evaluation function. Let’s put them all together. You’ll train the model for 10 epochs. That’s 10 full passes through the entire training dataset. But it’s not just repetition - with each pass, the model refines its understanding of what makes a 2 different from a 7.\nAfter each training epoch, you’re going to evaluate on the test set to see how well it performs on unseen data. This tells you if the model is actually learning generalizable patterns or if it’s just memorizing the training data."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#what-youll-see",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#what-youll-see",
    "title": "Module 2 - Session 4: Training and Evaluating Your Classifier",
    "section": "What You’ll See",
    "text": "What You’ll See\n\nBy epoch 10: Loss: tiny, Accuracy: high (often 95%+)\nWhen accuracy stops improving: Model is done learning, May not need all 10 epochs\n\nAnd here’s what you’ll see. By epoch 10, you’ll notice something really satisfying: the loss is tiny and the accuracy is high. When your accuracy stops improving, it’s often a sign that your model is done learning for now, so you may not even need all 10 epochs.\nAnd that’s it. You’re ready to train your first image classifier in PyTorch. Head over to the lab and give it a try."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#module-2-summary",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#module-2-summary",
    "title": "Module 2 - Session 4: Training and Evaluating Your Classifier",
    "section": "Module 2 Summary",
    "text": "Module 2 Summary\nYou’ve learned:\n\nPyTorch data pipeline (Dataset, DataLoader, Transforms)\nBuilding custom models with nn.Module\nLoss functions (MSE vs Cross-Entropy)\nHow optimizers use gradients to update weights\nDevice management (CPU vs GPU)\nComplete image classification pipeline\n\n\nCongratulations! You’ve completed Module 2. You’ve learned how PyTorch handles data at scale, built custom model architectures, understood the mathematics behind loss functions and optimizers, managed devices for GPU acceleration, and built your first complete image classifier.\nThis foundation will serve you well as you move forward in the course. You now understand not just how to use PyTorch, but why it works the way it does."
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#lab-1-building-your-first-image-classifier",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#lab-1-building-your-first-image-classifier",
    "title": "Module 2 - Session 4: Training and Evaluating Your Classifier",
    "section": "Lab 1: Building Your First Image Classifier",
    "text": "Lab 1: Building Your First Image Classifier\n\n“Don’t tell me the moon is shining; show me the glint of light on broken glass.”\n\n\nCUE: START THE LAB HERE"
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#assignment-2-emnist-letter-detective",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#assignment-2-emnist-letter-detective",
    "title": "Module 2 - Session 4: Training and Evaluating Your Classifier",
    "section": "Assignment 2: EMNIST Letter Detective",
    "text": "Assignment 2: EMNIST Letter Detective\n\n“The eye sees only what the mind is prepared to comprehend.”\n\n\nCUE: START THE ASSIGNMENT HERE"
  },
  {
    "objectID": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#whats-next",
    "href": "W4_DL/C1_M2_PyTorch_Workflow/session4.html#whats-next",
    "title": "Module 2 - Session 4: Training and Evaluating Your Classifier",
    "section": "What’s Next?",
    "text": "What’s Next?\nIn Module 3: Data Management we learn:\n\nHow to manage and preprocess data for deep learning\nHow to build a robust data pipeline\nHow to use data augmentation to improve model performance\nHow to use data validation to ensure model performance"
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session2.html#session-2-pytorch-techniques-and-model-inspection",
    "href": "W4_DL/C1_M4_Core_NN_Components/session2.html#session-2-pytorch-techniques-and-model-inspection",
    "title": "Module 4 - Session 2: PyTorch Techniques and Model Inspection",
    "section": "Session 2: PyTorch Techniques and Model Inspection",
    "text": "Session 2: PyTorch Techniques and Model Inspection\nWhat you’ll know by the end:\n\nHow PyTorch’s dynamic computation graphs work\nWhen to use Sequential vs. custom modules\nHow to build modular, reusable architectures\nTools for inspecting and debugging models\n\n\nWelcome back. You’ve just trained your first convolutional neural network for the Botanical Garden app. But let’s take a closer look. The structure is completely linear. Data flows straight through. There’s three blocks of convolution, ReLU, and pooling layers. And then it’s flattened and passed through a few more layers before outputting a prediction.\nNow that’s a solid start, but so far it’s just a stack of layers. It looks repetitive and it doesn’t really show off what makes PyTorch special. In PyTorch, you’re not locked into that rigid model structure. And it accomplishes this using something called a dynamic computation graph that gets built as your model runs step by step."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session2.html#dynamic-computation-graphs",
    "href": "W4_DL/C1_M4_Core_NN_Components/session2.html#dynamic-computation-graphs",
    "title": "Module 4 - Session 2: PyTorch Techniques and Model Inspection",
    "section": "Dynamic Computation Graphs",
    "text": "Dynamic Computation Graphs\n\n\n\n\n\n\n\nWhat makes PyTorch special\n\nGraph built on-the-fly as your model runs\nEvery operation recorded step-by-step\nUsed for backpropagation, then discarded\n\n\nIn PyTorch, you’re not locked into that rigid model structure. And it accomplishes this using something called a dynamic computation graph that gets built as your model runs step by step. As you heard way back in Module 1, older frameworks worked differently. You had to define your computation graphs ahead of time before any data could pass through.\nBut what does that actually mean? What is a computation graph? When you write a sequential block, you’re defining a specific mathematical equation. Conv2d might specify thousands of multiplications and additions. ReLU zeros out any negative values, and when chained together, you get one giant equation. Now imagine spelling out that very equation every single calculation one step at a time. Multiply this by that, add the results of this, zero out negatives, multiply again, add the bias, on and on and on countless times. That step-by-step breakdown? That’s a computation graph. Every operation you apply is recorded as part of that graph.\nWhy? Because during training, all deep learning frameworks need to walk backwards through the graph using the chain rule from calculus. That’s how it figures out how to adjust each and every parameter.\nAnd older frameworks handled this differently than PyTorch does now. You had to define that entire graph up front, every operation, every connection, before anything could run. Once defined, the structure was locked.\nAnd that’s exactly what PyTorch set out to change. Let’s look at an example. Imagine you’re building a CNN for your botanical garden app, but now you want it to handle flowers differently from butterflies. In PyTorch, you can write that logic directly inside the forward method. In older frameworks with static graphs, that kind of control was really, really difficult. Yes, they allowed you to have the conditionals, but only by building every possible path ahead of time.\nPyTorch takes a different approach. That if statement doesn’t just control the logic, it shapes the graph itself. Each time forward runs, PyTorch records exactly what happens. Every multiplication, addition, layer, and branch. The result is a custom computation graph built on the fly, based on the actual path that your data takes. That graph is used for back propagation, so the parameters get updated, and then the graph is discarded. Next time forward runs, PyTorch starts from scratch, building a brand new graph tailored for that run, even if it follows a completely different path.\nAnd that’s the core difference. Static frameworks make you think like a compiler, but PyTorch lets you think like a Python programmer. Write logic, branch, adapt on the fly. This flexibility comes from using nn.Module instead of nn.Sequential, where the init defines our model, and forward allows us to define the flow of your dynamic graph."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session2.html#why-dynamic-graphs-matter",
    "href": "W4_DL/C1_M4_Core_NN_Components/session2.html#why-dynamic-graphs-matter",
    "title": "Module 4 - Session 2: PyTorch Techniques and Model Inspection",
    "section": "Why Dynamic Graphs Matter",
    "text": "Why Dynamic Graphs Matter\ndef forward(self, x):\n    if x.shape[0] &gt; 100:\n        # Complex path\n    else:\n        # Simple path\nReal-world benefits\n\nAdaptive models (simpler for simple cases, complex for tricky ones)\nStandard Python debugging (just add a print)\nVariable input sizes (sentences: 3 words vs. 50 words)\nSmall performance cost, huge flexibility gains\n\n\nNow, these dynamic graphs do come with a small performance trade-off. But for researchers and developers, that flexibility means faster iteration, easier debugging, and more expressive models. And it’s not just a nice idea, it solves real problems that you will actually run into.\nFor example, static graphs often require all inputs to be the same shape. But what if you’re working with sentences, where some have three words and some really long ones have 50? In PyTorch, it just works.\nIf you need to debug something in the middle of a computation, in static frameworks that meant switching to a special debug mode. Interrupting the flow wasn’t allowed. In PyTorch, it’s just Python. If you need to investigate an issue, just add a print. You can even build models that adapt to the input, like running a simpler model for simple cases and a complex model for trickier cases.\nYour model becomes smart about its own computation. And these are not edge cases. This is how modern AI works. In PyTorch, it’s all possible by just writing Python code."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session2.html#use-nn.sequential-for-fixed-patterns",
    "href": "W4_DL/C1_M4_Core_NN_Components/session2.html#use-nn.sequential-for-fixed-patterns",
    "title": "Module 4 - Session 2: PyTorch Techniques and Model Inspection",
    "section": "Use nn.Sequential for fixed patterns",
    "text": "Use nn.Sequential for fixed patterns\n    def __init__(self, in_channels):\n        # ...\n        self.features = nn.Sequential(\n            ConvBlock(in_channels, 32),\n            ConvBlock(32, 64),\n            ConvBlock(64, 128),\n            # ...\n        )\n        self.classifier = nn.Sequential(\n            # ...\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x\n\nPyTorch’s nn-sequential to group layers that run in order. Now in the forward, that’s it. You want to add that fourth block your client just asked for? Well now you can just update init. No forward method change is needed. No naming conflicts. No forgotten layers. You define the sequence once and sequential handles the execution.\nLook at that forward method. Two lines for the sequential blocks instead of 15.\nWhy should you even bother with two methods? Well, there’s a good reason as it separates concerns as was suggested by the previous video. The init method is there to define your model’s architecture, the layers and their learnable parameters that will persist across training. These will be the actual values that your model is learning. While the forward method, in a sense, is defining the dynamic flow of your computation graph. And it’s this separation that enables PyTorch’s flexibility."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session2.html#use-nn.module-for-reusable-blocks",
    "href": "W4_DL/C1_M4_Core_NN_Components/session2.html#use-nn.module-for-reusable-blocks",
    "title": "Module 4 - Session 2: PyTorch Techniques and Model Inspection",
    "section": "Use nn.Module for reusable blocks",
    "text": "Use nn.Module for reusable blocks\nclass ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        self.conv = nn.Conv2d(...)\n        self.relu = nn.ReLU()\n        self.pool = nn.MaxPool2d(...)\nWorkflow: Start explicit, then refactor\n\nSince you’re repeating that same pattern, you can group those layers into a single block. It keeps things cleaner and easier to reuse. This is now a reusable building block, just like any built-in PyTorch layer.\nNow look how clean your CNN becomes. Adding that fourth block? Well just add a new conv block to features. Want to change all blocks to use batch normalization? Update conv block once and all three blocks will get the change. This is modularity. Building complex models from simpler reusable parts.\nYou can even nest modules inside modules to create clean scalable architectures.\nSo here’s a quick workflow tip. Start explicit, then refactor. And when building something new, write everything out even if it’s repetitive. It makes debugging easier and helps you see exactly what’s happening. Once it works, look for patterns.\nOther repeated sequences? Well use sequential. Other reusable blocks? Create custom modules like conv block. Think of it as a rough draft that you polish as you go along. You’re not writing redundant code because you don’t know better. You’re doing it to understand and debug effectively."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session2.html#inspecting-your-model",
    "href": "W4_DL/C1_M4_Core_NN_Components/session2.html#inspecting-your-model",
    "title": "Module 4 - Session 2: PyTorch Techniques and Model Inspection",
    "section": "Inspecting Your Model",
    "text": "Inspecting Your Model\nBasic inspection\n# Structure overview\nprint(model)\n\n# Counting and locating parameters\ntotal = sum(p.numel() for p in model.parameters())\n\n# Per layer (shows where each set lives)\nfor name, param in model.named_parameters():\n    print(f\"{name}: {param.shape}\")\nInspecting nested blocks\n\nmodel.children(): top-level only\nmodel.modules(): everything, including nested (think folder structure)\n\nNote: the shape for, say, fc1.weight connecting 2,048 inputs to 512 outputs is reversed: (512, 2048) because each row = weights for one output neuron.\n\nWelcome back. You’ve learned how to train a convolutional neural network layer by layer with a solid data pipeline and tools to boost performance. Now it’s time for one last skill, inspecting what’s inside your model. In this video, you’ll explore tools to examine your model structure, count its parameters, and understand how layers are wired together. You’ll also see how this helps you solve real issues like those pesky shape mismatch errors.\nLet’s start with a simple question. How do you see what’s inside your model? Your first instinct might be to print it. And you’ll get something like this. Each line shows you the name that you gave the layer, like conv1 or fc2, the type of layer, such as conv2d, maxpool2d, or dropout, and key settings like input and output sizes or kernel size. This mirrors exactly what you defined in init. It’s like PyTorch is showing you a blueprint, perfect for spotting those structural mistakes.\nBut notice what’s missing. How many parameters does each layer have? What shapes are the tensors? What’s actually inside those sequential blocks? In this video, you’ll learn how to dig deeper.\nSo let’s start with that first question. How many parameters does your model have? To count parameters, you might try, but instead of a list, you’ll get something like this. That’s a generator. Can you think of a reason why PyTorch might use generators here? Because it’s efficient. It doesn’t load everything into memory. It just gives you one parameter at a time when they’re needed.\nTo actually see the parameters, you’ll need to iterate, and you’ll get shapes like this. Each shape represents a set of parameters, usually weights and biases from your layers.\nBut if you want the total number of parameters, here’s the standard approach. The .numL method gives you the number of elements in each tensor. Add them all up, and you’ve got your total parameter count. Over a million parameters, well, great, but where exactly are they?\nTo find out, you need to look at each layer individually, and that’s where .namedParameters comes in. This shows you exactly where each set of weights and biases live, layer by layer.\nTo understand these shapes, let’s take a look at fc1.weight as an example. It connects 2,048 inputs to 512 outputs, so you get a weight matrix with a shape 512 by 2,048. Each row holds the weights for one output neuron, one weight for every input. Now, that might feel backwards if you’re expecting it in the order of input-output, but the shape reflects the purpose. Each output combines information from all inputs. So PyTorch organizes the weights around the outputs. And the bias, well, that’s the 512. There’s one value per output neuron.\nBut what if your model includes nested blocks like sequential or custom modules? How do you peek inside them? Well, PyTorch gives you two handy methods, children and modules. Let’s start with children. This shows only the top-level components, like your convolutional or your fully-connected layers. If a block contains other layers like sequential or a custom module, you won’t see what’s inside.\nTo go deeper, try modules. What’s the difference? Think of your model like a folder structure. Children shows only the top-level folders. Modules shows everything inside, including layers nested inside sequential or other custom blocks. This is especially helpful when you’re working with modular architectures and you’ll want to inspect every layer."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session2.html#debugging-shape-mismatches",
    "href": "W4_DL/C1_M4_Core_NN_Components/session2.html#debugging-shape-mismatches",
    "title": "Module 4 - Session 2: PyTorch Techniques and Model Inspection",
    "section": "Debugging Shape Mismatches",
    "text": "Debugging Shape Mismatches\nCommon error: “mat1 and mat2 shapes cannot be multiplied”\nTwo-step approach:\n\nCheck layer shape: print(model.fc1.weight.shape) - what does FC1 expect?\nTrace shapes through forward: Print shapes at each step to see what it actually gets\n\ndef forward(self, x):\n    print(f\"After features: {x.shape}\")\n    x = x.flatten()\n    print(f\"After flatten: {x.shape}\")\n    # ...\nCombine inspection (what layer expects) with shape tracing (what it gets) to quickly pinpoint the issue.\n\nNow, you’ve got the full picture of your model, but what happens when something goes wrong? Well, let’s take a look at a common PyTorch error. This one usually means the input to a linear layer did not match what the layer expected. In real projects, the first thing most people check is the shape of the layer itself.\nIf the error happens at FC1, you can print its weight shape like this, and that gives you the fastest answer. But if you’re not sure which layer is causing the issue or you want to inspect multiple layers at once, you can just use named parameters.\nSo FC1 expects 1024 inputs, but your model’s passing in 2048. Why the mismatch? To trace the shape through your model, try printing it inside the forward pass. Now you can see the shape that your features block is producing and whether flattening is working as expected.\nBy combining model inspection, what FC1 expects, with shape tracing, what it actually gets, you can quickly pinpoint where things went off track. That’s how inspection and debugging work together."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session2.html#module-4-synthesis",
    "href": "W4_DL/C1_M4_Core_NN_Components/session2.html#module-4-synthesis",
    "title": "Module 4 - Session 2: PyTorch Techniques and Model Inspection",
    "section": "Module 4 Synthesis",
    "text": "Module 4 Synthesis\nFrom single neuron to CNN\n\nStarted: predicting delivery times\nNow: convolutional neural networks\nBuilt data pipelines, trained and evaluated models, inspected what’s happening\n\n\nAnd with that, you’ve reached the end of this video and the end of course one. From a single neuron predicting delivery times to a convolutional neural network, you’ve come a long way. You’ve built a solid foundation in PyTorch, creating data pipelines, building and training models, evaluating performance, and inspecting what’s happening under the hood."
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session2.html#lab-2-model-debugging-inspection-and-modularization",
    "href": "W4_DL/C1_M4_Core_NN_Components/session2.html#lab-2-model-debugging-inspection-and-modularization",
    "title": "Module 4 - Session 2: PyTorch Techniques and Model Inspection",
    "section": "Lab 2: Model Debugging, Inspection, and Modularization",
    "text": "Lab 2: Model Debugging, Inspection, and Modularization\n\n“Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it.” — Brian Kernighan\n\n\nCUE: START THE LAB HERE"
  },
  {
    "objectID": "W4_DL/C1_M4_Core_NN_Components/session2.html#assignment-1-overcoming-overfitting-building-a-robust-cnn",
    "href": "W4_DL/C1_M4_Core_NN_Components/session2.html#assignment-1-overcoming-overfitting-building-a-robust-cnn",
    "title": "Module 4 - Session 2: PyTorch Techniques and Model Inspection",
    "section": "Assignment 1: Overcoming Overfitting: Building a Robust CNN",
    "text": "Assignment 1: Overcoming Overfitting: Building a Robust CNN\n\nCUE: START THE ASSIGNMENT HERE"
  },
  {
    "objectID": "W4_DL/index.html",
    "href": "W4_DL/index.html",
    "title": "Week 4: Deep Learning Modules",
    "section": "",
    "text": "Overview: This week introduces you to deep learning with PyTorch and building image classifiers.\n\n\n\nTrainer Notes\nStudent Notes\nLab Setup\n\n\n\n\n\nSession 1: Introduction to PyTorch and Neural Networks\nSession 2: The ML Pipeline and Building Your First Model\nSession 3: Activation Functions\nSession 4: Working with Tensors\nLab 1: Building a Simple Neural Network\nLab 2: Modeling Non-Linear Patterns with Activation Functions\nLab 3: Tensors: The Core of PyTorch\nAssignment: Deeper Regression, Smarter Features\n\n\n\n\n\nSession 1: Data and Model Building\nSession 1.5: From Equations to Vectors (Optional)\nSession 2: Loss Functions and Optimizers\nSession 3: Device Management and Image Classification Setup\nSession 4: Training and Evaluating Your Classifier\nLab 1: Building Your First Image Classifier\nAssignment: EMNIST Letter Detective\n\n\n\n\n\nLab 1: Data Management\nAssignment: Building a Robust Data Pipeline\n\n\n\n\n\nSession 1: Convolutional Neural Networks\nSession 1.5: Transfer Learning\nSession 2: PyTorch Techniques and Model Inspection\nLab 1: Building a CNN for Nature Classification\nLab 2: Model Debugging, Inspection, and Modularization\nAssignment: Overcoming Overfitting: Building a Robust CNN\n\n\n\n\n\n\n\nPress S for speaker notes.\nPress M for outline view or O for slide overview.\n\n\n\n\n\n\nTensorFlow Playground\nNN Playground"
  },
  {
    "objectID": "W4_DL/index.html#notes",
    "href": "W4_DL/index.html#notes",
    "title": "Week 4: Deep Learning Modules",
    "section": "",
    "text": "Trainer Notes\nStudent Notes\nLab Setup"
  },
  {
    "objectID": "W4_DL/index.html#module-1-pytorch-fundamentals-2-days",
    "href": "W4_DL/index.html#module-1-pytorch-fundamentals-2-days",
    "title": "Week 4: Deep Learning Modules",
    "section": "",
    "text": "Session 1: Introduction to PyTorch and Neural Networks\nSession 2: The ML Pipeline and Building Your First Model\nSession 3: Activation Functions\nSession 4: Working with Tensors\nLab 1: Building a Simple Neural Network\nLab 2: Modeling Non-Linear Patterns with Activation Functions\nLab 3: Tensors: The Core of PyTorch\nAssignment: Deeper Regression, Smarter Features"
  },
  {
    "objectID": "W4_DL/index.html#module-2-image-classification-with-pytorch-1-day",
    "href": "W4_DL/index.html#module-2-image-classification-with-pytorch-1-day",
    "title": "Week 4: Deep Learning Modules",
    "section": "",
    "text": "Session 1: Data and Model Building\nSession 1.5: From Equations to Vectors (Optional)\nSession 2: Loss Functions and Optimizers\nSession 3: Device Management and Image Classification Setup\nSession 4: Training and Evaluating Your Classifier\nLab 1: Building Your First Image Classifier\nAssignment: EMNIST Letter Detective"
  },
  {
    "objectID": "W4_DL/index.html#module-3-data-management-0.5-day",
    "href": "W4_DL/index.html#module-3-data-management-0.5-day",
    "title": "Week 4: Deep Learning Modules",
    "section": "",
    "text": "Lab 1: Data Management\nAssignment: Building a Robust Data Pipeline"
  },
  {
    "objectID": "W4_DL/index.html#module-4-core-neural-network-components-1-day",
    "href": "W4_DL/index.html#module-4-core-neural-network-components-1-day",
    "title": "Week 4: Deep Learning Modules",
    "section": "",
    "text": "Session 1: Convolutional Neural Networks\nSession 1.5: Transfer Learning\nSession 2: PyTorch Techniques and Model Inspection\nLab 1: Building a CNN for Nature Classification\nLab 2: Model Debugging, Inspection, and Modularization\nAssignment: Overcoming Overfitting: Building a Robust CNN"
  },
  {
    "objectID": "W4_DL/index.html#important-notes-to-presenter",
    "href": "W4_DL/index.html#important-notes-to-presenter",
    "title": "Week 4: Deep Learning Modules",
    "section": "",
    "text": "Press S for speaker notes.\nPress M for outline view or O for slide overview."
  },
  {
    "objectID": "W4_DL/index.html#resources",
    "href": "W4_DL/index.html#resources",
    "title": "Week 4: Deep Learning Modules",
    "section": "",
    "text": "TensorFlow Playground\nNN Playground"
  },
  {
    "objectID": "W4_DL/student_notes.html",
    "href": "W4_DL/student_notes.html",
    "title": "Student Notes",
    "section": "",
    "text": "Skill:\n\nEach module has at least 1 lab and 1 assignment\n\nKnowledge:\n\nAuto-graded MCQ Quiz on Tuesday (M1 & M2)\nAuto-graded MCQ Quiz on Thursday (M3 & M4 + few questions from M1 & M2)\n\nHow do I get 100%?:\nAchievement of 100% requires understanding the material in the lab; which requires reading and review of the lab, as well as paying attention to the lecture that builds up to the lab. And then, doing the assignments. Review your work and check your understanding.\n\nBonus: you are engaged with the material and the lecture.\nBonus: you exhibit a high amount of effort in mastering the material. Example: doing the optional exercises like the ones in M1 Lab 3 (Tensors).\n\nHow to mess things up?:\n\nCheat\nSprinting through the lab without understanding the material\nDoing the lab at lecture time (you need to pay attention to the lecture to understand the material)\n\nRemember: if you get stuck, ask the instructor for help. We are here to help you learn; not to judge you."
  },
  {
    "objectID": "W4_DL/student_notes.html#week-4-assessment-quizzes-labs-and-assignments",
    "href": "W4_DL/student_notes.html#week-4-assessment-quizzes-labs-and-assignments",
    "title": "Student Notes",
    "section": "",
    "text": "Skill:\n\nEach module has at least 1 lab and 1 assignment\n\nKnowledge:\n\nAuto-graded MCQ Quiz on Tuesday (M1 & M2)\nAuto-graded MCQ Quiz on Thursday (M3 & M4 + few questions from M1 & M2)\n\nHow do I get 100%?:\nAchievement of 100% requires understanding the material in the lab; which requires reading and review of the lab, as well as paying attention to the lecture that builds up to the lab. And then, doing the assignments. Review your work and check your understanding.\n\nBonus: you are engaged with the material and the lecture.\nBonus: you exhibit a high amount of effort in mastering the material. Example: doing the optional exercises like the ones in M1 Lab 3 (Tensors).\n\nHow to mess things up?:\n\nCheat\nSprinting through the lab without understanding the material\nDoing the lab at lecture time (you need to pay attention to the lecture to understand the material)\n\nRemember: if you get stuck, ask the instructor for help. We are here to help you learn; not to judge you."
  },
  {
    "objectID": "W6/D1/day_1a_prompting.html#module-overview",
    "href": "W6/D1/day_1a_prompting.html#module-overview",
    "title": "Day 1a: Prompting",
    "section": "Module Overview",
    "text": "Module Overview\nSession 1: Prompting\n\nLLM fundamentals and output configuration\nZero-shot, few-shot, and chain-of-thought prompting\nSystem, role, and contextual prompting\nAdvanced techniques: ReAct, step-back, self-consistency\nCode prompting\n\nSession 2: Evaluation and Structured Output\n\nStructured output and schemas\nPointwise and pairwise evaluation\nEvaluation methods and best practices\n\n\nToday is split into two sessions. This first session focuses entirely on prompting - the foundation of working with LLMs. We’ll start with understanding how LLMs work, then move through increasingly sophisticated prompting techniques.\nThe second session will build on this by showing you how to get structured outputs and evaluate whether your prompts are working well. These two sessions work together: good prompting gets you good outputs, and evaluation tells you if your prompts are actually good."
  },
  {
    "objectID": "W6/D1/day_1a_prompting.html#how-llms-work",
    "href": "W6/D1/day_1a_prompting.html#how-llms-work",
    "title": "Day 1a: Prompting",
    "section": "How LLMs Work",
    "text": "How LLMs Work\nPrediction engines, not databases\n\nLarge language model as a prediction engine showing sequential token prediction process\nBefore we dive into prompting techniques, we need to understand how LLMs actually work. This is crucial because it explains why certain prompting techniques are effective.\nAn LLM is a prediction engine. It takes sequential text as input and predicts what the following token should be, based on the data it was trained on. The model does this over and over again, adding the previously predicted token to the end of the sequential text for predicting the following token.\nThe next token prediction is based on the relationship between what’s in the previous tokens and what the LLM has seen during its training. This is why context matters so much - the model uses the tokens you provide to predict what comes next.\nWhen you write a prompt, you are attempting to set up the LLM to predict the right sequence of tokens. Prompt engineering is the process of designing high-quality prompts that guide LLMs to produce accurate outputs."
  },
  {
    "objectID": "W6/D1/day_1a_prompting.html#prompt-engineering-defined",
    "href": "W6/D1/day_1a_prompting.html#prompt-engineering-defined",
    "title": "Day 1a: Prompting",
    "section": "Prompt Engineering Defined",
    "text": "Prompt Engineering Defined\nDesigning high-quality prompts\n\nTinkering to find the best prompt\nOptimizing prompt length\nEvaluating writing style and structure\nMatching prompts to tasks\n\n\nPrompt engineering is the process of designing high-quality prompts that guide LLMs to produce accurate outputs. This process involves several key activities:\nFirst, tinkering - you’ll try different phrasings, structures, and approaches to find what works best for your specific task. There’s no one-size-fits-all solution.\nSecond, optimizing prompt length. Longer prompts aren’t always better - you need to find the right balance between providing enough context and being concise.\nThird, evaluating the writing style and structure in relation to the task. Different tasks require different approaches. A creative writing task needs different prompting than a data extraction task.\nFinally, matching prompts to tasks. Prompts might need to be optimized for your specific model, regardless of whether you use Gemini, GPT, Claude, or an open source model like Gemma or LLaMA."
  },
  {
    "objectID": "W6/D1/day_1a_prompting.html#llm-output-configuration",
    "href": "W6/D1/day_1a_prompting.html#llm-output-configuration",
    "title": "Day 1a: Prompting",
    "section": "LLM Output Configuration",
    "text": "LLM Output Configuration\nControlling how the model generates\n\nOutput length\nTemperature\nTop-K\nTop-P\n\n\nOnce you choose your model, you need to figure out the model configuration. Most LLMs come with various configuration options that control the LLM’s output. Effective prompt engineering requires setting these configurations optimally for your task.\nThese aren’t just technical details - they fundamentally change how the model behaves. Understanding these settings is as important as writing good prompts."
  },
  {
    "objectID": "W6/D1/day_1a_prompting.html#output-length",
    "href": "W6/D1/day_1a_prompting.html#output-length",
    "title": "Day 1a: Prompting",
    "section": "Output Length",
    "text": "Output Length\nControlling response size\n\nTokens and cost\nAn important configuration setting is the number of tokens to generate in a response. Generating more tokens requires more computation from the LLM, leading to higher energy consumption, potentially slower response times, and higher costs.\nBut here’s a crucial point: reducing the output length doesn’t cause the LLM to become more stylistically or textually succinct in the output it creates. It just causes the LLM to stop predicting more tokens once the limit is reached. If your needs require a short output length, you’ll also possibly need to engineer your prompt to accommodate.\nOutput length restriction is especially important for some LLM prompting techniques, like ReAct, where the LLM will keep emitting useless tokens after the response you want.\nBe aware: generating more tokens requires more computation, leading to higher energy consumption and potentially slower response times, which leads to higher costs."
  },
  {
    "objectID": "W6/D1/day_1a_prompting.html#sampling-controls",
    "href": "W6/D1/day_1a_prompting.html#sampling-controls",
    "title": "Day 1a: Prompting",
    "section": "Sampling Controls",
    "text": "Sampling Controls\nHow tokens are selected\n\nTemperature, top-K, and top-P\nTemperature: Control the randomness of the output\nTop-K: Consider only the K most likely tokens\nTop-P (nucleus sampling): Consider tokens whose cumulative probability exceeds P\n\n\nLLMs predict probabilities for what the next token could be, with each token in the vocabulary getting a probability. Those probabilities are then sampled to determine the next produced token.\nThis is a key concept: LLMs don’t formally predict a single token. Rather, LLMs predict probabilities for what the next token could be, with each token in the LLM’s vocabulary getting a probability. Those token probabilities are then sampled to determine what the next produced token will be.\nTemperature, top-K, and top-P are the most common configuration settings that determine how predicted token probabilities are processed to choose a single output token. Understanding these helps you control the randomness and creativity of your outputs.\nTop-K and top-P (also known as nucleus sampling) are two sampling settings used in LLMs to restrict the predicted next token candidates.\nTop-K restricts the sampling to only the K most likely tokens. If K is 10, the model only considers the top 10 most probable tokens, ignoring all others. This can help prevent the model from selecting very unlikely tokens.\nTop-P, or nucleus sampling, considers tokens whose cumulative probability exceeds P. So if P is 0.9, the model considers tokens in order of probability until their cumulative probability reaches 90%, then ignores the rest. This is more dynamic than top-K because it adapts to the probability distribution.\nBoth methods help control the randomness and quality of outputs by focusing on more likely tokens."
  },
  {
    "objectID": "W6/D1/day_1a_prompting.html#temperature",
    "href": "W6/D1/day_1a_prompting.html#temperature",
    "title": "Day 1a: Prompting",
    "section": "Temperature",
    "text": "Temperature\n\n\nControlling randomness\n\nLow temperature (0): Deterministic, highest probability token always selected\nHigh temperature: More diverse or unexpected results\nVery high temperature: All tokens become equally likely\n\n\n\n\n\nTemperature scale showing deterministic to random output behavior\n\n\n\n\nTemperature controls the degree of randomness in token selection. Lower temperatures are good for prompts that expect a more deterministic response, while higher temperatures can lead to more diverse or unexpected results.\nA temperature of 0 (greedy decoding) is deterministic: the highest probability token is always selected. Note that if two tokens have the same highest predicted probability, depending on how tiebreaking is implemented you may not always get the same output with temperature 0.\nTemperatures close to the max tend to create more random output. And as temperature gets higher and higher, all tokens become equally likely to be the next predicted token.\nThe Gemini temperature control can be understood in a similar way to the softmax function used in machine learning. A low temperature setting mirrors a low softmax temperature, emphasizing a single, preferred temperature with high certainty. A higher Gemini temperature setting is like a high softmax temperature, making a wider range of temperatures around the selected setting more acceptable."
  },
  {
    "objectID": "W6/D1/day_1a_prompting.html#general-prompting-zero-shot",
    "href": "W6/D1/day_1a_prompting.html#general-prompting-zero-shot",
    "title": "Day 1a: Prompting",
    "section": "General Prompting / Zero-Shot",
    "text": "General Prompting / Zero-Shot\nDirect instruction without examples\n\nZero-shot prompting\nZero-shot prompting is the simplest form: you just ask the model to do something directly, without showing it any examples first. The model relies entirely on what it learned during training.\nThis works well for straightforward tasks that the model has seen many times during training: translation, summarization, classification, and so on. The model has internalized patterns for these tasks.\nZero-shot prompting is also called “general prompting” because it’s the most general approach - you’re not providing any task-specific examples or structure.\nUse cases:\n\nTranslation\nSummarization\nClassification\nSimple Q&A\n\nHowever, zero-shot has limits. If the task is ambiguous, or if you need a specific format, or if the model needs to follow a particular style, zero-shot might not be enough. That’s when we move to few-shot."
  },
  {
    "objectID": "W6/D1/day_1a_prompting.html#one-shot-few-shot-prompting",
    "href": "W6/D1/day_1a_prompting.html#one-shot-few-shot-prompting",
    "title": "Day 1a: Prompting",
    "section": "One-Shot & Few-Shot Prompting",
    "text": "One-Shot & Few-Shot Prompting\nInstruction + examples\n\nOne-Shot & Few-Shot Prompting\nFew-shot prompting adds examples to your instruction. You show the model a few examples of the task you want it to perform, then ask it to do the same thing for a new input.\nOne-shot is a special case of few-shot with exactly one example. Few-shot typically uses 2-5 examples.\nThis is incredibly powerful because it lets you specify exactly what you want without having to describe it in words. Instead of saying “translate to formal Arabic,” you just show a few examples of formal Arabic translations, and the model picks up the pattern.\nWhat’s happening under the hood? The model is doing pattern recognition. It sees the examples and identifies the pattern: “Oh, I see - for each English phrase, there’s a corresponding Arabic phrase. And the style is formal. And the format is numbered list with arrow.”\nThis is why few-shot works so well - it’s showing, not telling. You’re demonstrating the task rather than describing it. And neural networks are excellent at learning from demonstrations.\nBut there’s a limit. Too many examples can confuse the model or hit token limits. Usually 2-5 examples is the sweet spot. And the examples need to be representative - if all your examples are simple cases, the model won’t handle complex cases well."
  },
  {
    "objectID": "W6/D1/day_1a_prompting.html#system-prompting",
    "href": "W6/D1/day_1a_prompting.html#system-prompting",
    "title": "Day 1a: Prompting",
    "section": "System Prompting",
    "text": "System Prompting\nPersistent context and behavior\n\nSystem Prompting\nSystem instructions are persistent instructions that apply to the entire conversation. Unlike regular prompts that are specific to one request, system instructions set the overall behavior and context.\nThink of system instructions as the “personality” or “role” of the assistant. You’re telling the model: “For this entire conversation, act like this, follow these rules, use this style.”\nThis is essential for building applications. If you’re building a customer service bot, you want it to be polite and helpful in every interaction, not just when you remember to add “be polite” to each prompt. System instructions let you set that once and have it apply everywhere.\nSystem prompting is different from role prompting - system prompts set general behavior, while role prompts define a specific persona or expertise area."
  },
  {
    "objectID": "W6/D1/day_1a_prompting.html#role-prompting",
    "href": "W6/D1/day_1a_prompting.html#role-prompting",
    "title": "Day 1a: Prompting",
    "section": "Role Prompting",
    "text": "Role Prompting\nDefining expertise and perspective\nYou are a Python programming tutor with 10 years \nof experience. Explain concepts clearly and \nprovide code examples.\nUse cases:\n\nDomain expertise\nPerspective setting\nStyle consistency\n\n\nRole prompting defines a specific role, persona, or expertise area for the model. Instead of just setting general behavior, you’re telling the model to act as a specific type of person or expert.\nThis is powerful because it leverages the model’s training data about how different roles communicate. A Python tutor will explain things differently than a data science consultant, even for the same topic.\nRole prompting helps with:\n\nDomain expertise: The model will draw on knowledge patterns associated with that role\nPerspective setting: Different roles have different perspectives\nStyle consistency: Roles have consistent communication styles\n\nThe key is being specific. “You are a tutor” is vague. “You are a Python programming tutor with 10 years of experience who specializes in teaching beginners” is much better."
  },
  {
    "objectID": "W6/D1/day_1a_prompting.html#contextual-prompting",
    "href": "W6/D1/day_1a_prompting.html#contextual-prompting",
    "title": "Day 1a: Prompting",
    "section": "Contextual Prompting",
    "text": "Contextual Prompting\nProviding relevant background\nContext: The user is working on a machine learning \nproject using scikit-learn. They have a dataset \nwith 10,000 samples and 50 features.\n\nQuestion: What preprocessing steps should I take?\n\nContextual prompting provides relevant background information that helps the model understand the situation and provide more appropriate responses.\nThis is different from system or role prompting because the context is specific to the current task or conversation, not a persistent setting. You’re providing situational information that helps the model tailor its response.\nContextual prompting is especially important when:\n\nThe task requires domain-specific knowledge\nThe answer depends on specific circumstances\nYou want the model to consider multiple factors\n\nThe key is providing relevant context without overwhelming the model. Too much context can confuse the model or dilute the important information. Too little context can lead to generic or inappropriate responses."
  },
  {
    "objectID": "W6/D1/day_1a_prompting.html#step-back-prompting",
    "href": "W6/D1/day_1a_prompting.html#step-back-prompting",
    "title": "Day 1a: Prompting",
    "section": "Step-Back Prompting",
    "text": "Step-Back Prompting\nEvoking reasoning via abstraction\nInstead of asking directly, first ask the model to step back and think about the broader principles or concepts.\n\nStep-back prompting showing abstraction before specific reasoning\nStep-back prompting is a technique where you first ask the model to step back and think about broader principles or concepts before addressing the specific question. This helps the model reason more effectively by working at a higher level of abstraction first.\nThe idea is that by first understanding the general principles, the model can then apply those principles more effectively to the specific problem. This is similar to how humans often solve problems - we think about general strategies before diving into specifics.\nFor example, instead of asking “How do I optimize this specific SQL query?”, you might first ask “What are the general principles of SQL query optimization?” and then “Now apply those principles to this specific query.”\nThis technique is particularly effective for complex reasoning tasks where the model needs to understand underlying principles before solving the specific problem."
  },
  {
    "objectID": "W6/D1/day_1a_prompting.html#chain-of-thought-cot",
    "href": "W6/D1/day_1a_prompting.html#chain-of-thought-cot",
    "title": "Day 1a: Prompting",
    "section": "Chain of Thought (CoT)",
    "text": "Chain of Thought (CoT)\nAdding reasoning steps\n\nChain of thought prompting showing step-by-step reasoning process\nChain-of-thought prompting asks the model to show its reasoning process, step by step. Instead of just giving an answer, the model explains how it got there.\nThis is crucial for complex reasoning tasks. Math word problems, logic puzzles, multi-step planning - these all benefit from chain-of-thought because the model is forced to break down the problem into steps, and you can see if those steps make sense.\nBut chain-of-thought isn’t just for math. It works for any task that requires reasoning: analyzing a business problem, debugging code, planning a project. When you ask the model to “think step by step,” it often produces better results because it’s not jumping to conclusions.\nChain-of-thought works because it forces the model to be explicit about its reasoning. Instead of jumping from problem to answer, it has to show the intermediate steps. This often improves accuracy because the model is less likely to make calculation errors when it shows its work.\nFor CoT prompting, putting the answer after the reasoning is required because the generation of the reasoning changes the tokens that the model gets when it predicts the final answer. Also, set the temperature to 0 for CoT, as it’s based on greedy decoding."
  },
  {
    "objectID": "W6/D1/day_1a_prompting.html#self-consistency",
    "href": "W6/D1/day_1a_prompting.html#self-consistency",
    "title": "Day 1a: Prompting",
    "section": "Self-Consistency",
    "text": "Self-Consistency\nMultiple reasoning paths\nGenerate multiple chain-of-thought reasoning paths, then select the most consistent answer.\n\nSelf-consistency showing multiple reasoning paths converging on answer\nSelf-consistency is an extension of chain-of-thought prompting. Instead of generating one reasoning path, you generate multiple chain-of-thought reasoning paths, then select the most consistent answer.\nThe idea is that if multiple reasoning paths lead to the same answer, that answer is more likely to be correct. This is similar to ensemble methods in machine learning - multiple models often perform better than a single model.\nTo use self-consistency:\n\nGenerate multiple chain-of-thought responses (with temperature &gt; 0)\nExtract the final answers from each response\nSelect the answer that appears most frequently\n\nThis technique improves accuracy on reasoning tasks because it reduces the impact of errors in individual reasoning paths. If one path makes a mistake but others don’t, the correct answer will still be selected.\nSelf-consistency is particularly effective for tasks where there’s a clear right answer, like math problems or factual questions."
  },
  {
    "objectID": "W6/D1/day_1a_prompting.html#tree-of-thoughts-tot",
    "href": "W6/D1/day_1a_prompting.html#tree-of-thoughts-tot",
    "title": "Day 1a: Prompting",
    "section": "Tree of Thoughts (ToT)",
    "text": "Tree of Thoughts (ToT)\nExploring multiple reasoning branches\nInstead of linear reasoning, explore multiple reasoning branches and select the best path.\n\nTree of thoughts showing branching reasoning exploration\nTree of Thoughts (ToT) is an advanced prompting technique that goes beyond chain-of-thought. Instead of following a single linear reasoning path, ToT explores multiple reasoning branches and selects the best path.\nThe process works like this:\n\nGenerate multiple possible next steps (thoughts)\nEvaluate each thought\nSelect the most promising thoughts to expand\nRepeat until reaching a solution\n\nThis is similar to how humans solve complex problems - we consider multiple approaches, evaluate them, and pursue the most promising ones.\nToT is particularly useful for:\n\nComplex planning tasks\nProblems with multiple valid approaches\nTasks where exploration is beneficial\n\nHowever, ToT is more computationally expensive than chain-of-thought because it generates and evaluates multiple reasoning paths. It’s best used for complex problems where the additional exploration is worth the cost."
  },
  {
    "objectID": "W6/D1/day_1a_prompting.html#react-reason--act",
    "href": "W6/D1/day_1a_prompting.html#react-reason--act",
    "title": "Day 1a: Prompting",
    "section": "ReAct (Reason & Act)",
    "text": "ReAct (Reason & Act)\nSynergizing reasoning and acting\nThe model alternates between reasoning (thinking) and acting (taking actions like tool use).\n\nReAct pattern showing alternating reasoning and action steps\nReAct (Reason & Act) is a prompting technique that synergizes reasoning and acting in language models. The model alternates between reasoning steps (thinking about what to do) and acting steps (taking actions like using tools, searching, or executing code).\nThis is particularly powerful for tasks that require:\n\nTool use (searching, calculating, executing code)\nMulti-step problem solving\nDynamic decision making\n\nThe ReAct pattern works like this:\n\nReason: Think about what to do next\nAct: Take an action (use a tool, search, etc.)\nObserve: See the result of the action\nRepeat until the task is complete\n\nThis pattern is especially important for agent systems where the model needs to interact with external tools or systems. It allows the model to plan, execute, and adapt based on results.\nNote: For ReAct, output length restriction is especially important because the LLM will keep emitting useless tokens after the response you want if not properly controlled."
  },
  {
    "objectID": "W6/D1/day_1a_prompting.html#automatic-prompt-engineering",
    "href": "W6/D1/day_1a_prompting.html#automatic-prompt-engineering",
    "title": "Day 1a: Prompting",
    "section": "Automatic Prompt Engineering",
    "text": "Automatic Prompt Engineering\nUsing LLMs to improve prompts\nLLMs can be used to automatically generate, refine, and optimize prompts.\n\nAutomatic prompt engineering showing LLM improving its own prompts\nAutomatic Prompt Engineering is a meta-technique: using LLMs to improve prompts. Instead of manually crafting prompts, you can use an LLM to generate, refine, and optimize prompts.\nThis works by:\n\nProviding the LLM with examples of good prompts and their results\nAsking the LLM to generate new prompts for a task\nTesting the generated prompts\nRefining based on results\n\nThis is particularly useful for:\n\nFinding optimal prompt structures\nDiscovering effective phrasings\nAdapting prompts to new tasks\nScaling prompt engineering efforts\n\nThe key insight is that LLMs have learned patterns about effective communication from their training data, so they can apply those patterns to create better prompts.\nHowever, automatic prompt engineering still requires human oversight and evaluation. The LLM can suggest improvements, but you need to verify that they actually work better."
  },
  {
    "objectID": "W6/D1/day_1a_prompting.html#keytakeaways",
    "href": "W6/D1/day_1a_prompting.html#keytakeaways",
    "title": "Day 1a: Prompting",
    "section": "Keytakeaways",
    "text": "Keytakeaways\nYour complete toolkit\n\nZero-shot: Simple, well-known tasks\nFew-shot: Specific formats and styles\nSystem/Role/Contextual: Setting behavior and context\nChain-of-thought: Complex reasoning\nSelf-consistency: Validating results\nTree of Thoughts: Exploring good thought trajectories\nReAct: Reasoning with actions\n\n\nLet’s bring it all together. You now have a complete toolkit for prompting:\nUse zero-shot for straightforward tasks that the model knows well. Use few-shot when you need specific formats or styles. Use system, role, and contextual prompting to set behavior and provide background. Use chain-of-thought for complex reasoning problems. Use self-consistency to improve accuracy. Use Tree of Thoughts for exploring multiple reasoning paths. Use ReAct for tasks requiring tool use and dynamic decision making. And use code prompting for all aspects of working with code.\nThe key is matching the technique to the task. Don’t overcomplicate simple tasks with advanced techniques, and don’t under-specify complex tasks with basic prompting.\nIn the next session, we’ll learn how to evaluate whether your prompts are actually working well, and how to get structured outputs that are easier to work with programmatically."
  },
  {
    "objectID": "W6/D2/day_2_embeddings.html#module-overview",
    "href": "W6/D2/day_2_embeddings.html#module-overview",
    "title": "Day 2: Embeddings",
    "section": "Module Overview",
    "text": "Module Overview\nSession: Embeddings\n\nWhat are embeddings and why they matter\nTypes of embeddings: text, image, structured, graph\nEvaluating embedding quality\n\n\nToday we’re diving deep into embeddings - the foundation of modern retrieval systems. By the end of this session, you’ll understand how to transform any data type into numerical vectors.\nThis knowledge is critical because embeddings are what make semantic search possible. They’re what allow you to find relevant documents based on meaning, not just keyword matching."
  },
  {
    "objectID": "W6/D2/day_2_embeddings.html#what-youll-learn-today",
    "href": "W6/D2/day_2_embeddings.html#what-youll-learn-today",
    "title": "Day 2: Embeddings",
    "section": "What You’ll Learn Today",
    "text": "What You’ll Learn Today\nBy the end of this session, you will:\n\nUnderstand embeddings as numerical representations of data\nKnow how to evaluate embedding quality\nRecognize different types of embeddings and their use cases\n\n\nLet me start by telling you what you’ll know at the end of this hour that you don’t know right now.\nFirst, you’ll understand embeddings - not just as a buzzword, but as a concrete mathematical concept. You’ll see how text, images, and other data types can be transformed into vectors that capture semantic meaning.\nSecond, you’ll learn how to evaluate whether your embeddings are actually good. This is crucial because bad embeddings lead to bad search results.\nThird, you’ll understand the different types of embeddings and when to use each one. Not all embeddings are created equal, and choosing the right one matters."
  },
  {
    "objectID": "W6/D2/day_2_embeddings.html#what-are-embeddings",
    "href": "W6/D2/day_2_embeddings.html#what-are-embeddings",
    "title": "Day 2: Embeddings",
    "section": "What Are Embeddings?",
    "text": "What Are Embeddings?\nNumerical representations of real-world data\n\nEmbeddings as vectors in a low-dimensional space representing text, images, and other data types\nLet’s start with the fundamental question: what are embeddings?\nEmbeddings are numerical representations of real-world data - text, images, audio, videos, anything. The name comes from mathematics, where one space can be mapped, or embedded, into another space.\nFor example, BERT embeds text into a vector of 768 numbers. This maps from the very high-dimensional space of all possible sentences to a much smaller 768-dimensional space.\nThe key insight is that embeddings are low-dimensional vectors where the geometric distance between two vectors reflects the semantic similarity between the real-world objects they represent. If two vectors are close in the embedding space, the objects they represent are semantically similar.\nThis is powerful because it gives you compact representations that retain important semantic properties while enabling efficient computation and storage."
  },
  {
    "objectID": "W6/D2/day_2_embeddings.html#why-embeddings-matter",
    "href": "W6/D2/day_2_embeddings.html#why-embeddings-matter",
    "title": "Day 2: Embeddings",
    "section": "Why Embeddings Matter",
    "text": "Why Embeddings Matter\nCompact, meaningful representations\n\nLossy compression: Reduce dimensionality while preserving semantics\nSimilarity comparison: Measure relationships numerically\nMultimodal alignment: Map different data types to the same space\nEfficient computation: Enable fast search and retrieval\n\n\nSo why do embeddings matter? There are several key reasons.\nFirst, they act as lossy compression. You’re reducing the dimensionality of your data - from potentially infinite-dimensional text space to a fixed-size vector - while preserving important semantic properties.\nSecond, they enable similarity comparison. You can measure how similar two objects are by computing the distance between their embeddings. This is much more powerful than exact matching.\nThird, they enable multimodal alignment. You can map text, images, audio, and other data types into the same embedding space, allowing you to search across modalities - like finding videos based on text queries.\nFourth, they enable efficient computation. Once your data is in vector form, you can use optimized algorithms for search, clustering, and other operations that would be impossible or too slow on raw data.\nThese properties make embeddings essential for modern AI applications."
  },
  {
    "objectID": "W6/D2/day_2_embeddings.html#embeddings-in-retrieval-systems",
    "href": "W6/D2/day_2_embeddings.html#embeddings-in-retrieval-systems",
    "title": "Day 2: Embeddings",
    "section": "Embeddings in Retrieval Systems",
    "text": "Embeddings in Retrieval Systems\nThe three-step process\n\nPrecompute embeddings for billions of items\nMap query embeddings into the same space\nRetrieve nearest neighbors efficiently\n\n\nThe power of embeddings becomes clear when you look at how modern retrieval systems work. Think about Google Search - it’s a retrieval task over the search space of the entire internet.\nToday’s retrieval systems succeed through three steps:\nFirst, you precompute embeddings for billions of items in your search space. This is done offline, so you can use expensive models and take your time.\nSecond, when a query comes in, you map it into the same embedding space. This is done in real-time, so you need fast models.\nThird, you efficiently compute and retrieve items whose embeddings are nearest neighbors of the query embedding. This is where vector search algorithms and vector databases come in.\nThis three-step process is what makes semantic search possible at scale. Without embeddings, you’d be stuck with keyword matching. With embeddings, you can find semantically similar content even if it uses different words."
  },
  {
    "objectID": "W6/D2/day_2_embeddings.html#joint-embeddings-for-multimodality",
    "href": "W6/D2/day_2_embeddings.html#joint-embeddings-for-multimodality",
    "title": "Day 2: Embeddings",
    "section": "Joint Embeddings for Multimodality",
    "text": "Joint Embeddings for Multimodality\nMultiple data types in one space\n\nObjects of different types (text, images, videos) projected into a joint vector space with semantic meaning\nOne of the most powerful applications of embeddings is joint embeddings - mapping multiple types of objects into the same embedding space.\nFor example, you can map text, images, and videos into the same space. This means you can retrieve videos based on text queries, or find images that match a text description, or search for text that describes an image.\nThe key is that these embedding representations are designed to capture as much of the original object’s characteristics as possible, while placing objects with similar semantic properties closer in the embedding space.\nThis is what enables applications like image search with text queries, or finding relevant videos based on a description. The embeddings bridge the gap between different modalities."
  },
  {
    "objectID": "W6/D2/day_2_embeddings.html#task-specific-embeddings",
    "href": "W6/D2/day_2_embeddings.html#task-specific-embeddings",
    "title": "Day 2: Embeddings",
    "section": "Task-Specific Embeddings",
    "text": "Task-Specific Embeddings\n\n2D visualization of pre-trained GloVe and Word2Vec word embeddingsDifferent embeddings for different tasks\n\nSame object → different embeddings\nOptimized for the task at hand\nSemantic meaning preserved for specific use cases\n\n\nHere’s an important point: embeddings are task-specific. You can generate different embeddings for the same object, each optimized for a different task.\nFor example, you might have one embedding optimized for sentiment analysis, another for topic classification, and another for semantic search. The same text document would have different embeddings in each case.\nThis is both a feature and a challenge. It means you can optimize for your specific use case, but it also means you need to choose the right embedding model for your task.\nThe semantic meaning is preserved, but it’s preserved in a way that’s useful for your specific task. This is why evaluation is so important - you need to make sure your embeddings are actually good for what you’re trying to do."
  },
  {
    "objectID": "W6/D2/day_2_embeddings.html#why-evaluation-matters",
    "href": "W6/D2/day_2_embeddings.html#why-evaluation-matters",
    "title": "Day 2: Embeddings",
    "section": "Why Evaluation Matters",
    "text": "Why Evaluation Matters\nBad embeddings → bad results\n\nEmbeddings are not automatically good\nQuality depends on model, data, and task\nEvaluation tells you if embeddings work for your use case\n\n\nBefore we dive into types of embeddings, let’s talk about evaluation. This is crucial because embeddings are not automatically good - their quality depends on the model, the data, and the task.\nYou can’t just grab any embedding model and assume it will work for your use case. You need to evaluate whether your embeddings are actually capturing the semantic relationships you care about.\nEvaluation tells you if your embeddings work for your specific use case. It helps you choose the right model, tune parameters, and understand limitations.\nWithout evaluation, you’re flying blind. You might think your retrieval system is working, but you’re actually getting poor results because your embeddings don’t capture the right relationships."
  },
  {
    "objectID": "W6/D2/day_2_embeddings.html#evaluation-methods",
    "href": "W6/D2/day_2_embeddings.html#evaluation-methods",
    "title": "Day 2: Embeddings",
    "section": "Evaluation Methods",
    "text": "Evaluation Methods\n\nIntrinsic evaluation: Direct measurement of embedding properties\nExtrinsic evaluation: Performance on downstream tasks (IR, classification, ..etc.)\nBenchmarks: MTEB, BEIR for standardized comparison\n\n\nThere are several ways to evaluate embeddings:\nIntrinsic evaluation measures the embedding properties directly - things like whether similar items are close in the embedding space, or whether the embeddings capture certain linguistic properties.\nExtrinsic evaluation measures performance on downstream tasks - like how well your embeddings work for information retrieval, or classification, or clustering.\nBenchmarks like MTEB (Massive Text Embedding Benchmark) and BEIR provide standardized ways to compare different embedding models. These are important because they give you a common ground for comparison.\nThe best approach is usually a combination - use benchmarks to narrow down your options, then do task-specific evaluation to find what works best for your use case."
  },
  {
    "objectID": "W6/D2/day_2_embeddings.html#search-example-the-challenge",
    "href": "W6/D2/day_2_embeddings.html#search-example-the-challenge",
    "title": "Day 2: Embeddings",
    "section": "Search Example: The Challenge",
    "text": "Search Example: The Challenge\nFinding relevant documents\n\nQuery: “How do I reset my password?”\nCorpus: Millions of support articles\nGoal: Find the most relevant articles\n\n\nLet me give you a concrete example of why embedding quality matters. Imagine you’re building a search system for a support knowledge base.\nA user asks: “How do I reset my password?”\nYou have millions of support articles in your corpus. Your goal is to find the most relevant articles.\nWith keyword matching, you might find articles that mention “reset” and “password” but miss articles that say “change your login credentials” or “forgot password recovery.”\nWith good embeddings, you should find all semantically similar articles, even if they use different words. But with bad embeddings, you might miss relevant articles or get irrelevant ones.\nThis is why evaluation is so important - you need to know if your embeddings are actually finding the right documents."
  },
  {
    "objectID": "W6/D2/day_2_embeddings.html#text-embeddings-overview",
    "href": "W6/D2/day_2_embeddings.html#text-embeddings-overview",
    "title": "Day 2: Embeddings",
    "section": "Text Embeddings Overview",
    "text": "Text Embeddings Overview\nFrom words to documents\n\nWord embeddings: Individual words → vectors\nDocument embeddings: Entire documents → vectors\nContext-aware: Meaning depends on surrounding text\n\n\nNow let’s talk about types of embeddings. We’ll start with text embeddings, which are probably the most common.\nText embeddings come in different flavors. Word embeddings map individual words to vectors. Document embeddings map entire documents to vectors. And modern embeddings are context-aware - the meaning depends on the surrounding text.\nThe evolution of text embeddings tells an important story about how the field has progressed from simple bag-of-words models to sophisticated neural networks that understand context."
  },
  {
    "objectID": "W6/D2/day_2_embeddings.html#word-embeddings",
    "href": "W6/D2/day_2_embeddings.html#word-embeddings",
    "title": "Day 2: Embeddings",
    "section": "Word Embeddings",
    "text": "Word Embeddings\nIndividual words as vectors\n\nWord2Vec: Predicts words from context\nGloVe: Global word-word co-occurrence statistics\nFastText: Handles out-of-vocabulary words\n\n\nWord embeddings showing similar words clustered together in vector space\nWord embeddings were one of the first breakthroughs in NLP. They map individual words to fixed-size vectors.\nWord2Vec was one of the earliest and most influential. It learns embeddings by predicting words from their context - words that appear in similar contexts get similar embeddings.\nGloVe takes a different approach - it uses global word-word co-occurrence statistics from a corpus. It’s based on the idea that words that co-occur frequently are likely related.\nFastText extends Word2Vec by representing words as bags of character n-grams. This means it can handle out-of-vocabulary words by breaking them into subword units.\nThe key insight is that these embeddings capture semantic relationships - words with similar meanings end up close in the embedding space. You can do arithmetic on them - “king” minus “man” plus “woman” gives you something close to “queen.”"
  },
  {
    "objectID": "W6/D2/day_2_embeddings.html#document-embeddings-shallow-models",
    "href": "W6/D2/day_2_embeddings.html#document-embeddings-shallow-models",
    "title": "Day 2: Embeddings",
    "section": "Document Embeddings: Shallow Models",
    "text": "Document Embeddings: Shallow Models\nBag-of-words approaches\n\nTF-IDF: Term frequency × inverse document frequency\nBM25: Probabilistic ranking function\nLimitations: No word order, no context\n\n\nBefore deep learning, document embeddings were mostly based on bag-of-words approaches. These are called “shallow” because they don’t use deep neural networks.\nTF-IDF - Term Frequency times Inverse Document Frequency - is a classic approach. It weights words by how common they are in the document relative to how common they are across all documents. Common words get lower weights.\nBM25 is a probabilistic ranking function that’s still widely used today, especially in search engines. It’s an improvement over TF-IDF that handles document length normalization better.\nThe main limitation of these approaches is that they ignore word order and context. “The cat sat on the mat” and “The mat sat on the cat” would have the same representation, even though they mean completely different things.\nThey also can’t capture semantic relationships - “car” and “automobile” are treated as completely different words."
  },
  {
    "objectID": "W6/D2/day_2_embeddings.html#document-embeddings-deep-models",
    "href": "W6/D2/day_2_embeddings.html#document-embeddings-deep-models",
    "title": "Day 2: Embeddings",
    "section": "Document Embeddings: Deep Models",
    "text": "Document Embeddings: Deep Models\nContext-aware neural embeddings\n\nBERT: Bidirectional encoder representations\nSentence-BERT: Efficient sentence embeddings\nModern LLMs: GPT, T5, Gemini embeddings\n\n\nSingle-vector vs. Multi-vector encoders\nDeep models changed everything. They use neural networks to learn embeddings that capture context and semantic meaning.\nBERT - Bidirectional Encoder Representations from Transformers - was a breakthrough. It reads text in both directions simultaneously, so it understands context. The word “bank” gets different embeddings depending on whether it’s “river bank” or “financial bank.”\nSentence-BERT makes BERT practical for sentence-level tasks. Regular BERT requires running the full model for every sentence pair you want to compare, which is too slow. Sentence-BERT fine-tunes BERT to produce sentence embeddings directly, making similarity comparison much faster.\nModern LLMs like GPT, T5, and Gemini can also produce embeddings. These are often very high quality because they’re trained on massive amounts of data, but they can be expensive to run.\nThe key advantage of deep models is that they understand context and semantics. They can tell that “car” and “automobile” are similar, and that “The cat sat on the mat” is different from “The mat sat on the cat.”"
  },
  {
    "objectID": "W6/D2/day_2_embeddings.html#image-multimodal-embeddings",
    "href": "W6/D2/day_2_embeddings.html#image-multimodal-embeddings",
    "title": "Day 2: Embeddings",
    "section": "Image & Multimodal Embeddings",
    "text": "Image & Multimodal Embeddings\nVisual understanding in vector space\n\nCNN-based: Convolutional neural networks for images\nVision transformers: ViT, CLIP for joint text-image space\nMultimodal: Same space for text, images, videos\n\n\nImages and text projected into a joint embedding matrix (OpenAI’s CLIP model)\nImages can also be embedded into vectors. Early approaches used CNNs - convolutional neural networks - trained on image classification tasks. The final layers of these networks produce image embeddings.\nVision transformers, like ViT, apply the transformer architecture to images by splitting them into patches. These often work better than CNNs for many tasks.\nCLIP is particularly interesting - it learns a joint embedding space for images and text. You can embed both an image and a text description into the same space, and similar images and texts will be close together. This enables powerful applications like image search with text queries.\nMultimodal embeddings extend this to videos, audio, and other data types. The goal is always the same: map different modalities into the same space so you can search and compare across them."
  },
  {
    "objectID": "W6/D2/day_2_embeddings.html#structured-data-embeddings",
    "href": "W6/D2/day_2_embeddings.html#structured-data-embeddings",
    "title": "Day 2: Embeddings",
    "section": "Structured Data Embeddings",
    "text": "Structured Data Embeddings\nTables, graphs, and relational data\n\nGeneral structured data: Feature engineering + ML\nUser-item data: Collaborative filtering embeddings\nGraph embeddings: Node and edge representations\n\n\nStructured data - like tables, databases, and graphs - can also be embedded.\nFor general structured data, you typically do feature engineering to convert rows into feature vectors, then use machine learning models to learn embeddings. This is common in recommendation systems.\nFor user-item data, collaborative filtering learns embeddings for users and items simultaneously. Users with similar preferences get similar embeddings, and items that are liked by similar users get similar embeddings.\nGraph embeddings are particularly interesting. They embed nodes and edges in a graph into vectors, preserving the graph structure. Nodes that are connected or have similar neighborhoods get similar embeddings. This is useful for social networks, knowledge graphs, and other graph-structured data.\nThe key insight is that embeddings aren’t just for text and images - you can embed any structured data into vectors if you design the right approach."
  },
  {
    "objectID": "W6/D2/day_2_embeddings.html#training-approaches",
    "href": "W6/D2/day_2_embeddings.html#training-approaches",
    "title": "Day 2: Embeddings",
    "section": "Training Approaches",
    "text": "Training Approaches\nHow embeddings are learned\n\nSupervised: Task-specific labels guide learning\nSelf-supervised: Learn from data structure itself\nTransfer learning: Pre-trained models fine-tuned\n\n\nNow let’s talk about how embeddings are actually trained. There are several approaches:\nSupervised training uses task-specific labels. For example, you might train embeddings for sentiment analysis by using labeled examples of positive and negative text. The embeddings learn to separate positive and negative examples.\nSelf-supervised training learns from the data structure itself, without explicit labels. Word2Vec is self-supervised - it learns from word co-occurrence patterns. BERT is also self-supervised - it learns by predicting masked words.\nTransfer learning takes a pre-trained model and fine-tunes it for your specific task. This is often the most practical approach - you start with a model trained on massive amounts of data, then fine-tune it for your use case.\nThe choice depends on your data, your task, and your resources. Pre-trained models are often the best starting point because they’ve learned from much more data than you have."
  },
  {
    "objectID": "W6/D2/day_2_embeddings.html#pre-trained-vs.-custom-embeddings",
    "href": "W6/D2/day_2_embeddings.html#pre-trained-vs.-custom-embeddings",
    "title": "Day 2: Embeddings",
    "section": "Pre-trained vs. Custom Embeddings",
    "text": "Pre-trained vs. Custom Embeddings\nWhen to train your own\n\nPre-trained: Use when available, often better\nCustom: Needed for domain-specific tasks\nFine-tuning: Best of both worlds\n\n\nShould you use pre-trained embeddings or train your own?\nPre-trained embeddings are usually the better choice. They’re trained on massive datasets, they’re well-tested, and they often perform better than what you could train yourself. Unless you have a very specific domain or very specific requirements, start with pre-trained.\nCustom embeddings make sense when you have domain-specific data that’s very different from what pre-trained models were trained on. For example, if you’re working with medical text, legal documents, or highly technical content, domain-specific embeddings might help.\nFine-tuning is often the best approach - start with a pre-trained model, then fine-tune it on your domain-specific data. This gives you the benefits of both: the general knowledge from pre-training and the domain specificity from fine-tuning.\nThe key is to evaluate. Don’t assume custom is better - test both and see what works for your use case."
  },
  {
    "objectID": "W6/D2/day_2_vectorstores.html#module-overview",
    "href": "W6/D2/day_2_vectorstores.html#module-overview",
    "title": "Day 2: Vector Stores",
    "section": "Module Overview",
    "text": "Module Overview\nSession: Vector Stores\n\nVector search algorithms\nVector databases and operational considerations\nApplications: RAG and retrieval systems\n\n\nIn the second part of this session, we’re focusing on Vector Stores and how to operationalize embeddings.\nYou’ll learn about vector search algorithms - the techniques that make it possible to find similar vectors in massive datasets quickly.\nYou’ll understand vector databases - the specialized systems that manage embeddings at scale.\nAnd finally, you’ll see how all of this comes together in RAG applications - the most common use case for embeddings today."
  },
  {
    "objectID": "W6/D2/day_2_vectorstores.html#what-youll-learn-today",
    "href": "W6/D2/day_2_vectorstores.html#what-youll-learn-today",
    "title": "Day 2: Vector Stores",
    "section": "What You’ll Learn Today",
    "text": "What You’ll Learn Today\nBy the end of this session, you will:\n\nUnderstand vector search algorithms and trade-offs\nKnow how to choose and deploy vector databases\nBuild RAG applications with embeddings and vector stores\n\n\nContinuing our journey, here’s what you’ll master in this section:\nFourth, you’ll learn about vector search algorithms - the techniques that make it possible to find similar vectors in massive datasets quickly.\nFifth, you’ll understand vector databases - the specialized systems that manage embeddings at scale. You’ll know what to look for when choosing one.\nFinally, you’ll see how all of this comes together in RAG applications - the most common use case for embeddings today."
  },
  {
    "objectID": "W6/D2/day_2_vectorstores.html#the-nearest-neighbor-problem",
    "href": "W6/D2/day_2_vectorstores.html#the-nearest-neighbor-problem",
    "title": "Day 2: Vector Stores",
    "section": "The Nearest Neighbor Problem",
    "text": "The Nearest Neighbor Problem\nFinding similar vectors at scale\n\nExact search: Brute force, too slow for large datasets\nApproximate search: Trade accuracy for speed\nScale: Billions of vectors, milliseconds response time\n\n\nOnce you have embeddings, you need to search through them. This is the nearest neighbor problem: given a query vector, find the most similar vectors in your dataset.\nExact search - computing distances to every vector - is too slow for large datasets. If you have a billion vectors, you’d need to compute a billion distances for every query. That’s not practical.\nApproximate search algorithms trade a small amount of accuracy for massive speed improvements. Instead of finding the exact nearest neighbors, they find approximate nearest neighbors - vectors that are very close, if not the closest.\nThe scale requirements are extreme: billions of vectors, milliseconds response time. This is what makes vector search algorithms so important - they’re what make semantic search possible at scale."
  },
  {
    "objectID": "W6/D2/day_2_vectorstores.html#important-vector-search-algorithms",
    "href": "W6/D2/day_2_vectorstores.html#important-vector-search-algorithms",
    "title": "Day 2: Vector Stores",
    "section": "Important Vector Search Algorithms",
    "text": "Important Vector Search Algorithms\nSpeed vs. accuracy trade-offs\n\nLSH: Locality Sensitive Hashing\nHNSW: Hierarchical Navigable Small Worlds\nScaNN: Google’s optimized ANN algorithm\n\n\nThere are several important vector search algorithms, each with different trade-offs:\nLSH - Locality Sensitive Hashing - uses hash functions that map similar vectors to the same buckets. It’s fast but can have lower recall.\nHNSW - Hierarchical Navigable Small Worlds - builds a graph structure where you navigate from node to node to find nearest neighbors. It’s very fast and has good accuracy, which is why it’s widely used.\nScaNN - Scalable Nearest Neighbors - is Google’s optimized algorithm. It uses advanced quantization and pruning techniques to achieve very high speed while maintaining accuracy.\nThe choice depends on your requirements: how much accuracy can you sacrifice for speed? How much memory can you use? How often does your dataset change?\nMost vector databases support multiple algorithms and let you choose based on your needs."
  },
  {
    "objectID": "W6/D2/day_2_vectorstores.html#popular-vector-databases",
    "href": "W6/D2/day_2_vectorstores.html#popular-vector-databases",
    "title": "Day 2: Vector Stores",
    "section": "Popular Vector Databases",
    "text": "Popular Vector Databases\nOptions for different needs\n\nPinecone: Fully managed, easy to use\nWeaviate: Open source, self-hosted\nChromaDB: Lightweight, Python-first\npgvector: PostgreSQL extension\nVertex AI: Google Cloud’s managed service\n\n\nThere are many vector databases to choose from, each with different strengths:\nPinecone is fully managed and very easy to use. It’s a good choice if you want to get started quickly and don’t want to manage infrastructure. But it’s a commercial service, so there’s a cost.\nWeaviate is open source and can be self-hosted. It’s more flexible and you have more control, but you need to manage the infrastructure yourself.\nChromaDB is lightweight and Python-first. It’s good for development and smaller applications. It’s easy to integrate into Python applications.\npgvector is a PostgreSQL extension, so you can add vector search to an existing PostgreSQL database. This is great if you’re already using PostgreSQL and want to add vector capabilities.\nVertex AI Vector Search is Google Cloud’s managed service. It uses ScaNN and is optimized for very large scale.\nThe choice depends on your needs: scale, budget, infrastructure preferences, and feature requirements."
  },
  {
    "objectID": "W6/D2/day_2_vectorstores.html#operational-considerations",
    "href": "W6/D2/day_2_vectorstores.html#operational-considerations",
    "title": "Day 2: Vector Stores",
    "section": "Operational Considerations",
    "text": "Operational Considerations\nProduction deployment factors\n\nScalability: Handle growing datasets\nLatency: Response time requirements\nConsistency: Update and synchronization\nCost: Storage and compute costs\n\n\nWhen choosing and deploying a vector database, there are several operational considerations:\nScalability: Can it handle your dataset size? Can it scale as your data grows? Some databases are better at horizontal scaling than others.\nLatency: What are your response time requirements? Vector search can be fast, but you need to make sure it meets your SLA. This depends on the algorithm, the dataset size, and the infrastructure.\nConsistency: How do updates work? If you add new vectors, are they immediately searchable? How do you handle updates and deletions? Some databases have eventual consistency, which might be fine for your use case or might not.\nCost: What are the storage and compute costs? Managed services are convenient but can be expensive. Self-hosted gives you more control but you need to manage the infrastructure.\nYou also need to think about monitoring, backup, disaster recovery, and all the other operational concerns of any production system."
  },
  {
    "objectID": "W6/D2/day_2_vectorstores.html#retrieval-augmented-generation-rag",
    "href": "W6/D2/day_2_vectorstores.html#retrieval-augmented-generation-rag",
    "title": "Day 2: Vector Stores",
    "section": "Retrieval Augmented Generation (RAG)",
    "text": "Retrieval Augmented Generation (RAG)\nCombining retrieval with generation\n\nProblem: LLMs have limited, static knowledge\nSolution: Retrieve relevant context, then generate\nResult: Up-to-date, source-attributed responses\n\nIn Detail:\n\nIndexing: Embed documents, store in vector database\nQuery: Embed user query\nRetrieval: Find similar documents\nGeneration: LLM generates response from context\n\n\nNow let’s talk about the most important application: RAG - Retrieval Augmented Generation.\nThe problem is that LLMs have limited, static knowledge. They only know what they were trained on, and that knowledge is frozen at training time. They can’t access new information, and they can’t cite sources.\nRAG solves this by combining retrieval with generation. First, you retrieve relevant documents from a knowledge base using vector search. Then, you pass those documents as context to the LLM, which generates a response based on the retrieved context.\nThe result is a system that can answer questions about up-to-date information, can cite sources, and can access information that wasn’t in the training data.\nThis is why embeddings and vector stores are so important today - they’re the foundation of RAG systems."
  },
  {
    "objectID": "W6/D2/day_2_vectorstores.html#rag-architecture",
    "href": "W6/D2/day_2_vectorstores.html#rag-architecture",
    "title": "Day 2: Vector Stores",
    "section": "RAG Architecture",
    "text": "RAG Architecture\n\nDetailed RAG architecture showing indexing, querying, retrieval, and generation steps\nLet’s break down the RAG architecture:\nFirst, indexing: you take your documents, embed them using an embedding model, and store them in a vector database along with metadata.\nSecond, querying: when a user asks a question, you embed the query using the same embedding model.\nThird, retrieval: you search the vector database for documents similar to the query embedding. You might retrieve the top K documents, or all documents above a similarity threshold.\nFourth, generation: you pass the retrieved documents as context to an LLM, along with the user’s query. The LLM generates a response that’s grounded in the retrieved context.\nThis pipeline is what makes RAG work. Each step is important: good embeddings lead to good retrieval, which leads to good generation.\nYou can also add steps like re-ranking (using a more expensive model to re-rank the retrieved documents) or filtering (using metadata to filter before or after vector search)."
  },
  {
    "objectID": "W6/D2/day_2_vectorstores.html#other-applications",
    "href": "W6/D2/day_2_vectorstores.html#other-applications",
    "title": "Day 2: Vector Stores",
    "section": "Other Applications",
    "text": "Other Applications\n\nBeyond RAG: Retrieval, Semantic text similarity, Classification, Clustering, Reranking\nRAG is the most talked-about application, but embeddings and vector stores are used in many other ways:\nSemantic search: Instead of keyword matching, find documents based on meaning. This is what powers modern search engines.\nRecommendation systems: Find items similar to what a user likes, or users similar to a given user. This is how Netflix, Amazon, and Spotify make recommendations.\nDeduplication: Find duplicate or near-duplicate content. This is useful for content moderation, data cleaning, and copyright detection.\nClustering: Group similar items together. This is useful for organizing content, discovering topics, and understanding data structure.\nThe common thread is that all of these applications benefit from being able to find similar items quickly. That’s what embeddings and vector stores enable."
  },
  {
    "objectID": "W6/D2/day_2_vectorstores.html#key-takeaways",
    "href": "W6/D2/day_2_vectorstores.html#key-takeaways",
    "title": "Day 2: Vector Stores",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nDifferent types of embeddings for different data types\nEvaluation is crucial for ensuring quality\nVector search algorithms trade accuracy for speed\nVector databases are essential for production systems\nRAG combines retrieval with generation\n\n\nLet’s summarize what we’ve covered today.\nThere are different types of embeddings for different data types: text, images, structured data, graphs. Each has its own techniques and use cases.\nEvaluation is crucial. You can’t assume embeddings are good - you need to evaluate them for your specific use case.\nVector search algorithms like LSH, HNSW, and ScaNN trade a small amount of accuracy for massive speed improvements, making semantic search possible at scale.\nVector databases are specialized systems that provide efficient storage, fast search, and database operations. They’re essential for production applications.\nRAG combines retrieval with generation, using embeddings and vector stores to give LLMs access to up-to-date, source-attributed information.\nThese concepts work together to enable modern AI applications. Understanding embeddings and vector stores is essential for building production-ready retrieval systems.\nThank you, and good luck building with embeddings and vector stores!"
  },
  {
    "objectID": "W6/D3/day_3_adk_intro.html#what-is-adk",
    "href": "W6/D3/day_3_adk_intro.html#what-is-adk",
    "title": "Introduction to ADK",
    "section": "What is ADK?",
    "text": "What is ADK?\n\n\n\nADK\n\n\n\nAgent Development Kit (ADK) is a flexible and modular framework for developing and deploying AI agents. While optimized for Gemini and the Google ecosystem, ADK is:\n\nmodel-agnostic, deployment-agnostic, and\nis built for compatibility with other frameworks"
  },
  {
    "objectID": "W6/D3/day_3_adk_intro.html#where-does-adk-fit-in-the-genai-project",
    "href": "W6/D3/day_3_adk_intro.html#where-does-adk-fit-in-the-genai-project",
    "title": "Introduction to ADK",
    "section": "Where does ADK fit in the GenAI Project?",
    "text": "Where does ADK fit in the GenAI Project?\n\n\n\nADK fits in the “Application Integration” phase of the GenAI Project Lifecycle.\n\n\n\nADK was designed to make agent development feel more like software development, to make it easier for developers to create, deploy, and orchestrate agentic architectures that range from simple tasks to complex workflows.\n\n\n\nBefore diving into tools, we must understand the lifecycle.\nADK is primarily for the “Application Integration” phase, but helps with “Evaluate” and “Select” too."
  },
  {
    "objectID": "W6/D3/day_3_adk_intro.html#features",
    "href": "W6/D3/day_3_adk_intro.html#features",
    "title": "Introduction to ADK",
    "section": "Features",
    "text": "Features\n\nFlexible Orchestration\nMulti-Agent Architecture\nRich Tool Ecosystem\nDeployment Ready\nBuilt-in Evaluation\nBuilding Safe and Secure Agents\n\n\n\nFlexible Orchestration:\nDefine workflows using workflow agents (Sequential, Parallel, Loop) for predictable execution pipelines, or leverage LLM-driven dynamic routing (LlmAgent transfer) for more adaptive behavior.\nMulti-Agent Architecture:\nCompose multiple specialized agents in a hierarchy to build modular, scalable applications. This enables complex coordination, delegation, and specialization of responsibilities.\nRich Tool Ecosystem:\nAgents can access a broad set of capabilities: use pre-built tools (Search, Code Exec), create custom Python functions, integrate with 3rd-party libraries, or even designate other agents as tools.\nDeployment Ready:\nContainerize and deploy agents anywhere: run locally, scale to production with Vertex AI Agent Engine, or integrate into existing infrastructure with Cloud Run or Docker.\nBuilt-in Evaluation:\nADK enables systematic evaluation of agents—not just the final answer, but the full execution trace—against predefined test cases, ensuring both quality and reliability.\nBuilding Safe and Secure Agents:\nAdopt battle-tested patterns and security/safety best practices to build trustworthy agents, with controls for privacy, cost, and safe tool usage."
  },
  {
    "objectID": "W6/D3/day_3_adk_intro.html#framework-comparison",
    "href": "W6/D3/day_3_adk_intro.html#framework-comparison",
    "title": "Introduction to ADK",
    "section": "Framework Comparison",
    "text": "Framework Comparison\n\n\n\n\n\n\n\n\nFeature\nADK\nLangChain\n\n\n\n\nPhilosophy\nEngineering-first\nPrototyping-first\n\n\nModularity\nHigh\nMixed\n\n\nEcosystem\nIntegrated (Google/Vertex)\nBroad (Community-driven)\n\n\nStability\nEnterprise-focused APIs\nFast-moving, breaking changes\n\n\n\n\n\nLangChain is great for quick experiments and vast integrations.\nADK is better for building production-grade, maintainable systems, especially in the Google ecosystem."
  },
  {
    "objectID": "W6/D3/day_3_adk_intro.html#no-code-agent-design",
    "href": "W6/D3/day_3_adk_intro.html#no-code-agent-design",
    "title": "Introduction to ADK",
    "section": "No-Code Agent Design",
    "text": "No-Code Agent Design\n\n\n\nVisual Builder\n\n\n\nDrag-and-Drop: Design workflows visually.\nAI Assistant: Start building with natural language.\nExportable: Generates Python/Java code for your project.\n\n\n\nNew experimental feature.\nLowers barrier to entry. Great for prototyping."
  },
  {
    "objectID": "W6/D3/day_3_adk_intro.html#get-started",
    "href": "W6/D3/day_3_adk_intro.html#get-started",
    "title": "Introduction to ADK",
    "section": "Get started",
    "text": "Get started\nSee Python Quick Start for ADK\n\nInstall dependencies.\nSet up API keys.\nRun your first agent.\n\n\n\nLet’s get our hands on the keyboard.\nFollow the guide.\nEnsure everyone has a working environment."
  },
  {
    "objectID": "W6/D3/day_3_adk_intro.html#coding-with-ai",
    "href": "W6/D3/day_3_adk_intro.html#coding-with-ai",
    "title": "Introduction to ADK",
    "section": "Coding with AI",
    "text": "Coding with AI\n\nLLM-Optimized Docs: Supports /llms.txt.\nIntegration:\n\nCursor: Add docs directly to context.\nGemini CLI: Query docs from terminal.\n\nBenefit: AI assistants understand ADK perfectly.\n\n\n\nADK is built for AI, with AI.\nUsing llms.txt makes your coding partner smarter."
  },
  {
    "objectID": "W6/D3/day_3_adk_intro.html#core-concepts",
    "href": "W6/D3/day_3_adk_intro.html#core-concepts",
    "title": "Introduction to ADK",
    "section": "Core Concepts",
    "text": "Core Concepts\n\n\n\nADK Components\n\n\n\nCore Reasoning & Identity\nContext & History\nCapabilities & Actions\nCoordination & Control\n\n\nSee: https://google.github.io/adk-docs/get-started/about/"
  },
  {
    "objectID": "W6/D3/day_3_adk_intro.html#core-reasoning-identity",
    "href": "W6/D3/day_3_adk_intro.html#core-reasoning-identity",
    "title": "Introduction to ADK",
    "section": "1. Core Reasoning & Identity",
    "text": "1. Core Reasoning & Identity\n\nAgents (The Specialist): The fundamental unit. An agent is a persona designed for a specific job (e.g., a “Travel Agent” or “Coding Assistant”).\nModels (The Intelligence): The underlying LLM (like Gemini). This is the “IQ” of the agent that allows it to understand language and reason through problems.\n\n\nAnalogy: If the Agent is a doctor, the Model is the medical degree and years of study in their head."
  },
  {
    "objectID": "W6/D3/day_3_adk_intro.html#context-history",
    "href": "W6/D3/day_3_adk_intro.html#context-history",
    "title": "Introduction to ADK",
    "section": "2. Context & History",
    "text": "2. Context & History\n\nEvents (The Transcript): A chronological record of everything that happened—what the user said, what the agent thought, and what the tools returned.\nSessions (The Appointment): A specific instance of interaction. It groups events together so the agent knows who it is talking to right now.\n\n\nRelating Topics: Sessions are the “folders” that contain the Events.\n\n\nMemory (The Patient File): Unlike a session (which might end), Memory persists. It allows the agent to remember your name or preferences across different sessions weeks apart."
  },
  {
    "objectID": "W6/D3/day_3_adk_intro.html#capabilities-actions",
    "href": "W6/D3/day_3_adk_intro.html#capabilities-actions",
    "title": "Introduction to ADK",
    "section": "3. Capabilities & Actions",
    "text": "3. Capabilities & Actions\n\nTools (The Toolbox): External functions the agent can call, like a calculator, a Google Search API, or a database query.\nCode Execution (The Sandbox): A specific tool that allows the agent to write and run code (Python) to solve math or data problems that are too hard for “talk” alone.\nArtifacts (The Briefcase): These handle files. If the agent generates a PDF or needs to read a CSV, that file is an Artifact.\n\n\nConnecting the Dots: If an agent needs to analyze a budget, it uses Tools to read the Artifact (file), and uses Code Execution to calculate the totals."
  },
  {
    "objectID": "W6/D3/day_3_adk_intro.html#coordination-control",
    "href": "W6/D3/day_3_adk_intro.html#coordination-control",
    "title": "Introduction to ADK",
    "section": "4. Coordination & Control",
    "text": "4. Coordination & Control\n\nPlanning (The Blueprint): For complex asks, the agent doesn’t just “guess.” It creates a step-by-step plan before acting.\nRunner (The Orchestrator): This is the engine that actually executes the plan, feeding information between the Model, Tools, and Memory.\nCallbacks (The Status Reports): Hooks that trigger at specific moments (e.g., “Agent started thinking” or “Tool failed”).\n\n\nExample: If a tool fails, a Callback catches the error so the Runner can ask the Model for a new Plan."
  },
  {
    "objectID": "W6/D3/day_3_adk_intro.html#key-takeaways",
    "href": "W6/D3/day_3_adk_intro.html#key-takeaways",
    "title": "Introduction to ADK",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nAgents are the building blocks of ADK.\nModels power reasoning.\nEvents form the conversation history.\nTools extend their capabilities.\nSessions manage context.\nMemory keeps long-term information.\nPlanning breaks down complex goals.\nRunner coordinates the execution flow.\nCallbacks help with logging and error handling.\nArtifacts handle files.\nCode Execution allows agents to generate and execute code.\n\nSee: Core Concepts & Key Capabilities"
  },
  {
    "objectID": "W6/D4/day_4_agent_tools_best_practices.html#the-isolated-genius",
    "href": "W6/D4/day_4_agent_tools_best_practices.html#the-isolated-genius",
    "title": "Day 4: Agent Tools & Best Practices",
    "section": "The Isolated Genius",
    "text": "The Isolated Genius\n\nImagine the world’s smartest physicist.\nLocked in a soundproof room.\nWith no hands.\nAnd no memory of anything that happened 5 minutes ago.\n\n\n\nThis is your LLM.\nIt can solve differential equations, but it can’t check the weather.\nIt can write code, but it can’t run it.\nTo build Agents, we need to solve two problems:\n\nIsolation (No hands/senses).\nAmnesia (No memory/continuity)."
  },
  {
    "objectID": "W6/D4/day_4_agent_tools_best_practices.html#the-goal",
    "href": "W6/D4/day_4_agent_tools_best_practices.html#the-goal",
    "title": "Day 4: Agent Tools & Best Practices",
    "section": "The Goal",
    "text": "The Goal\n\n\n\nAI App Integration"
  },
  {
    "objectID": "W6/D4/day_4_agent_tools_best_practices.html#the-two-missing-links",
    "href": "W6/D4/day_4_agent_tools_best_practices.html#the-two-missing-links",
    "title": "Day 4: Agent Tools & Best Practices",
    "section": "The Two Missing Links",
    "text": "The Two Missing Links\n\n\n\nA brain in a jar\n\n\n\nSpatial Connection: Touching the world (Files, APIs, Databases).\nTemporal Connection: Existing across time (Waiting, Remembering).\n\n\n\nToday we cover the standardized solutions to these two problems.\nMCP solves the Spatial problem.\nLong-Running Operations solve the Temporal problem."
  },
  {
    "objectID": "W6/D4/day_4_agent_tools_best_practices.html#the-integration-tax",
    "href": "W6/D4/day_4_agent_tools_best_practices.html#the-integration-tax",
    "title": "Day 4: Agent Tools & Best Practices",
    "section": "The “Integration Tax”",
    "text": "The “Integration Tax”\n\n\n\nThe \\(M \\times N\\) problem.\n\n\n\nDifferent servers specify different interfaces.\nClients have to implement their own tools for every interface."
  },
  {
    "objectID": "W6/D4/day_4_agent_tools_best_practices.html#enter-mcp-the-usb-c-for-ai",
    "href": "W6/D4/day_4_agent_tools_best_practices.html#enter-mcp-the-usb-c-for-ai",
    "title": "Day 4: Agent Tools & Best Practices",
    "section": "Enter MCP: The “USB-C” for AI",
    "text": "Enter MCP: The “USB-C” for AI\n\n\n\nThe MCP solution to the \\(M \\times N\\) problem.\n\n\n\nMCP servers define their interfaces once in a standardized way for tool-aware LLMs to use.\nMCP clients can then use these servers as tools without having to implement the interface themselves.\n\n\n\nThink of MCP like USB-C.\nYou don’t need a different keyboard for a Dell vs. a Mac.\nSimilarly, with MCP, you write a “GitHub Tool” once, and it works with Claude, Gemini, and Local Llama."
  },
  {
    "objectID": "W6/D4/day_4_agent_tools_best_practices.html#how-it-works-the-invisible-wire",
    "href": "W6/D4/day_4_agent_tools_best_practices.html#how-it-works-the-invisible-wire",
    "title": "Day 4: Agent Tools & Best Practices",
    "section": "How it Works: The Invisible Wire",
    "text": "How it Works: The Invisible Wire\n\n\n\nThe Invisible Wire\n\n\n\nHost: The App (e.g., Cursor, Python Script).\nClient: The “Driver” that speaks MCP.\nServer: The “App” that has the data (e.g., GitHub, Postgres).\n\n\n\nYou don’t see the Client. It’s the invisible wire.\nYou just pick a Server (like installing a printer driver) and suddenly your Agent has new capabilities."
  },
  {
    "objectID": "W6/D4/day_4_agent_tools_best_practices.html#restaurant-analogy",
    "href": "W6/D4/day_4_agent_tools_best_practices.html#restaurant-analogy",
    "title": "Day 4: Agent Tools & Best Practices",
    "section": "Restaurant Analogy",
    "text": "Restaurant Analogy\n\n\n\nThe Restaurant Analogy\n\n\n\nHere is how the restaurant analogy in the image explains these concepts:\n\nHost (The Maitre d’): This represents the main application or environment (such as Claude Desktop or an IDE) where the user interacts with the AI. It oversees the entire process and manages which “waiters” are available.\nClient (The Waiters): This is the specific connector within the Host application that maintains a persistent 1:1 connection with a server. Like a waiter, it carries the user’s request to the kitchen and brings the results back.\nMCP Server (The Chef Bot Station): A small program that exposes specific data or capabilities. It acts as the “chef” that has the actual access to the ingredients (data) and tools needed to fulfill a request.\n\nThe Capabilities\nThe right side of the image illustrates the three primary types of content a server provides:\n\nResources (The Ingredients): These are data sources that the LLM can “read” but not execute. In a technical sense, these are files, database records, or API responses.\nTools (The Utensils): These are functions that the model can “call” to perform actions. Just as a chef uses a whisk to change the state of ingredients, a tool allows the model to write code, search the web, or trigger external API actions.\nPrompts (The Cookbooks): These are pre-defined templates or instructions that help the LLM perform specific tasks consistently, similar to how a recipe ensures a dish is prepared the same way every time."
  },
  {
    "objectID": "W6/D4/day_4_agent_tools_best_practices.html#the-goldfish-memory-problem",
    "href": "W6/D4/day_4_agent_tools_best_practices.html#the-goldfish-memory-problem",
    "title": "Day 4: Agent Tools & Best Practices",
    "section": "The “Goldfish Memory” Problem",
    "text": "The “Goldfish Memory” Problem\n\n\n\nThe “Goldfish Memory” Problem\n\n\n\n\nThis is the “Statefulness Gap”.\nReal business processes take time.\nA manager might take 3 hours to approve an expense.\nIf your Python script crashes or the connection drops, the context is lost."
  },
  {
    "objectID": "W6/D4/day_4_agent_tools_best_practices.html#long-running-operations-lro",
    "href": "W6/D4/day_4_agent_tools_best_practices.html#long-running-operations-lro",
    "title": "Day 4: Agent Tools & Best Practices",
    "section": "Long-Running Operations (LRO)",
    "text": "Long-Running Operations (LRO)\n\n\n\nLRO Pattern\n\n\n\nInvoke: Start the task.\nPause: Wait for external input (Human-in-the-Loop).\nResume: Continue exactly where you left off.\n\n\n\nWe need an architecture that supports “Freezing” the agent.\nThink of a waiter taking an order to the kitchen.\nThey don’t stand there for 20 minutes. They go do other things.\nWhen the bell rings (Event), they pick up the plate (Resume)."
  },
  {
    "objectID": "W6/D4/day_4_agent_tools_best_practices.html#the-solution-resumability",
    "href": "W6/D4/day_4_agent_tools_best_practices.html#the-solution-resumability",
    "title": "Day 4: Agent Tools & Best Practices",
    "section": "The Solution: Resumability",
    "text": "The Solution: Resumability\n\nThe App Wrapper: A container that saves state to a database.\nThe Invocation ID: The unique “Ticket Number” for that specific task.\n\n\n\nIn the lab, we saw check_for_approval().\nIt looks for a special event: adk_request_confirmation.\nWhen it sees it, it saves the Invocation ID.\nTo resume, we don’t start over. We call run_async(invocation_id=...).\nThe Agent wakes up: “Ah, yes, the deployment. Proceeding.”"
  },
  {
    "objectID": "W6/D4/day_4_agent_tools_best_practices.html#visualizing-the-loop",
    "href": "W6/D4/day_4_agent_tools_best_practices.html#visualizing-the-loop",
    "title": "Day 4: Agent Tools & Best Practices",
    "section": "Visualizing the Loop",
    "text": "Visualizing the Loop\n\n\n\nA circular workflow diagram. Arrow 1: Agent pauses. Arrow 2: State saved to DB. Arrow 3: Human clicks Approve. Arrow 4: Agent wakes up and finishes task.\n\n\n\nThe Agent doesn’t “wait” in active memory.\nIt “persists” to disk.\nThis creates Safe, Asynchronous Autonomy.\n\n\n\nThis allows agents to run for days or weeks.\nIt enables Human-in-the-Loop for high-stakes decisions (money, production data)."
  },
  {
    "objectID": "W6/D4/day_4_agent_tools_best_practices.html#the-complete-agent",
    "href": "W6/D4/day_4_agent_tools_best_practices.html#the-complete-agent",
    "title": "Day 4: Agent Tools & Best Practices",
    "section": "The Complete Agent",
    "text": "The Complete Agent\n\nLLM: Think & Use Tools\nSpatial Connection:\n\nMCP Host: The application that the agent is running in.\nMCP Client: The agent that is using the MCP tools.\nMCP Server: The server that is providing the MCP tools.\n\nTemporal Connection:\n\nHIL (Human-in-the-Loop): Pause & Resume\nLRO (Long-Running Operations): Continue where it left off.\n\n\n\n\nWithout these, you just have a chatbot.\nWith them, you have an Agent that can work in the world and across time."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-finite-canvas-why-we-cant-just-send-it-all",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-finite-canvas-why-we-cant-just-send-it-all",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "The Finite Canvas: Why We Can’t Just “Send It All”",
    "text": "The Finite Canvas: Why We Can’t Just “Send It All”\n\n\n\nThe Myth\n“Models have 1M+ context windows now. Why bother with RAG? Just dump the whole folder into the prompt.”\n\n\nThe Reality\nLarge \\(\\neq\\) Efficient. The context window is your system’s most expensive and volatile resource.\n\n\n\n\n\nAcknowledge the shift from 4k to 128k+ windows.\nIntroduce the “Architect’s Perspective”: Capacity is not the same as capability.\nSet the stage for why “brute force” context fails in production."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-architects-blueprint-ram-vs.-hard-drive",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-architects-blueprint-ram-vs.-hard-drive",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "The Architect’s Blueprint: RAM vs. Hard Drive",
    "text": "The Architect’s Blueprint: RAM vs. Hard Drive\n\n\n\n\n\ngraph LR\n    subgraph Storage [\"Cold Storage (The Library)\"]\n    DB[(Vector Database)]\n    end\n\n    subgraph Processing [\"Active Workspace (The Desk)\"]\n    CW[Context Window]\n    end\n\n    DB -- \"Selective Retrieval\" --&gt; CW\n    CW -- \"Attention Mechanism\" --&gt; LLM((LLM Reasoning))\n\n    style DB fill:#f9f,stroke:#333,stroke-width:2px\n    style CW fill:#00ffcc,stroke:#333,stroke-width:4px\n\n\n\n\n\n\n\nVector Database: Massive, cheap, persistent. The “Hard Drive.”\nContext Window: Fast, high-bandwidth, strictly limited. The “RAM.”\n\n\n\nUse the computing analogy to explain data “living” vs. data “acting.”\nExplain that the LLM cannot “see” the database; it only sees what is loaded into the window.\nEmphasize that loading 10TB of data into 128GB of RAM causes system degradation."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-working-memory-constraint",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-working-memory-constraint",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "The “Working Memory” Constraint",
    "text": "The “Working Memory” Constraint\n\nThe Brilliant Intern Analogy:\n\nGive them one clean sheet of facts \\(\\rightarrow\\) High Precision.\nPile 500 unorganized folders on their desk \\(\\rightarrow\\) Massive Confusion.\n\n\n\nThe Reasoning Buffer\nThe window must balance three competing forces:\n\nThe Goal: User Query\nThe Constraints: System Prompt / Persona\nThe Evidence: Retrieved Snippets\n\n\n\nExplain that the Context Window is a “Reasoning Buffer,” not just a storage bin.\nEvery extra token of “Evidence” creates noise that competes with the “Goal” and “Constraints.”\nIf evidence is too large, the model “forgets” the original instructions."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-architects-logic-selection-over-volume",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-architects-logic-selection-over-volume",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "The Architect’s Logic: Selection over Volume",
    "text": "The Architect’s Logic: Selection over Volume\n\n“Your value as an architect lies in Selection Logic, not API credits.”\n\n\n\n\nBig Data Mindset\n\n“More is better.”\nFill the 128k window.\nHigh Noise, Low Signal.\n\n\n\nRight Data Mindset\n\n“Less is more.”\nFind the best 2k tokens.\nUndeniable Accuracy.\n\n\n\n\n\n\nContrast the “Junior” vs. “Senior” approach.\nEmphasize that the goal is to make the answer “undeniable” for the model by providing only the most relevant facts."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#analogy-the-library-vs.-the-index-card",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#analogy-the-library-vs.-the-index-card",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "Analogy: The Library vs. The Index Card",
    "text": "Analogy: The Library vs. The Index Card\n\nImage: A researcher overwhelmed by a mountain of books on a desk vs. a researcher holding a single, highlighted index card.\nThe Dump Truck Approach: Sending every book in the “Aerospace” section.\nThe Architect’s Approach: Finding the exact paragraph and delivering an Index Card.\n\n\nOur Goal: Build the system that creates the Index Card.\n\n\nUse the Lunar Rover torque setting example from the text.\nExplain that “Send It All” forces the LLM to do the retrieval work inside its reasoning engine, which is inefficient.\nRAG is the “Index Card” generator."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#key-takeaway-the-optimal-reasoning-zone",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#key-takeaway-the-optimal-reasoning-zone",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "Key Takeaway: The Optimal Reasoning Zone",
    "text": "Key Takeaway: The Optimal Reasoning Zone\n\nStructural Limitation: Context window size is a physical and logical boundary.\nQuality &gt; Quantity: High-quality data prevents “Reasoning Decay.”\nArchitect’s Duty: Curate the “Finite Canvas” to ensure reliability.\n\nNext Up: Signal-to-Noise: The Enemy of Reasoning\n\n\nSummarize the section.\nTransition to the next topic: what happens when we ignore these rules (The “Lost in the Middle” phenomenon)."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#signal-to-noise-the-enemy-of-reasoning",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#signal-to-noise-the-enemy-of-reasoning",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "Signal-to-Noise: The Enemy of Reasoning",
    "text": "Signal-to-Noise: The Enemy of Reasoning\n\nThe Fallacy: “More data = Smarter answers.”\nThe Reality: The LLM is a Probabilistic Engine, every token of “Noise” increase the probability of noise output.\nThe Metric: Signal-to-Noise Ratio (SNR)\n\nSignal: The specific “nugget” of truth required.\nNoise: Irrelevant data, headers, footers, and Distractors.\n\n\n\n\nArchitect’s Rule: As Noise increases, Attention is diluted.\n\n\n\nStart by debunking the myth that feeding every document into a prompt helps.\nIntroduce SNR as a core architectural metric.\nExplain that the Transformer’s attention mechanism is a zero-sum game; more weight on noise means less on signal."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#defining-the-players-signal-vs.-noise",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#defining-the-players-signal-vs.-noise",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "Defining the Players: Signal vs. Noise",
    "text": "Defining the Players: Signal vs. Noise\n\n\n\nThe Signal 🎯\n\nTargeted: Answers the specific user query.\nExample: “Electronics have a 14-day return window.”\nGoal: Maximize presence in the prompt.\n\n\n\nThe Noise 🔊\n\nDistraction: Surrounding filler and meta-data.\nExample: Legal disclaimers about furniture in an electronics query.\nGoal: Minimize or filter out.\n\n\n\n\n\n\nUse the refund policy example to make it concrete.\nEmphasize that even “good” data is noise if it doesn’t answer the specific question asked."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-lost-in-the-middle-phenomenon",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-lost-in-the-middle-phenomenon",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "The “Lost in the Middle” Phenomenon",
    "text": "The “Lost in the Middle” Phenomenon\n\nResearch Insight: LLMs do not treat the context window equally.\nPrimacy Bias: High recall for information at the Start.\nRecency Bias: High recall for information at the End.\nThe Danger Zone: Information buried in the middle is often ignored or causes hallucinations.\n\n\n\n\n\n\ngraph LR\n    A[Start of Prompt] --&gt; B{High Recall}\n    B --&gt; C[Middle of Context]\n    C --&gt; D{Information Loss}\n    D --&gt; E[End of Prompt]\n    E --&gt; F{High Recall}\n    \n    style C fill:#f96,stroke:#333,stroke-width:2px\n    style D fill:#f96,stroke:#333,stroke-width:4px\n\n\n\n\n\n\n\n\nCite Liu et al. (2023) as the foundational study for this.\nUse the analogy of a human reading a 50-page brief in 30 seconds—you remember the intro and the conclusion."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#visualizing-performance-degradation",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#visualizing-performance-degradation",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "Visualizing Performance Degradation",
    "text": "Visualizing Performance Degradation\n\n\n\nThe Accuracy Curve\n\n1-3 Chunks: Accuracy climbs as signal is found.\nThe Peak: The “Goldilocks Zone.”\n10+ Chunks: Performance plummets.\n\n\n\n\n\n\nContext Degradation\n\n\n\n\n\n\n\nExplain that adding more context doesn’t just cost money (tokens); it actively degrades the quality of the answer.\nThis justifies why we limit ‘k’ in retrieval."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-architects-defense-strategic-chunking",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-architects-defense-strategic-chunking",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "The Architect’s Defense: Strategic Chunking",
    "text": "The Architect’s Defense: Strategic Chunking\n\nAtomic Chunking: Slicing data into small, semantically dense units (200-500 words).\nPrecision over Volume: We want the best results, not the most results.\nData Layout: Structure your data to respect the LLM’s attention limits.\n\n\n\nArchitect’s Goal: Ensure the “Signal” is never fighting for its life in a sea of irrelevant tokens.\n\n\n\nTransition to the solution: Chunking is a noise filter.\nExplain that “re-ranking” is a secondary fix; the primary fix is good data architecture at the chunking stage."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-goldilocks-zone-semantic-integrity-vs.-specificity",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-goldilocks-zone-semantic-integrity-vs.-specificity",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "The Goldilocks Zone: Semantic Integrity vs. Specificity",
    "text": "The Goldilocks Zone: Semantic Integrity vs. Specificity\nThe Architect’s Dilemma\n\nVector DBs store “Units of Thought”\nHow do we slice the data?\nBalance is the goal\n\n\n\nIntroduce the concept of chunking as the foundational step in RAG.\nExplain that the “quality” of retrieval is pre-determined by how we slice the data before it even hits the database."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-risk-of-micro-chunks",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-risk-of-micro-chunks",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "The Risk of “Micro-Chunks”",
    "text": "The Risk of “Micro-Chunks”\nLoss of Semantic Integrity\n\nSize: ~50–100 tokens\nThe “Detective Novel” Problem: “He picked up the key.”\nDangling References: Pronouns (it, he, this) lose their subjects\nRetrieval Failure: Embedding models match keywords, not intent\n\n\n\nArchitect’s Rule: Never let a chunk be smaller than the smallest complete thought required to understand the subject.\n\n\n\nUse the detective novel analogy: without context, “the key” could be a physical object or a metaphorical witness.\nExplain that LLMs waste “reasoning tokens” trying to stitch these fragments back together."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-risk-of-macro-chunks",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-risk-of-macro-chunks",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "The Risk of “Macro-Chunks”",
    "text": "The Risk of “Macro-Chunks”\nSignal-to-Noise Dilution\n\nSize: 1,000+ tokens\nVector Averaging: The “Blurry Point” in latent space\nLost in the Middle: LLMs ignore facts buried in long contexts\nSpecificity vs. Context: Large chunks are “close to everything, perfect for nothing”\n\n\n\n\nHigh Specificity\n\nPrecise\nHigh Signal\nLow Context\n\n\n\nHigh Context\n\nBroad\nHigh Noise\nLow Precision\n\n\n\n\n\n\nExplain Vector Averaging: An embedding of a whole chapter represents the “average” topic, losing the specific nuances of individual paragraphs.\nMention “Lost in the Middle” syndrome—a known LLM behavior where performance drops for information in the center of a prompt."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#mental-model-the-performance-curve",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#mental-model-the-performance-curve",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "Mental Model: The Performance Curve",
    "text": "Mental Model: The Performance Curve\n\n\n\n\n\ngraph LR\n    A[Small Chunks] --&gt;|Low Integrity| B(Goldilocks Zone)\n    C[Large Chunks] --&gt;|High Noise| B\n    B --&gt; D{Peak Performance}\n    \n    style B fill:#f9f,stroke:#333,stroke-width:4px\n\n\n\n\n\n\n\nUnder-chunking: High noise, LLM hallucination\nOver-chunking: Missing context, retrieval failure\nSweet Spot: Usually 512 – 800 tokens for general RAG\n\n\n\nVisualize this as a Bell Curve.\nExplain that the “Sweet Spot” varies by use case but 512 is the industrial starting point."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-slicing-strategy-recursive-flow-we-will-see-it-later",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-slicing-strategy-recursive-flow-we-will-see-it-later",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "The Slicing Strategy: Recursive Flow (we will see it later)",
    "text": "The Slicing Strategy: Recursive Flow (we will see it later)\n\n\n\n\n\ngraph LR\n    Doc[Raw Document] --&gt; Strat{Strategy}\n    Strat --&gt; Fixed[Fixed-Size]\n    Strat --&gt; Rec[Recursive]\n    \n    Fixed --&gt; Fail[Broken Sentences]\n    \n    Rec --&gt; P[Paragraphs \\n\\n]\n    P --&gt; S[Sentences .]\n    S --&gt; W[Words]\n    \n    W --&gt; Gold[Goldilocks Result]\n\n\n\n\n\n\n\n\nContrast Fixed-size (blind cutting) with Recursive (logical cutting).\nEmphasize that Recursive splitting respects the natural structure of human language."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-architects-ledger-tuning-knobs",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-architects-ledger-tuning-knobs",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "The Architect’s Ledger: Tuning Knobs",
    "text": "The Architect’s Ledger: Tuning Knobs\n\n\n\n\n\n\n\n\nFeature\nSmall Chunks (128-256)\nLarge Chunks (1024+)\n\n\n\n\nBest For\nFact Retrieval (Dates, Prices)\nThemes & Summarization\n\n\nLatency\nLower (fewer tokens)\nHigher (more context)\n\n\nAccuracy\nHigh Precision\nHigh Recall\n\n\nRisk\nMissing Context\n“Lost in the Middle”\n\n\n\n\n\nClosing thought: Chunking is your first “tuning knob.”\nIf the LLM says “I don’t know,” increase chunk size.\nIf it’s giving irrelevant rambling, decrease chunk size."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-architects-ledger-latency-and-token-economics",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-architects-ledger-latency-and-token-economics",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "The Architect’s Ledger: Latency and Token Economics",
    "text": "The Architect’s Ledger: Latency and Token Economics\n\nAccuracy is not enough.\nA “perfect” answer that costs $5.00 and takes 30 seconds is a failed product.\nThe Architect’s Dual Constraint:\n\nThe Bill (Cost)\nThe Wait (Latency)\n\n\n\n\nTransition from the previous section: We’ve solved for semantic integrity, now we solve for business viability.\nExplain that as a junior peer, you need to think about the “ledger”—the balance sheet of the application."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-hidden-tax-token-economics",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-hidden-tax-token-economics",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "The Hidden Tax: Token Economics",
    "text": "The Hidden Tax: Token Economics\n\nLLMs charge by Input Volume.\nYour prompt isn’t just the question; it’s the Total Payload.\n\n\n\n\nThe Payload\n\nSystem Instructions\nUser Query\nRetrieved Context (The Chunks)\n\n\n\nThe Math\n\\(Cost \\propto (T_{Prompt} + T_{Chunks})\\)\n\n\n\n\n\nThe “More is Better” Trap: Sending 10,000 tokens of context to answer a 10-token fact is an 1,000x economic inefficiency.\n\n\n\nEmphasize that input tokens are often the largest part of the bill in RAG.\nUse the analogy of paying for a whole book just to read one sentence."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-latency-budget",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-latency-budget",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "The Latency Budget",
    "text": "The Latency Budget\n\nTime is UX: Users drop off after 2 seconds of silence.\nLarge chunks create two bottlenecks:\n\n\nThe Pre-fill Penalty: The LLM must “attend” to every token before generating the first word.\nThe Retrieval Drag: Moving 5MB of text context from a DB to an API is slower than moving 50KB.\n\n\n\nDefine TTFT (Time To First Token) as the metric that defines “snappiness.”\nExplain that processing overhead scales with context length."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#visualizing-the-trade-off",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#visualizing-the-trade-off",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "Visualizing the Trade-off",
    "text": "Visualizing the Trade-off\n\n\n\n\n\n\n\ngraph LR\n    A[Small Chunks] --&gt; B(Low Latency / Low Cost)\n    A --&gt; C(Risk: Missing Context)\n    D[Large Chunks] --&gt; E(High Latency / High Cost)\n    D --&gt; F(Reward: Deep Context)\n    \n    style B fill:#d4edda,stroke:#155724\n    style E fill:#f8d7da,stroke:#721c24\n\n\n\n\n\n\n\n\n\n\nlatency_cost_chunk_tradeoff\n\n\n\n\n\n\n\nExplain the “Efficiency Frontier”: finding the sweet spot where accuracy is high but cost hasn’t spiked yet.\nMention the “knee of the curve.”"
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-rag-efficiency-equation",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-rag-efficiency-equation",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "The RAG Efficiency Equation",
    "text": "The RAG Efficiency Equation\nWe quantify system health using the Signal-to-Noise Ratio:\n\\[\\text{Efficiency} = \\frac{\\text{Retrieval Precision (Signal)}}{\\text{Total Tokens (Noise)} \\times \\text{Latency}}\\]\n\n\nExplain that “Signal” is the specific fact needed for the answer.\n“Noise” is the fluff surrounding it in the chunk."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-architects-levers",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#the-architects-levers",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "The Architect’s Levers",
    "text": "The Architect’s Levers\n\n\n\n\n\n\n\n\nLever\nStrategy\nImpact\n\n\n\n\nGranularity\nSmall Chunks + High Top-K\nHigh Signal, manageable cost.\n\n\nDistillation\nSummarize context first\nDrastically reduces LLM input size.\n\n\nHard Filters\nMetadata Filtering\nBypasses vector math; ultra-fast."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#architectural-flow-economic-leaks",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#architectural-flow-economic-leaks",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "Architectural Flow: Economic Leaks",
    "text": "Architectural Flow: Economic Leaks\n\n\n\n\n\ngraph LR\n    User([User Query]) --&gt; Router{Strategy}\n    \n    Router --&gt;|Small| S_DB[(256-token Chunks)]\n    Router --&gt;|Large| L_DB[(1024-token Chunks)]\n    \n    S_DB --&gt; S_LLM[LLM]\n    L_DB --&gt; L_LLM[LLM]\n    \n    S_LLM --&gt; S_Out[Fast & Cheap]\n    L_LLM --&gt; L_Out[Slow & Expensive]\n    \n    style S_Out fill:#d4edda,stroke:#155724\n    style L_Out fill:#f8d7da,stroke:#721c24\n\n\n\n\n\n\n\n\nWalk through the flow.\nHighlight that the choice of chunk size at the start dictates the entire downstream cost."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#summary-context-is-a-liability",
    "href": "W6/W6-chunking-and-preprocessing/01-context-economics/draft.html#summary-context-is-a-liability",
    "title": "Context Economics: The Signal-to-Noise Ratio",
    "section": "Summary: Context is a Liability",
    "text": "Summary: Context is a Liability\n\nCurate, Don’t Dump: High context volume is a risk to reasoning.\nRespect the U-Curve: Position critical info at the edges or keep context short.\nChunking is Key: Small, distinct chunks maintain high SNR.\n\n\n\nWrap up by reminding them that as architects, they are the “gatekeepers” of the LLM’s attention.\nPreview the next section: How to find the perfect chunk size."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#the-cut-off-problem-why-fixed-sizing-fails",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#the-cut-off-problem-why-fixed-sizing-fails",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "The “Cut-Off” Problem: Why Fixed Sizing Fails",
    "text": "The “Cut-Off” Problem: Why Fixed Sizing Fails\n\nThe Architect’s Mantra: “The LLM is only as smart as the context you give it.”\nThe Pipeline Foundation: Data ingestion is the bedrock of RAG.\nThe Failure Point: Mangled fragments = Hallucinations.\nGoal: Move from “Counting Characters” to “Preserving Meaning.”\n\n\n\nIntroduce the section by emphasizing that even GPT-4 fails if the input data is broken.\nContrast the “Beginner” approach (just splitting text) with the “Architect” approach (designing for integrity)."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#contextual-integrity",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#contextual-integrity",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "Contextual Integrity",
    "text": "Contextual Integrity\n\nThe Principle: Every chunk must be a self-contained thought.\nThe Goal: Zero “guessing” required by the LLM.\nThe Atomic Unit of Meaning:\n\nLike a LEGO brick: Cut it in half, and it loses its “hooks.”\nData “hooks” allow the retriever to connect queries to answers.\n\n\n\n\nUse the LEGO analogy to explain why partial data is useless.\nExplain that “Contextual Integrity” is our North Star for this module."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#we-saw-the-mid-sentence-failure",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#we-saw-the-mid-sentence-failure",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "We Saw The “Mid-Sentence” Failure",
    "text": "We Saw The “Mid-Sentence” Failure\n\nMechanical Blindness: RecursiveCharacterTextSplitter doesn’t “read”; it counts.\nThe Anatomy of a Broken Chunk:\n\n\n\n\nOriginal Logic\n“The system triggers a shutdown if temperature &gt; 150C and backup pump is inactive.”\n\n\nThe “Slicer” Result\n\nChunk A: “…trigger an immediate shutdown if the inter”\nChunk B: “nal temperature exceeds 150 degrees…”\n\n\n\n\n\n\nHighlight how “inter-nal” being split ruins keyword search/embeddings.\nPoint out that the “Action” is in Chunk A, but the “Condition” is in Chunk B."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#logic-severing-a-case-study",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#logic-severing-a-case-study",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "Logic Severing: A Case Study",
    "text": "Logic Severing: A Case Study\n\n\n\n\n\ngraph LR\n    A[User Query: &lt;br&gt; When does it shut down?] --&gt; B{Retriever}\n    B --&gt; C[Retrieves Chunk B: &lt;br&gt; 'temp exceeds 150C...']\n    C --&gt; D[LLM Analysis]\n    D --&gt; E[Error: Missing 'Shutdown' &lt;br&gt; context from Chunk A]\n\n\n\n\n\n\n\nLost Entities: “Internal” becomes “inter” (Search fails).\nBroken Logic: The “Action” (Shutdown) is separated from the “Condition” (Temp/Pump).\n\n\n\nWalk through the diagram.\nExplain that the retriever might only find the chunk with the number ‘150’, missing the actual instruction."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#garbage-in-hallucination-out",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#garbage-in-hallucination-out",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "“Garbage In, Hallucination Out”",
    "text": "“Garbage In, Hallucination Out”\n\nInformation Asymmetry: LLMs hallucinate to bridge gaps we created.\nThe Hallucination Chain:\n\nQuery: “Is 160 degrees safe?”\nRetrieval: Only gets the “150 degrees” fragment.\nThe Gap: LLM doesn’t see the “Shutdown” rule.\nThe Invention: “It is likely safe if the pump is running.”\n\n\nResult: A high-risk system failure due to a character-count constraint.\n\n\nEmphasize that hallucinations are often “logical guesses” based on incomplete data.\nThis frames data engineering as a safety requirement, not just a technical one."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#syntactic-vs.-semantic-impact",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#syntactic-vs.-semantic-impact",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "Syntactic vs. Semantic Impact",
    "text": "Syntactic vs. Semantic Impact\n\nImage: Plot showing fixed-size red lines cutting through high-density information peaks vs semantic valleys\nSyntactic (Red Lines): Cuts through the “peaks” (Core Ideas).\nSemantic (Target): Cuts through the “valleys” (Natural Pauses).\n\n\n\nExplain the visual: Peaks are where the “meaning” is densest.\nFixed splitting is random; semantic splitting is intentional."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#comparison-the-architects-verdict",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#comparison-the-architects-verdict",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "Comparison: The Architect’s Verdict",
    "text": "Comparison: The Architect’s Verdict\n\n\n\nFeature\nSyntactic (Fixed/Recursive)\nSemantic (Meaning-Based)\n\n\n\n\nPrimary Metric\nCharacter/Token Count\nTopic/Intent Change\n\n\nLogic\n“Stop at 500 chars”\n“Stop when subject changes”\n\n\nCost\nLow Compute\nHigher (Requires Embeddings)\n\n\nBest For\nSimple MVPs\nProfessional/Legal/Tech RAG\n\n\n\n\n\nUse the progressive reveal to drive home the “Verdict.”\nPrepare students for the next section where they learn how to measure “Intent.”"
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#the-mental-model-the-semantic-rollercoaster",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#the-mental-model-the-semantic-rollercoaster",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "The Mental Model: The Semantic Rollercoaster",
    "text": "The Mental Model: The Semantic Rollercoaster\n\n\n\nThe “Blind” Approach\n\nFixed Chunking\nCuts every \\(N\\) characters.\nLike a blindfolded gardener.\nSplitting branches mid-air.\n\n\n\nThe “Architect” Approach\n\nSemantic Chunking\nCuts based on meaning.\nLike an expert editor.\nIdentifying natural transitions.\n\n\n\n\n\n\nRecap: Fixed chunking is easy but dangerous because it ignores context.\nIntroduce the shift from structural rules (character counts) to logical rules (intent).\nThe goal is to give the RAG system “eyes” to see topic boundaries."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#the-coffee-shop-analogy",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#the-coffee-shop-analogy",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "The Coffee Shop Analogy",
    "text": "The Coffee Shop Analogy\n\n\n\nPhase A: The Deep Dive\n\n“Grind size affects extraction.”\n“Water should be 200°F.”\nContext: Brewing Espresso.\n\n\n\n\nPhase B: The Semantic Jolt\n\n“Did you see the game last night?”\n“The quarterback was incredible.”\nContext: Sports.\n\n\n\n\n\nThe Architect’s Insight: A human senses the “jolt” instantly. Our system needs a “sensor” to detect this shift before the RAG retrieval fails.\n\n\n\nUse the coffee shop eavesdropping example to explain “Semantic Shift.”\nExplain that sentences in Phase A are “close” while Phase B is “far” from A.\nThis jolt is where we want our chunk boundary to exist."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#visualizing-meaning-points-in-space",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#visualizing-meaning-points-in-space",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "Visualizing Meaning: Points in Space",
    "text": "Visualizing Meaning: Points in Space\n\n\n\n\n\ngraph LR\n    subgraph \"The Security District\"\n    A[Data is encrypted] --- B[AES-256 Standard]\n    B --- C[Rotate Keys Monthly]\n    end\n\n    C -.-&gt;|BIG GAP: Semantic Shift| D\n\n    subgraph \"The Compute District\"\n    D[NVIDIA H100 GPUs] --- E[4-Day Training Cycle]\n    end\n\n    style A fill:#f9f,stroke:#333\n    style B fill:#f9f,stroke:#333\n    style C fill:#f9f,stroke:#333\n    style D fill:#bbf,stroke:#333\n    style E fill:#bbf,stroke:#333\n\n\n\n\n\n\n\nSentences are GPS Coordinates in a multi-dimensional city.\nSimilar topics “cluster” together in specific districts.\nA topic switch is a teleportation across town.\n\n\n\nIntroduce the concept of Vector Space without using the word “tensor” or “matrix.”\nExplain that proximity in space equals similarity in meaning.\nThe “Big Gap” is the logical place to snip the document."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#the-spike-detecting-the-moment-of-change",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#the-spike-detecting-the-moment-of-change",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "The “Spike”: Detecting the Moment of Change",
    "text": "The “Spike”: Detecting the Moment of Change\n\n\n\nThe Logic\n\nValleys: Low distance between sentences. (Keep together)\nPeaks: Sudden jump in distance. (The “Cut” signal)\nThreshold: Our “tolerance” for change.\n\n\n\n\n\n\nImage: A line graph showing semantic distance between sentences with a red dashed horizontal threshold line. Spikes above the line indicate chunk boundaries.\n\n\n\n\n\n\n\nExplain the “Heart Rate Monitor” metaphor.\nThe green line represents the distance between sentence \\(n\\) and sentence \\(n+1\\).\nWhen the green line crosses the red threshold, the “Architect” places a boundary."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#embeddings-the-semantic-sensor",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#embeddings-the-semantic-sensor",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "Embeddings: The Semantic Sensor",
    "text": "Embeddings: The Semantic Sensor\nHow do we calculate “distance” without reading every word?\n\nInput: Feed two sentences into an Embedding Model.\nProcess: Model converts “vibe” into a Vector (list of numbers).\nCalculation: Use Cosine Similarity to measure the overlap.\n\n\n\nDemystify embeddings: they are not black boxes, they are “Semantic Thermometers.”\nExplain Cosine Similarity as a simple geometric overlap check.\nHigh overlap (90%) = Stay in chunk. Low overlap (40%) = Break chunk."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#summary-the-architects-mindset",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#summary-the-architects-mindset",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "Summary: The Architect’s Mindset",
    "text": "Summary: The Architect’s Mindset\n\nFixed Chunking is Structural\n\nBased on volume and storage limits.\n\nSemantic Chunking is Logical\n\nBased on intent and complete thoughts.\n\n\n\nGoal: Create “Semantic Islands”—pure, unpolluted information blocks that ensure the LLM receives the right context every time.\n\n\n\nFinal takeaway: We want “Semantic Islands.”\nFragmented sentences lead to hallucination; complete thoughts lead to accuracy.\nTransition to the next section: The actual algorithm logic."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#the-architects-blueprint-algorithm-logic",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#the-architects-blueprint-algorithm-logic",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "The Architect’s Blueprint: Algorithm Logic",
    "text": "The Architect’s Blueprint: Algorithm Logic\n\nThe Goal: Move from “Mental Model” to a reproducible pipeline.\nThe Strategy: Treat text as a Signal Processing problem.\nThe Process: A 4-step modular workflow to identify semantic “breaks.”\n\n\n\n\n\n\n\ngraph LR\n    A[Raw Text] --&gt; B[Tokenize]\n    B --&gt; C[Embed]\n    C --&gt; D[Compare]\n    D --&gt; E[Split]\n    style E fill:#f96,stroke:#333,stroke-width:2px\n\n\n\n\n\n\n\n\nWe are moving from the “Rollercoaster” analogy to actual engineering.\nExplain that treatnig text as a signal allows us to use mathematical thresholds rather than “guessing” chunk sizes."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#step-1-sentence-tokenization",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#step-1-sentence-tokenization",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "Step 1: Sentence Tokenization",
    "text": "Step 1: Sentence Tokenization\nDefining the “Atomic Unit”\n\nThe Atom: The Sentence, not the character or word.\nThe Logic: Sentences represent the smallest unit of a complete thought.\nAvoid “Dirty” Data:\n\nUse robust libraries (NLTK, SpaCy).\nHandle edge cases: “Dr. Smith” or “e.g.” shouldn’t trigger a split.\n\n\n\n\n\nInput\n\n“The revenue grew by 10%. Dr. Smith reported this on Tuesday.”\n\n\n\nOutput\n\n“The revenue grew by 10%.”\n“Dr. Smith reported this on Tuesday.”\n\n\n\n\n\n\nWhy not fixed-length? Because fixed-length cuts thoughts in half.\nMention that the quality of the tokenizer dictates the quality of the entire downstream RAG pipeline."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#step-2-generating-embeddings",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#step-2-generating-embeddings",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "Step 2: Generating Embeddings",
    "text": "Step 2: Generating Embeddings\nTranslating Meaning to Math\n\nVectorization: Convert each sentence \\(s_i\\) into a high-dimensional vector \\(v_i\\).\nModel Choice: Use efficient Transformers (e.g., all-MiniLM-L6-v2).\nThe “Context Window” Enhancement:\n\nDon’t just compare \\(s_1\\) to \\(s_2\\).\nCompare Sliding Windows (average of sentences \\([1,2]\\) vs \\([3,4]\\)).\nBenefit: Smooths out noise from short transitional phrases like “However,”.\n\n\n\n\nExplain that a single word like “However” has a very different embedding than a full sentence, which can cause “false drops” in similarity.\nSliding windows provide “semantic momentum.”"
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#step-3-cosine-similarity",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#step-3-cosine-similarity",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "Step 3: Cosine Similarity",
    "text": "Step 3: Cosine Similarity\nMeasuring the Distance in “Thought-Space”\n\n\nThe Metric: Cosine Similarity (Score of 0.0 to 1.0).\nThe Calculation: Compare adjacent pairs \\((v_i, v_{i+1})\\).\n\n\n\n\n\nThe Logic\n\n1.0: Semantically identical.\n0.0: Completely unrelated.\n\n\n\nThe Signal\n\n\n\nImage: Plot showing peaks and valleys of similarity scores\n\n\n\n\n\n\n\nRemind them of the “Rollercoaster” from the previous section.\nHigh similarity = the “peaks” (staying on topic).\nLow similarity = the “valleys” (topic shifts)."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#step-4-the-breakpoint",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#step-4-the-breakpoint",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "Step 4: The ‘Breakpoint’",
    "text": "Step 4: The ‘Breakpoint’\nIdentifying the Threshold (\\(T\\))\nHow do we decide when to “cut”?\n\nStatic Threshold: Hard limit (e.g., \\(T = 0.6\\)). Simple, but rigid.\nPercentile-Based: Adaptive. Set \\(T\\) at the bottom 5th or 10th percentile of the document’s scores.\nGradient-Based: Look for the “steepest drop” in the signal.\n\nThe Final Assembly: - If \\(Score &gt; T\\): Keep building the current chunk. - If \\(Score \\leq T\\): Close chunk; start a new one.\n\n\nPercentile-based is usually best for production because it adapts to different writing styles (legal vs. conversational).\nGradient-based is more complex but handles documents with very subtle transitions well."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#the-architectural-flowchart",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#the-architectural-flowchart",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "The Architectural Flowchart",
    "text": "The Architectural Flowchart\n\n\n\n\n\ngraph LR\n    A[Raw &lt;br&gt; Document] --&gt; B[Sentence &lt;br&gt; Tokenizer]\n    B --&gt; C[List of &lt;br&gt; Sentences]\n    C --&gt; D[Embedding &lt;br&gt; Model]\n    D --&gt; E[Vector &lt;br&gt; Sequence]\n    E --&gt; F[Calculate Cosine &lt;br&gt; Similarity Between Neighbors]\n    F --&gt; G{Similarity &lt; Threshold?}\n    G -- Yes --&gt; H[Create Breakpoint &lt;br&gt; Or New Chunk]\n    G -- No --&gt; I[Combine into &lt;br&gt; Current Chunk]\n    H --&gt; J[Final Semantic Chunks]\n    I --&gt; J\n\n\n\n\n\n\n\n\nEmphasize the modularity: You can swap the Embedding Model (Step D) or the Threshold Logic (Step G) without breaking the rest of the pipe.\nThis is “The Architect’s” way: building interchangeable components."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#why-this-works-for-production",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#why-this-works-for-production",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "Why this works for Production",
    "text": "Why this works for Production\n\nSolves Context Fragmentation: No more cutting a “Revenue” paragraph in half.\nHigher Retrieval Accuracy: The LLM receives a “complete thought” as context.\nCoherent Responses: Reduced “hallucinations” caused by missing context.\n\n\nArchitect’s Rule: The system only cuts when the “Signal” drops—meaning the author has actually moved on.\n\n\n\nCompare this to “Naive Chunking” (fixed 500 characters).\nIn Naive chunking, the “Revenue” data might be split across two chunks, making it harder for the RAG system to find the whole answer."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#system-reliability-tuning-the-threshold",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#system-reliability-tuning-the-threshold",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "System Reliability: Tuning the Threshold",
    "text": "System Reliability: Tuning the Threshold\n\nTransitioning from Prototype to Production.\nWhy “Hard Thresholds” are a recipe for failure.\nEngineering trade-offs: Cost, Latency, and Quality.\nGoal: Moving from “Code that runs” to “Systems that scale.”\n\n\n\nRecap: We know how to find peaks in distance.\nNow: We focus on making those peaks meaningful across different document types.\nEmphasize that an Architect’s job is managing trade-offs, not just writing logic."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#the-trap-of-static-thresholds",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#the-trap-of-static-thresholds",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "The Trap of Static Thresholds",
    "text": "The Trap of Static Thresholds\n\n\n\nThe Problem\n\nHard Thresholds: e.g., “Split if distance &gt; 0.4”\nLegal Contracts: Dense, cohesive (Low variance).\nCreative Stories: Erratic, shifting (High variance).\nResult: Zero splits or “Micro-chunks.”\n\n\n\nThe Visual\n\n\n\nImage: A graph showing two different document types with a single horizontal line failing to intersect both meaningfully\n\n\n\n\n\n\n\nExplain “Semantic Gravity.”\nA hard threshold is a “one-size-fits-all” solution that fits no one.\nMention that technical manuals vs. conversational transcripts have different “rhythms.”"
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#the-solution-percentile-based-splitting",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#the-solution-percentile-based-splitting",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "The Solution: Percentile-Based Splitting",
    "text": "The Solution: Percentile-Based Splitting\n\nLogic: Split at the \\(X^{th}\\) percentile of internal distances.\nAdaptive: The threshold moves based on the document’s own “gravity.”\nFocus: Capturing the top 5% or 2% of “Meaning Shifts.”\n\n\n\n\n\n\ngraph LR\n    A[Calculate All &lt;br&gt; Sentence Distances] --&gt; B[Sort Distances]\n    B --&gt; C[Identify 95th Percentile &lt;br&gt; Value]\n    C --&gt; D{Is current distance &lt;br&gt; &gt; 95th Percentile?}\n    D -- Yes --&gt; E[Create Breakpoint]\n    D -- No --&gt; F[Continue Chunk]\n\n\n\n\n\n\n\n\nExplain that we look at the document as a whole before cutting.\nUse the 95th percentile as a starting point.\nTip: Use 90th for technical docs (subtle shifts) and 98th for news (broad shifts)."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#the-semantic-tax-cost-analysis",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#the-semantic-tax-cost-analysis",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "The “Semantic Tax”: Cost Analysis",
    "text": "The “Semantic Tax”: Cost Analysis\nSemantic chunking is high-fidelity but high-overhead.\n\n\n\nFeature\nRecursive Splitting\nSemantic Splitting\n\n\n\n\nCompute Cost\nNegligible\nModerate (Embeddings)\n\n\nLatency\nNear-instant\nModel Dependent\n\n\nAPI Tokens\nZero\nHigh (if using Cloud APIs)\n\n\n\n\n\nExplain the “Double-Dip”: You embed once to split, and potentially again to store.\nEmphasize the hybrid approach to save costs while maintaining quality."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#latency-vs.-quality-matrix",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#latency-vs.-quality-matrix",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "Latency vs. Quality Matrix",
    "text": "Latency vs. Quality Matrix\n\nImage: A scatter plot showing Recursive Splitting in the ‘Fast/Low Quality’ quadrant and Semantic Splitting in the ‘Slower/High Quality’ quadrant\nRecursive: Use for real-time “Chat with PDF” (&lt; 2s target).\nSemantic: Use for “Knowledge Bases” (Ingest once, query 1000x).\n\n\n\nThis is the “Production Decision Matrix.”\nAsk the students: Is the user waiting for a spinner, or is this happening in the background?"
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#handling-noise-the-buffer-window",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#handling-noise-the-buffer-window",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "Handling Noise: The Buffer Window",
    "text": "Handling Noise: The Buffer Window\n\nThe Danger: “Click here” or “Page 42” creates false peaks.\nThe Safeguard: Use a Moving Average.\nCompare the average of the last 3 sentences to the next 3.\nSmoothing: Flattens the “Semantic Rollercoaster.”\n\n\n\nExplain that single-sentence comparisons are too “jittery.”\nAnalogy: Like a shock absorber on a car—it ignores the small pebbles to focus on the big bumps."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#the-robust-splitter-pseudo-code",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#the-robust-splitter-pseudo-code",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "The Robust Splitter: Pseudo-Code",
    "text": "The Robust Splitter: Pseudo-Code\ndef robust_split(text, percentile=95, min_size=200):\n    sentences = split_into_sentences(text)\n    embeddings = get_embeddings(sentences)\n    \n    # Smoothing the signal\n    distances = calculate_cosine_distances(embeddings, window=3)\n    threshold = np.percentile(distances, percentile)\n    \n    chunks = []\n    # Logic to enforce min_size and create breakpoints...\n    return chunks\n\nMin/Max Constraints: Never allow “micro-chunks.”\nContext Preservation: Ensure every chunk is an “Idea.”\n\n\n\nWalk through the logic: Embed -&gt; Smooth -&gt; Percentile -&gt; Constraint Check.\nMention that min_size prevents chunks that have no context for the LLM to use."
  },
  {
    "objectID": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#section-summary-the-architects-view",
    "href": "W6/W6-chunking-and-preprocessing/03-semantic-chunking/draft.html#section-summary-the-architects-view",
    "title": "Semantic Segmentation: Breaking by Meaning",
    "section": "Section Summary: The Architect’s View",
    "text": "Section Summary: The Architect’s View\n\nPrecision: Semantic Segmentation provides “High-Fidelity” context.\nResilience: Use percentiles and smoothing to handle messy data.\nEfficiency: Balance the “Semantic Tax” with the “Retrieval Reward.”\nOutcome: The LLM receives a perfectly encapsulated “Idea.”\n\n\n\nFinal wrap-up.\nRemind them: We want to feed the LLM “Ideas,” not “Strings.”\nTransition to the next module on Evaluation."
  },
  {
    "objectID": "W6/index.html",
    "href": "W6/index.html",
    "title": "AI Pros Bootcamp",
    "section": "",
    "text": "Day 1:\n\nPrompting\nEvaluation and Structured Output\n\nDay 2:\n\nEmbeddings\nVector Stores\nRAG Architectures\n\nDay 3:\n\nIntroduction to Agents\nAgent Development Kit (ADK)\n\nDay 4:\n\nAgent Tools & Best Practices"
  },
  {
    "objectID": "W6/index.html#week-6-agentic-ai",
    "href": "W6/index.html#week-6-agentic-ai",
    "title": "AI Pros Bootcamp",
    "section": "",
    "text": "Day 1:\n\nPrompting\nEvaluation and Structured Output\n\nDay 2:\n\nEmbeddings\nVector Stores\nRAG Architectures\n\nDay 3:\n\nIntroduction to Agents\nAgent Development Kit (ADK)\n\nDay 4:\n\nAgent Tools & Best Practices"
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#the-fastapi-class",
    "href": "W7/M2/01_fastapi_intro.html#the-fastapi-class",
    "title": "Introduction to FastAPI",
    "section": "1. The FastAPI Class",
    "text": "1. The FastAPI Class\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/items\")\ndef get_items():\n    return [1, 2, 3]\nThe FastAPI class is the main entry point for your application. It inherits from Starlette and acts as the central hub where you:\n\nRegister routes using decorators like @app.get(), @app.post(), ..etc.\nConfigure global settings like exception handlers (404, 500, ..etc.).\nManage lifecycles: events such as: startup and shutdown\n\n\n\nM1 Connection (Verbs): Remember those HTTP Verbs? GET, POST, PUT?\nConcept: The @app.get() decorator is how we implement an HTTP Verb in Python. You are literally telling the server: “When you hear a GET request at this path, run this function.”\nThe app object is the “Brain” of your server. It holds the map (Routing Table) of where every request should go.\nManage lifecycles: events such as:\n\nstartup (e.g., connect to db)\nand shutdown (e.g., disconnect from db)."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#the-request-class",
    "href": "W7/M2/01_fastapi_intro.html#the-request-class",
    "title": "Introduction to FastAPI",
    "section": "2. The Request Class",
    "text": "2. The Request Class\n\nFigure: A diagram showing the flow of an HTTP request. A data packet labeled ‘Request’ enters a funnel labeled ‘FastAPI’. The funnel splits the packet into ‘Head’ (Metadata) and ‘Body’ (Payload).from fastapi import Request\nThe Request class provides direct access to the underlying HTTP request. This is useful when you need to access:\n\nThe client’s IP address.\nRaw Headers or Cookies.\nThe request Body as a raw stream.\n\n\n\nM1 Connection (The Message): Recall the “Envelope vs. Contents” metaphor?\nThe Request object gives you raw access to the entire envelope.\nUsually, FastAPI opens it for you (as we’ll see next), but sometimes you need to check the postmark (Client IP) or read a raw message directly.\nUse Case: Rate limiting (checking IP) or logging incoming traffic."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#request-parameters",
    "href": "W7/M2/01_fastapi_intro.html#request-parameters",
    "title": "Introduction to FastAPI",
    "section": "3. Request Parameters",
    "text": "3. Request Parameters\nfrom fastapi import Body, Cookie, File, Form, Header, Path, Query\nThese are the special functions that you can put in path operation function parameters or dependency functions with Annotated to get data from the request.\n\nPath & Query: For values in the URL or query string.\nBody, Form, & File: For data, form fields, or files sent in the request payload.\nHeader & Cookie: For extracting metadata from the request.\n\n\n\nM1 Connection (URL Anatomy): This is where theory meets practice.\nPath params map to the Resource Location (The “What”).\nQuery params map to the Parameters (The “How”).\nHeader params let you read the Metadata (e.g., Auth tokens or User-Agent).\nFeature: FastAPI automatically splits the URL string into these clean Python variables for you. You don’t parse strings; you just ask for variables."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#the-response-class",
    "href": "W7/M2/01_fastapi_intro.html#the-response-class",
    "title": "Introduction to FastAPI",
    "section": "4. The Response Class",
    "text": "4. The Response Class\n\nFigure: A diagram showing the output of the FastAPI funnel. Data comes out and is packaged into a box labeled ‘Response’. A label is being attached to the box that says ‘Status: 200 OK’.from fastapi import Response\nYou can declare a parameter in a path operation function or dependency to be of type Response and then you can set data for the response like headers or cookies.\n\nSet custom HTTP status codes (e.g., 201 Created).\nAdd custom headers or set cookies.\nReturn different types of content, such as JSON, HTML, or plain text.\n\n\n\nM1 Connection (Status Codes): Remember the traffic lights (200, 404, 500)?\nThis object is how you control those lights.\nBy default, FastAPI returns 200 OK. But if you are creating a resource, you might want to manually set 201 Created.\nThis is also where you set Cookies (the “VIP badge” for state) to send back to the user."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#custom-response-classes",
    "href": "W7/M2/01_fastapi_intro.html#custom-response-classes",
    "title": "Introduction to FastAPI",
    "section": "5. Custom Response Classes",
    "text": "5. Custom Response Classes\nfrom fastapi.responses import (\n    FileResponse,\n    HTMLResponse,\n    JSONResponse,\n    ORJSONResponse,\n    PlainTextResponse,\n    RedirectResponse,\n    Response,\n    StreamingResponse,\n    UJSONResponse,\n)\nRead more about it in the FastAPI docs for Custom Response - HTML, Stream, File, others."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#status-codes",
    "href": "W7/M2/01_fastapi_intro.html#status-codes",
    "title": "Introduction to FastAPI",
    "section": "Status Codes",
    "text": "Status Codes\nfrom fastapi import status\nIt contains a group of named constants (variables) with integer status codes. For example:\n\n200: status.HTTP_200_OK\n403: status.HTTP_403_FORBIDDEN\netc.\n\nRead more about it in the FastAPI docs about Response Status Code.\n\nIt can be convenient to quickly access HTTP (and WebSocket) status codes in your app, using autocompletion for the name without having to remember the integer status codes by memory."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#the-apirouter-class",
    "href": "W7/M2/01_fastapi_intro.html#the-apirouter-class",
    "title": "Introduction to FastAPI",
    "section": "6. The APIRouter Class",
    "text": "6. The APIRouter Class\nfrom fastapi import APIRouter\nGroup path operations, for example to structure an app in multiple files: routers/items.py and routers/users.py:\n.\n├── app\n│   ├── __init__.py\n│   ├── main.py\n│   └── routers\n│   │   ├── __init__.py\n│   │   ├── items.py\n│   │   └── users.py\nRead more about it in the FastAPI docs for Bigger Applications - Multiple Files."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#running-fastapi-development",
    "href": "W7/M2/01_fastapi_intro.html#running-fastapi-development",
    "title": "Introduction to FastAPI",
    "section": "Running FastAPI: Development",
    "text": "Running FastAPI: Development\nTo start your API in development mode, use the command:\nfastapi dev main.py\n\nMode: Development\nAuto-reload: Enabled (Server restarts when code changes).\nHost: 127.0.0.1 (Localhost).\nWarning: This mode is resource-intensive and less stable. Do not use in production.\n\n\n\nConcept: The “Workshop”.\nfastapi dev is for you, the developer.\nIt watches your files. If you save a change, the server reloads instantly so you can test it.\nIt locks the doors (only listens to localhost), so no one from the outside internet can access your broken, half-written code."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#running-fastapi-production",
    "href": "W7/M2/01_fastapi_intro.html#running-fastapi-production",
    "title": "Introduction to FastAPI",
    "section": "Running FastAPI: Production",
    "text": "Running FastAPI: Production\nTo start your API in production mode, use the command:\nfastapi run main.py\n\nMode: Production\nAuto-reload: Disabled (Stable, maximizing performance).\nHost: 0.0.0.0 (Listen on all available IP addresses).\nTermination Proxy: Typically runs behind an HTTPS proxy (like Nginx or a Load Balancer).\n\n\n\nConcept: The “Stage”.\nfastapi run is for the world.\nIt maximizes stability and performance. It doesn’t waste energy watching files.\nIt opens the doors (0.0.0.0) so the container or internet can reach it.\nImportant: In real deployments, you usually put a “Bodyguard” (Termination Proxy) in front of it to handle HTTPS encryption."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#fastapi-standing-on-giants",
    "href": "W7/M2/01_fastapi_intro.html#fastapi-standing-on-giants",
    "title": "Introduction to FastAPI",
    "section": "FastAPI: Standing on Giants",
    "text": "FastAPI: Standing on Giants\nFastAPI is not built from scratch. It creates a powerful synergy by combining two best-in-class libraries:\n\nStarlette: For the web parts.\nPydantic: For the data parts.\n\n\n\nConcept: FastAPI is a “Glue Framework”.\nIt doesn’t re-invent the wheel. It takes the fastest web server (Starlette) and the best data validator (Pydantic) and wraps them in a unified, developer-friendly API.\nYou get the speed of Starlette and the safety of Pydantic without having to wire them together yourself."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#starlette-the-web-engine",
    "href": "W7/M2/01_fastapi_intro.html#starlette-the-web-engine",
    "title": "Introduction to FastAPI",
    "section": "Starlette: The Web Engine",
    "text": "Starlette: The Web Engine\nStarlette provides the underlying web capabilities:\n\nAsynchronous Core: Built on anyio, allowing for high concurrency (dealing with many users at once).\nWebSockets: Native support for real-time bi-directional communication.\n\n\n\nAnalogy: If FastAPI is the car, Starlette is the Engine.\nIt handles the raw HTTP bytes, the connections, and the async event loop.\nFeatures like “Background Tasks” (sending an email after a user signs up) come directly from Starlette.\nWhen you use FastAPI(), you are actually creating a Starlette app with extra superpowers."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#pydantic-the-data-enforcer",
    "href": "W7/M2/01_fastapi_intro.html#pydantic-the-data-enforcer",
    "title": "Introduction to FastAPI",
    "section": "Pydantic: The Data Enforcer",
    "text": "Pydantic: The Data Enforcer\nPydantic provides the data validation and serialization:\n\nFigure: the BaseModel\nEnforces that input data matches your defined types: \"123\" \\(\\rightarrow\\) 123\nWritten in Rust (v2), making it one of the fastest validators available.\nIt also draws the map (OpenAPI/Swagger UI) based on your Python code.\n\n\n\nThe shape-sorter itself represents your Pydantic Model (Schema).\nA structure that defines the expected “shapes” (data types) of your inputs.\nAnalogy: If Starlette is the Engine, Pydantic is the Security System.\nIt checks every piece of data entering the car.\nIt’s not just checking errors; it’s fixing data (Parsing).\n\nExtra: The Linguistic Origin\nThe name is a portmanteau of Py (for Python) and pedantic.\nIn English, a “pedantic” person is someone who is excessively concerned with minor details, rules, or formalisms. In the context of programming, being “pedantic” usually has a negative connotation, implying that a tool or person is being needlessly difficult about small syntax errors or strict types."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#key-takeaways",
    "href": "W7/M2/01_fastapi_intro.html#key-takeaways",
    "title": "Introduction to FastAPI",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nFastAPI Class: The central hub for routing, configuration, and application lifecycle.\nRequest & Response: Use Request for raw access to headers/IPs and Response to manually control status codes and cookies.\nModular Routing: APIRouter allows you to split large applications into manageable, logical files.\nDev vs. Prod: fastapi dev enables auto-reload for local iteration; fastapi run optimizes for performance and security in production.\nThe “Giants”: FastAPI combines Starlette (for high-concurrency async performance) and Pydantic (for strict, automated data validation and documentation)."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#decorators-the-symbol",
    "href": "W7/M2/01_fastapi_intro.html#decorators-the-symbol",
    "title": "Introduction to FastAPI",
    "section": "Decorators: The @ Symbol",
    "text": "Decorators: The @ Symbol\nA Decorator is a function that takes another function and extends its behavior without explicitly modifying it.\n@app.get(\"/items\")\ndef get_items():\n    return [\"a\", \"b\"]\nIn FastAPI: The @app.get decorator tells FastAPI: “Take the function below (get_items) and register it in the Routing Table for the path /items.”\n\n\nConcept: The “Wrapper”.\nImagine wrapping a gift. The gift (your function) stays the same, but the wrapping (the decorator) adds a label saying “To: /users”.\nM1 Connection: This is how we map a URL Resource (M1 Lesson 2) to a Python Function.\nWithout the decorator, get_items is just a standard Python function that does nothing on the web. The decorator “activates” it for the web server."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#type-hints-matter",
    "href": "W7/M2/01_fastapi_intro.html#type-hints-matter",
    "title": "Introduction to FastAPI",
    "section": "Type Hints Matter",
    "text": "Type Hints Matter\nType hints are the single definition that drives three separate systems:\n\nValidation & Parsing\nDocumentation\nAuto-completion\n\n\nUnlike standard Python where type hints are usually ignored at runtime, FastAPI reads them to execute logic.\n\nHook: Standard Python ignores types at runtime. FastAPI enforces them.\nM1 Connection (The Contract): In M1, we talked about “Content Negotiation” (e.g., “I speak JSON”).\nType Hints are how you define that contract in code.\nIf you say item_id: int, FastAPI builds a Gatekeeper that physically stops any request that sends text instead of a number.\nIt validates (Checks), Converts (String “10” -&gt; Int 10), and Documents (Tells the world “I need an Int”) all from one word."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#without-types",
    "href": "W7/M2/01_fastapi_intro.html#without-types",
    "title": "Introduction to FastAPI",
    "section": "Without Types",
    "text": "Without Types\nManual Parsing:\ndef create_item(request):\n    data = request.json\n    \n    # 1. Manually check existence\n    if \"price\" not in data:\n        return {\"error\": \"Price is required\"}, 400\n        \n    # 2. Manually check type\n    if not isinstance(data[\"price\"], (int, float)):\n        return {\"error\": \"Price must be a number\"}, 400\n        \n    # 3. Manually parse/convert\n    price = float(data[\"price\"])\n    \n    # ... finally business logic ...\n\n\nPain Point: This is the “Bad Old Days” of defensive coding.\nLook at this code. The “Business Logic” is one line at the end.\nThe rest? Boilerplate Validation.\nYou are manually checking: “Is it there?”, “Is it a number?”, “Can I convert it?”.\nRisk: If you forget one check, your app crashes or acts unpredictably."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#with-type-hints",
    "href": "W7/M2/01_fastapi_intro.html#with-type-hints",
    "title": "Introduction to FastAPI",
    "section": "With Type Hints",
    "text": "With Type Hints\nIn FastAPI, you declare the type in the function signature. The framework inspects these signatures at runtime.\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n# FastAPI reads 'float' and handles validation/conversion for you\n@app.post(\"/items/\")\nasync def create_item(price: float):\n    # 'price' is guaranteed to be a float here.\n    return {\"price_with_tax\": price * 1.2}\n\n\nDeclaration: price: float tells FastAPI everything it needs to know.\nAutomatic Parsing: It converts the payload to a float automatically.\nAutomatic 422 Errors: If the user sends “ten”, FastAPI returns a standard error response detailing exactly where the validation failed."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#complex-data-structures-pydantic-models",
    "href": "W7/M2/01_fastapi_intro.html#complex-data-structures-pydantic-models",
    "title": "Introduction to FastAPI",
    "section": "Complex Data Structures (Pydantic Models)",
    "text": "Complex Data Structures (Pydantic Models)\nfrom pydantic import BaseModel\n\nclass Item(BaseModel):\n    name: str\n    price: float\n    tags: list[str] = [] # Optional list of strings\n\n@app.post(\"/items/\")\nasync def create_item(item: Item): \n    # FastAPI validates the JSON body against the 'Item' class schema\n    return item\n\n\nThe Solution: Pydantic Models.\nInstead of writing checks, we write a Blueprint.\nBy inheriting from BaseModel, we tell Pydantic: “This is what an Item should look like.”\nMechanism: When a request comes in, FastAPI checks it against this blueprint.\nIf the tags list is missing? No problem, it provides a default [].\nIf price comes in as the string “5.50”? Pydantic converts it to a float for you."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#editor-support",
    "href": "W7/M2/01_fastapi_intro.html#editor-support",
    "title": "Introduction to FastAPI",
    "section": "Editor Support",
    "text": "Editor Support\n\nThe “Invisible” Feature.\n\nBecause FastAPI uses standard Python types, your IDE (VS Code, PyCharm) understands the code.\n\nScenario: You type item. (dot) inside your function.\nResult: The editor immediately suggests .name, .price, and .tags because it knows item is of type Item.\n\n\n\nConcept: This isn’t just about catching errors; it’s about Developer Experience (DX).\nBecause we use standard Python classes, VS Code (the “Client” in our LSP example from M1) can talk to its Language Server and tell you exactly what fields exist.\nYou don’t have to memorize the database schema. The editor tells you."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#constraints-field",
    "href": "W7/M2/01_fastapi_intro.html#constraints-field",
    "title": "Introduction to FastAPI",
    "section": "Constraints: Field",
    "text": "Constraints: Field\nPydantic uses Field or specialized types to define further constraints.\nfrom pydantic import Field\n\nclass User(BaseModel):\n    # Set: {Strings with length between 3 and 10}\n    username: str = Field(min_length=3, max_length=10)\n\n\nRefining the Mold: Sometimes, saying “it’s a string” isn’t enough.\nA username is a string, but it’s not any string. It can’t be 1 character, and it can’t be 1 million characters.\nField() allows us to add metadata constraints.\nThis is “Declarative Validation”. We declare the rules, and Pydantic enforces them."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#the-annotated",
    "href": "W7/M2/01_fastapi_intro.html#the-annotated",
    "title": "Introduction to FastAPI",
    "section": "The Annotated",
    "text": "The Annotated\nAnnotated was introduced (in PEP 593) to allow “tool-specific metadata” to exist alongside types:\nfrom typing import Annotated\nfrom pydantic import BaseModel, Field\n\nclass User(BaseModel):\n    # The 'int' is the type, the 'Field' is the metadata tag\n    age: Annotated[int, Field(gt=18, lt=100)]\n\nFor editors and other tools, the type of age is still the first thing: str.\nFor Pydantic, it knows to enforce additional constraints specified by Field.\n\n\n\nDeep Dive: Why Annotated?\nPython is a dynamic language. Static type checkers (like Mypy) look at age: int and stop there. They don’t care about min_length.\nAnnotated allows us to serve two masters:\n\nThe Type Checker: Sees int. Happy.\nFastAPI/Pydantic: Sees Field(gt=18). Enforces logic.\n\nIt’s a way to attach “Runtime Metadata” to “Static Types”."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#using-type-hints",
    "href": "W7/M2/01_fastapi_intro.html#using-type-hints",
    "title": "Introduction to FastAPI",
    "section": "Using Type Hints",
    "text": "Using Type Hints\nclass Fruit(BaseModel):\n    # Exclusive OR: either 'red' or 'green'\n    color: Literal['red', 'green']\n\n    # Nested Structure\n    bazam: dict[str, list[tuple[int, bool, float]]]  \n\n\nAdvanced Sculpting:\nLiteral: Think of this as a “Dropdown Menu” or an “Enum”. If the user sends “blue”, the gate slams shut.\nNested Structures: This is where Pydantic shines.\nWe have a dictionary, where keys are strings, and values are lists of tuples…\nTrying to validate this manually would be a nightmare of nested if/for loops.\nHere? It’s one line."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#custom-parsing-functions",
    "href": "W7/M2/01_fastapi_intro.html#custom-parsing-functions",
    "title": "Introduction to FastAPI",
    "section": "Custom Parsing Functions",
    "text": "Custom Parsing Functions\nIf you wish to customize:\n\nOn failure: raise ValueError\nOn success: return\n\nclass User(BaseModel):\n    # Set: {Integers that are even} (Custom Subset)\n    even_id: int\n\n    @field_validator('even_id')\n    def must_be_even(cls, v):\n        if v % 2 != 0: raise ValueError(\"Must be even\")\n        return v\n\n\nPower User Limit: Sometimes, declarative rules (min/max) aren’t enough.\n“Must be an even number” is a logical check, not just a range check.\nThe Hook: Pydantic lets you escape the declarative world and write raw Python functions when you need to.\nIf you raise a ValueError, FastAPI catches it and converts it into a nice generic 422 Unprocessable Entity error for the user."
  },
  {
    "objectID": "W7/M2/01_fastapi_intro.html#key-takeaways-1",
    "href": "W7/M2/01_fastapi_intro.html#key-takeaways-1",
    "title": "Introduction to FastAPI",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nBlueprints: Use Python classes for automatic validation and parsing.\nDX: Type hints enable auto-completion and catch errors early.\nConstraints: Use Field and Annotated for precise data rules.\nValidation: Use @field_validator for custom business logic."
  },
  {
    "objectID": "W7/M2/10x_developer.html",
    "href": "W7/M2/10x_developer.html",
    "title": "Becoming a 10x Developer",
    "section": "",
    "text": "Features:\n\nTrained on code repositories and can assist with most programming languages and frameworks\nProvides code suggestions, explanations, and automated implementations based on natural language prompts and existing code context.\n\nExamples:\n\nMicrosoft’s GitHub Copilot in VS Code\nCursor\nGoogle’s Antigravity"
  },
  {
    "objectID": "W7/M2/10x_developer.html#agents-core-capabilities",
    "href": "W7/M2/10x_developer.html#agents-core-capabilities",
    "title": "Becoming a 10x Developer",
    "section": "Agents Core Capabilities",
    "text": "Agents Core Capabilities\n\nEnd-to-End Autonomy: Agents manage complete coding tasks by breaking down high-level objectives into actionable steps, moving beyond simple code completions or chat.\nSystem Interaction: They can read error messages, modify multiple files simultaneously, execute terminal commands, and verify results (e.g., running tests).\nSelf-Correction: Agents monitor their own progress and adapt their approach if they encounter errors or failed tests during execution."
  },
  {
    "objectID": "W7/M2/10x_developer.html#integration-in-vs-code",
    "href": "W7/M2/10x_developer.html#integration-in-vs-code",
    "title": "Becoming a 10x Developer",
    "section": "Integration in VS Code",
    "text": "Integration in VS Code\n\nFlexible Environments: Sessions can\n\nrun locally (interactive or background) or\nin the cloud for collaborative, remote workflows.\n\nUnified Management: The VS Code Chat view serves as the central hub to monitor, manage, and interact with all active agent sessions."
  },
  {
    "objectID": "W7/M2/10x_developer.html#types-of-agents",
    "href": "W7/M2/10x_developer.html#types-of-agents",
    "title": "Becoming a 10x Developer",
    "section": "Types of Agents",
    "text": "Types of Agents\nVS Code supports four main categories of agents, each designed for different use cases and levels of interaction:\n\n\n\nDiagram showing agent types by environment and interaction.\n\n\nSee: Types of agents."
  },
  {
    "objectID": "W7/M2/10x_developer.html#first-challenger-cursor",
    "href": "W7/M2/10x_developer.html#first-challenger-cursor",
    "title": "Becoming a 10x Developer",
    "section": "First Challenger: Cursor",
    "text": "First Challenger: Cursor\n\nTab, Tab, Tab: “Our custom autocomplete model predicts your next actions.”\n\nTrained on git diff of git commits and Pull Requests (PRs) .. not just code\n\nComposer 1: their 1st proprietry model\n\nTrained specifically for “agentic” coding using reinforcement learning (RL) within actual development environments.\n\nCursor CLI: Built to help you ship, right from your terminal.\n\n\nBetter than VS Code."
  },
  {
    "objectID": "W7/M2/10x_developer.html#new-challengers",
    "href": "W7/M2/10x_developer.html#new-challengers",
    "title": "Becoming a 10x Developer",
    "section": "New Challengers",
    "text": "New Challengers"
  },
  {
    "objectID": "W7/M2/10x_developer.html#antigravity",
    "href": "W7/M2/10x_developer.html#antigravity",
    "title": "Becoming a 10x Developer",
    "section": "Antigravity",
    "text": "Antigravity\n\nHigher-level Abstractions: A more intuitive task-based approach to monitoring agent activity, presenting you with essential artifacts and verification results to build trust.\nCross-surface Agents: Synchronized agentic control across your editor, terminal, and browser for powerful development workflows.\nUser Feedback: Intuitively integrate feedback across surfaces and artifacts to guide and refine the agent’s work.\nAn Agent-First Experience: Manage multiple agents at the same time, across any workspace, from one central mission control view."
  },
  {
    "objectID": "W7/M2/10x_developer.html#why-enterprises-choose-cline",
    "href": "W7/M2/10x_developer.html#why-enterprises-choose-cline",
    "title": "Becoming a 10x Developer",
    "section": "Why enterprises choose Cline",
    "text": "Why enterprises choose Cline\n\n\n\nThe coding agent for enterprises that use any provider in any IDE\n\n\n\nWe don’t see your code and prompts: Client-side architecture. When you bring your own inference, data flows from you to your provider. We’re not in the middle.\nBring your own inference: Connects directly to Amazon Bedrock, GCP Vertex, Azure OpenAI, or models running on your servers. Keep data within your security perimeter.\nDeploy on your infrastructure: Secure your data by deploying within VPC, on-prem, or air-gapped environments. You control where it runs and how it’s configured."
  },
  {
    "objectID": "W7/M2/10x_developer.html#tokens-and-pricing",
    "href": "W7/M2/10x_developer.html#tokens-and-pricing",
    "title": "Becoming a 10x Developer",
    "section": "Tokens and Pricing",
    "text": "Tokens and Pricing\nHow do these models think and how much they cost?\nSee: Tokens & Pricing | Cursor"
  },
  {
    "objectID": "W7/M2/10x_developer.html#essential-ide-tips-and-tricks",
    "href": "W7/M2/10x_developer.html#essential-ide-tips-and-tricks",
    "title": "Becoming a 10x Developer",
    "section": "Essential IDE Tips and Tricks",
    "text": "Essential IDE Tips and Tricks\nBefore working with AI, let’s work with the IDE:\nPersonalize the look and feel:\n\nSet your Theme ~ 2 min\nSet your Font to ‘Fira Code’ ~ 2 min\n\nMemorize these tricks:\n\nCode Navigation ~ 10 min\nEditing Hacks! ~ 10–15 min\n\nCompare Files\n\nDefine your own Snippets! ~ 10 min"
  },
  {
    "objectID": "W7/M2/10x_developer.html#ai-ide-tips-and-tricks",
    "href": "W7/M2/10x_developer.html#ai-ide-tips-and-tricks",
    "title": "Becoming a 10x Developer",
    "section": "AI-IDE Tips and Tricks",
    "text": "AI-IDE Tips and Tricks\nNow, let’s focus on how the IDE makes AI work for us:\n\nCopilot Smart Actions ~ 5 min\nPrompt engineering ~ 15 min\nContext Engineering ~ 10 min\n\n\nNever, copy-paste into ChatGPT anymore.\n\nImprove the feedback loop:\n\nTest-Driven Development ~ 10 min\nDebug with AI ~ 5 min\n\nDoing Data Science?\n\nEdit Notebooks with AI ~ 5 min\n\nNecessary customizations:\n\nProblem 1: “AI writes out-of-date code”\nProblem 2: “I want AI to also write commands, not just code”\n…etc.\n\nEnter: GitHub Copilot Customization ~ 10 min\n\nUse MCP servers in VS Code ~ 10 min\nMCP Tools:\n\nContext7 (Upstash): ~ 5 min (Solution to Problem 1)\nDBHub (Bytebase): ~ 5 min (Solution to Problem 2)\nUnity MCP: Control the Unity Editor from MCP clients via a Unity bridge + local Python server.\n\n\nReference:\n\nReference Cheat Sheet"
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#the-hook",
    "href": "W7/M3/01_building_mcp_servers.html#the-hook",
    "title": "Building MCP Servers",
    "section": "The Hook",
    "text": "The Hook\n\n\n\nFigure: A stylized bridge connecting chaotic data islands to an organized AI agent, representing a standardized protocol.\n\n\nHow do we bridge the gap between our data and AI agents in a standardized, scalable way?\n\nWe have powerful LLMs, and we have our valuable data and business logic. But connecting them has been a messy process of custom integrations and brittle glue code. We need a standard. We need a protocol. That’s what MCP is. Today, we’re going to master the art of building these connectors in Python. We’ll start with the foundational SDK, discover how to speed up development with FastMCP, and finally, learn how to instantly AI-enable our existing web applications."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#todays-journey",
    "href": "W7/M3/01_building_mcp_servers.html#todays-journey",
    "title": "Building MCP Servers",
    "section": "Today’s Journey",
    "text": "Today’s Journey\n\nThe Foundation (MCP Python SDK)\n\nCore concepts: Server, Resources, Tools, Prompts\nUnderstanding the primitives\n\nThe Accelerator (FastMCP)\n\nDeveloper experience first\nDecorators and simplified patterns\n\nThe Bridge (FastAPI-MCP)\n\nIntegrating with existing web apps\nPreserving auth and documentation\n\n\n\nOur journey today has three distinct stages. First, we’ll build the foundation by exploring the official MCP Python SDK. This gives us a deep understanding of the core concepts: Servers, Resources, Tools, and Prompts. Next, we’ll accelerate our workflow with FastMCP, a tool designed to let us “move fast and make things” by removing boilerplate. Finally, we’ll cross the bridge to the real world with FastAPI-MCP, showing how to expose our existing FastAPI applications to agents with zero friction."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#the-problem-the-integration-mess",
    "href": "W7/M3/01_building_mcp_servers.html#the-problem-the-integration-mess",
    "title": "Building MCP Servers",
    "section": "The Problem: The Integration Mess",
    "text": "The Problem: The Integration Mess\nConnecting AI to data is hard\n\nEvery tool has a unique API\nEvery LLM needs custom glue code\nN tools \\(\\times\\) M models = N \\(\\times\\) M integrations\nFragile, hard to maintain, not scalable\n\nWe need a standard protocol.\n\nBefore we define MCP, let’s understand the problem it solves. Right now, connecting AI to data is a mess. Every tool has a different API, and every model provider requires a different format for tools. If you have N tools and M models, you end up writing N times M integration scripts. It’s fragile, it’s hard to maintain, and it doesn’t scale. We need a universal standard."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#what-is-mcp",
    "href": "W7/M3/01_building_mcp_servers.html#what-is-mcp",
    "title": "Building MCP Servers",
    "section": "What is MCP?",
    "text": "What is MCP?\nModel Context Protocol\n\nStandardized way to connect LLMs to tools and data\nLike a web API, but for AI interaction\nSeparates context from intelligence\n\n\nThink of the Model Context Protocol, or MCP, as HTTP for AI agents. It’s a standardized way to connect Large Language Models to the tools and data they need. Instead of building custom integrations for every model, MCP provides a uniform structure. It neatly separates the distinct challenge of providing context from the interaction with the LLM itself."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#step-1-install-the-sdk",
    "href": "W7/M3/01_building_mcp_servers.html#step-1-install-the-sdk",
    "title": "Building MCP Servers",
    "section": "Step 1: Install the SDK",
    "text": "Step 1: Install the SDK\nGet the official library:\nuv add mcp\nImport in Python:\nimport mcp\nfrom mcp.server.mcpserver import MCPServer\n\nGetting started is simple. We install the official mcp package using uv. This provides all the core primitives we need to build our server. Then, we import the MCPServer class, which will be our main entry point."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#the-core-concept-server",
    "href": "W7/M3/01_building_mcp_servers.html#the-core-concept-server",
    "title": "Building MCP Servers",
    "section": "The Core Concept: Server",
    "text": "The Core Concept: Server\n\n\nMCPServer is your main interface\nfrom mcp.server.mcpserver import MCPServer\n\nmcp = MCPServer(\"Demo\")\n\nHandles connection management\nProtocol compliance\nMessage routing\nLifecycle management\n\n\n\n\n\nFigure: A central server rack with a Python logo connecting to smaller nodes as a hub. (Click to Enlarge)\n\n\n\n\nIn the official SDK, the MCPServer instance is your main interface. You initialize it with a name, and it handles the heavy lifting: managing connections, ensuring protocol compliance, routing messages, and handling the application lifecycle. It’s the robust foundation we build upon."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#resources-reading-data",
    "href": "W7/M3/01_building_mcp_servers.html#resources-reading-data",
    "title": "Building MCP Servers",
    "section": "Resources: Reading Data",
    "text": "Resources: Reading Data\n\n\nExpose data to LLMs\n@mcp.resource(\"file://documents/{name}\")\ndef read_document(name: str) -&gt; str:\n    \"\"\"Read a document by name.\"\"\"\n    return f\"Content of {name}\"\n\nRead-only data sources (like GET requests)\nSide-effect free (mostly)\nURI templates for dynamic access\n\n\n\n\n\nFigure: A magnified open document folder symbolizing read-only access to structured data.\n\n\n\n\nResources are how we get data into the LLM’s context. Think of them like GET endpoints in a REST API. They are designed for reading files, fetching database rows, or retrieving system state. They should be side-effect free—interaction with them shouldn’t change the state of the world significantly."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#tools-taking-action",
    "href": "W7/M3/01_building_mcp_servers.html#tools-taking-action",
    "title": "Building MCP Servers",
    "section": "Tools: Taking Action",
    "text": "Tools: Taking Action\n\n\nLet LLMs perform computations\n@mcp.tool()\ndef add(a: int, b: int) -&gt; int:\n    \"\"\"Add two numbers together.\"\"\"\n    return a + b\n\nPerform computation or actions\nSide effects allowed (database writes, API calls)\nModel-controlled execution\n\n\n\n\n\nFigure: Interlocking gears and a wrench interacting with a data block to symbolize active computation.\n\n\n\n\nWhen the agent needs to do something, it uses Tools. These are the functional counterparts to resources. Tools allow the LLM to perform computations, query databases, or call external APIs. This is where the agency comes in—the LLM decides when to call a tool and what arguments to pass."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#prompts-interaction-templates",
    "href": "W7/M3/01_building_mcp_servers.html#prompts-interaction-templates",
    "title": "Building MCP Servers",
    "section": "Prompts: Interaction Templates",
    "text": "Prompts: Interaction Templates\n\n\nReusable templates for users\n@mcp.prompt(title=\"Code Review\")\ndef review_code(code: str) -&gt; str:\n    return f\"Please review this code:\\n\\n{code}\"\n\nUser-controlled invocation\nStandard workflows (e.g., “Fix Bug”, “Summarize”)\nPre-packaged instructions\n\n\n\n\n\nFigure: A clipboard with a structured form and pencil representing reusable templates.\n\n\n\n\nPrompts are reusable templates for interactions. Think of them as slash commands or menu options for the user. They provide a structured way to start a task, like “Review this code” or “Check system health,” making standard workflows repeatable and easy to use."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#part-2-the-accelerator-fastmcp",
    "href": "W7/M3/01_building_mcp_servers.html#part-2-the-accelerator-fastmcp",
    "title": "Building MCP Servers",
    "section": "Part 2: The Accelerator (FastMCP)",
    "text": "Part 2: The Accelerator (FastMCP)"
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#framework-vs-library",
    "href": "W7/M3/01_building_mcp_servers.html#framework-vs-library",
    "title": "Building MCP Servers",
    "section": "Framework vs Library",
    "text": "Framework vs Library\nThe Distinction:\n\nMCP SDK (Library): “Mechanism, not Policy.” Provides the plumbing (JSON-RPC, Core Types). precise, but low-level.\nFastMCP (Framework): “Batteries Included.” Provides the policy (Decorators, Validation). Opinionated and fast.\n\nThe Engineering Trade-off: Control vs. Velocity\n\nFrom an engineering perspective, the distinction is between a library and a framework. The official SDK is a library—it gives you the mechanisms (the plumbing of JSON-RPC) but enforces no policy. FastMCP is a framework—it gives you the policy (decorators, validation) and batteries. The trade-off is classic: do you want absolute control over the bits, or do you want development velocity?"
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#the-implementation-gap",
    "href": "W7/M3/01_building_mcp_servers.html#the-implementation-gap",
    "title": "Building MCP Servers",
    "section": "The Implementation Gap",
    "text": "The Implementation Gap\n\n\n\nRaw SDK (Plumbing)\n# 1. Manual Schema\nTool(\n    name=\"get_weather\",\n    inputSchema={\n        \"type\": \"object\",\n        \"properties\": {\n            \"city\": {\"type\": \"string\"}\n        }\n    }\n)\n\n# 2. Manual Routing\nif name == \"get_weather\":\n    city = args[\"city\"]\n    return f\"Sunny in {city}\"\n\n\nFastMCP (Framework)\n# 1. Logic is Interface\n@mcp.tool()\ndef get_weather(city: str) -&gt; str:\n    \"\"\"Get current weather\"\"\"\n    return f\"Sunny in {city}\"\n\n\n\n\nLet’s look at the code side-by-side to see the real impact. On the left, with the Raw SDK, you are manually defining JSON schemas and writing if/else routing blocks. On the right, with FastMCP, your code is the interface. The schema is inferred from your type hints. This isn’t just about saving keystrokes; it’s about eliminating a whole class of bugs."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#the-hidden-cost-schema-drift",
    "href": "W7/M3/01_building_mcp_servers.html#the-hidden-cost-schema-drift",
    "title": "Building MCP Servers",
    "section": "The Hidden Cost: Schema Drift",
    "text": "The Hidden Cost: Schema Drift\nWhen implementation diverges from definition.\n\nSDK: You update the code, but forget the JSON schema. \\(\\rightarrow\\) Runtime Error.\nFastMCP: Single source of truth. The code generates the schema.\n\nIn 2026, manual schema maintenance is technical debt.\n\nThe biggest problem isn’t verbosity; it’s Schema Drift. In the SDK approach, if you change your function arguments but forget to update the manual JSON schema, you have a bug that only explodes at runtime. In FastMCP, type introspection ensures your schema and code are always perfectly in sync. Manual schema maintenance is a technical debt risk we can avoid."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#step-1-install-fastmcp",
    "href": "W7/M3/01_building_mcp_servers.html#step-1-install-fastmcp",
    "title": "Building MCP Servers",
    "section": "Step 1: Install FastMCP",
    "text": "Step 1: Install FastMCP\nInstallation:\nuv add \"fastmcp\"\nThat’s it.\n\nInstallation is just as easy. Add the fastmcp package. It includes everything you need, including the CLI tools for development and the dependencies for running the server."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#comparison-the-batteries",
    "href": "W7/M3/01_building_mcp_servers.html#comparison-the-batteries",
    "title": "Building MCP Servers",
    "section": "Comparison: The “Batteries”",
    "text": "Comparison: The “Batteries”\n\n\n\nFeature\nRaw SDK\nFastMCP\n\n\n\n\nRegistration\nManual list_tools\n@mcp.tool\n\n\nValidation\nManual Checks\nAutomatic (Pydantic)\n\n\nObservability\nSelf-Implemented\nOpenTelemetry Native\n\n\nDrift Risk\nHigh\nNone\n\n\n\n\nHere is the capabilities matrix. FastMCP adds the layer that the SDK explicitly leaves out: automatic validation, native observability via OpenTelemetry, and zero-config tool registration. It fills the “gap” between the raw protocol and a production-ready application."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#core-abstractions",
    "href": "W7/M3/01_building_mcp_servers.html#core-abstractions",
    "title": "Building MCP Servers",
    "section": "Core Abstractions",
    "text": "Core Abstractions\n\n\n\nComponents: What you expose (Tools, Resources, Prompts)\nProviders: Where they come from (Functions, Files, OpenAPI)\nTransforms: How they look (Namespacing, Filtering)\n\n\n\n\n\nFigure: A circular flow diagram showing Providers, Transformers, and Components in a data refinement cycle.\n\n\n\n\nFastMCP organizes the world into three concepts. Components are what you expose. Providers are where those components come from—your functions, files on disk, or even an external API spec. And Transforms let you shape that data—renaming tools, filtering them for security, or versioning your API. It’s a powerful compositional model."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#running-fastmcp",
    "href": "W7/M3/01_building_mcp_servers.html#running-fastmcp",
    "title": "Building MCP Servers",
    "section": "Running FastMCP",
    "text": "Running FastMCP\nDevelopment (Hot Reload)\nfastmcp dev server.py\nProduction\nif __name__ == \"__main__\":\n    mcp.run() # Auto-selects streamable-http\n\nFor development, fastmcp dev gives you hot reloading and an inspector to test your tools. For production, mcp.run() automatically selects the robust streamable-HTTP transport. It covers the full lifecycle of your application development."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#part-3-the-bridge-fastapi-mcp",
    "href": "W7/M3/01_building_mcp_servers.html#part-3-the-bridge-fastapi-mcp",
    "title": "Building MCP Servers",
    "section": "Part 3: The Bridge (FastAPI-MCP)",
    "text": "Part 3: The Bridge (FastAPI-MCP)"
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#the-integration-challenge",
    "href": "W7/M3/01_building_mcp_servers.html#the-integration-challenge",
    "title": "Building MCP Servers",
    "section": "The Integration Challenge",
    "text": "The Integration Challenge\n\n\nYou have a FastAPI app.\n\nDo you rewrite it for MCP?\nDo you duplicate your authentication?\nDo you maintain two codebases?\n\nNo. You Mount.\n\n\n\n\nFigure: A split-screen showing an overwhelmed developer facing duplicate stacks of FastAPI and MCP code.\n\n\n\n\nNow, what if you already have a massive FastAPI application? Rewriting everything as MCP tools would be a nightmare of duplication—logic, auth, validation. We don’t want two codebases. We want to expose our existing investment to the AI world."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#step-1-install-fastapi-mcp",
    "href": "W7/M3/01_building_mcp_servers.html#step-1-install-fastapi-mcp",
    "title": "Building MCP Servers",
    "section": "Step 1: Install FastAPI-MCP",
    "text": "Step 1: Install FastAPI-MCP\nAdd the package:\nuv add \"fastapi-mcp\"\nRequirements: - Existing FastAPI app - Python 3.10+\n\nTo bridge the gap, we use the fastapi-mcp package. Install it alongside your existing FastAPI application. It’s a lightweight wrapper that brings MCP capabilities to your existing routes."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#fastapi-mcp-one-app-two-interfaces",
    "href": "W7/M3/01_building_mcp_servers.html#fastapi-mcp-one-app-two-interfaces",
    "title": "Building MCP Servers",
    "section": "FastAPI-MCP: One App, Two Interfaces",
    "text": "FastAPI-MCP: One App, Two Interfaces\n\n\nfrom fastapi import FastAPI\nfrom fastapi_mcp import FastApiMCP\n\napp = FastAPI()\nmcp = FastApiMCP(app)\n\nmcp.mount() # Adds /mcp endpoint\n\nZero Config: Point at your app, it works\nNative Integration: Uses ASGI (in-memory, fast)\nPreserves Auth: Depends(...) just works\n\n\n\n\n\nFigure: A visual transformation showing FastAPI and MCP blocks merging into a single unified block.\n\n\n\n\nThis is fastapi-mcp. With essentially three lines of code, you mount an MCP server inside your FastAPI app. It automatically discovers your routes and converts them into MCP tools. It uses the efficient ASGI transport, so there’s no network overhead. And crucially, it respects your existing authentication."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#what-gets-preserved",
    "href": "W7/M3/01_building_mcp_servers.html#what-gets-preserved",
    "title": "Building MCP Servers",
    "section": "What Gets Preserved?",
    "text": "What Gets Preserved?\nEverything.\n\nRequest Models \\(\\rightarrow\\) Tool Input Schemas\nResponse Models \\(\\rightarrow\\) Tool Output Schemas\nDocstrings \\(\\rightarrow\\) Tool Descriptions\nDependencies \\(\\rightarrow\\) Security & Context\n\n\nWhen I say it converts your routes, I mean it does it intelligently. Your Pydantic request models become strict input schemas for the LLM. Your response models define the output structure. Your docstrings become the instructions for the agent. And your dependencies—like database sessions or user context—are fully preserved."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#deployment-options",
    "href": "W7/M3/01_building_mcp_servers.html#deployment-options",
    "title": "Building MCP Servers",
    "section": "Deployment Options",
    "text": "Deployment Options\n1. Mounted (Monolith)\n\nSimplest. One container, one process.\nBest for most use cases.\n\n2. Separate (Microservices)\n\nScale independently.\nmcp = FastApiMCP(original_app_url=...)\nGood for high-traffic separation.\n\n\nYou have choices in deployment. You can mount it directly, which is the simplest “monolithic” approach—perfect for most teams. Or, if you need to scale your AI traffic separately from your user traffic, you can deploy the MCP server as a separate microservice that proxies requests to your main API."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#key-takeaways",
    "href": "W7/M3/01_building_mcp_servers.html#key-takeaways",
    "title": "Building MCP Servers",
    "section": "Key Takeaways",
    "text": "Key Takeaways"
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#the-foundation-sdk",
    "href": "W7/M3/01_building_mcp_servers.html#the-foundation-sdk",
    "title": "Building MCP Servers",
    "section": "The Foundation (SDK)",
    "text": "The Foundation (SDK)\n\nServer: The central hub governing the protocol\nResources: Reading data (File://, DB://) safely\nTools: Executing actions (API calls, side effects)\nPrompts: Reusable templates for user interaction\n\n\nLet’s recap the core pillars. The SDK gives us the Server, our central hub. We use Resources to read data safely, Tools to perform actions and computations, and Prompts to create reusable templates for our users. This is the raw material of any MCP server."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#fastmcp-benefits",
    "href": "W7/M3/01_building_mcp_servers.html#fastmcp-benefits",
    "title": "Building MCP Servers",
    "section": "FastMCP Benefits",
    "text": "FastMCP Benefits\n\nDeveloper Experience: “Move fast and make things”\nLess Boilerplate: No manual JSON schemas\nType Inference: Python hints \\(\\rightarrow\\) MCP Specs\nInstant Dev Server: Hot reloading included\n\n\nFastMCP takes that foundation and accelerates it. It prioritizes developer experience, removing the need for manual schema definitions by inferring everything from your Python type hints. Plus, the built-in dev server with hot reloading makes iteration a breeze."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#fastapi-integration",
    "href": "W7/M3/01_building_mcp_servers.html#fastapi-integration",
    "title": "Building MCP Servers",
    "section": "FastAPI Integration",
    "text": "FastAPI Integration\n\nZero Rewrite: Mount existing app as MCP server\nProtocol Agnostic: HTTP/SSE handled automatically\nSecurity Preserved: Existing Depends() just work\nDual Interface: Serve humans and agents simultaneously\n\n\nAnd for our existing applications, FastAPI-MCP offers a zero-rewrite solution. By mounting your app, you get protocol handling for free, you preserve your existing security model, and you serve both human users and AI agents from a single codebase."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#which-tool-when-12",
    "href": "W7/M3/01_building_mcp_servers.html#which-tool-when-12",
    "title": "Building MCP Servers",
    "section": "Which Tool When? (1/2)",
    "text": "Which Tool When? (1/2)\n\nMCP Python SDK\n\nYou need full control over the protocol.\nYou are building low-level custom integrations.\nYou are building an MCP Client.\n\nFastMCP\n\nYou are building a new server from scratch.\nYou want speed and simplicity.\nYou want built-in best practices.\n\n\n\nSo, which tool should you reach for? Use the Official SDK if you need low-level control or are building a client. Reach for FastMCP if you’re building a new server from scratch and want the best developer experience."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#which-tool-when-22",
    "href": "W7/M3/01_building_mcp_servers.html#which-tool-when-22",
    "title": "Building MCP Servers",
    "section": "Which Tool When? (2/2)",
    "text": "Which Tool When? (2/2)\n\nFastAPI-MCP\n\nYou have an existing FastAPI application.\nYou want to reuse logic, auth, and models.\nYou want to become AI-Ready instantly.\n\n\n\n… And use FastAPI-MCP if you’re sitting on a goldmine of existing FastAPI services that you want to open up to the new world of AI agents."
  },
  {
    "objectID": "W7/M3/01_building_mcp_servers.html#the-complete-picture",
    "href": "W7/M3/01_building_mcp_servers.html#the-complete-picture",
    "title": "Building MCP Servers",
    "section": "The Complete Picture",
    "text": "The Complete Picture\n\n\nYou are now equipped to build.\n\nFoundational understanding\nRapid development tools\nIntegration strategies\n\nGo connect your world.\n\n\n\n\nFigure: A three-layered pyramid showing the SDK foundation, FastMCP builder tools, and FastAPI-MCP bridge.\n\n\n\n\nYou now have the complete picture. You understand the foundation, you have the tools for speed, and you have the bridge for integration. The era of isolated data is over. You are now equipped to build the connectors that will power the next generation of AI applications. Go connect your world."
  },
  {
    "objectID": "W7/M5/01_deployment.html#the-works-on-my-machine-problem",
    "href": "W7/M5/01_deployment.html#the-works-on-my-machine-problem",
    "title": "Module 5: Deployment",
    "section": "The “Works on My Machine” Problem",
    "text": "The “Works on My Machine” Problem\n\nFigure: Local vs. Production environment gap.\nLocal: You control everything.\nProduction: The untamed wild.\nGoal: Bridge the gap reliably.\n\n\n\nHook: We’ve all been there. It runs perfectly on your laptop, but fails the moment you show it to someone else.\nContext: In the previous modules, we built an API, containerized it, and connected a database. But it’s still trapped on your machine.\nThe Gap: Deployment is about crossing the chasm between a controlled local environment and the public internet. Today, we make your work real."
  },
  {
    "objectID": "W7/M5/01_deployment.html#the-road-to-production",
    "href": "W7/M5/01_deployment.html#the-road-to-production",
    "title": "Module 5: Deployment",
    "section": "The Road to Production",
    "text": "The Road to Production\n\nConfiguration: Separating secrets from code.\nPlatform: Hosting on Railway (PaaS).\nDatabase: Managed storage & networking.\nAutomation: Continuous Deployment interactions.\nDiagnostics: validation & logs.\n\n\n\nLay of the Land: Here is our journey for this module.\nStep 1: We start by securing our app with Environment Variables.\nStep 2: We choose a home for it—Railway, a Platform as a Service.\nStep 3: We give it memory by provisioning a production database.\nStep 4: We automate the process so we never manually copy files again.\nStep 5: Finally, we learn how to fix it when things break."
  },
  {
    "objectID": "W7/M5/01_deployment.html#configuration-code-vs.-environment",
    "href": "W7/M5/01_deployment.html#configuration-code-vs.-environment",
    "title": "Module 5: Deployment",
    "section": "Configuration: Code vs. Environment",
    "text": "Configuration: Code vs. Environment\n\nFigure: Separation of code and configuration.\nRule: Code and Config must be strictly separated.\nPython:\nimport os\n# Reads from System Env or .env file\ndb_url = os.getenv(\"DATABASE_URL\")\nWhy: Security (Secrets) & Flexibility.\n\n\n\nDefinition: The “12-Factor App” methodology states strict separation of config from code.\nCode: Notice the Python snippet. We don’t hardcode the URL. We ask the Operating System for it.\nBenefit: This allows the same code to run locally (reading from a .env file) and in production (reading from the platform’s secret store)."
  },
  {
    "objectID": "W7/M5/01_deployment.html#the-binding-contract-host-port",
    "href": "W7/M5/01_deployment.html#the-binding-contract-host-port",
    "title": "Module 5: Deployment",
    "section": "The Binding Contract: Host & Port",
    "text": "The Binding Contract: Host & Port\n\nFigure: Localhost vs. Public interface binding.\n127.0.0.1 (Localhost): Listening inside the house (Loopback).\n0.0.0.0 (Any): Listening at the front door (Public).\n$PORT: The specific door number assigned by the cloud.\n\n\n\nThe Problem: By default, apps run on localhost (127.0.0.1). This is secure—only you can access it.\nFix: For deployment, we must listen on 0.0.0.0. This tells the app to accept connections from the outside world.\nThe Port: We don’t verify the port (like 8000). The Cloud Provider gives us a dynamic port variable $PORT that we must use."
  },
  {
    "objectID": "W7/M5/01_deployment.html#the-start-command",
    "href": "W7/M5/01_deployment.html#the-start-command",
    "title": "Module 5: Deployment",
    "section": "The Start Command",
    "text": "The Start Command\n\nFigure: The web server start command.\nPurpose: Tells the platform how to run your app.\nProcfile: Standard file for run commands (web: uvicorn ...).\nFlags: --host 0.0.0.0 and --port $PORT.\n\n\n\nThe Instruction: Installing dependencies is not enough; the server needs to know what command starts the web server.\nProcfile: We often use a Procfile to declare this: “web equals this command”.\nVital Flags: We explicitly pass the host and port arguments we just learned about."
  },
  {
    "objectID": "W7/M5/01_deployment.html#about-railway",
    "href": "W7/M5/01_deployment.html#about-railway",
    "title": "Module 5: Deployment",
    "section": "About Railway",
    "text": "About Railway\n\nFigure: PaaS deployment workflow.\nFlexible Sources: Deploy from Repo (Code) or Registry (Docker Image).\nHassle-Free: Sane defaults & Zero Config out of the box.\nOperational Model: “Push to Deploy” with built-in observability.\n\n\n\nWhat is Railway? It’s a modern cloud deployment platform designed for instant deployments and effortless scaling.\nFlexibility: You can point it to a GitHub repo (it builds the image for you) or bring your own Docker image.\nPhilosophy: It emphasizes “Sane Defaults”. You don’t need a PhD in Kubernetes to get online. It just works."
  },
  {
    "objectID": "W7/M5/01_deployment.html#provisioning-postgresql",
    "href": "W7/M5/01_deployment.html#provisioning-postgresql",
    "title": "Module 5: Deployment",
    "section": "Provisioning PostgreSQL",
    "text": "Provisioning PostgreSQL\n\nFigure: Internal networking between services.\nManaged Service: Automated backups, updates, and scaling.\nInternal Networking: Secure communication (private IP).\nConnection: DATABASE_URL env var auto-injected.\n\n\n\nThe Database: Moving your database to production is scary. Data loss is permanent.\nManaged Services: We use a “Managed” Postgres. Railway handles backups and uptime.\nNetworking: Crucially, your web app talks to the database over an private internal network, not the public internet. It’s faster and more secure.\nAuto-Magic: Railway often auto-injects the connection string as DATABASE_URL, simplifying configuration."
  },
  {
    "objectID": "W7/M5/01_deployment.html#step-1-preparation",
    "href": "W7/M5/01_deployment.html#step-1-preparation",
    "title": "Module 5: Deployment",
    "section": "Step 1: Preparation",
    "text": "Step 1: Preparation\n\nFigure: Python project dependency manifests.\npyproject.toml: Project metadata & dependencies (managed by uv).\nuv.lock: Lockfile for reproducible builds.\nProcfile: Defines the start command (e.g., web: dbmate --wait up && uvicorn ...).\n\n\n\nModern Python: We use uv locally, so we rely on pyproject.toml instead of requirements.txt.\nThe Wait Flag: In the Procfile, we use dbmate --wait up. This is crucial because it tells our app to wait until the database is ready before applying migrations and starting the server.\nAutomation: This ensures that every deployment automatically updates your database schema before your code runs."
  },
  {
    "objectID": "W7/M5/01_deployment.html#step-2-connection",
    "href": "W7/M5/01_deployment.html#step-2-connection",
    "title": "Module 5: Deployment",
    "section": "Step 2: Connection",
    "text": "Step 2: Connection\n\nFigure: Connecting GitHub to the deployment platform.\nSource: Connect GitHub account.\nRepo: Select your project repository.\nTrigger: “Deploy Now” (starts initial build).\n\n\n\nLinking Up: We don’t upload files. We link our GitHub repository.\nAccess: This gives Railway permission to read our code and watch for changes.\nFirst Run: It will try to deploy immediately. It might fail if config is missing—that’s okay."
  },
  {
    "objectID": "W7/M5/01_deployment.html#step-3-variables",
    "href": "W7/M5/01_deployment.html#step-3-variables",
    "title": "Module 5: Deployment",
    "section": "Step 3: Variables",
    "text": "Step 3: Variables\n\nFigure: Configuring environment variables.\nDashboard: Go to “Variables” tab.\nSecrets: Add OPENAI_API_KEY, passwords, etc.\nRedeploy: Changing variables triggers a restart.\n\n\n\nInjecting Secrets: Remember the 12-Factor App? This is where we input those values.\nSecurity: These values are encrypted and injected into the container at runtime. The public never sees them."
  },
  {
    "objectID": "W7/M5/01_deployment.html#step-4-provision-database",
    "href": "W7/M5/01_deployment.html#step-4-provision-database",
    "title": "Module 5: Deployment",
    "section": "Step 4: Provision Database",
    "text": "Step 4: Provision Database\n\nFigure: Provisioning a managed database service.\nAction: Add “PostgreSQL” service (Plugin).\nWiring: Railway auto-injects DATABASE_URL variable.\nMigrations: Handled via dbmate on startup.\n\n\n\nOne-Click Power: We click “New Service” -&gt; “Database”.\nMagic: Railway spins up a Postgres container and automatically sets the DATABASE_URL variable in our web app.\nThe Handshake: Because of our Procfile command (dbmate --wait up), the moment this variable is available, our app will apply any new migrations to the production database automatically."
  },
  {
    "objectID": "W7/M5/01_deployment.html#step-5-verification",
    "href": "W7/M5/01_deployment.html#step-5-verification",
    "title": "Module 5: Deployment",
    "section": "Step 5: Verification",
    "text": "Step 5: Verification\n\nFigure: Verifying the deployed API.\nPublic URL: https://your-project.up.railway.app\nRoutes: Check /docs for Swagger UI.\nTest: Make a live request.\n\n\n\nThe Moment of Truth: Click the generatd URL.\nDocs: If you see the Swagger UI, your API is alive effectively.\nLive: You can now send this link to anyone in the world."
  },
  {
    "objectID": "W7/M5/01_deployment.html#continuous-deployment-environments",
    "href": "W7/M5/01_deployment.html#continuous-deployment-environments",
    "title": "Module 5: Deployment",
    "section": "Continuous Deployment & Environments",
    "text": "Continuous Deployment & Environments\n\nFigure: Continuous Deployment lifecycle and environments.\nTrigger: git push triggers build & deploy.\nEnvironments: Supports Static (Prod) and Ephemeral (PR Previews).\nWorkflow: Test changes in a unique URL before merging.\n\n\n\nAutomation: The act of saving your code is the deployment mechanism.\nEnvironments: Railway isn’t just for Production.\nReview Apps: It can create “Ephemeral Environments” for every Pull Request. You get a unique URL to test your changes (like a new feature) in isolation before merging to main."
  },
  {
    "objectID": "W7/M5/01_deployment.html#diagnostics-when-things-break",
    "href": "W7/M5/01_deployment.html#diagnostics-when-things-break",
    "title": "Module 5: Deployment",
    "section": "Diagnostics: When Things Break",
    "text": "Diagnostics: When Things Break\n\nFigure: Monitoring build and application logs.\nBuild Logs: Why did the build fail? (e.g., missing dependencies).\nDeploy Logs: Why did the container crash? (e.g., migration failures).\nWeb Console: Real-time feedback on migrations & startup.\n\n\n\nReality Check: Your first deployment will likely fail. That’s normal.\nThe Detective Work: Check the Deploy Logs. If dbmate fails (e.g., a syntax error in your migration SQL), the app won’t start.\nWait Timeout: If the database takes too long to respond, dbmate --wait will timeout (default 60s). This is also visible in the logs."
  },
  {
    "objectID": "W7/M5/01_deployment.html#key-takeaways",
    "href": "W7/M5/01_deployment.html#key-takeaways",
    "title": "Module 5: Deployment",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nFigure: Key takeaways for successful deployment.\nSeparate Config: Use Env Vars, never hardcode secrets.\nTrust the Platform: Let PaaS handle the infrastructure.\nAutomate: git push should be your only deployment command.\nObserve: Logs are your eyes and ears in production.\n\n\n\nSummary: We’ve transformed a local script into a global service.\nReview: We secured it with config, hosted it on a managed platform, automated updates with Git, and learned how to debug it.\nNext: Your API is now ready for real users."
  },
  {
    "objectID": "W7/index.html",
    "href": "W7/index.html",
    "title": "AI Pros Bootcamp",
    "section": "",
    "text": "Back to Index."
  }
]