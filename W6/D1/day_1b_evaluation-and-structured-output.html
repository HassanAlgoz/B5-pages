<!DOCTYPE html>
<html lang="en"><head>
<link href="../../assets/icon.svg" rel="icon" type="image/svg+xml">
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.26">

  <meta name="author" content="malfadly@sdaia.gov.sa">
  <title>AI Pros Bootcamp – Day 1b: Evaluation and Structured Output</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-2476b6dbe24137c74cb80772f2f63bf0.css">
  <link rel="stylesheet" href="../../assets/sdaia.scss">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <link rel="icon" href="../../assets/icon.svg">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-image="../../assets/anim.svg" data-background-opacity="0.1" class="quarto-title-block center">
  <h1 class="title">Day 1b: Evaluation and Structured Output</h1>

<div class="quarto-title-authors">
</div>

</section>
<section id="session-overview" class="slide level2">
<h2>Session Overview</h2>
<p><strong>Evaluation and Structured Output</strong></p>
<ul>
<li>Structured Output: JSON, schemas, parsing</li>
<li>Evaluation Methods</li>
<li>Pointwise Evaluation</li>
<li>Pairwise Evaluation</li>
<li>Best Practices</li>
</ul>
<aside class="notes">
<p>This session has five main parts. First, we’ll learn how to get structured outputs - instead of free-form text, you’ll get JSON or other structured data that’s easy to parse and use in your applications.</p>
<p>Then we’ll dive into evaluation. Pointwise evaluation scores individual responses - is this answer good or bad? Pairwise evaluation compares two responses - which one is better? And we’ll discuss when to use each method and how to choose the right evaluation approach.</p>
<p>Finally, we’ll cover best practices for documenting and tracking your prompt engineering work, which is essential for iterative improvement.</p>
<p>These skills are what separate prototyping from production. Anyone can get a response from ChatGPT. But building an application that reliably produces good, structured outputs and can evaluate its own performance? That requires these techniques.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section>
<section id="session-2-evaluation-and-structured-output" class="title-slide slide level1 center">
<h1>Session 2: Evaluation and Structured Output</h1>

</section>
<section id="the-problem-with-free-form-text" class="slide level2">
<h2>The Problem with Free-Form Text</h2>
<p><strong>Unstructured outputs are hard to use</strong></p>
<pre><code>Response: "The user seems happy based on the 
emojis and positive words in their message."</code></pre>
<ul>
<li>Requires parsing</li>
<li>Error-prone extraction</li>
<li>Inconsistent formatting</li>
<li>Hard to validate</li>
</ul>
<aside class="notes">
<p>When you ask an LLM a question, you usually get free-form text back. That’s great for reading, but terrible for building applications. How do you extract the sentiment? How do you parse the answer? How do you use it in your code?</p>
<p>Free-form text requires parsing, which is error-prone. You might try to extract JSON from the text, or use regex to find patterns, but it’s fragile. The model might format things differently, or include extra text, or miss something you need.</p>
<p>That’s why structured output exists - instead of getting text, you get data structures that are easy to work with programmatically. This is the foundation for building reliable applications.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="structured-output" class="slide level2">
<h2>Structured Output</h2>
<p><strong>Getting data, not text</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode numberSource json number-lines code-with-copy"><code class="sourceCode json"><span id="cb2-1"><a></a><span class="fu">{</span></span>
<span id="cb2-2"><a></a>  <span class="dt">"sentiment"</span><span class="fu">:</span> <span class="st">"positive"</span><span class="fu">,</span></span>
<span id="cb2-3"><a></a>  <span class="dt">"confidence"</span><span class="fu">:</span> <span class="fl">0.85</span><span class="fu">,</span></span>
<span id="cb2-4"><a></a>  <span class="dt">"keywords"</span><span class="fu">:</span> <span class="ot">[</span><span class="st">"happy"</span><span class="ot">,</span> <span class="st">"excited"</span><span class="ot">,</span> <span class="st">"great"</span><span class="ot">]</span></span>
<span id="cb2-5"><a></a><span class="fu">}</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><strong>Easy parsing</strong>: No fragile text extraction</li>
<li><strong>Integration</strong>: Works with databases, APIs, services</li>
</ul>
<aside class="notes">
<p>Structured output means getting responses in a specific format - usually JSON, but it could be XML, CSV, or any other structured format. Instead of parsing text, you’re parsing data structures.</p>
<p>This makes everything easier. You can validate the structure. You can access fields directly. You can type-check the data. You can use it in your application without worrying about parsing errors.</p>
<p>Most modern LLM APIs support structured output through schemas. You define what you want, and the model returns data that matches that schema. It’s like having a contract with the model: “I’ll give you this input, you’ll give me this structure.”</p>
<p>Structured output is the difference between a demo and an application. In a demo, you can manually read the response. In an application, you need to process it automatically.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="schema-example-product-data" class="slide level2 smaller">
<h2>Schema Example: Product Data</h2>
<p><strong>Defining product structure</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode numberSource json number-lines code-with-copy"><code class="sourceCode json"><span id="cb3-1"><a></a><span class="fu">{</span></span>
<span id="cb3-2"><a></a>  <span class="dt">"type"</span><span class="fu">:</span> <span class="st">"object"</span><span class="fu">,</span></span>
<span id="cb3-3"><a></a>  <span class="dt">"properties"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb3-4"><a></a>    <span class="dt">"name"</span><span class="fu">:</span> <span class="fu">{</span> <span class="dt">"type"</span><span class="fu">:</span> <span class="st">"string"</span><span class="fu">,</span> <span class="dt">"description"</span><span class="fu">:</span> <span class="st">"Product name"</span> <span class="fu">},</span></span>
<span id="cb3-5"><a></a>    <span class="dt">"category"</span><span class="fu">:</span> <span class="fu">{</span> <span class="dt">"type"</span><span class="fu">:</span> <span class="st">"string"</span><span class="fu">,</span> <span class="dt">"description"</span><span class="fu">:</span> <span class="st">"Product category"</span> <span class="fu">},</span></span>
<span id="cb3-6"><a></a>    <span class="dt">"price"</span><span class="fu">:</span> <span class="fu">{</span> <span class="dt">"type"</span><span class="fu">:</span> <span class="st">"number"</span><span class="fu">,</span> <span class="dt">"format"</span><span class="fu">:</span> <span class="st">"float"</span><span class="fu">,</span> <span class="dt">"description"</span><span class="fu">:</span> <span class="st">"Product price"</span> <span class="fu">},</span></span>
<span id="cb3-7"><a></a>    <span class="dt">"features"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb3-8"><a></a>      <span class="dt">"type"</span><span class="fu">:</span> <span class="st">"array"</span><span class="fu">,</span></span>
<span id="cb3-9"><a></a>      <span class="dt">"items"</span><span class="fu">:</span> <span class="fu">{</span> <span class="dt">"type"</span><span class="fu">:</span> <span class="st">"string"</span> <span class="fu">},</span></span>
<span id="cb3-10"><a></a>      <span class="dt">"description"</span><span class="fu">:</span> <span class="st">"Key features of the product"</span></span>
<span id="cb3-11"><a></a>    <span class="fu">},</span></span>
<span id="cb3-12"><a></a>    <span class="dt">"release_date"</span><span class="fu">:</span> <span class="fu">{</span> <span class="dt">"type"</span><span class="fu">:</span> <span class="st">"string"</span><span class="fu">,</span> <span class="dt">"format"</span><span class="fu">:</span> <span class="st">"date"</span><span class="fu">,</span> <span class="dt">"description"</span><span class="fu">:</span> <span class="st">"Date the product was released"</span> <span class="fu">}</span></span>
<span id="cb3-13"><a></a>  <span class="fu">}</span></span>
<span id="cb3-14"><a></a><span class="fu">}</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="smaller">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Tip</strong></p>
</div>
<div class="callout-content">
<p><a href="https://json-schema.org/"><strong>JSON Schema</strong></a> is a declarative language for annotating and validating JSON documents’ structure, constraints, and data types. It helps you standardize and define expectations for JSON data.</p>
</div>
</div>
</div>
</div>
<aside class="notes">
<p>Each field has a type and a description. The description helps the model understand what should go in that field.</p>
<p>When you provide this schema to the model along with product data, the model will generate a JSON object that conforms to this structure. This makes it much easier to work with the output programmatically.</p>
<p>The key insight from the whitepaper: by preprocessing your data and instead of providing full documents, only providing both the schema and the data, you give the LLM a clear understanding of the product’s attributes, making it much more likely to generate an accurate and relevant description.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="schema-benefits" class="slide level2 smaller">
<h2>Schema Benefits</h2>
<p><strong>Guiding the model’s attention</strong></p>

<img data-src="../assets/llm-json-schema.png" class="r-stretch quarto-figure-center"><p class="caption">Schema guiding model attention to relevant fields</p><aside class="notes">
<p>The structured input approach, guiding the LLM’s attention to the relevant fields, is especially valuable when working with large volumes of data or when integrating LLMs into complex applications.</p>
<p>Instead of giving the model a full document and asking it to extract information, you’re providing:</p>
<ol type="1">
<li>A schema that defines what you want</li>
<li>The relevant data in a structured format</li>
</ol>
<p>This helps the model focus on the right information and produce consistent outputs. It’s like giving the model a form to fill out rather than asking it to write a free-form essay.</p>
<p>This approach is particularly powerful for:</p>
<ul>
<li>Data extraction tasks</li>
<li>Information retrieval</li>
<li>Form filling</li>
<li>Database operations</li>
<li>API integrations</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="evaluation-why-it-matters" class="slide level2 smaller">
<h2>Evaluation: Why It Matters</h2>
<p><strong>Measuring what works</strong></p>
<ul>
<li>Prompts are experiments</li>
<li>Models can be inconsistent</li>
<li>Production needs reliability</li>
</ul>
<aside class="notes">
<p>Now let’s talk about evaluation. Prompting is experimental - you try something, see if it works, adjust, try again. But how do you know if it actually works? How do you measure improvement?</p>
<p>Evaluation is the answer. It’s how you measure whether your prompts are producing good results. Without evaluation, you’re flying blind. You might think your prompt is great because you saw one good response, but what about edge cases? What about consistency?</p>
<p>Evaluation is especially important for production systems. You can’t deploy something and hope it works. You need to know, with data, that it’s producing good results consistently.</p>
<p>The whitepaper emphasizes that prompt engineering is an iterative process. You craft and test different prompts, analyze, and document the results. You refine your prompt based on the model’s performance. You keep experimenting until you achieve the desired output.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="evaluation-methods-overview" class="slide level2 smaller">
<h2>Evaluation Methods Overview</h2>
<ul>
<li><strong>Automated metrics</strong>: Fast, but task-specific
<ul>
<li>BLEU for <strong>translation</strong></li>
<li>ROUGE for <strong>summarization</strong></li>
<li>BERTScore for <strong>paraphrasing</strong></li>
</ul></li>
<li><strong>Human evaluation</strong>: Gold standard, but expensive and slow</li>
<li><strong>LLM-as-judge</strong>: Scalable, but needs validation</li>
<li><strong>Hybrid</strong>: Combine methods for reliability</li>
</ul>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p><strong>Human evaluation</strong>: At <a href="https://lmarena.ai/leaderboard">LM Arena</a> users are presented with two anonymous models (e.g., Model A vs.&nbsp;Model B), and vote on which answer is better.</p>
</div>
</div>
</div>
<aside class="notes">
<p>Automated metrics are fast and cheap - things like BLEU for translation, ROUGE for summarization. But they’re task-specific and don’t always correlate with human judgment.</p>
<p>There are several ways to actually perform evaluation. Human evaluation is the gold standard - humans are the best judges of quality. But it’s expensive and slow, so it’s not practical for large-scale evaluation.</p>
<p>LLM-as-judge is a newer approach: use an LLM to evaluate other LLM responses. It’s scalable and can be quite good, but you need to validate it against human evaluation to make sure it’s reliable.</p>
<p>The best approach is often hybrid: use automated metrics for quick feedback, LLM-as-judge for scale, and human evaluation for validation and high-stakes decisions.</p>
<p>The key is matching the evaluation method to your needs. For prototyping, maybe LLM-as-judge is enough. For production, you might need human evaluation for critical decisions. For scale, automated metrics might be necessary.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="llm-as-judge" class="slide level2">
<h2>LLM-as-Judge</h2>
<p><strong>Using models to evaluate models</strong></p>
<pre><code>Judge Prompt: "Rate this response on a scale 
of 1-5 for correctness, completeness, and clarity."

Response: [The response to evaluate]
Score: 4/5</code></pre>

<img data-src="../assets/llm_evaluator_3.png" class="r-stretch quarto-figure-center"><p class="caption">LLM-as-judge showing model evaluating model responses</p><aside class="notes">
<p>LLM-as-judge is a powerful technique: you use an LLM to evaluate other LLM responses. You give the judge LLM the original question, the response to evaluate, and evaluation criteria, and it scores the response.</p>
<p>This is scalable - you can evaluate thousands of responses quickly. And it can be quite good, especially for tasks where the evaluation criteria are clear.</p>
<p>But it’s not perfect. The judge LLM can have biases. It might not catch subtle errors. And it needs to be validated against human evaluation to ensure it’s reliable. Still, for many use cases, it’s a great balance between quality and scale.</p>
<p>The key to effective LLM-as-judge is: - Clear evaluation criteria - Good judge prompts - Validation against human evaluation - Understanding the judge’s limitations</p>
<p>Use LLM-as-judge for scale, but always validate with human evaluation for critical decisions.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="pointwise-evaluation" class="slide level2 smaller">
<h2>Pointwise Evaluation</h2>
<p><strong>The simplest form of evaluation</strong></p>
<pre><code>Customer Query: "How do I reset my account password, and will I lose my saved progress in the app?"

LLM A: "To reset your password, click 'Forgot Password' on the login screen. We will send an email to your registered address. Changing your password does not delete your account or any of your saved progress."</code></pre>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p><strong>Evaluation Criteria (LLM B Analysis)</strong>:</p>
<ul>
<li><strong>Correct</strong> ✅ PASS - Factually accurate per Official Documentation (Section 4.2: Password Management). Password resets are strictly credential updates and do not trigger data wipes.</li>
<li><strong>Complete</strong> ✅ PASS - Addresses both parts of the user’s query: 1) The ‘How-to’ instructions for resetting and 2) The specific concern regarding data loss.</li>
<li><strong>Relevant</strong> ✅ PASS - Stays strictly on topic. It provides direct instructions and reassurances without drifting into unrelated features like MFA setup or subscription tiers.</li>
<li><strong>Safe</strong> ✅ PASS - Follows Company Security Guidelines by instructing the user to use the official ‘Forgot Password’ flow rather than asking the user to provide their current credentials in the chat.</li>
</ul>
</div>
</div>
</div>
<aside class="notes">
<p>Pointwise evaluation scores individual responses. You take a response, and you give it a score - usually on a scale from 0 to 1, or as a rating like “good” or “bad.”</p>
<p>This is the simplest form of evaluation. You have a response, you evaluate it, you get a score. It’s straightforward, but it has limitations - a score of 0.8 doesn’t tell you why it’s 0.8, or what would make it better.</p>
<p>Often, you’ll combine multiple criteria into a single score, or keep them separate to understand different aspects of quality. The key is defining what “good” means for your specific use case.</p>
<p>Each of these can be scored separately, or combined into an overall score.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="evaluation-different-ways-to-score" class="slide level2 smaller">
<h2>Evaluation: Different ways to score</h2>

<img data-src="../assets/scoring_dimensions.png" class="r-stretch quarto-figure-center"><p class="caption">Multiple scoring dimensions</p><aside class="notes">
<p>Pointwise evaluation is useful when you have clear criteria. Is the response correct? Is it complete? Is it in the right format? Is it relevant? Does it meet safety guidelines? These are yes/no or numeric questions that you can score.</p>
<p>There are many ways to score a response pointwise. Correctness is the most obvious - is the answer factually correct? But there are other dimensions too.</p>
<ul>
<li><strong>Correctness</strong>: Is the answer factually correct?</li>
<li><strong>Completeness</strong>: Does it cover everything it should?</li>
<li><strong>Format</strong>: Does it match structural requirements?</li>
<li><strong>Relevance</strong>: Is it actually answering the question?</li>
<li><strong>Safety</strong>: Does it meet content guidelines?</li>
</ul>
<p>Completeness asks whether the response covers everything it should. Format checks if the response matches structural requirements. Relevance checks if it’s actually answering the question. Safety checks if it meets content guidelines.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="pairwise-evaluation" class="slide level2 smaller">
<h2>Pairwise Evaluation</h2>
<p><strong>Customer Query</strong>: “I forgot the PIN to my smart-lock at home. My kids are stuck outside in the rain! How do I override the lock, and is there a master code?”</p>
<p><strong>A vs B</strong>:</p>
<p><strong>Response A</strong>: “Oh no! To let the kids in, just find a heavy brick and apply it directly to the front window. It’s the ultimate master code! While you’re at it, did you know that rain is actually just the sky crying? Also, I recommend buying a trampoline. It won’t help with the lock, but it’s fun.”</p>
<p><strong>Response B</strong>: “For security reasons, there is no universal master code for our smart-locks. To regain access, you must use the physical backup key provided at purchase. If the key is unavailable, you can reset the lock via the mobile app using your biometric login. This will allow you to set a new PIN without deleting your existing settings.”</p>
<aside class="notes">
<p>Pairwise evaluation compares two responses and asks: which one is better? Instead of scoring each response independently, you’re making a relative judgment.</p>
<p>Pairwise evaluation shines when you need to make relative comparisons. If you’re trying to decide between two prompts, pairwise evaluation will tell you which one is better more reliably than trying to score each one independently.</p>
<p>It’s also great for ranking. If you generate multiple responses and want to pick the best one, pairwise evaluation can rank them. You compare each pair, and the response that wins more comparisons is ranked higher.</p>
<p>And it’s useful when absolute scores are hard to define. Sometimes it’s easier to say “this is better” than to say “this is 0.85 out of 1.0.” Pairwise evaluation leverages that human intuition.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="best-practices-document-everything" class="slide level2 smaller">
<h2>Best Practices: Document Everything</h2>
<p><strong>Learning from iteration</strong></p>

<img data-src="../assets/prompt_card_template.png" class="r-stretch quarto-figure-center"><p class="caption">Prompt Card Template</p><aside class="notes">
<p>The whitepaper emphasizes the importance of documenting your prompt attempts in full detail so you can learn over time what went well and what did not.</p>
<p>Prompt outputs can differ across models, across sampling settings, and even across different versions of the same model. Moreover, even across identical prompts to the same model, small differences in output sentence formatting and word choice can occur.</p>
<p>We recommend creating a tracking system with fields for:</p>
<ul>
<li><strong>Name and version</strong>: Identify the prompt</li>
<li><strong>Goal</strong>: One sentence explanation of the goal</li>
<li><strong>Model</strong>: Name and version of the used model</li>
<li><strong>Configuration</strong>: Temperature, token limit, top-K, top-P</li>
<li><strong>Prompt</strong>: Write out the full prompt</li>
<li><strong>Output</strong>: Write out the output or multiple outputs</li>
<li><strong>Performance</strong>: OK/NOT OK/SOMETIMES OK</li>
<li><strong>Feedback</strong>: What worked, what didn’t</li>
</ul>
<p>The advantages of this approach are that you have a complete record when you inevitably have to revisit your prompting work - either to pick it up in the future, to test prompt performance on different versions of a model, and to help debug future errors.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="key-takeaways" class="slide level2">
<h2>Key Takeaways</h2>
<p><strong>Measuring success</strong></p>
<ul>
<li><strong>Structured output</strong>: Get data, not text</li>
<li><strong>Evaluation methods</strong>: Choose based on needs</li>
<li><strong>Pointwise evaluation</strong>: Score individual responses</li>
<li><strong>Pairwise evaluation</strong>: Compare responses</li>
<li><strong>Documentation</strong>: Track and learn from iterations</li>
</ul>
<aside class="notes">
<p>Let’s bring it all together. Evaluation and structured output are what turn LLM interactions into reliable applications.</p>
<p>Structured output gives you data you can work with programmatically. Pointwise evaluation tells you if individual responses are good. Pairwise evaluation helps you compare and improve. Different evaluation methods give you different trade-offs between quality, speed, and cost. And documentation helps you learn from your iterations.</p>
<p>The key is matching the approach to your needs. For prototyping, maybe LLM-as-judge is enough. For production, you might need human evaluation for critical decisions. For scale, automated metrics might be necessary.</p>
<p>Together with the prompting techniques from the first session, you now have the foundation for building real AI applications. You can craft effective prompts, get structured outputs, and evaluate whether they’re working. That’s Day 1 complete.</p>
<p>Remember: prompt engineering is an iterative process. Craft and test different prompts, analyze, and document the results. Refine your prompt based on the model’s performance. Keep experimenting until you achieve the desired output. When you change a model or model configuration, go back and keep experimenting with the previously used prompts.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="../../assets/icon.svg" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"},{"title":"Index","icon":"<svg width='1.8rem' viewBox='0 0 24 24'><path d='M5 7h14M5 12h14M5 17h7' stroke='white' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'/></svg>","src":"../index.html"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: false,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: true,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>